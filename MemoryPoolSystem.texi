\input texinfo   @c -*-texinfo-*-
@c %**start of header
@setfilename MemoryPoolSystem.info
@documentencoding UTF-8
@ifinfo
@*Generated by Sphinx 8.1.3.@*
@end ifinfo
@settitle Memory Pool System Documentation
@defindex ge
@paragraphindent 0
@exampleindent 4
@finalout
@dircategory Miscellaneous
@direntry
* MemoryPoolSystem: (MemoryPoolSystem.info). One line description of project.
@end direntry

@c %**end of header

@copying
@quotation
Memory Pool System 1.118.0, Feb 11, 2025

Ravenbrook Limited

Copyright @copyright{} 2025, Ravenbrook Limited
@end quotation

@end copying

@titlepage
@title Memory Pool System Documentation
@insertcopying
@end titlepage
@contents

@c %** start of user preamble

@c %** end of user preamble

@ifnottex
@node Top
@top Memory Pool System Documentation
@insertcopying
@end ifnottex

@c %**start of body
@anchor{index doc}@anchor{0}
@menu
* Guide:: 
* Reference:: 
* Pool reference:: 
* Design:: 
* Old design:: 
* Bibliography:: 
* Memory Management Glossary:: 
* Index to source code:: 
* Memory Pool System Kit Open Source License:: 
* Contact us:: 
* Contributing to the MPS:: 
* Release notes:: 
* Introduction to memory management:: 
* Home:: 
* Frequently Asked Questions:: 
* Copyright:: 
* Acknowledgements:: 
* Index:: 

@detailmenu
 --- The Detailed Node Listing ---

Guide

* Overview of the Memory Pool System:: 
* Building the Memory Pool System:: 
* Garbage collecting a language with the Memory Pool System:: 
* The stretchy vector problem:: 
* Debugging with the Memory Pool System:: 
* Tuning the Memory Pool System for performance:: 
* Advanced topics:: 
* Implementing malloc and free:: 

Overview of the Memory Pool System

* Supported target platforms:: 
* Technical introduction:: 
* What next?:: 

Building the Memory Pool System

* Introduction:: 
* Getting hold of the MPS Kit:: 
* Compiling the MPS for your project:: 
* Building the MPS manual:: 
* Building the MPS for development:: 
* Installing the Memory Pool System:: 

Compiling the MPS for your project

* Compiling for production:: 
* Compiling for debugging:: 
* Optimizing for your object format:: 
* Compiling without the C library:: 

Building the MPS for development

* Prerequisites:: 
* Platforms:: 
* Running make:: 

Installing the Memory Pool System

* mpseventsql:: 

Garbage collecting a language with the Memory Pool System

* The Scheme interpreter:: 
* Choosing an arena class:: 
* Choosing a pool class:: 
* Describing your objects:: 
* Creating the pool:: 
* Roots:: 
* Threads:: 
* Allocation:: 
* Maintaining consistency:: 
* Tidying up:: 
* What next?: What next?<2>. 

Describing your objects

* Alignment:: 
* The scan method:: 
* The skip method:: 
* The forward method:: 
* The is-forwarded method:: 
* The padding method:: 

Debugging with the Memory Pool System

* General debugging advice:: 
* Address space layout randomization:: 
* Example; underscanning: Example underscanning. 
* Example; allocating with wrong size: Example allocating with wrong size. 
* What next?: What next?<3>. 

Advanced topics

* Finalization:: 
* Location dependency:: 
* Weak hash tables:: 
* Global symbol table:: 
* Segregation of objects:: 

Reference

* Interface conventions:: 
* Keyword arguments:: 
* Error handing:: 
* Arenas:: 
* Pools:: 
* Allocation: Allocation<2>. 
* Object formats:: 
* Scanning:: 
* Threads: Threads<2>. 
* Roots: Roots<2>. 
* Garbage collection:: 
* Messages:: 
* Finalization: Finalization<2>. 
* Location dependency: Location dependency<2>. 
* Segregated allocation caches:: 
* Allocation patterns:: 
* Allocation frames:: 
* Debugging pools:: 
* Telemetry:: 
* Weak references:: 
* Transforms:: 
* Plinth:: 
* Platforms: Platforms<2>. 
* Porting the MPS:: 
* Deprecated interfaces:: 
* Security issues:: 

Interface conventions

* Support policy:: 
* Language:: 
* Headers:: 
* Identifiers:: 
* Types:: 
* Functions:: 
* Type punning:: 
* Macros:: 
* General types:: 

Error handing

* Result codes:: 
* Assertions:: 
* Varieties:: 

Assertions

* Assertion handling:: 
* Common assertions and their causes:: 

Arenas

* Client arenas:: 
* Virtual memory arenas:: 
* Arena properties:: 
* Arena states:: 
* Running garbage collections:: 
* Using idle time for collection:: 
* Arena introspection and debugging:: 
* Arena extension callbacks:: 

Pools

* Pool classes:: 
* Pool introspection:: 

Allocation

* Manual allocation:: 
* Allocation points:: 
* Allocation point protocol:: 
* Example; allocating a symbol: Example allocating a symbol. 
* Cautions:: 
* Example; inserting into a doubly linked list: Example inserting into a doubly linked list. 
* Allocation point implementation:: 

Object formats

* Interface:: 
* In-band headers:: 
* Cautions: Cautions<2>. 
* Format methods:: 
* Object format introspection:: 

Scanning

* Scanning protocol:: 
* Tagged references:: 
* Critical path:: 
* Ambiguous references:: 
* Unfixed references:: 
* Example; Scheme objects: Example Scheme objects. 
* Scanning interface:: 
* Fixing interface:: 
* Area scanners:: 

Threads

* Thread safety:: 
* Thread registration:: 
* Signal and exception handling issues:: 
* Fork safety:: 
* Thread interface:: 

Roots

* Registering roots:: 
* Cautions: Cautions<3>. 
* Thread roots:: 
* Ranks:: 
* Root modes:: 
* Root interface:: 
* Root introspection:: 

Garbage collection

* Generation chains:: 
* Scheduling of collections:: 
* Garbage collection start messages:: 
* Garbage collection messages:: 

Messages

* Finalization messages:: 
* Example; interactive chatter: Example interactive chatter. 
* Message types:: 
* Message interface:: 
* Message queue interface:: 

Finalization

* Multiple finalizations:: 
* Cautions: Cautions<4>. 
* Finalization interface:: 
* Finalization messages: Finalization messages<2>. 

Location dependency

* Terminology:: 
* Creating dependencies:: 
* Adding dependencies:: 
* Testing dependencies for staleness:: 
* Thread safety: Thread safety<2>. 
* Location dependency interface:: 

Segregated allocation caches

* Cache interface:: 
* Allocation interface:: 

Allocation patterns

* Ramp allocation:: 

Telemetry

* Telemetry utilities:: 
* Example:: 
* Event categories:: 
* Environment variables:: 
* Decoding the telemetry stream:: 
* Making the telemetry stream readable:: 
* Loading the telemetry stream into SQLite:: 
* Decoding the telemetry stream in Python:: 
* Telemetry events:: 
* Telemetry interface:: 
* Telemetry labels:: 
* Customizing the telemetry system:: 

Transforms

* Cautions: Cautions<5>. 
* Interface: Interface<2>. 

Plinth

* I/O module:: 
* Library module:: 

Platforms

* Platform codes:: 
* Platform interface:: 
* Historical platform codes:: 
* Historical platform list:: 
* Platform limitations:: 

Porting the MPS

* Platform code:: 
* Functional modules:: 
* Platform detection:: 
* Platform configuration:: 
* Module selection:: 
* Makefile:: 
* Porting strategy:: 
* Update the documentation:: 
* Contribute:: 

Deprecated interfaces

* Deprecated in version 1.118: Deprecated in version 1 118. 
* Deprecated in version 1.115: Deprecated in version 1 115. 
* Deprecated in version 1.113: Deprecated in version 1 113. 
* Deprecated in version 1.112: Deprecated in version 1 112. 

Security issues

* Predictable address space layout on FreeBSD:: 
* Address disclosure:: 
* Telemetry: Telemetry<2>. 

Pool reference

* Choosing a pool class: Choosing a pool class<2>. 
* Pool class properties:: 
* Writing a new pool class:: 
* AMC (Automatic Mostly-Copying): AMC Automatic Mostly-Copying. 
* AMCZ (Automatic Mostly-Copying Zero-rank): AMCZ Automatic Mostly-Copying Zero-rank. 
* AMS (Automatic Mark and Sweep): AMS Automatic Mark and Sweep. 
* AWL (Automatic Weak Linked): AWL Automatic Weak Linked. 
* LO (Leaf Object): LO Leaf Object. 
* MFS (Manual Fixed Small): MFS Manual Fixed Small. 
* MVFF (Manual Variable First Fit): MVFF Manual Variable First Fit. 
* MVT (Manual Variable Temporal): MVT Manual Variable Temporal. 
* SNC (Stack No Checking): SNC Stack No Checking. 

Choosing a pool class

* Choosing an automatic pool class:: 
* Choosing a manual pool class:: 

AMC (Automatic Mostly-Copying)

* AMC properties:: 
* AMC interface:: 
* Hash arrays:: 

AMCZ (Automatic Mostly-Copying Zero-rank)

* AMCZ properties:: 
* AMCZ interface:: 

AMS (Automatic Mark and Sweep)

* AMS properties:: 
* AMS interface:: 

AWL (Automatic Weak Linked)

* AWL properties:: 
* Dependent objects:: 
* Protection faults:: 
* Caution:: 
* AWL interface:: 

LO (Leaf Object)

* LO properties:: 
* LO interface:: 

MFS (Manual Fixed Small)

* MFS properties:: 
* MFS interface:: 

MVFF (Manual Variable First Fit)

* MVFF properties:: 
* MVFF interface:: 

MVT (Manual Variable Temporal)

* Temporal fit:: 
* MVT properties:: 
* MVT interface:: 

SNC (Stack No Checking)

* SNC properties:: 
* SNC interface:: 

Design

* Fixed-length queues:: 
* Generic modules:: 
* Bootstrapping:: 
* Coalescing block structures:: 
* Fast high-resolution clock:: 
* MPS Configuration:: 
* The critical path through the MPS:: 
* Documentation:: 
* Execution environment:: 
* Fail-over allocator:: 
* Finalization: Finalization<3>. 
* Free list allocator:: 
* New developer guide:: 
* Transliterating the alphabet into hexadecimal:: 
* C Style – formatting:: 
* C Style – naming:: 
* Review checklist:: 
* C interface design:: 
* Keyword arguments in the MPS:: 
* Lands:: 
* Lock module:: 
* Client message protocol:: 
* Monitor:: 
* Nailboards for ambiguously referenced segments:: 
* Pool classes: Pool classes<2>. 
* Mutator context:: 
* Memory protection:: 
* POSIX implementation of protection module:: 
* Ranges of addresses:: 
* Ring data structure:: 
* Shield:: 
* Signatures in the MPS:: 
* Stack probe:: 
* Splay trees:: 
* Stack and register scanning:: 
* Tests:: 
* Multi-threaded testing:: 
* Thread manager:: 
* Thread safety in the MPS:: 
* Transforms: Transforms<2>. 
* General MPS types:: 
* Library version mechanism:: 
* Virtual mapping:: 
* Walking formatted objects:: 
* Write barrier:: 
* The WriteF function:: 

Fixed-length queues

* Introduction: Introduction<2>. 
* Requirements:: 
* Interface: Interface<3>. 

Generic modules

* Introduction: Introduction<3>. 
* Requirements: Requirements<2>. 
* Design: Design<2>. 
* Modules:: 
* Limitations of generic implementations:: 

Bootstrapping

* Introduction: Introduction<4>. 
* Bootstrapping problems:: 

Bootstrapping problems

* Virtual memory descriptor:: 
* Arena descriptor:: 
* Arena’s free land:: 

Coalescing block structures

* Introduction: Introduction<5>. 
* Requirements: Requirements<3>. 
* Interface: Interface<4>. 
* Implementation:: 
* Testing:: 
* Notes for future development:: 
* Risks:: 

Interface

* External types:: 
* External classes:: 
* Keyword arguments: Keyword arguments<2>. 
* Limitations:: 

Implementation

* Splay tree:: 
* Low memory behaviour:: 
* The CBS block:: 

Fast high-resolution clock

* Introduction: Introduction<6>. 
* Requirements: Requirements<4>. 
* Interface: Interface<5>. 
* Implementation: Implementation<2>. 

MPS Configuration

* Introduction: Introduction<7>. 
* Requirements: Requirements<5>. 
* Definitions:: 
* Overview:: 
* The build system:: 
* Implementation: Implementation<3>. 
* Source code configuration:: 
* Configuration options:: 
* To document:: 
* References:: 

Requirements

* Retired requirements:: 

The build system

* Abstract build function:: 
* File Structure:: 
* Modules and naming:: 
* Build system rationale:: 
* Warnings and errors:: 

Implementation

* Target platform detection:: 
* Target varieties:: 

Source code configuration

* Configuration Parameters:: 
* Abstract and Concrete Module Interfaces:: 

The critical path through the MPS

* Introduction: Introduction<8>. 
* What makes the critical path critical:: 
* How the MPS avoids scanning and fixing:: 
* Where to find the critical path:: 
* The format scanner:: 
* The second stage fix in the MPM:: 
* The third stage fix in the segment class:: 
* Other considerations:: 
* References: References<2>. 

Documentation

* Introduction: Introduction<9>. 
* Types: Types<2>. 
* Requirements: Requirements<6>. 
* Implementation: Implementation<4>. 
* Manual extensions:: 
* Design formatting conventions:: 
* References: References<3>. 

Execution environment

* Introduction: Introduction<10>. 
* Discussion:: 
* Interpretation:: 
* Requirements: Requirements<7>. 
* Architecture:: 

Fail-over allocator

* Introduction: Introduction<11>. 
* Interface: Interface<6>. 
* Implementation: Implementation<5>. 

Interface

* Types: Types<3>. 
* Classes:: 
* Keyword arguments: Keyword arguments<3>. 

Finalization

* Overview: Overview<2>. 
* Requirements: Requirements<8>. 
* Implementation: Implementation<6>. 
* External interface:: 
* Internal interface:: 

Free list allocator

* Introduction: Introduction<12>. 
* Overview: Overview<3>. 
* Requirements: Requirements<9>. 
* Interface: Interface<7>. 
* Implementation: Implementation<7>. 
* Testing: Testing<2>. 
* Opportunities for improvement:: 

Interface

* Types: Types<4>. 
* Classes: Classes<2>. 
* Keyword arguments: Keyword arguments<4>. 

New developer guide

* Introduction: Introduction<13>. 
* What to read first:: 
* References: References<4>. 

Transliterating the alphabet into hexadecimal

* Introduction: Introduction<14>. 
* Transliteration:: 
* Justification:: 
* Notes:: 
* References: References<5>. 

C Style – formatting

* Introduction: Introduction<15>. 
* General formatting conventions:: 

General formatting conventions

* Line width:: 
* White space:: 
* Sections and paragraphs:: 
* Statements:: 
* Indentation:: 
* Positioning of braces:: 
* Switch statements:: 
* Comments:: 
* Macros: Macros<2>. 

C Style – naming

* Introduction: Introduction<16>. 
* Capitalization:: 
* Prefixes:: 
* Suffixes:: 

Review checklist

* Introduction: Introduction<17>. 
* Checklist:: 

C interface design

* Introduction: Introduction<18>. 
* Analysis:: 
* Architecture: Architecture<2>. 
* Naming conventions:: 
* Type conventions:: 
* Checking:: 
* Binary compatibility issues:: 
* Constraints:: 
* Implementation: Implementation<8>. 
* Notes: Notes<2>. 

Analysis

* Goals:: 
* Requirements: Requirements<10>. 

Keyword arguments in the MPS

* Introduction: Introduction<19>. 
* Overview: Overview<4>. 
* Internals:: 
* The varargs legacy:: 
* References: References<6>. 

Lands

* Introduction: Introduction<20>. 
* Definitions: Definitions<2>. 
* Requirements: Requirements<11>. 
* Interface: Interface<8>. 
* Implementations:: 
* Testing: Testing<3>. 

Interface

* Types: Types<5>. 
* Generic functions:: 

Lock module

* Introduction: Introduction<21>. 
* Background:: 
* Requirements: Requirements<12>. 
* Interface: Interface<9>. 
* Implementation: Implementation<9>. 
* Example: Example<2>. 
* References: References<7>. 

Client message protocol

* Introduction: Introduction<22>. 
* Requirements: Requirements<13>. 
* Design: Design<3>. 
* External interface: External interface<2>. 
* Internal interface: Internal interface<2>. 
* Message life cycle:: 
* References: References<8>. 

External interface

* Functions: Functions<2>. 
* Types of messages:: 

Internal interface

* Types: Types<6>. 
* Functions: Functions<3>. 

Monitor

* Introduction: Introduction<23>. 
* Requirements: Requirements<14>. 
* Installation and usage:: 
* References: References<9>. 

Nailboards for ambiguously referenced segments

* Introduction: Introduction<24>. 
* Requirements: Requirements<15>. 
* Implementation: Implementation<10>. 
* Future:: 
* References: References<10>. 

Pool classes

* Introduction: Introduction<25>. 
* Classes and structures:: 
* Fields:: 
* Methods:: 

Mutator context

* Introduction: Introduction<26>. 
* Requirements: Requirements<16>. 
* Interface: Interface<10>. 
* Implementations: Implementations<2>. 

Implementations

* Generic implementation:: 
* Posix implementation:: 
* Windows implementation:: 
* macOS implementation:: 

Memory protection

* Introduction: Introduction<27>. 
* Requirements: Requirements<17>. 
* Design: Design<4>. 
* Interface: Interface<11>. 
* Implementations: Implementations<3>. 

POSIX implementation of protection module

* Introduction: Introduction<28>. 
* Requirements: Requirements<18>. 
* Data structures:: 
* Functions: Functions<4>. 
* Threads: Threads<3>. 

Ranges of addresses

* Introduction: Introduction<29>. 
* Requirements: Requirements<19>. 
* Interface: Interface<12>. 

Ring data structure

* Introduction: Introduction<30>. 
* Description:: 
* Interface: Interface<13>. 
* Naming:: 
* Deques:: 
* Defects:: 

Interface

* Init / Finish:: 
* Checking: Checking<2>. 
* Iteration:: 
* Element access:: 
* Append / Remove:: 

Shield

* Introduction: Introduction<31>. 
* Overview: Overview<5>. 
* Interface: Interface<14>. 
* Mechanism:: 
* Implementation: Implementation<11>. 
* Initial ideas:: 
* Improvement Ideas:: 
* References: References<11>. 

Interface

* Mutator access:: 
* Entering the shield:: 
* Collector access to segments:: 
* Collector access to the unprotectable:: 

Implementation

* Definitions: Definitions<3>. 
* Properties:: 
* Invariants:: 
* Proof Hints:: 

Improvement Ideas

* Mass exposure:: 
* Segment independence:: 
* Concurrent collection:: 
* Early Resume:: 
* Expose modes:: 

Signatures in the MPS

* Introduction: Introduction<32>. 
* Overview: Overview<6>. 
* Definitions: Definitions<4>. 
* Init and Finish:: 
* Checking: Checking<3>. 
* Rules:: 
* Tools:: 
* References: References<12>. 

Stack probe

* Introduction: Introduction<33>. 
* Requirements: Requirements<20>. 
* Design: Design<5>. 
* Interface: Interface<15>. 
* Issues:: 
* Implementations: Implementations<4>. 

Splay trees

* Introduction: Introduction<34>. 
* Overview: Overview<7>. 
* Definitions: Definitions<5>. 
* Requirements: Requirements<21>. 
* Generic binary tree interface:: 
* Splay tree interface:: 
* Client-determined properties:: 
* Usage:: 
* Implementation: Implementation<12>. 
* Testing: Testing<4>. 
* Error Handling:: 
* Future: Future<2>. 
* References: References<13>. 

Generic binary tree interface

* Types: Types<7>. 
* Functions: Functions<5>. 

Splay tree interface

* Types: Types<8>. 
* Functions: Functions<6>. 

Implementation

* Top-down splaying:: 
* Top-level operations:: 

Stack and register scanning

* Introduction: Introduction<35>. 
* Requirements: Requirements<22>. 
* Design: Design<6>. 
* Analysis: Analysis<2>. 
* Interface: Interface<16>. 
* Implementations: Implementations<5>. 
* References: References<14>. 

Tests

* Introduction: Introduction<36>. 
* Running tests:: 
* Test targets:: 
* Test features:: 
* Test list:: 
* Test database:: 
* Test runner:: 
* Performance test:: 
* Adding a new test:: 
* Continuous integration:: 
* MMQA tests:: 
* Other tests:: 
* References: References<15>. 

Multi-threaded testing

* Introduction: Introduction<37>. 
* Requirements: Requirements<23>. 
* Implementation: Implementation<13>. 
* Interface: Interface<17>. 
* References: References<16>. 

Thread manager

* Introduction: Introduction<38>. 
* Requirements: Requirements<24>. 
* Design: Design<7>. 
* Interface: Interface<18>. 
* Implementations: Implementations<6>. 

Implementations

* Generic implementation: Generic implementation<2>. 
* POSIX threads implementation:: 
* Windows implementation: Windows implementation<2>. 
* macOS implementation: macOS implementation<2>. 

Thread safety in the MPS

* Introduction: Introduction<39>. 
* Requirements: Requirements<25>. 
* Analysis: Analysis<3>. 
* Design: Design<8>. 
* Fork safety: Fork safety<3>. 

Analysis

* Performance cost of locking:: 
* Recursive vs binary locks:: 
* Fork safety: Fork safety<2>. 

Transforms

* Introduction: Introduction<40>. 
* Background: Background<2>. 
* Overview: Overview<8>. 
* Not yet written:: 
* References: References<17>. 

General MPS types

* Introduction: Introduction<41>. 
* Rationale:: 
* Concrete types:: 
* Abstract types:: 

Library version mechanism

* Introduction: Introduction<42>. 
* Readership:: 
* Source:: 
* Overview: Overview<9>. 
* Architecture: Architecture<3>. 
* Implementation: Implementation<14>. 

Virtual mapping

* Introduction: Introduction<43>. 
* Requirements: Requirements<26>. 
* Design: Design<9>. 
* Interface: Interface<19>. 
* Implementations: Implementations<7>. 
* Testing: Testing<5>. 

Implementations

* Generic implementation: Generic implementation<3>. 
* Unix implementation:: 
* Windows implementation: Windows implementation<3>. 

Walking formatted objects

* Introduction: Introduction<44>. 
* Use cases:: 
* Requirements: Requirements<27>. 
* Design: Design<10>. 
* References: References<18>. 

Write barrier

* Introduction: Introduction<45>. 
* Overview: Overview<10>. 
* Write Barrier Processes:: 
* Write barrier deferral:: 
* Improvements:: 
* References: References<19>. 

The WriteF function

* Introduction: Introduction<46>. 
* Design: Design<11>. 
* References: References<20>. 

Old design

* Allocation frame protocol:: 
* Arena:: 
* Virtual Memory Arena:: 
* Bit tables:: 
* Allocation buffers and allocation points:: 
* Checking: Checking<4>. 
* Collection framework:: 
* Diagnostic feedback:: 
* The generic fix function:: 
* I/O subsystem:: 
* Library interface:: 
* Locus manager:: 
* GC messages:: 
* Debugging features for client objects:: 
* AMC pool class:: 
* AMS pool class:: 
* AWL pool class:: 
* LO pool class:: 
* MFS pool class:: 
* MRG pool class:: 
* Manual Variable Temporal (MVT) pool design: Manual Variable Temporal MVT pool design. 
* MVFF pool class:: 
* Protocol inheritance:: 
* POSIX thread extensions:: 
* Root manager:: 
* The generic scanner:: 
* Segment data structure:: 
* MPS Strategy:: 
* Telemetry: Telemetry<3>. 
* Tracer:: 

Allocation frame protocol

* Introduction: Introduction<47>. 
* Definitions: Definitions<6>. 
* Purpose:: 
* Requirements: Requirements<28>. 
* Overview: Overview<11>. 
* Operations:: 
* Interface: Interface<20>. 
* Lightweight frames:: 

Requirements

* Known requirements:: 
* Proto-requirements:: 

Interface

* External types: External types<2>. 
* External functions:: 
* Internal types:: 

Lightweight frames

* Overview: Overview<12>. 
* Synchronization:: 
* Implementation: Implementation<15>. 

Arena

* Introduction: Introduction<48>. 
* Overview: Overview<13>. 
* Definitions: Definitions<7>. 
* Requirements: Requirements<29>. 
* Architecture: Architecture<4>. 
* Implementation: Implementation<16>. 

Requirements

* Block management:: 
* Address translation:: 
* Arena partition:: 
* Constraints: Constraints<2>. 

Architecture

* Statics:: 
* Arena classes:: 
* Chunks:: 
* Tracts:: 
* Control pool:: 
* Polling:: 
* Commit limit:: 
* Spare committed (aka “hysteresis”): Spare committed aka “hysteresis”. 
* Pause time control:: 
* Locks:: 
* Location dependencies:: 
* Finalization: Finalization<4>. 

Implementation

* Tract cache:: 
* Control pool: Control pool<2>. 
* Traces:: 
* Polling: Polling<2>. 
* Location dependencies: Location dependencies<2>. 
* Roots: Roots<3>. 

Virtual Memory Arena

* Introduction: Introduction<49>. 
* Overview: Overview<14>. 
* Notes: Notes<3>. 
* Requirements: Requirements<30>. 
* Architecture: Architecture<5>. 
* Solution ideas:: 
* Data structures: Data structures<2>. 
* Notes: Notes<4>. 

Requirements

* Placement:: 
* Arena partition: Arena partition<2>. 

Bit tables

* Introduction: Introduction<50>. 
* Definitions: Definitions<8>. 
* Requirements: Requirements<31>. 
* Non requirements:: 
* Background: Background<3>. 
* Clients:: 
* Overview: Overview<15>. 
* Interface: Interface<21>. 
* Detailed design:: 
* Testing: Testing<6>. 
* References: References<21>. 

Detailed design

* Data structures: Data structures<3>. 
* Functions: Functions<7>. 

Allocation buffers and allocation points

* Introduction: Introduction<51>. 
* Glossary:: 
* Source: Source<2>. 
* Requirements: Requirements<32>. 
* Classes: Classes<3>. 
* Logging:: 
* Measurement:: 
* Notes from the whiteboard:: 
* Synchronization: Synchronization<2>. 
* Interface: Interface<22>. 
* Diagrams:: 

Checking

* Introduction: Introduction<52>. 
* Implementation: Implementation<17>. 
* Common assertions:: 

Collection framework

* Introduction: Introduction<53>. 
* Overview: Overview<16>. 
* Collection abstractions:: 
* The tracer:: 
* Barriers:: 

Collection abstractions

* Colours@comma{} scanning and fixing: Colours scanning and fixing. 
* Reference sets:: 

The tracer

* The condemn phase:: 
* The grey mutator phase:: 
* The flip phase:: 
* The black mutator phase:: 
* The reclaim phase:: 

Barriers

* Hardware barriers:: 
* Software barriers:: 

Diagnostic feedback

* Introduction: Introduction<54>. 
* Overview: Overview<17>. 
* Requirements: Requirements<33>. 
* Usage: Usage<2>. 
* How to write a diagnostic:: 
* How the MPS diagnostic system works:: 
* References: References<22>. 

How to write a diagnostic

* Compile away in non-diag varieties; no side effects:: 
* Writing good paragraph text:: 

How the MPS diagnostic system works

* Parts of the MPS diagnostic system:: 
* Statistics:: 
* Related systems:: 

The generic fix function

* Introduction: Introduction<55>. 
* Was-marked protocol:: 
* Implementation: Implementation<18>. 

I/O subsystem

* Introduction: Introduction<56>. 
* Background: Background<4>. 
* Purpose: Purpose<2>. 
* Requirements: Requirements<34>. 
* Architecture: Architecture<6>. 
* Interface: Interface<23>. 
* I/O module implementations:: 
* Notes: Notes<5>. 
* Attachments:: 

Requirements

* General:: 
* Functional:: 

Architecture

* Example configurations:: 

Interface

* I/O module state:: 
* Message types: Message types<2>. 
* Limits:: 
* Interface set-up and tear-down:: 
* Message send and receive:: 

I/O module implementations

* Routeing:: 

Library interface

* Introduction: Introduction<57>. 
* Goals: Goals<2>. 
* Description: Description<2>. 
* Implementation: Implementation<19>. 

Description

* Overview: Overview<18>. 

Locus manager

* Introduction: Introduction<58>. 
* Overview: Overview<19>. 
* Definitions: Definitions<9>. 
* Requirements: Requirements<35>. 
* Analysis: Analysis<4>. 
* Interface: Interface<24>. 
* Architecture: Architecture<7>. 
* Implementation: Implementation<20>. 
* Notes: Notes<6>. 

Overview

* Why is it important to manage address space?:: 
* Discovering the layout:: 

Interface

* Loci:: 
* Peaks:: 

Architecture

* Data objects:: 
* Overview of strategy:: 
* Allocation: Allocation<3>. 
* Deallocation:: 
* Region placement recomputation:: 

GC messages

* Introduction: Introduction<59>. 
* Overview: Overview<20>. 
* Introduction: Introduction<60>. 
* Purpose: Purpose<3>. 
* Names and parts:: 
* Lifecycle:: 
* Testing: Testing<7>. 

Lifecycle

* Requirements: Requirements<36>. 
* Storage:: 
* Creating and Posting:: 
* Getting and discarding:: 
* Final clearup:: 

Testing

* Coverage:: 

Debugging features for client objects

* Introduction: Introduction<61>. 
* Overview: Overview<21>. 
* Requirements: Requirements<37>. 
* Solution ideas: Solution ideas<2>. 
* Architecture: Architecture<8>. 
* Client interface:: 
* Examples:: 
* Implementation: Implementation<21>. 

AMC pool class

* Guide Introduction:: 
* Guide: Guide<2>. 
* Initial design:: 

Guide

* Segment states:: 
* Pads:: 
* Placement pads are okay:: 
* Retained pads could be a problem:: 
* Small@comma{} medium@comma{} and large segments: Small medium and large segments. 
* The LSP payoff calculation:: 
* Retained pages:: 
* Feedback about retained pages:: 

Initial design

* Introduction: Introduction<62>. 
* Overview: Overview<22>. 
* Definitions: Definitions<10>. 
* Segments:: 
* Fixing and nailing:: 
* Emergency tracing:: 
* Buffers:: 
* Types: Types<9>. 
* Generations:: 
* Ramps:: 
* Headers: Headers<2>. 
* Old and aging notes below here:: 

AMS pool class

* Introduction: Introduction<63>. 
* Overview: Overview<23>. 
* Requirements: Requirements<38>. 
* Architecture: Architecture<9>. 
* Implementation: Implementation<22>. 
* Testing: Testing<8>. 
* Notes: Notes<7>. 

Architecture

* Subclassing:: 
* Allocation: Allocation<4>. 
* Colours:: 
* Scanning: Scanning<2>. 

Implementation

* Colour:: 
* Iteration: Iteration<2>. 
* Scanning Algorithm:: 
* Allocation: Allocation<5>. 
* Initialization:: 
* Condemnation:: 
* Reclaim:: 
* Segment merging and splitting:: 

AWL pool class

* Introduction: Introduction<64>. 
* Requirements: Requirements<39>. 
* Definitions: Definitions<11>. 
* Overview: Overview<24>. 
* Interface: Interface<25>. 
* Data structures: Data structures<4>. 
* Functions: Functions<8>. 
* Test:: 

Functions

* External:: 
* Internal:: 

LO pool class

* Introduction: Introduction<65>. 
* Definitions: Definitions<12>. 
* Requirements: Requirements<40>. 
* Overview: Overview<25>. 
* Interface: Interface<26>. 
* Data structures: Data structures<5>. 
* Functions: Functions<9>. 
* Attachment:: 

Functions

* External: External<2>. 
* Internal: Internal<2>. 

MFS pool class

* Overview: Overview<26>. 
* Implementation: Implementation<23>. 

MRG pool class

* Introduction: Introduction<66>. 
* Goals: Goals<3>. 
* Requirements: Requirements<41>. 
* Terminology: Terminology<2>. 
* Overview: Overview<27>. 
* Protocols:: 
* Data structures: Data structures<6>. 
* Functions: Functions<10>. 
* Transgressions:: 
* Future: Future<3>. 
* Tests: Tests<2>. 
* Notes: Notes<8>. 

Protocols

* Object Registration:: 
* Finalizer execution:: 
* Setup / destroy:: 

Tests

* Functionality:: 
* Attributes:: 
* Implementation: Implementation<24>. 

Manual Variable Temporal (MVT) pool design

* Introduction: Introduction<67>. 
* Definitions: Definitions<13>. 
* Abbreviations:: 
* Overview: Overview<28>. 
* Requirements: Requirements<42>. 
* Architecture: Architecture<10>. 
* Analysis: Analysis<5>. 
* Ideas:: 
* Implementation: Implementation<25>. 
* Testing: Testing<9>. 
* Text:: 

Requirements

* Critical requirements:: 
* Essential requirements:: 
* Nice requirements:: 

Ideas

* Strategy:: 
* Policy:: 
* Mechanism: Mechanism<2>. 

Implementation

* Splay Tree:: 
* Coalescing Block Structure:: 
* Fail-over to address-ordered free list:: 
* Available Block Queue:: 
* Pool implementation:: 
* AP Dispatch:: 

MVFF pool class

* Introduction: Introduction<68>. 
* Overview: Overview<29>. 
* Methods: Methods<2>. 
* Implementation: Implementation<26>. 
* Details:: 

Protocol inheritance

* Introduction: Introduction<69>. 
* Purpose: Purpose<4>. 
* Requirements: Requirements<43>. 
* Overview: Overview<30>. 
* Interface: Interface<27>. 
* Implementation: Implementation<27>. 
* Common instance methods:: 
* References: References<23>. 

Interface

* Class declaration:: 
* Class definition:: 
* Class access:: 
* Single inheritance:: 
* Specialization:: 
* Extension:: 
* Methods: Methods<3>. 
* Conversion:: 
* Introspection:: 
* Protocol guidelines:: 
* Example: Example<3>. 

POSIX thread extensions

* Introduction: Introduction<70>. 
* Definitions: Definitions<14>. 
* Requirements: Requirements<44>. 
* Analysis: Analysis<6>. 
* Interface: Interface<28>. 
* Implementation: Implementation<28>. 
* Attachments: Attachments<2>. 
* References: References<24>. 

Root manager

* Basics:: 
* Details: Details<2>. 

Details

* Creation:: 
* Destruction:: 
* Invariants: Invariants<2>. 
* Scanning: Scanning<3>. 

The generic scanner

* Summaries:: 

Summaries

* Scanned summary:: 
* Partial scans:: 

Segment data structure

* Introduction: Introduction<71>. 
* Overview: Overview<31>. 
* Data Structure:: 
* Interface: Interface<29>. 
* Extensibility:: 

Interface

* Splitting and merging:: 

Extensibility

* Allocation: Allocation<6>. 
* Garbage collection: Garbage collection<2>. 
* Splitting and merging: Splitting and merging<2>. 

MPS Strategy

* Introduction: Introduction<72>. 
* Overview: Overview<32>. 
* Requirements: Requirements<45>. 
* Generations: Generations<2>. 
* Policy: Policy<2>. 
* References: References<25>. 

Generations

* General data structures:: 
* AMC data structures:: 
* Collections:: 
* Zones:: 
* Parameters:: 
* Accounting:: 
* Ramps: Ramps<2>. 

Policy

* Assignment of zones:: 
* Deciding whether to collect the world:: 
* Starting a trace:: 
* Trace progress:: 

Telemetry

* Introduction: Introduction<73>. 
* Overview: Overview<33>. 
* Requirements: Requirements<46>. 
* Architecture: Architecture<11>. 
* Analysis: Analysis<7>. 
* Ideas: Ideas<2>. 
* Implementation: Implementation<29>. 

Implementation

* Annotation:: 
* Registration:: 
* Control:: 
* Debugging:: 
* Dumper tool:: 
* Allocation replayer tool:: 

Tracer

* Introduction: Introduction<74>. 
* Architecture: Architecture<12>. 
* Analysis: Analysis<8>. 
* Ideas: Ideas<3>. 
* Implementation: Implementation<30>. 
* Life cycle of a trace object:: 
* References: References<26>. 

Implementation

* Speed:: 

Life cycle of a trace object

* Making progress; scanning grey segments: Making progress scanning grey segments. 

Memory Management Glossary

* Memory Management Glossary; A: Memory Management Glossary A. 
* Memory Management Glossary; B: Memory Management Glossary B. 
* Memory Management Glossary; C: Memory Management Glossary C. 
* Memory Management Glossary; D: Memory Management Glossary D. 
* Memory Management Glossary; E: Memory Management Glossary E. 
* Memory Management Glossary; F: Memory Management Glossary F. 
* Memory Management Glossary; G: Memory Management Glossary G. 
* Memory Management Glossary; H: Memory Management Glossary H. 
* Memory Management Glossary; I: Memory Management Glossary I. 
* Memory Management Glossary; K: Memory Management Glossary K. 
* Memory Management Glossary; L: Memory Management Glossary L. 
* Memory Management Glossary; M: Memory Management Glossary M. 
* Memory Management Glossary; N: Memory Management Glossary N. 
* Memory Management Glossary; O: Memory Management Glossary O. 
* Memory Management Glossary; P: Memory Management Glossary P. 
* Memory Management Glossary; Q: Memory Management Glossary Q. 
* Memory Management Glossary; R: Memory Management Glossary R. 
* Memory Management Glossary; S: Memory Management Glossary S. 
* Memory Management Glossary; T: Memory Management Glossary T. 
* Memory Management Glossary; U: Memory Management Glossary U. 
* Memory Management Glossary; V: Memory Management Glossary V. 
* Memory Management Glossary; W: Memory Management Glossary W. 
* Memory Management Glossary; Z: Memory Management Glossary Z. 
* All:: 

Index to source code

* External MPS interface:: 
* Plinth: Plinth<2>. 
* Configuration:: 
* Core MPS:: 
* Platform interfaces:: 
* Pool classes: Pool classes<3>. 
* Auxiliary programs:: 
* Benchmarks:: 
* Test support:: 
* Interactive test cases:: 
* Automated test cases:: 
* Build infrastructure:: 

Memory Pool System Kit Open Source License

* License:: 

Contributing to the MPS

* Review:: 
* Licensing:: 
* Thank you:: 

Release notes

* Release 1.118.0: Release 1 118 0. 
* Release 1.117.0: Release 1 117 0. 
* Release 1.116.0: Release 1 116 0. 
* Release 1.115.0: Release 1 115 0. 
* Release 1.114.0: Release 1 114 0. 
* Release 1.113.0: Release 1 113 0. 
* Release 1.112.0: Release 1 112 0. 
* Release 1.111.0: Release 1 111 0. 
* Release 1.110.0: Release 1 110 0. 

Release 1.118.0

* New features:: 
* Interface changes:: 
* Other changes:: 

Release 1.117.0

* New features: New features<2>. 
* Interface changes: Interface changes<2>. 
* Other changes: Other changes<2>. 

Release 1.116.0

* New features: New features<3>. 
* Interface changes: Interface changes<3>. 
* Other changes: Other changes<3>. 

Release 1.115.0

* New features: New features<4>. 
* Interface changes: Interface changes<4>. 
* Other changes: Other changes<4>. 

Release 1.114.0

* New features: New features<5>. 
* Interface changes: Interface changes<5>. 
* Other changes: Other changes<5>. 

Release 1.113.0

* New features: New features<6>. 
* Interface changes: Interface changes<6>. 
* Other changes: Other changes<6>. 

Release 1.112.0

* New features: New features<7>. 
* Interface changes: Interface changes<7>. 
* Other changes: Other changes<7>. 

Release 1.111.0

* New features: New features<8>. 
* Interface changes: Interface changes<8>. 
* Other changes: Other changes<8>. 

Release 1.110.0

* New features: New features<9>. 
* Interface changes: Interface changes<9>. 

Introduction to memory management

* Overview: Overview<34>. 
* Allocation techniques:: 
* Recycling techniques:: 
* Memory management in various languages:: 

Overview

* Hardware memory management:: 
* Operating system memory management:: 
* Application memory management:: 
* Memory management problems:: 
* Manual memory management:: 
* Automatic memory management:: 
* More information:: 

Allocation techniques

* First fit:: 
* Buddy system:: 
* Suballocators:: 

Recycling techniques

* Tracing collectors:: 
* Reference counts:: 

Tracing collectors

* Mark-sweep collection:: 
* Copying collection:: 
* Incremental collection:: 
* Conservative garbage collection:: 

Reference counts

* Simple reference counting:: 
* Deferred reference counting:: 
* One-bit reference counting:: 
* Weighted reference counting:: 

Frequently Asked Questions

* C-specific questions:: 
* C++-specific questions:: 
* Common objections to garbage collection:: 
* Miscellaneous:: 

C-specific questions

* Can I use garbage collection in C?:: 
* Why do I need to test the return value from malloc? Surely it always succeeds?:: 
* What’s the point of having a garbage collector? Why not use malloc and free?:: 
* What’s wrong with ANSI malloc in the C library?:: 

C++-specific questions

* Can I use garbage collection in C++?:: 
* Why is delete so slow?:: 
* What happens if you use class libraries that leak memory?:: 
* Can’t I get all the benefits of garbage collection using C++ constructors and destructors?:: 

Common objections to garbage collection

* What languages use garbage collection?:: 
* What’s the advantage of garbage collection?:: 
* Programs with GC are huge and bloated; GC isn’t suitable for small programs or systems:: 
* I can’t use GC because I can’t afford to have my program pause:: 
* Isn’t it much cheaper to use reference counts rather than garbage collection?:: 
* Isn’t GC unreliable? I’ve heard that GCs often kill the program:: 
* I’ve heard that GC uses twice as much memory:: 
* Doesn’t garbage collection make programs slow?:: 
* Manual memory management gives me control—it doesn’t pause:: 

Miscellaneous

* Why does my disk rattle so much?:: 
* Where can I find out more about garbage collection?:: 
* Where can I get a garbage collector?:: 
* Why does my program use so much memory?:: 
* I use a library@comma{} and my program grows every time I call it. Why?: I use a library and my program grows every time I call it Why?. 
* Should I write my own memory allocator to make my program fast?:: 
* Why can’t I just use local data on the stack or in global variables?:: 
* Why should I worry about virtual memory? Can’t I just use as much memory as I want?:: 

@end detailmenu
@end menu

@node Guide,Reference,Top,Top
@anchor{guide/index doc}@anchor{1}@anchor{guide/index contents}@anchor{2}@anchor{guide/index guide}@anchor{3}@anchor{guide/index id1}@anchor{4}
@chapter Guide


@geindex Memory Pool System; overview
@geindex Ravenbrook Limited
@geindex license; commercial terms

@menu
* Overview of the Memory Pool System:: 
* Building the Memory Pool System:: 
* Garbage collecting a language with the Memory Pool System:: 
* The stretchy vector problem:: 
* Debugging with the Memory Pool System:: 
* Tuning the Memory Pool System for performance:: 
* Advanced topics:: 
* Implementing malloc and free:: 

@end menu

@node Overview of the Memory Pool System,Building the Memory Pool System,,Guide
@anchor{guide/overview doc}@anchor{5}@anchor{guide/overview guide-overview}@anchor{6}@anchor{guide/overview overview-of-the-memory-pool-system}@anchor{7}
@section Overview of the Memory Pool System


@c IMPORTANT: If you change the paragraph below, also change
@c readme.txt

The Memory Pool System is a very general, adaptable, flexible,
reliable, and efficient memory management system. It permits the
flexible combination of memory management techniques, supporting
@ref{8,,manual} and @ref{9,,automatic memory management}, @ref{a,,inline allocation},
@ref{b,,finalization}, @ref{c,,weakness}, and
multiple concurrent co-operating @ref{d,,incremental} @ref{e,,generational} @ref{f,,garbage collections}. It also
includes a library of @ref{10,,memory pool classes}
implementing specialized memory management policies.

The MPS has been in development since 1994 and deployed in successful
commercial products since 1997. Bugs are almost unknown in production.
It is under continuous development and support by Ravenbrook@footnote{https://www.ravenbrook.com/}.

The MPS is distributed under the BSD 2-clause @ref{11,,open source license}.

@c comment: Keep this section synchronized with readme.txt

@geindex Memory Pool System; supported target platforms
@geindex platforms; supported

@menu
* Supported target platforms:: 
* Technical introduction:: 
* What next?:: 

@end menu

@node Supported target platforms,Technical introduction,,Overview of the Memory Pool System
@anchor{guide/overview guide-overview-platforms}@anchor{12}@anchor{guide/overview supported-target-platforms}@anchor{13}
@subsection Supported target platforms


The MPS is currently supported for deployment on:


@itemize -

@item 
Windows Vista or later, on IA-32 and x86-64, using Microsoft Visual
C/C++;

@item 
Linux 2.6 or later, on IA-32 using GCC and on x86-64 or ARM64 using
GCC or Clang/LLVM;

@item 
FreeBSD 7 or later, on IA-32 and x86-64, using GCC or Clang/LLVM;

@item 
macOS 10.4 or later, on x86-64 or ARM64, using Clang/LLVM.
@end itemize

The MPS is highly portable and has run on many other processors and
operating systems in the past (see @ref{14,,Building the Memory Pool System}). Most of the
MPS is written in very pure ANSI C and compiles without warnings on
anything.

@cartouche
@quotation Warning 
If you are running a multi-threaded 32-bit application on 64-bit
Windows 7 via the WOW64 emulator, then you must install this hotfix from Microsoft@footnote{https://support.microsoft.com/kb/2864432/en-us}. See WOW64 bug: GetThreadContext() may return stale contents@footnote{https://zachsaw.blogspot.com/2010/11/wow64-bug-getthreadcontext-may-return.html}
for a description of the problem.
@end quotation
@end cartouche

@geindex Memory Pool System; technical introduction

@node Technical introduction,What next?,Supported target platforms,Overview of the Memory Pool System
@anchor{guide/overview technical-introduction}@anchor{15}
@subsection Technical introduction


The figure below gives a simplified picture of a program’s memory from
the point of view of the Memory Pool System.


@float Figure

@image{MemoryPoolSystem-figures/overview,,,Diagram: Overview of the Memory Pool System.,svg}

@caption{Overview of the Memory Pool System.}

@end float


The `arena' is the top-level data structure in the MPS. An
@ref{16,,arena} is responsible for requesting @ref{17,,memory (3)} from
the operating system (and returning it), for making memory available
to @ref{18,,pools}, and for @ref{f,,garbage collection}. Multiple
arenas are supported, but it’s usually best to have only one arena in
your program, because the MPS can’t collect cyclic structures that
span multiple arenas. See @ref{19,,Arenas}.

The MPS is designed to co-operate with other memory managers (for
example @ref{1a,,malloc} and @ref{1b,,free (2)} in @ref{1c,,C}, or operators
@code{new} and @code{delete} in @ref{1d,,C++}), so you need not move all your
memory management to the MPS at once, and you can co-operate with
libraries that use other allocation mechanisms.

Within the arena you create one or more `pools'. A @ref{18,,pool} is
responsible for requesting memory from the @ref{16,,arena} and making it
available to your program. See @ref{1e,,Pools}.

Pools belong to `pool classes' that specify policies for how their
memory is managed. Some pools are @ref{8,,manually managed} (you must explicitly return memory to the pool,
for example by calling @ref{1f,,mps_free()}) and others are
@ref{9,,automatically managed} (the
@ref{20,,garbage collector} reclaims @ref{21,,unreachable} blocks). See
@ref{22,,Pool reference}.

@ref{23,,Formatted} pools need you to tell them how to
`scan' for @ref{24,,references} to allocated blocks. See
@ref{25,,Scanning}.

The arena needs you to tell it how to find your `roots': references
to allocated blocks that are stored in static data, in memory not
managed by the MPS, in your program’s @ref{26,,registers}, or on its
@ref{27,,control stack}. See @ref{28,,Roots}.

The MPS is designed to work with multi-threaded programs. Functions in
the C interface are thread safe, except in a few documented cases. See
@ref{29,,Threads}. The @ref{2a,,allocation point protocol} provides
fast lock-free allocation on multiple threads simultaneously. See
@ref{2b,,Allocation}.

The garbage collector is @ref{d,,incremental}: it proceeds in small steps interleaved with the
execution of your program, so there are no long waits. The garbage
collector is designed to work efficiently with multiple pools, and
in cases where there are many references between objects in different
pools. See @ref{2c,,Garbage collection}.

@node What next?,,Technical introduction,Overview of the Memory Pool System
@anchor{guide/overview what-next}@anchor{2d}
@subsection What next?


For a much more detailed technical overview of the MPS, see
@ref{2e,,Brooksby (2002)}.

If you’re going to try it out, see @ref{14,,Building the Memory Pool System}.

If you have a program in need of memory management, then you’ll want
to learn how to integrate it with the Memory Pool System. See
@ref{2f,,Garbage collecting a language with the Memory Pool System}.

If you want to know more technical details, they appear in the
@ref{30,,Reference}.

@geindex building
@geindex compiling
@geindex installing

@c mode: -*- rst -*-

@c NOTE: This file is a chapter of the MPS manual, and so uses some
@c Sphinx markup.  It does double-duty as plain text / GitHub rendered
@c instructions for bootstrapping the manual.  When editing, be
@c careful to ensure that the manual builds correctly.  See GitHub
@c issue #158 <https://github.com/Ravenbrook/mps/issues/158>.

@node Building the Memory Pool System,Garbage collecting a language with the Memory Pool System,Overview of the Memory Pool System,Guide
@anchor{guide/build doc}@anchor{31}@anchor{guide/build building-the-memory-pool-system}@anchor{32}@anchor{guide/build guide-build}@anchor{14}
@section Building the Memory Pool System


@menu
* Introduction:: 
* Getting hold of the MPS Kit:: 
* Compiling the MPS for your project:: 
* Building the MPS manual:: 
* Building the MPS for development:: 
* Installing the Memory Pool System:: 

@end menu

@node Introduction,Getting hold of the MPS Kit,,Building the Memory Pool System
@anchor{guide/build introduction}@anchor{33}
@subsection Introduction


This document describes the various ways in which you can build the MPS,
its manual, its libraries, and the tests and tools that come with it.

You may be building the MPS for a number of different purposes.

@node Getting hold of the MPS Kit,Compiling the MPS for your project,Introduction,Building the Memory Pool System
@anchor{guide/build getting-hold-of-the-mps-kit}@anchor{34}
@subsection Getting hold of the MPS Kit


Download the latest MPS Kit release from @indicateurl{https://www.ravenbrook.com/project/mps/release/}.

@node Compiling the MPS for your project,Building the MPS manual,Getting hold of the MPS Kit,Building the Memory Pool System
@anchor{guide/build compiling-the-mps-for-your-project}@anchor{35}
@subsection Compiling the MPS for your project


It is easy to compile the MPS.  You can do it separately, or include the
source in your own project’s build system.  This section describes
compilation in terms of command lines, but you can equally add the files
to a project in an IDE.

The MPS also comes with Makefiles and IDE project files for building
libraries, tools, and tests.  See “Building the MPS for development”.

@menu
* Compiling for production:: 
* Compiling for debugging:: 
* Optimizing for your object format:: 
* Compiling without the C library:: 

@end menu

@node Compiling for production,Compiling for debugging,,Compiling the MPS for your project
@anchor{guide/build compiling-for-production}@anchor{36}
@subsubsection Compiling for production


In the simplest case, you can compile the MPS to an object file with just:

@example
cc -c mps.c           (Unix/macOS)
cl /c mps.c           (Windows)
@end example

This will build a “hot” variety (for production) object file for use
with @code{mps.h}.  You can greatly improve performance by allowing global
optimization, for example:

@example
cc -O2 -c mps.c       (Unix/macOS)
cl /O2 /c mps.c       (Windows)
@end example

@node Compiling for debugging,Optimizing for your object format,Compiling for production,Compiling the MPS for your project
@anchor{guide/build compiling-for-debugging}@anchor{37}
@subsubsection Compiling for debugging


You can get a “cool” variety MPS (with more internal checking, for
debugging and development) with:

@example
cc -g -DCONFIG_VAR_COOL -c mps.c    (Unix/macOS)
cl /Zi /DCONFIG_VAR_COOL /c mps.c   (Windows)
@end example

@node Optimizing for your object format,Compiling without the C library,Compiling for debugging,Compiling the MPS for your project
@anchor{guide/build optimizing-for-your-object-format}@anchor{38}
@subsubsection Optimizing for your object format


If you are using your own @ref{39,,object format}, you will also get
improved performance by allowing the compiler to do global optimizations
between it and the MPS.  So if your format implementation is in, say,
@code{myformat.c}, then you could make a file @code{mymps.c} containing:

@example
#include "mps.c"
#include "myformat.c"
@end example

then:

@example
cc -O2 -c mymps.c     (Unix/macOS)
cl /O2 /c mymps.c     (Windows)
@end example

This will get your format code inlined with the MPS garbage collector.

@node Compiling without the C library,,Optimizing for your object format,Compiling the MPS for your project
@anchor{guide/build compiling-without-the-c-library}@anchor{3a}
@subsubsection Compiling without the C library


If you’re building the MPS for an environment without the standard C
library, you can exclude @ref{3b,,the plinth} component of
the MPS with:

@example
cc -DCONFIG_PLINTH_NONE -c mps.c
cl /Gs /DCONFIG_PLINTH_NONE /c mps.c
@end example

but you must then provide your own implementation of @code{mpslib.h}.
You can base this on the ANSI plinth in @code{mpsliban.c}.

If you want to do anything beyond these simple cases, use the MPS build
as described in the section “Building the MPS for development” below.

@node Building the MPS manual,Building the MPS for development,Compiling the MPS for your project,Building the Memory Pool System
@anchor{guide/build building-the-mps-manual}@anchor{3c}
@subsection Building the MPS manual


Builds of the MPS manual from the main MPS repo should be available at
@indicateurl{https://memory-pool-system.readthedocs.io/}.

If that’s not available, or if you have a variant of the MPS Kit, or
are making modifications to the MPS itself, then you should build the
manual for yourself.  This uses Sphinx
@indicateurl{https://www.sphinx-doc.org/}.

On Unix-like platforms (including macOS), the Makefile in the manual
directory can fetch and install a local copy of Sphinx and build the
manual, like this:

@example
cd manual
make html
@end example

then open manual/html/index.html.

On Windows platforms, follow the Sphinx installation instructions@footnote{https://www.sphinx-doc.org/en/master/usage/installation.html} for
Windows, then invoke Sphinx as shown in the Makefile in the manual
directory.

@node Building the MPS for development,Installing the Memory Pool System,Building the MPS manual,Building the Memory Pool System
@anchor{guide/build building-the-mps-for-development}@anchor{3d}
@subsection Building the MPS for development


If you’re making modifications to the MPS itself, want to build MPS
libraries for linking, or want to build MPS tests and tools, you should
use the MPS build.  This uses makefiles or Xcode projects.

@menu
* Prerequisites:: 
* Platforms:: 
* Running make:: 

@end menu

@node Prerequisites,Platforms,,Building the MPS for development
@anchor{guide/build prerequisites}@anchor{3e}
@subsubsection Prerequisites


For Unix-like platforms you will need the GNU Make tool.  Some platforms
(such as Linux) have GNU Make as their default make tool.  For others
you will need to get and install it.  (It’s available free from
@indicateurl{ftp://ftp.gnu.org/gnu/make/}.)  On FreeBSD this can be done as root
with @code{pkg_add -r gmake}.

On Windows platforms the NMAKE tool is used. This comes with Microsoft
Visual Studio C++ or the Microsoft Windows SDK.

On macOS the MPS is built using Xcode, either by opening
@code{mps.xcodeproj} with the Xcode app, or using the command-line
“xcodebuild” tool, installed from Xcode → Preferences → Downloads →
Components → Command Line Tools.

@node Platforms,Running make,Prerequisites,Building the MPS for development
@anchor{guide/build platforms}@anchor{3f}
@subsubsection Platforms


The MPS uses a six-character platform code to express a combination of
operating system, CPU architecture, and compiler toolchain.  Each
six-character code breaks down into three pairs of characters, like
this:

@example
OSARCT
@end example

Where @code{OS} denotes the operating system, @code{AR} the CPU
architecture, and @code{CT} the compiler toolchain.  Here are the
platforms that we have regular access to and on which the MPS works
well:


@multitable {xxxxxxxxxxxx} {xxxxxxxxxxx} {xxxxxxxxxxxxxxx} {xxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxx} 
@headitem

Platform

@tab

OS

@tab

Architecture

@tab

Compiler

@tab

Makefile

@item

@code{fri3gc}

@tab

FreeBSD

@tab

IA-32

@tab

GCC

@tab

@code{fri3gc.gmk}

@item

@code{fri3ll}

@tab

FreeBSD

@tab

IA-32

@tab

Clang

@tab

@code{fri3ll.gmk}

@item

@code{fri6gc}

@tab

FreeBSD

@tab

x86-64

@tab

GCC

@tab

@code{fri6gc.gmk}

@item

@code{fri6ll}

@tab

FreeBSD

@tab

x86-64

@tab

Clang

@tab

@code{fri6ll.gmk}

@item

@code{lia6gc}

@tab

Linux

@tab

ARM64

@tab

GCC

@tab

@code{lia6gc.gmk}

@item

@code{lia6ll}

@tab

Linux

@tab

ARM64

@tab

Clang

@tab

@code{lia6ll.gmk}

@item

@code{lii3gc}

@tab

Linux

@tab

IA-32

@tab

GCC

@tab

@code{lii3gc.gmk}

@item

@code{lii6gc}

@tab

Linux

@tab

x86-64

@tab

GCC

@tab

@code{lii6gc.gmk}

@item

@code{lii6ll}

@tab

Linux

@tab

x86-64

@tab

Clang

@tab

@code{lii6ll.gmk}

@item

@code{w3i3mv}

@tab

Windows

@tab

IA-32

@tab

Microsoft C

@tab

@code{w3i3mv.nmk}

@item

@code{w3i6mv}

@tab

Windows

@tab

x86-64

@tab

Microsoft C

@tab

@code{w3i6mv.nmk}

@item

@code{xca6ll}

@tab

macOS

@tab

ARM64

@tab

Clang

@tab

@code{mps.xcodeproj}

@item

@code{xci6ll}

@tab

macOS

@tab

x86-64

@tab

Clang

@tab

@code{mps.xcodeproj}

@end multitable


Historically, the MPS worked on a much wider variety of platforms, and
still could: IRIX, OSF/1 (Tru64), Solaris, SunOS, Classic Mac OS;
MIPS, PowerPC, ALPHA, SPARC v8, SPARC v9; Metrowerks Codewarrior,
SunPro C, Digital C, EGCS, Pelles C. If you are interested in support
on any of these platforms or any new platforms, please contact
Ravenbrook at @email{mps-questions@@ravenbrook.com}.

@node Running make,,Platforms,Building the MPS for development
@anchor{guide/build running-make}@anchor{40}
@subsubsection Running make


To build all MPS targets on Unix-like platforms, change to the @code{code}
directory and run the command:

@example
make -f <makefile>
@end example

where @code{make} is the command for GNU Make.  (Sometimes this will be
@code{gmake} or @code{gnumake}.)

To build just one target, run:

@example
make -f <makefile> <target>
@end example

To build a restricted set of targets for just one variety, run:

@example
make -f <makefile> 'VARIETY=<variety>' <target>
@end example

For example, to build just the “cool” variety of the @code{amcss} test on
64-bit Linux with Clang:

@example
gmake -f lii6ll.gmk VARIETY=cool amcss
@end example

On Windows platforms you need to run the “Visual Studio Command Prompt”
from the Start menu.  Then run one of these commands:

@example
nmake /f w3i3mv.nmk         (32-bit)
nmake /f w3i6mv.nmk         (64-bit)
@end example

You will need to switch your build environment between 32-bit and
64-bit using Microsoft’s @code{setenv} command, for example, @code{setenv
/x86} or @code{setenv /x64}.

To build just one target, run one of these commands:

@example
nmake /f w3i3mv.nmk <target>         (32-bit)
nmake /f w3i6mv.nmk <target>         (64-bit)
@end example

On macOS (64-bit only), you can build from the command line with:

@example
xcodebuild
@end example

On most platforms, the output of the build goes to a directory named
after the platform (e.g. @code{lii6ll}) so that you can share the source
tree across platforms.  On macOS the output goes in a directory
called @code{xc}.  Building generates @code{mps.a} or @code{mps.lib} or
equivalent, a library of object code which you can link with your
application, subject to the @ref{11,,MPS licensing conditions}.
It also generates a number of test programs, such as @code{amcss} (a
stress test for the Automatic Mostly-Copying pool class) and tools
such as @code{mpseventcnv} (for decoding telemetry logs).

@node Installing the Memory Pool System,,Building the MPS for development,Building the Memory Pool System
@anchor{guide/build installing-the-memory-pool-system}@anchor{41}
@subsection Installing the Memory Pool System


Unix-like platforms can use the GNU Autoconf @code{configure} script in the
root directory of the MPS Kit to generate a Makefile that can build and
install the MPS.  For example:

@example
./configure --prefix=/opt/mps
make install
@end example

will install the MPS public headers in @code{/opt/mps/include}, the
libraries in @code{/opt/mps/lib} etc.

There is currently no automatic way to “install” the MPS on Windows.

On any platform, you can install by copying the libraries built by the
make to, for example, @code{/usr/local/lib}, and all the headers beginning
with @code{mps} to @code{/usr/local/include}.

Note, however, that you may get better performance by using the method
described in the section “Optimizing for your object format” above.

@menu
* mpseventsql:: 

@end menu

@node mpseventsql,,,Installing the Memory Pool System
@anchor{guide/build mpseventsql}@anchor{42}
@subsubsection mpseventsql


The MPS Kit can build a command-line program @code{mpseventsql} that
loads a diagnostic stream of events into a SQLite3@footnote{http://www.sqlite.org/} database for processing. In order to build
this program, you need to install the SQLite3 development resources.


@itemize *

@item 
On macOS, SQLite3 is pre-installed, so this tool builds by
default.

@item 
On Linux, you need to install the @code{libsqlite3-dev} package:

@example
apt-get install libsqlite3-dev
@end example

and then re-run @code{./configure} and @code{make} as described above.

@item 
On FreeBSD, you need to build and install the @code{databases/sqlite3}
port from the ports collection:

@example
cd /usr/ports/databases/sqlite3
make install clean
@end example

and then re-run @code{./configure} and @code{make} as described above.

@item 
On Windows, you should visit the SQLite Download Page@footnote{http://www.sqlite.org/download.html} and download the
@code{sqlite-amalgamation} ZIP archive. (At time of writing this is the
first download on the page.) When you unzip the archive, you’ll find
it contains files named @code{sqlite3.c} and @code{sqlite3.h}. Copy these
two files into the @code{code} directory in the MPS Kit. Then in the
“Visual Studio Command Prompt”, visit the @code{code} directory and run
one of these commands:

@example
nmake /f w3i3mv.nmk mpseventsql.exe         (32-bit)
nmake /f w3i6mv.nmk mpseventsql.exe         (64-bit)
@end example
@end itemize

@c end

@geindex Memory Pool System; tutorial

@node Garbage collecting a language with the Memory Pool System,The stretchy vector problem,Building the Memory Pool System,Guide
@anchor{guide/lang doc}@anchor{43}@anchor{guide/lang garbage-collecting-a-language-with-the-memory-pool-system}@anchor{44}@anchor{guide/lang guide-lang}@anchor{2f}
@section Garbage collecting a language with the Memory Pool System


Have you written the lexer, parser, code generator and the runtime
system for your programming language, and come to the realization that
you are going to need a memory manager too? If so, you’ve come to the
right place.

In this guide, I’ll explain how to use the MPS to add incremental,
moving, generational garbage collection to the runtime system for a
programming language.

I’m assuming that you are familiar with the overall architecture of
the MPS (see the chapter @ref{6,,Overview of the Memory Pool System}) and that you’ve
downloaded and built the MPS (see the chapter @ref{14,,Building the Memory Pool System}).

@geindex Scheme; toy interpreter

@menu
* The Scheme interpreter:: 
* Choosing an arena class:: 
* Choosing a pool class:: 
* Describing your objects:: 
* Creating the pool:: 
* Roots:: 
* Threads:: 
* Allocation:: 
* Maintaining consistency:: 
* Tidying up:: 
* What next?: What next?<2>. 

@end menu

@node The Scheme interpreter,Choosing an arena class,,Garbage collecting a language with the Memory Pool System
@anchor{guide/lang the-scheme-interpreter}@anchor{45}
@subsection The Scheme interpreter


As a running example throughout this guide, I’ll be using a small
interpreter for a subset of the @ref{46,,Scheme} programming language.
I’ll be quoting the relevant sections of code as needed, but you may
find it helpful to experiment with this interpreter yourself, in either
of its versions:

@code{scheme-malloc.c}

@quotation

The toy Scheme interpreter before integration with the MPS, using
@ref{1a,,malloc} and @ref{1b,,free (2)} for memory management.
@end quotation

@code{scheme.c}

@quotation

The toy Scheme interpreter after integration with the MPS.
@end quotation

This simple interpreter allocates two kinds of objects on the
@ref{47,,heap}:


@enumerate 

@item 
All Scheme objects (there are no @ref{48,,unboxed} objects).

@item 
The global symbol table: a hash table consisting of a vector of
pointers to strings.
@end enumerate

A Scheme object (whose type is not necessarily known) is represented
by an @code{obj_t}, which is a pointer to a union of every type in
the language:

@example
typedef union obj_u *obj_t;
typedef union obj_u @{
    type_s type;
    pair_s pair;
    symbol_s symbol;
    integer_s integer;
    special_s special;
    operator_s operator;
    string_s string;
    port_s port;
    character_s character;
    vector_s vector;
    table_s table;
    buckets_s buckets;
@} obj_s;
@end example

Each of these types is a structure whose first word is a number
specifying the type of the object (@code{TYPE_PAIR} for pairs,
@code{TYPE_SYMBOL} for symbols, and so on). For example, pairs are
represented by a pointer to the structure @code{pair_s} defined as
follows:

@example
typedef struct pair_s @{
    type_t type;        /* TYPE_PAIR */
    obj_t car, cdr;     /* first and second projections */
@} pair_s;
@end example

Because the first word of every object is its type, functions can
operate on objects generically, testing @code{TYPE(obj)} as necessary
(which is a macro for @code{obj->type.type}). For example, the @code{print}
function is implemented like this:

@example
static void print(obj_t obj, unsigned depth, FILE *stream)
@{
    switch (TYPE(obj)) @{
    case TYPE_INTEGER:
        fprintf(stream, "%ld", obj->integer.integer);
        break;

    case TYPE_SYMBOL:
        fputs(obj->symbol.string, stream);
        break;

    /* ... and so on for the other types ... */
    @}
@}
@end example

Each constructor allocates memory for the new object by calling
@code{malloc()}. For example, @code{make_pair()} is the constructor
for pairs:

@example
static obj_t make_pair(obj_t car, obj_t cdr)
@{
    obj_t obj = (obj_t)malloc(sizeof(pair_s));
    if (obj == NULL) error("out of memory");
    obj->pair.type = TYPE_PAIR;
    CAR(obj) = car;
    CDR(obj) = cdr;
    return obj;
@}
@end example

Objects are never freed, because it is necessary to prove that they
are @ref{49,,dead} before their memory can be @ref{4a,,reclaimed}. To
prove that they are dead, we need a @ref{4b,,tracing}
@ref{20,,garbage collector}, which the MPS will provide.

@geindex arena class; choosing
@geindex arena; creating

@node Choosing an arena class,Choosing a pool class,The Scheme interpreter,Garbage collecting a language with the Memory Pool System
@anchor{guide/lang choosing-an-arena-class}@anchor{4c}
@subsection Choosing an arena class


You’ll recall from the @ref{6,,Overview of the Memory Pool System} that the functionality of
the MPS is divided between the @ref{16,,arenas}, which request memory
from (and return it to) the operating system, and @ref{18,,pools}, which
allocate blocks of memory for your program.

There are two main classes of arena: the @ref{4d,,client arena},
@ref{4e,,mps_arena_class_cl()}, which gets its memory from your program,
and the @ref{4f,,virtual memory arena}, @ref{50,,mps_arena_class_vm()},
which gets its memory from the operating system’s @ref{51,,virtual memory} interface.

The client arena is intended for use on embedded systems where there
is no virtual memory, and has a couple of disadvantages (you have to
decide how much memory you are going to use; and the MPS can’t return
memory to the operating system for use by other processes) so for
general-purpose programs you’ll want to use the virtual memory arena.

You’ll need a couple of headers: @code{mps.h} for the MPS interface, and
@code{mpsavm.h} for the virtual memory arena class:

@example
#include "mps.h"
#include "mpsavm.h"
@end example

There’s only one arena, and many MPS functions take an arena as an
argument, so it makes sense for the arena to be a global variable
rather than having to pass it around everywhere:

@example
static mps_arena_t arena;
@end example

Create an arena by calling @ref{52,,mps_arena_create_k()}. This function
takes a @ref{53,,keyword argument} when creating a virtual memory arena:
the size of virtual @ref{54,,address space} (`not' @ref{55,,RAM}), in
bytes, that the arena will reserve initially. The MPS will ask for
more address space if it runs out, but the more times it has to extend
its address space, the less efficient garbage collection will become.
The MPS works best if you reserve an address space that is several
times larger than your peak memory usage.

@cartouche
@quotation Note 
Functions in the MPS interface take @ref{53,,keyword arguments} for
arguments that are optional, or are only required in some
circumstances. These argument are passed in the form of an array
of structures of type @ref{56,,mps_arg_s}. See
@ref{57,,Keyword arguments} for the full details.
@end quotation
@end cartouche

Let’s reserve 32 megabytes:

@example
mps_res_t res;
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_ARENA_SIZE, 32 * 1024 * 1024);
    res = mps_arena_create_k(&arena, mps_arena_class_vm(), args);
@} MPS_ARGS_END(args);
if (res != MPS_RES_OK) error("Couldn't create arena");
@end example

@ref{52,,mps_arena_create_k()} is typical of functions in the MPS
interface in that it stores its result in a location pointed to by an
@ref{58,,out parameter} (here, @code{&arena}) and returns a @ref{59,,result code}, which is @ref{5a,,MPS_RES_OK} if the function succeeded, or
some other value if it failed.

@cartouche
@quotation Note 
The MPS is designed to co-operate with other memory managers, so
when integrating your language with the MPS you need not feel
obliged to move all your memory management to the MPS: you can
continue to use @code{malloc()} and @code{free()} to manage some
of your memory, for example, while using the MPS for the rest.

The toy Scheme interpreter illustrates this by continuing to use
@code{malloc()} and @code{free()} to manage its global symbol
table.
@end quotation
@end cartouche

@ref{19,,Arenas}, @ref{5b,,Error handing}.

@geindex pool class; choosing

@node Choosing a pool class,Describing your objects,Choosing an arena class,Garbage collecting a language with the Memory Pool System
@anchor{guide/lang choosing-a-pool-class}@anchor{5c}
@subsection Choosing a pool class


Pool classes come with a policy for how their memory will be managed:
some pool classes use @ref{9,,automatic memory management} and others
use @ref{8,,manual}; some use @ref{5d,,moving collection} and others @ref{5e,,non-moving}.

The section @ref{5f,,Choosing a pool class} in the @ref{22,,Pool reference} contains a procedure
for choosing a pool class. In the case of the toy Scheme interpreter,
the answers to the questions are (1) yes, the MPS needs to
automatically reclaim unreachable blocks; (2) yes, it’s acceptable for
the MPS to move blocks in memory and protect them with @ref{60,,barriers (1)}; and (3) the Scheme objects will contain @ref{61,,exact references}
to other Scheme objects in the same pool.

The recommended class is @ref{62,,AMC (Automatic Mostly-Copying)}. This pool class uses
automatic memory management, moving garbage collection,
@ref{63,,allocation points} and @ref{23,,formatted objects}, so it will
provide an introduction to these features of the MPS.

@cartouche
@quotation Note 
The MPS is designed for pools of different classes to co-exist in
the same arena, so that objects requiring different memory
management policies can be segregated into pools of suitable
classes.
@end quotation
@end cartouche

@ref{1e,,Pools}.

@geindex object format
@geindex format; object
@geindex Scheme; object format

@node Describing your objects,Creating the pool,Choosing a pool class,Garbage collecting a language with the Memory Pool System
@anchor{guide/lang describing-your-objects}@anchor{64}
@subsection Describing your objects


In order for the MPS to be able to automatically manage your objects,
you need to tell it how to perform various operations on an object
(@ref{65,,scan} it for @ref{24,,references}; replace it with a
@ref{66,,forwarding} or @ref{67,,padding object}, and
so on). You do this by creating an @ref{39,,object format}. Here’s the
code for creating the object format for the toy Scheme interpreter:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_FMT_ALIGN, ALIGNMENT);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_SCAN, obj_scan);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_SKIP, obj_skip);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_FWD, obj_fwd);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_ISFWD, obj_isfwd);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_PAD, obj_pad);
    res = mps_fmt_create_k(&obj_fmt, arena, args);
@} MPS_ARGS_END(args);
if (res != MPS_RES_OK) error("Couldn't create obj format");
@end example

The keyword arguments specify the @ref{68,,alignment} and the
@ref{69,,format methods} required by the AMC pool class. These are
described in the following sections.

@ref{6a,,Object formats}.

@geindex alignment
@geindex alignment; object
@geindex Scheme; object alignment

@menu
* Alignment:: 
* The scan method:: 
* The skip method:: 
* The forward method:: 
* The is-forwarded method:: 
* The padding method:: 

@end menu

@node Alignment,The scan method,,Describing your objects
@anchor{guide/lang alignment}@anchor{6b}@anchor{guide/lang guide-lang-alignment}@anchor{6c}
@subsubsection Alignment


The argument for the keyword @code{MPS_KEY_FMT_ALIGN} is the
@ref{68,,alignment} of objects belonging to this format. Determining the
alignment is hard to do portably, because it depends on the target
architecture and on the way the compiler lays out its structures in
memory. Here are some things you might try:


@enumerate 

@item 
Some modern compilers support the @code{alignof} operator:

@example
#define ALIGNMENT alignof(obj_s)
@end example

@item 
On older compilers you may be able to use this trick:

@example
#define ALIGNMENT offsetof(struct @{char c; obj_s obj;@}, obj)
@end example

but this is not reliable because some compilers pack structures
more tightly than their alignment requirements in some
circumstances (for example, GCC if the @code{-fstruct-pack} option is
specified).

@item 
The MPS interface provides the type @ref{6d,,mps_word_t}, which is
an unsigned integral type that is the same size as the platform’s
@ref{6e,,object pointer} types.

So if you know that all your objects can be word-aligned, you can
use:

@example
#define ALIGNMENT sizeof(mps_word_t)
@end example

@item 
The MPS interface provides the type @ref{6f,,MPS_PF_ALIGN}, which
is the @ref{70,,natural alignment} of the platform: the largest
alignment that might be required. So as a last resort, you can
use:

@example
#define ALIGNMENT MPS_PF_ALIGN
@end example

But this may be larger than necessary and so waste space. For
example, on Windows on x86-64, @ref{6f,,MPS_PF_ALIGN} is 16 bytes,
but this is only necessary for SSE@footnote{https://en.wikipedia.org/wiki/Streaming_SIMD_Extensions} types; ordinary types on this
platform require no more than 8-byte alignment.
@end enumerate

@geindex scan method
@geindex format method; scan
@geindex Scheme; scan method

@node The scan method,The skip method,Alignment,Describing your objects
@anchor{guide/lang guide-lang-scan}@anchor{71}@anchor{guide/lang the-scan-method}@anchor{72}
@subsubsection The scan method


The @ref{73,,scan method} is a function of type
@ref{74,,mps_fmt_scan_t}. It is called by the MPS to @ref{65,,scan} a
block of memory. Its task is to identify all references within the
objects in the block of memory, and “fix” them, by calling the macros
@ref{75,,MPS_FIX1()} and @ref{76,,MPS_FIX2()} on each reference (possibly
via the convenience macro @ref{77,,MPS_FIX12()}).

“Fixing” is a generic operation whose effect depends on the context in
which the scan method was called. The scan method is called to
discover references and so determine which objects are @ref{78,,alive} and which are @ref{49,,dead}, and also to update references
after objects have been moved.

Here’s the scan method for the toy Scheme interpreter:

@example
static mps_res_t obj_scan(mps_ss_t ss, mps_addr_t base, mps_addr_t limit)
@{
    MPS_SCAN_BEGIN(ss) @{
        while (base < limit) @{
            obj_t obj = base;
            switch (TYPE(obj)) @{
            case TYPE_PAIR:
                FIX(CAR(obj));
                FIX(CDR(obj));
                base = (char *)base + ALIGN_OBJ(sizeof(pair_s));
                break;
            case TYPE_INTEGER:
                base = (char *)base + ALIGN_OBJ(sizeof(integer_s));
                break;
            /* ... and so on for the other types ... */
            default:
                assert(0);
                fprintf(stderr, "Unexpected object on the heap\n");
                abort();
            @}
        @}
    @} MPS_SCAN_END(ss);
    return MPS_RES_OK;
@}
@end example

The scan method receives a @ref{79,,scan state} (@code{ss}) argument,
and the block of memory to scan, from @code{base} (inclusive) to
@code{limit} (exclusive). This block of memory is known to be packed
with objects belonging to the object format, and so the scan method
loops over the objects in the block, dispatching on the type of each
object, and then updating @code{base} to point to the next object in the
block.

For each reference in an object @code{obj_scan()} fixes it by calling
@ref{77,,MPS_FIX12()} via the macro @code{FIX()}, which is defined as
follows:

@example
#define FIX(ref)                                                        \
    do @{                                                                \
        mps_addr_t _addr = (ref); /* copy to local to avoid type pun */ \
        mps_res_t res = MPS_FIX12(ss, &_addr);                          \
        if (res != MPS_RES_OK) return res;                              \
        (ref) = _addr;                                                  \
    @} while (0)
@end example

Each call to @ref{77,,MPS_FIX12()} must appear between calls to the
macros @ref{7a,,MPS_SCAN_BEGIN()} and @ref{7b,,MPS_SCAN_END()}. It’s
usually most convenient to call @ref{7a,,MPS_SCAN_BEGIN()} at the start
of the function and @ref{7b,,MPS_SCAN_END()} at the end, as here.

@cartouche
@quotation Note 

@enumerate 

@item 
When the MPS calls your scan method, it may be part-way through
moving your objects. It is therefore essential that the scan
method only examine objects in the range of addresses it is
given. Objects in other ranges of addresses are not guaranteed
to be in a consistent state.

@item 
Scanning is an operation on the @ref{7c,,critical path} of the
MPS, which means that it is important that it runs as quickly
as possible.

@item 
If your reference is @ref{7d,,tagged}, you
must remove the tag before fixing it. (This is not quite true,
but see @ref{7e,,Tagged references} for the full story.)

@item 
The “fix” operation may update the reference. So if your
reference is tagged, you must make sure that the tag is
restored after the reference is updated.

@item 
The “fix” operation may fail by returning a @ref{59,,result code}
other than @ref{5a,,MPS_RES_OK}. A scan function must
propagate such a result code to the caller, and should do so as
soon as practicable.
@end enumerate
@end quotation
@end cartouche

@ref{6a,,Object formats}, @ref{25,,Scanning}.

@geindex skip method
@geindex format method; skip
@geindex Scheme; skip method

@node The skip method,The forward method,The scan method,Describing your objects
@anchor{guide/lang guide-lang-skip}@anchor{7f}@anchor{guide/lang the-skip-method}@anchor{80}
@subsubsection The skip method


The @ref{81,,skip method} is a function of type
@ref{82,,mps_fmt_skip_t}. It is called by the MPS to skip over an
object belonging to the format, and also to determine its size.

Here’s the skip method for the toy Scheme interpreter:

@example
static mps_addr_t obj_skip(mps_addr_t base)
@{
    obj_t obj = base;
    switch (TYPE(obj)) @{
    case TYPE_PAIR:
        base = (char *)base + ALIGN_OBJ(sizeof(pair_s));
        break;
    case TYPE_INTEGER:
        base = (char *)base + ALIGN_OBJ(sizeof(integer_s));
        break;
    /* ... and so on for the other types ... */
    default:
        assert(0);
        fprintf(stderr, "Unexpected object on the heap\n");
        abort();
    @}
    return base;
@}
@end example

The argument @code{base} is the address to the base of the object.
The skip method must return the address of the base of the “next
object”: in formats of variant A like this one, this is the address
just past the end of the object, rounded up to the object format’s
alignment.

@ref{6a,,Object formats}.

@geindex forward method
@geindex format method; forward
@geindex Scheme; forward method

@node The forward method,The is-forwarded method,The skip method,Describing your objects
@anchor{guide/lang guide-lang-fwd}@anchor{83}@anchor{guide/lang the-forward-method}@anchor{84}
@subsubsection The forward method


The @ref{85,,forward method} is a function of type
@ref{86,,mps_fmt_fwd_t}. It is called by the MPS after it has moved an
object, and its task is to replace the old object with a
@ref{66,,forwarding object} pointing to the new location of the object.


@float Figure

@image{MemoryPoolSystem-figures/copying,,,Diagram: Copying garbage collection.,svg}

@caption{Copying garbage collection.}

@end float


The forwarding object must satisfy these properties:


@enumerate 

@item 
It must be scannable and skippable, and so it will need to have a
type field to distinguish it from other Scheme objects.

@item 
It must contain a pointer to the new location of the object (a
@ref{87,,forwarding pointer}).

@item 
It must be the same size as the old object. This means that the
@ref{71,,scan method} and the @ref{7f,,skip method} will both need to know the length of the
forwarding object. This can be arbitrarily long (in the case of
string objects, for example) so it must contain a length field.
@end enumerate

This poses a problem, because the above analysis suggests that
forwarding objects need to contain at least three words, but Scheme
objects might be as small as two words (for example, integers).

This conundrum can be solved by having two types of forwarding object.
The first type is suitable for forwarding objects of three words or
longer:

@example
typedef struct fwd_s @{
    type_t type;                  /* TYPE_FWD */
    obj_t fwd;                    /* forwarded object */
    size_t size;                  /* total size of this object */
@} fwd_s;
@end example

while the second type is suitable for forwarding objects of two words:

@example
typedef struct fwd2_s @{
    type_t type;                  /* TYPE_FWD2 */
    obj_t fwd;                    /* forwarded object */
@} fwd2_s;
@end example

Here’s the forward method for the toy Scheme interpreter:

@example
static void obj_fwd(mps_addr_t old, mps_addr_t new)
@{
    obj_t obj = old;
    mps_addr_t limit = obj_skip(old);
    size_t size = (char *)limit - (char *)old;
    assert(size >= ALIGN_WORD(sizeof(fwd2_s)));
    if (size == ALIGN_WORD(sizeof(fwd2_s))) @{
        TYPE(obj) = TYPE_FWD2;
        obj->fwd2.fwd = new;
    @} else @{
        TYPE(obj) = TYPE_FWD;
        obj->fwd.fwd = new;
        obj->fwd.size = size;
    @}
@}
@end example

The argument @code{old} is the old address of the object, and
@code{new} is the location to which it has been moved.

The forwarding objects must be scannable and skippable, so the
following code must be added to @code{obj_scan()} and
@code{obj_skip()}:

@example
case TYPE_FWD:
    base = (char *)base + ALIGN_WORD(obj->fwd.size);
    break;
case TYPE_FWD2:
    base = (char *)base + ALIGN_WORD(sizeof(fwd2_s));
    break;
@end example

@cartouche
@quotation Note 
Objects that consist of a single word present a problem for the
design of the forwarding object. In the toy Scheme interpreter,
this happens on some 64-bit platforms, where a pointer is 8 bytes
long, and a @code{character_s} object (which consists of a
4-byte @code{int} and a 1-byte @code{char}) is also 8 bytes long.

There are a couple of solutions to this problem:


@enumerate 

@item 
Allocate the small objects with enough padding so that they can
be forwarded. (This is how the problem is solved in the toy
Scheme interpreter.)

@item 
Use a @ref{88,,tag} to distinguish between the client object and
a forwarding object that replaces it. It might help to allocate
the small objects in their own pool so that the number of types
that the scan method has to distinguish is minimized. Since
these objects do not contain references, they could be
allocated from the @ref{89,,AMCZ (Automatic Mostly-Copying Zero-rank)} pool, and so the cost of
scanning them could be avoided.
@end enumerate
@end quotation
@end cartouche

@ref{6a,,Object formats}.

@geindex is-forwarded method
@geindex format method; is-forwarded
@geindex Scheme; is-forwarded method

@node The is-forwarded method,The padding method,The forward method,Describing your objects
@anchor{guide/lang guide-lang-isfwd}@anchor{8a}@anchor{guide/lang the-is-forwarded-method}@anchor{8b}
@subsubsection The is-forwarded method


The @ref{8c,,is-forwarded method} is a function of type
@ref{8d,,mps_fmt_isfwd_t}. It is called by the MPS to determine if an
object is a @ref{66,,forwarding object}, and if it is, to determine the
location where that object was moved.

Here’s the is-forwarded method for the toy Scheme interpreter:

@example
static mps_addr_t obj_isfwd(mps_addr_t addr)
@{
    obj_t obj = addr;
    switch (TYPE(obj)) @{
    case TYPE_FWD2:
        return obj->fwd2.fwd;
    case TYPE_FWD:
        return obj->fwd.fwd;
    @}
    return NULL;
@}
@end example

It receives the address of an object, and returns the address to which
that object was moved, or @code{NULL} if the object was not moved.

@ref{6a,,Object formats}.

@geindex padding method
@geindex format method; padding
@geindex Scheme; padding method

@node The padding method,,The is-forwarded method,Describing your objects
@anchor{guide/lang guide-lang-pad}@anchor{8e}@anchor{guide/lang the-padding-method}@anchor{8f}
@subsubsection The padding method


The @ref{90,,padding method} is a function of type
@ref{91,,mps_fmt_pad_t}. It is called by the MPS to fill a block of
memory with a @ref{67,,padding object}: this is an object that fills
gaps in a block of @ref{23,,formatted objects}, for
example to enable the MPS to pack objects into fixed-size units (such
as operating system @ref{92,,pages}).

A padding object must be scannable and skippable, and not confusable
with a @ref{66,,forwarding object}. This means they need a type and a
size. However, padding objects might need to be as small as the
alignment of the object format, which was specified to be a single
word. As with forwarding objects, this can be solved by having two
types of padding object. The first type is suitable for padding
objects of two words or longer:

@example
typedef struct pad_s @{
    type_t type;                  /* TYPE_PAD */
    size_t size;                  /* total size of this object */
@} pad_s;
@end example

while the second type is suitable for padding objects consisting of a
single word:

@example
typedef struct pad1_s @{
    type_t type;                  /* TYPE_PAD1 */
@} pad1_s;
@end example

Here’s the padding method:

@example
static void obj_pad(mps_addr_t addr, size_t size)
@{
    obj_t obj = addr;
    assert(size >= ALIGN_OBJ(sizeof(pad1_s)));
    if (size == ALIGN_OBJ(sizeof(pad1_s))) @{
        TYPE(obj) = TYPE_PAD1;
    @} else @{
        TYPE(obj) = TYPE_PAD;
        obj->pad.size = size;
    @}
@}
@end example

The argument @code{addr} is the address at which the padding object
must be created, and @code{size} is its size in bytes: this will
always be a multiple of the alignment of the object format.

The padding objects must be scannable and skippable, so the following
code must be added to @code{obj_scan()} and @code{obj_skip()}:

@example
case TYPE_PAD:
    base = (char *)base + ALIGN_OBJ(obj->pad.size);
    break;
case TYPE_PAD1:
    base = (char *)base + ALIGN_OBJ(sizeof(pad1_s));
    break;
@end example

@ref{6a,,Object formats}.

@geindex pool; creating
@geindex Scheme; pool

@node Creating the pool,Roots,Describing your objects,Garbage collecting a language with the Memory Pool System
@anchor{guide/lang creating-the-pool}@anchor{93}
@subsection Creating the pool


Now you know enough to create an @ref{62,,AMC (Automatic Mostly-Copying)} pool! Let’s review
the pool creation code. First, the header for the AMC pool class:

@example
#include "mpscamc.h"
@end example

Second, the @ref{39,,object format}:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_FMT_ALIGN, ALIGNMENT);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_SCAN, obj_scan);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_SKIP, obj_skip);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_FWD, obj_fwd);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_ISFWD, obj_isfwd);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_PAD, obj_pad);
    res = mps_fmt_create_k(&obj_fmt, arena, args);
@} MPS_ARGS_END(args);
if (res != MPS_RES_OK) error("Couldn't create obj format");
@end example

And finally the @ref{18,,pool}:

@example
mps_pool_t obj_pool;
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_FORMAT, obj_fmt);
    res = mps_pool_create_k(&obj_pool, arena, mps_class_amc(), args);
@} MPS_ARGS_END(args);
if (res != MPS_RES_OK) error("Couldn't create obj pool");
@end example

@geindex root; creating
@geindex Scheme; root

@node Roots,Threads,Creating the pool,Garbage collecting a language with the Memory Pool System
@anchor{guide/lang guide-lang-root}@anchor{94}@anchor{guide/lang roots}@anchor{95}
@subsection Roots


The @ref{39,,object format} tells the MPS how to find @ref{24,,references} from one object to another. This allows the MPS to
extrapolate the reachability property: if object `A' is
@ref{96,,reachable}, and the @ref{73,,scan method} fixes a reference from
`A' to another object `B', then `B' is reachable too.

But how does this process get started? How does the MPS know which
objects are reachable `a priori'? Such objects are known as
@ref{97,,roots}, and you must register them with the MPS,
creating root descriptions of type @ref{98,,mps_root_t}.

The most important root consists of the contents of the
@ref{26,,registers} and the @ref{27,,control stack} of each @ref{99,,thread}
in your program: this is covered in @ref{9a,,Threads}, below.

Other roots may be found in static variables in your program, or in
memory allocated by other memory managers. For these roots you must
describe to the MPS how to @ref{65,,scan} them for references.

The toy Scheme interpreter has a number of static variables that point
to heap-allocated objects. First, the special objects, including:

@example
static obj_t obj_empty;         /* (), the empty list */
@end example

Second, the predefined symbols, including:

@example
static obj_t obj_quote;         /* "quote" symbol */
@end example

And third, the global symbol table:

@example
static obj_t *symtab;
static size_t symtab_size;
@end example

You tell the MPS how to scan these by writing root scanning functions
of type @ref{9b,,mps_root_scan_t}. These functions are similar to the
@ref{71,,scan method} in an @ref{39,,object format},
described above.

In the case of the toy Scheme interpreter, the root scanning function
for the special objects and the predefined symbols could be written
like this:

@example
static mps_res_t globals_scan(mps_ss_t ss, void *p, size_t s)
@{
    MPS_SCAN_BEGIN(ss) @{
        FIX(obj_empty);
        /* ... and so on for the special objects ... */
        FIX(obj_quote);
        /* ... and so on for the predefined symbols ... */
    @} MPS_SCAN_END(ss);
    return MPS_RES_OK;
@}
@end example

but in fact the interpreter already has tables of these global
objects, so it’s simpler and more extensible for the root scanning
function to iterate over them:

@example
static mps_res_t globals_scan(mps_ss_t ss, void *p, size_t s)
@{
    MPS_SCAN_BEGIN(ss) @{
        size_t i;
        for (i = 0; i < LENGTH(sptab); ++i)
            FIX(*sptab[i].varp);
        for (i = 0; i < LENGTH(isymtab); ++i)
            FIX(*isymtab[i].varp);
    @} MPS_SCAN_END(ss);
    return MPS_RES_OK;
@}
@end example

Each root scanning function must be registered with the MPS by calling
@ref{9c,,mps_root_create()}, like this:

@example
mps_root_t globals_root;
res = mps_root_create(&globals_root, arena, mps_rank_exact(), 0,
                      globals_scan, NULL, 0);
if (res != MPS_RES_OK) error("Couldn't register globals root");
@end example

The third argument (here @ref{9d,,mps_rank_exact()}) is the @ref{9e,,rank}
of references in the root. “@ref{61,,Exact}” means
that:


@enumerate 

@item 
each reference in the root is a genuine pointer to another object
managed by the MPS, or else a null pointer (unlike @ref{9f,,ambiguous references}); and

@item 
each reference keeps the target of the reference alive (unlike
@ref{c,,weak references (1)}).
@end enumerate

The fourth argument is the @ref{a0,,root mode}, which tells the MPS
whether it is allowed to place a @ref{60,,barrier (1)} on the root. The
root mode @code{0} means that it is not allowed.

The sixth and seventh arguments (here @code{NULL} and @code{0}) are
passed to the root scanning function where they are received as the
parameters @code{p} and @code{s} respectively. In this case
there was no need to use them.

What about the global symbol table? This is trickier, because it gets
rehashed from time to time, and during the rehashing process there are
two copies of the symbol table in existence. Because the MPS is
@ref{a1,,asynchronous}, it might be
scanning, moving, or collecting, at any point in time, and if it is
doing so during the rehashing of the symbol table it had better scan
both the old and new copies of the table. This is most conveniently
done by registering a new root to refer to the new copy, and then
after the rehash has completed, de-registering the old root by calling
@ref{a2,,mps_root_destroy()}.

It would be possible to write a root scanning function of type
@ref{9b,,mps_root_scan_t}, as described above, to fix the references in
the global symbol table, but the case of a table of references is
sufficiently common that the MPS provides a convenient (and optimized)
function, @ref{a3,,mps_root_create_table()}, for registering it:

@example
static mps_root_t symtab_root;

/* ... */

mps_addr_t ref = symtab;
res = mps_root_create_table(&symtab_root, arena, mps_rank_exact(), 0,
                            ref, symtab_size);
if (res != MPS_RES_OK) error("Couldn't register new symtab root");
@end example
@anchor{guide/lang guide-lang-roots-rehash}@anchor{a4}
The root must be re-registered whenever the global symbol table
changes size:

@example
static void rehash(void) @{
    obj_t *old_symtab = symtab;
    unsigned old_symtab_size = symtab_size;
    mps_root_t old_symtab_root = symtab_root;
    unsigned i;
    mps_addr_t ref;
    mps_res_t res;

    symtab_size *= 2;
    symtab = malloc(sizeof(obj_t) * symtab_size);
    if (symtab == NULL) error("out of memory");

    /* Initialize the new table to NULL so that "find" will work. */
    for (i = 0; i < symtab_size; ++i)
        symtab[i] = NULL;

    ref = symtab;
    res = mps_root_create_table(&symtab_root, arena, mps_rank_exact(), 0,
                                ref, symtab_size);
    if (res != MPS_RES_OK) error("Couldn't register new symtab root");

    for (i = 0; i < old_symtab_size; ++i)
        if (old_symtab[i] != NULL) @{
            obj_t *where = find(old_symtab[i]->symbol.string);
            assert(where != NULL);    /* new table shouldn't be full */
            assert(*where == NULL);   /* shouldn't be in new table */
            *where = old_symtab[i];
        @}

    mps_root_destroy(old_symtab_root);
    free(old_symtab);
@}
@end example

@cartouche
@quotation Note 

@enumerate 

@item 
The old root description (referring to the old copy of the
symbol table) is not destroyed until after the new root
description has been registered. This is because the MPS is
@ref{a1,,asynchronous}: it might
be scanning, moving, or collecting, at any point in time. If
the old root description were destroyed before the new root
description was registered, there would be a period during
which:


@enumerate a

@item 
the symbol table was not reachable (at least as far as the
MPS was concerned) and so all the objects referenced by it
(and all the objects reachable from `those' objects) might
be dead; and

@item 
if the MPS moved an object, it would not know that the
object was referenced by the symbol table, and so would not
update the reference there to point to the new location of
the object. This would result in out-of-date references in
the old symbol table, and these would be copied into the new
symbol table.
@end enumerate

@item 
The root might be scanned as soon as it is registered, so it is
important to fill it with scannable references (@code{NULL}
in this case) before registering it.

@item 
The order of operations at the end is important: the old root
must be de-registered before its memory is freed.

@item 
When calling @ref{a3,,mps_root_create_table()}, take care to
avoid undefined behaviour due to @ref{a5,,type punning}. See the
@ref{a6,,warning}.
@end enumerate
@end quotation
@end cartouche

@ref{28,,Roots}.

@geindex thread; registering
@geindex Scheme; thread

@node Threads,Allocation,Roots,Garbage collecting a language with the Memory Pool System
@anchor{guide/lang guide-lang-threads}@anchor{9a}@anchor{guide/lang threads}@anchor{a7}
@subsection Threads


In a multi-threaded environment where @ref{d,,incremental garbage collection} is used, you must register each of your @ref{99,,threads}
with the MPS so that the MPS can examine their state.

Even in a single-threaded environment (like the toy Scheme
interpreter) it may also be necessary to register the (only) thread if
either of these conditions apply:


@enumerate 

@item 
you are using @ref{5d,,moving garbage collection} (as with the @ref{62,,AMC (Automatic Mostly-Copying)} pool);

@item 
the thread’s @ref{26,,registers} and @ref{27,,control stack}
constitute a @ref{97,,root} (that is, objects may be kept alive via
references in local variables: this is almost always the case for
programs written in @ref{1c,,C}).
@end enumerate

You register a thread with an @ref{16,,arena} by calling
@ref{a8,,mps_thread_reg()}:

@example
mps_thr_t thread;
res = mps_thread_reg(&thread, arena);
if (res != MPS_RES_OK) error("Couldn't register thread");
@end example

You register the thread’s @ref{26,,registers} and @ref{27,,control stack}
as a root by calling @ref{a9,,mps_root_create_thread()}:

@example
void *marker = &marker;
mps_root_t stack_root;
res = mps_root_create_thread(&stack_root, arena, thread, marker);
if (res != MPS_RES_OK) error("Couldn't create stack root");
@end example

In order to scan the control stack, the MPS needs to know where the
@ref{aa,,cold end} of the stack is, and that’s the role of the
@code{marker} variable: the compiler places it on the stack, so its
address is a position within the stack. As long as you don’t exit from
this function while the MPS is running, your program’s active local
variables will always be placed on the stack after @code{marker},
and so will be scanned for references by the MPS.

@ref{29,,Threads}.

@geindex allocation; tutorial
@geindex allocation point protocol; tutorial
@geindex Scheme; allocation

@node Allocation,Maintaining consistency,Threads,Garbage collecting a language with the Memory Pool System
@anchor{guide/lang allocation}@anchor{ab}@anchor{guide/lang guide-lang-allocation}@anchor{ac}
@subsection Allocation


It probably seemed a long journey to get here, but at last we’re ready
to start allocating.

@ref{8,,Manual} pools typically support
@ref{1a,,malloc}-like allocation using the function
@ref{ad,,mps_alloc()}. But @ref{9,,automatic} pools cannot, because of the following problem:

@example
static obj_t make_pair(obj_t car, obj_t cdr)
@{
    obj_t obj;
    mps_addr_t addr;
    mps_res_t res;
    res = mps_alloc(&addr, pool, sizeof(pair_s));
    if (res != MPS_RES_OK) error("out of memory in make_pair");
    obj = addr;

    /* What happens if the MPS scans obj just now? */

    obj->pair.type = TYPE_PAIR;
    CAR(obj) = car;
    CDR(obj) = cdr;
    return obj;
@}
@end example

Because the MPS is @ref{a1,,asynchronous}, it might scan any reachable object at any time, including
immediately after the object has been allocated. In this case, if the
MPS attempts to scan @code{obj} at the indicated point, the object’s
@code{type} field will be uninitialized, and so the @ref{73,,scan method} may abort.

The MPS solves this problem via the fast, nearly lock-free
@ref{ae,,Allocation point protocol}. This needs an additional
structure, an @ref{63,,allocation point}, to be attached to the pool by
calling @ref{af,,mps_ap_create_k()}:

@example
static mps_ap_t obj_ap;

/* ... */

res = mps_ap_create_k(&obj_ap, obj_pool, mps_args_none);
if (res != MPS_RES_OK) error("Couldn't create obj allocation point");
@end example

And then the constructor can be implemented like this:

@example
static obj_t make_pair(obj_t car, obj_t cdr)
@{
    obj_t obj;
    mps_addr_t addr;
    size_t size = ALIGN_OBJ(sizeof(pair_s));
    do @{
        mps_res_t res = mps_reserve(&addr, obj_ap, size);
        if (res != MPS_RES_OK) error("out of memory in make_pair");
        obj = addr;
        obj->pair.type = TYPE_PAIR;
        CAR(obj) = car;
        CDR(obj) = cdr;
    @} while (!mps_commit(obj_ap, addr, size));
    return obj;
@}
@end example

The function @ref{b0,,mps_reserve()} allocates a block of memory that
the MPS knows is uninitialized: the MPS promises not to scan this
block or move it until after it is @ref{b1,,committed (2)} by calling
@ref{b2,,mps_commit()}. So the new object can be initialized safely.

However, there’s a second problem:

@example
    CAR(obj) = car;
    CDR(obj) = cdr;

    /* What if the MPS moves car or cdr just now? */

@} while (!mps_commit(obj_ap, addr, size));
@end example

Because @code{obj} is not yet committed, the MPS won’t scan it, and
that means that it won’t discover that it contains references to
@code{car} and @code{cdr}, and so won’t update these references to
point to their new locations.

In such a circumstance (that is, when objects have moved since you
called @ref{b0,,mps_reserve()}), @ref{b2,,mps_commit()} returns false, and
we have to initialize the object again (most conveniently done via a
@code{while} loop, as here).

@cartouche
@quotation Note 

@enumerate 

@item 
When using the @ref{ae,,Allocation point protocol} it is up
to you to ensure that the requested size is aligned, because
@ref{b0,,mps_reserve()} is on the MPS’s @ref{7c,,critical path},
and so it is highly optimized: in nearly all cases it is just
an increment to a pointer and a test.

@item 
It is very rare for @ref{b2,,mps_commit()} to return false, but
in the course of millions of allocations even very rare events
occur, so it is important not to do anything you don’t want to
repeat between calling @ref{b0,,mps_reserve()} and
@ref{b2,,mps_commit()}. Also, the shorter the interval, the less
likely @ref{b2,,mps_commit()} is to return false.
@end enumerate
@end quotation
@end cartouche

@ref{2b,,Allocation}.

@geindex consistency; maintaining
@geindex asynchrony; cautions

@node Maintaining consistency,Tidying up,Allocation,Garbage collecting a language with the Memory Pool System
@anchor{guide/lang maintaining-consistency}@anchor{b3}
@subsection Maintaining consistency


The MPS is @ref{a1,,asynchronous}:
this means that it might be scanning, moving, or collecting, at any
point in time (potentially, between any pair of instructions in your
program). So you must make sure that your data structures always obey
these rules:


@enumerate 

@item 
A @ref{97,,root} must be scannable by its root scanning function as
soon as it has been registered.

See the discussion of the @ref{a4,,global symbol table} in the toy Scheme interpreter.

@item 
A @ref{23,,formatted object} must be scannable by the @ref{73,,scan method} as soon as it has been @ref{b1,,committed (2)} by calling
@ref{b2,,mps_commit()}.

See the discussion of the @ref{ac,,pair constructor} in the toy Scheme interpreter.

@item 
All objects in automatically managed pools that are
@ref{96,,reachable} by your code must always be provably reachable
from a root via a chain of @ref{24,,references} that are
@ref{b4,,fixed} by a scanning function.

See the discussion of the @ref{a4,,global symbol table} in the toy Scheme interpreter.

@item 
Formatted objects must remain scannable throughout their
@ref{b5,,lifetime}.

@c fixme: refer to example here when written.
@end enumerate

Examples of code that breaks these rules, together with tactics for
tracking down the causes, appear in the chapter @ref{b6,,Debugging with the Memory Pool System}.

@geindex destroying
@geindex tearing down
@geindex tidying up

@node Tidying up,What next?<2>,Maintaining consistency,Garbage collecting a language with the Memory Pool System
@anchor{guide/lang tidying-up}@anchor{b7}
@subsection Tidying up


When your program is done with the MPS, you should @ref{b8,,park} the arena (by calling @ref{b9,,mps_arena_park()}) to ensure that
no incremental garbage collection is in progress, and then tear down
all the MPS data structures. This causes the MPS to check the
consistency of its data structures and report any problems it detects.
It also causes the MPS to flush its @ref{ba,,telemetry stream}.

MPS data structures must be destroyed or deregistered in the reverse
order to that in which they were registered or created. So you must
destroy all @ref{63,,allocation points} created in a @ref{18,,pool} before
destroying the pool; destroy all @ref{97,,roots} and pools, and
deregister all @ref{99,,threads}, that were created in an @ref{16,,arena}
before destroying the arena, and so on.

For example:

@example
mps_arena_park(arena);        /* ensure no collection is running */
mps_ap_destroy(obj_ap);       /* destroy ap before pool */
mps_pool_destroy(obj_pool);   /* destroy pool before fmt */
mps_root_destroy(stack_root); /* destroy root before thread */
mps_thread_dereg(thread);     /* deregister thread before arena */
mps_fmt_destroy(obj_fmt);     /* destroy fmt before arena */
mps_arena_destroy(arena);     /* last of all */
@end example

@node What next?<2>,,Tidying up,Garbage collecting a language with the Memory Pool System
@anchor{guide/lang what-next}@anchor{bb}
@subsection What next?


This article has covered the basic knowledge needed to add
incremental, moving, generational garbage collection to the runtime
system for a programming language.

If everything is working for your language, then the next step is
the chapter @ref{bc,,Tuning the Memory Pool System for performance}.

But in the more likely event that things don’t work out quite as
smoothly for your language as they did in the toy Scheme interpreter,
then you’ll be more interested in the chapter @ref{b6,,Debugging with the Memory Pool System}.

@geindex stretchy vectors
@geindex atomic updates

@node The stretchy vector problem,Debugging with the Memory Pool System,Garbage collecting a language with the Memory Pool System,Guide
@anchor{guide/vector doc}@anchor{bd}@anchor{guide/vector guide-stretchy-vector}@anchor{be}@anchor{guide/vector the-stretchy-vector-problem}@anchor{bf}
@section The stretchy vector problem


The @ref{94,,previous chapter} pointed out that:

@quotation

Because the MPS is @ref{a1,,asynchronous}, it might be scanning, moving, or collecting, at any
point in time.
@end quotation

The consequences of this can take a while to sink in, so this chapter
discusses a particular instance that catches people out: the `stretchy
vector' problem (named after the <stretchy-vector>@footnote{https://opendylan.org/books/drm/Collection_Classes#stretchy-vector} abstract class in
Dylan).

A `stretchy vector' is a vector that can change length dynamically.
Such a vector is often implemented using two objects: an array, and a
header object that stores the length and a pointer to an array.
Stretching (or shrinking) such a vector involves five steps:


@enumerate 

@item 
allocate a new array;

@item 
copy elements from the old array to the new array;

@item 
clear unused elements in the new array (if stretching);

@item 
update the pointer to the array in the header;

@item 
update the length in the header.
@end enumerate

For example:

@example
typedef struct vector_s @{
    type_t type;                /* TYPE_VECTOR */
    size_t length;              /* number of elements */
    obj_t *array;               /* array of elements */
@} vector_s, *vector_t;

void resize_vector(vector_t vector, size_t new_length) @{
    obj_t *new_array = realloc(vector->array, new_length * sizeof(obj_t));
    if (new_array == NULL)
        error("out of memory in resize_vector");
    if (vector->length < new_length) @{
        memset(&vector->array[vector->length], 0,
               (new_length - vector->length) * sizeof(obj_t));
    @}
    vector->array = new_array;
    vector->length = new_length;
@}
@end example

When adapting this code to the MPS, the following problems must be
solved:


@enumerate 

@item 
During step 2, the new array must be @ref{96,,reachable} from the
roots, and @ref{65,,scannable}. (If it’s not reachable, then
it may be collected; if it’s not scannable, then references it
contains will not be updated when they are moved by the collector.)

This can solved by storing the new array in a @ref{97,,root} until
the header has been updated. If the thread’s stack has been
registered as a root by calling @ref{a9,,mps_root_create_thread()}
then any local variable will do.

@item 
References in the new array must not be scanned until they have been
copied or cleared. (Otherwise they will be invalid.)

This can be solved by clearing the new array before calling
@ref{b2,,mps_commit()}.

@item 
The old array must be scanned at the old length (otherwise the scan
may run off the end of the old array when the vector grows), and
the new array must be scanned at the new length (otherwise the scan
may run off the end of the old array when the vector shrinks).

@item 
The array object must be scannable without referring to the header
object. (Because the header object may have been protected by the
MPS: see @ref{c0,,Cautions}.)
@end enumerate

Problems 3 and 4 can be solved by storing the length in the array. The
revised data structures and resizing code might look like this:

@example
typedef struct vector_s @{
    type_t type;                /* TYPE_VECTOR */
    obj_t array;                /* TYPE_ARRAY object */
@} vector_s, *vector_t;

typedef struct array_s @{
    type_t type;                /* TYPE_ARRAY */
    size_t length;              /* number of elements */
    obj_t array[0];             /* array of elements */
@} array_s, *array_t;

void resize_vector(vector_t vector, size_t new_length) @{
    size_t size = ALIGN_OBJ(offsetof(array_s, array) + new_length * sizeof(obj_t));
    mps_addr_t addr;
    array_t array;

    do @{
        mps_res_t res = mps_reserve(&addr, ap, size);
        if (res != MPS_RES_OK) error("out of memory in resize_vector");
        array = addr;
        array->type = TYPE_ARRAY;
        array->length = new_length;
        memset(array->array, 0, new_length * sizeof(obj_t));
        /* Now the new array is scannable, and it is reachable via the
         * local variable 'array', so it is safe to commit it. */
    @} while(!mps_commit(ap, addr, size));

    /* Copy elements after committing, so that the collector will
     * update them if they move. */
    memcpy(array->array, vector->array->array,
           min(vector->array->length, new_length) * sizeof(obj_t));
    vector->array = array;
@}
@end example

Similar difficulties can arise even when adapting code written for
other garbage collectors. For example, here’s the function
setarrayvector()@footnote{https://www.lua.org/source/5.2/ltable.c.html#setarrayvector} from Lua@footnote{https://www.lua.org/}:

@example
static void setarrayvector (lua_State *L, Table *t, int size) @{
    int i;
    luaM_reallocvector(L, t->array, t->sizearray, size, TValue);
    for (i=t->sizearray; i<size; i++)
        setnilvalue(&t->array[i]);
    t->sizearray = size;
@}
@end example

Lua’s garbage collector is @ref{c1,,synchronous}, so it can be assumed that there cannot be a garbage
collection between the assignment to @code{t->array} (resulting from the
expansion of the luaM_reallocvector()@footnote{https://www.lua.org/source/5.2/lmem.h.html#luaM_reallocvector} macro) and the assignment to
@code{t->sizearray}, and so the collector will always consistently see
either the old array or the new array, with the correct size. This
assumption will no longer be correct if this code is adapted to the
MPS.

@geindex debugging

@node Debugging with the Memory Pool System,Tuning the Memory Pool System for performance,The stretchy vector problem,Guide
@anchor{guide/debug doc}@anchor{c2}@anchor{guide/debug debugging-with-the-memory-pool-system}@anchor{c3}@anchor{guide/debug guide-debug}@anchor{b6}@anchor{guide/debug luam-reallocvector}@anchor{c4}
@section Debugging with the Memory Pool System


Memory management errors are some of the most stubborn and difficult
to track down, because the effect so often appears at a distant point
in the program that is seemingly unrelated to the cause, and by the
time the error is revealed, the information needed to reconstruct the
cause has long vanished. Immediately after an @ref{c5,,overwriting error}, the block that overran its bounds is fine, and the block that
was overwritten may not be visited for a long time. A failure to
@ref{b4,,fix} a @ref{24,,reference} does not necessarily cause the object
pointed to by the missed reference to die immediately: there may be
other references to that object, or a garbage collection may be
delayed. And even if it does die, the space it occupies may not be
re-allocated for some time.

@menu
* General debugging advice:: 
* Address space layout randomization:: 
* Example; underscanning: Example underscanning. 
* Example; allocating with wrong size: Example allocating with wrong size. 
* What next?: What next?<3>. 

@end menu

@node General debugging advice,Address space layout randomization,,Debugging with the Memory Pool System
@anchor{guide/debug general-debugging-advice}@anchor{c6}@anchor{guide/debug guide-debug-advice}@anchor{c7}
@subsection General debugging advice



@enumerate 

@item 
Compile with debugging information turned on (@code{-g} on the GCC or
Clang command line).

@item 
@geindex cool variety
@geindex variety; cool

Build the @ref{c8,,cool} @ref{c9,,variety} of the MPS (by defining the
preprocessor constant @ref{ca,,CONFIG_VAR_COOL}, for example by
setting @code{-DCONFIG_VAR_COOL} on the GCC or Clang command line).
This variety contains many internal consistency checks (including
such checks on the @ref{7c,,critical path}, which make it too slow
for use in production), and can generate profiling output in the
form of the @ref{ba,,telemetry stream}.

@item 
If your program triggers an assertion failure in the MPS, consult
@ref{cb,,Common assertions and their causes} for suggestions as to the possible cause.

@item 
Prepare a reproducible test case if possible. The MPS may be
@ref{a1,,asynchronous}, but it is
deterministic, so in single-threaded applications you should be
able to get consistent results.

However, you need to beware of @ref{cc,,address space layout randomization}: if you perform computation based on the addresses
of objects, for example, hashing objects by their address, then
ASLR will cause your hash tables to be laid out differently on each
run, which may affect the order of memory management operations.
See @ref{cd,,Address space layout randomization} below.

A fact that assists with reproducibility is that the more
frequently the collector runs, the sooner and more reliably errors
are discovered. So if you have a bug that’s hard to reproduce, or
which manifests itself in different ways on different runs, you may
be able to provoke it more reliably, or get a more consistent
result, by having a mode for testing in which you run frequent
collections (by calling @ref{ce,,mps_arena_collect()} followed by
@ref{cf,,mps_arena_release()}), perhaps as frequently as every
allocation. (This will of course make the system run very slowly,
but it ensures that if there are roots or references that are not
being scanned then the failure will occur close in time to the cause,
making it easier to diagnose.)

@item 
@geindex debugger
@geindex abort

Run your test case inside the debugger. Use @code{assert()} and
@code{abort()} in your error handler (rather than @code{exit()})
so that you can enter the debugger with the contents of the control
stack available for inspection.

@item 
@geindex barrier; handling in GDB
@geindex signal; handling in GDB

If you are using GDB on FreeBSD or Linux, you may want to avoid
stopping on @ref{60,,barrier (1)} hits, because the MPS uses barriers
to protect parts of memory, and barrier hits are common and
expected. To avoid stopping on a barrier hit, run:

@example
handle SIGSEGV pass nostop noprint
@end example

You can add this command to your @code{.gdbinit} if you always want it
to be run.

On macOS and Windows, barrier hits do not use signals and so do not
enter the debugger.

@item 
@geindex thread; handling in GDB

Similarly, if you are using GDB on FreeBSD or Linux, and if the
@ref{d0,,client program} is multi-threaded, you may want to avoid
stopping when the MPS suspends and resumes threads by delivering
signals to them. To avoid stopping on thread suspension and
resumption, run:

@example
handle SIGXCPU pass nostop noprint
handle SIGXFSZ pass nostop noprint
@end example

If you have configured these signals as described under
@ref{d1,,Signal and exception handling issues}, you will need to adjust the signal
names accordingly.

On macOS and Windows, thread suspension and resumption does not use
signals and so does not enter the debugger.

@item 
@geindex postmortem debugging
@geindex postmortem state

If the @ref{d0,,client program} is stopped in the debugger with the
MPS part of the way through execution of an operation in an
@ref{16,,arena} (for example, a crash inside a @ref{73,,scan method}),
it will not be possible to call introspection functions, such as
@ref{d2,,mps_arena_has_addr()} or @ref{d3,,mps_addr_pool()} (because
the MPS is not re-entrant), and it may not be possible to examine
some regions of memory (because they are @ref{d4,,protected} by the
MPS).

If you are in this situation and would like to be able to call MPS
functions or examine regions of memory from the debugger, then you
can put the arena into the @ref{d5,,postmortem state} by calling
@ref{d6,,mps_arena_postmortem()} from the debugger. This unlocks the
arena and turns off protection.

@cartouche
@quotation Warning 
After calling @ref{d6,,mps_arena_postmortem()}, MPS-managed
memory is not in a consistent state, and so it is not safe to
continue running the client program.
@end quotation
@end cartouche
@end enumerate

@geindex ASLR
@geindex address space layout randomization

@node Address space layout randomization,Example underscanning,General debugging advice,Debugging with the Memory Pool System
@anchor{guide/debug address-space-layout-randomization}@anchor{d7}@anchor{guide/debug guide-debug-aslr}@anchor{cd}
@subsection Address space layout randomization


@ref{cc,,Address space layout randomization} (ASLR) makes it hard to
prepare a repeatable test case for a program that performs computation
based on the addresses of objects, for example, hashing objects by
their address. If this is affecting you, you’ll find it useful to
disable ASLR when testing.

Here’s a small program that you can use to check if ASLR is enabled on
your system. It outputs addresses from four key memory areas in a
program (data segment, text segment, stack and heap):

@example
#include <stdio.h>
#include <stdlib.h>

int data;

int main() @{
    void *heap = malloc(4);
    int stack = 0;
    printf("data: %p text: %p stack: %p heap: %p\n",
           &data, (void *)main, &stack, heap);
    return 0;
@}
@end example

When ASLR is turned on, running this program outputs different
addresses on each run. For example, here are four runs on macOS
10.9.3:

@example
data: 0x10a532020 text: 0x10a531ed0 stack: 0x7fff556ceb1c heap: 0x7f9f80c03980
data: 0x10d781020 text: 0x10d780ed0 stack: 0x7fff5247fb1c heap: 0x7fe498c03980
data: 0x10164b020 text: 0x10164aed0 stack: 0x7fff5e5b5b1c heap: 0x7fb783c03980
data: 0x10c7f8020 text: 0x10c7f7ed0 stack: 0x7fff53408b1c heap: 0x7f9740403980
@end example

By contrast, here are four runs on FreeBSD 8.3:

@example
data: 0x8049728 text: 0x8048470 stack: 0xbfbfebfc heap: 0x28201088
data: 0x8049728 text: 0x8048470 stack: 0xbfbfebfc heap: 0x28201088
data: 0x8049728 text: 0x8048470 stack: 0xbfbfebfc heap: 0x28201088
data: 0x8049728 text: 0x8048470 stack: 0xbfbfebfc heap: 0x28201088
@end example

Here’s the situation on each of the operating systems supported by the MPS:


@itemize *

@item 
`FreeBSD' (as of version 10.0) does not support ASLR, so there’s
nothing to do.

@item 
On `Windows' (Vista or later), ASLR is a property of the
executable, and it can be turned off at link time using the
/DYNAMICBASE:NO linker option@footnote{https://docs.microsoft.com/en-us/cpp/build/reference/dynamicbase}.

@item 
On `Linux' (kernel version 2.6.12 or later), ASLR can be turned
off for a single process by running setarch@footnote{http://man7.org/linux/man-pages/man8/setarch.8.html} with the @code{-R}
option:

@example
-R, --addr-no-randomize
       Disables randomization of the virtual address space
@end example

For example:

@example
$ setarch $(uname -m) -R ./myprogram
@end example

@item 
On `macOS' (10.7 or later), ASLR can be disabled for a single
process by starting the process using @code{posix_spawn()}, passing
the undocumented attribute @code{0x100}, like this:

@example
#include <spawn.h>

pid_t pid;
posix_spawnattr_t attr;

posix_spawnattr_init(&attr);
posix_spawnattr_setflags(&attr, 0x100);
posix_spawn(&pid, argv[0], NULL, &attr, argv, environ);
@end example

The MPS provides the source code for a command-line tool
implementing this (@code{tool/noaslr.c}). We’ve confirmed that this
works on macOS 10.9.3, but since the technique is undocumented, it
may well break in future releases. (If you know of a documented way
to achieve this, please @ref{d8,,contact us}.)
@end itemize

@geindex underscanning
@geindex bug; underscanning

@node Example underscanning,Example allocating with wrong size,Address space layout randomization,Debugging with the Memory Pool System
@anchor{guide/debug example-underscanning}@anchor{d9}@anchor{guide/debug guide-debug-underscanning}@anchor{da}
@subsection Example: underscanning


An easy mistake to make is to omit to @ref{b4,,fix} a @ref{24,,reference}
when @ref{65,,scanning} a @ref{23,,formatted object}. For example,
in the Scheme interpreter’s @ref{71,,scan method}, I
might have forgotten to fix the first element of a pair:

@example
case TYPE_PAIR:
case TYPE_PROMISE:
  /* oops, forgot: FIX(CAR(obj)); */
  FIX(CDR(obj));
  base = (char *)base + ALIGN_OBJ(sizeof(pair_s));
  break;
@end example

This means that as far as the MPS is concerned, the first element of
the pair is @ref{21,,unreachable} and so @ref{49,,dead}, so after
collecting the region of memory containing this object, the space will
be reused for other objects. So @code{CAR(obj)} might end up
pointing to the start of a valid object (but the wrong one), or to the
middle of a valid object, or to an unused region of memory, or into an
MPS internal control structure.

The reproducible test case is simple. Run a garbage collection by
calling @code{(gc)} and then evaluate any expression:

@example
$ gdb -q ./scheme
Reading symbols from ./scheme...done.
(gdb) run
Starting program: /home/grees/github.com/mps/example/scheme/scheme
MPS Toy Scheme Example
The prompt shows total allocated bytes and number of collections.
Try (vector-length (make-vector 100000 1)) to see the MPS in action.
You can force a complete garbage collection with (gc).
If you recurse too much the interpreter may crash from using too much C stack.
13248, 0> (gc)
Collection started.
  Why: Client requests: immediate full collection.
  Clock: 1819
Collection finished.
    live 5272
    condemned 16384
    not_condemned 0
    clock: 1987
13272, 1> foo
scheme: scheme.c:1421: lookup_in_frame: Assertion `TYPE(CAAR(frame)) == TYPE_SYMBOL' failed.

Program received signal SIGABRT, Aborted.
__GI_raise (sig=sig@@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:51
51  ../sysdeps/unix/sysv/linux/raise.c: No such file or directory.
@end example

What’s going on?

@example
(gdb) backtrace
#0  __GI_raise (sig=sig@@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:51
#1  0x00007ffff78058b1 in __GI_abort () at abort.c:79
#2  0x00007ffff77f542a in __assert_fail_base (fmt=0x7ffff797ca38 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n", assertion=assertion@@entry=0x555555604050 "TYPE(CAAR(frame)) == TYPE_SYMBOL", file=file@@entry=0x555555603bb2 "scheme.c", line=line@@entry=1421, function=function@@entry=0x555555605390 <__PRETTY_FUNCTION__.3661> "lookup_in_frame") at assert.c:92
#3  0x00007ffff77f54a2 in __GI___assert_fail (assertion=0x555555604050 "TYPE(CAAR(frame)) == TYPE_SYMBOL", file=0x555555603bb2 "scheme.c", line=1421, function=0x555555605390 <__PRETTY_FUNCTION__.3661> "lookup_in_frame") at assert.c:101
#4  0x000055555555d0d8 in lookup_in_frame (frame=0x7ffff5900bb8, symbol=0x7ffff5883418) at scheme.c:1421
#5  0x000055555555d16c in lookup (env=0x7ffff5880180, symbol=0x7ffff5883418) at scheme.c:1440
#6  0x000055555555d2d1 in eval (env=0x7ffff5880180, op_env=0x7ffff5880198, exp=0x7ffff5883418) at scheme.c:1487
#7  0x0000555555564f29 in start (argc=0, argv=0x7fffffffe0d0) at scheme.c:4341
#8  0x0000555555565717 in main (argc=0, argv=0x7fffffffe0d0) at scheme.c:4489
(gdb) frame 4
#4  0x000055555555d0d8 in lookup_in_frame (frame=0x7ffff5900bb8, symbol=0x7ffff5883418) at scheme.c:1421
1421            assert(TYPE(CAAR(frame)) == TYPE_SYMBOL);
(gdb) print (char *)symbol->symbol.string
$1 = 0x7ffff5883428 "foo"
@end example

The backtrace shows that the interpreter is in the middle of looking
up the symbol @code{foo} in the environment. The Scheme interpreter
implements the environment as a list of `frames', each of which is a
list of `bindings', each binding being a pair of a symbol and its
value, as shown here:


@float Figure

@image{MemoryPoolSystem-figures/scheme-env,,,Diagram: The environment data structure in the Scheme interpreter.,svg}

@caption{The environment data structure in the Scheme interpreter.}

@end float


In this case, because the evaluation is taking place at top level,
there is only one frame in the environment (the global frame). And
it’s this frame that’s corrupt:

@example
(gdb) list
1416        static obj_t lookup_in_frame(obj_t frame, obj_t symbol)
1417        @{
1418          while(frame != obj_empty) @{
1419            assert(TYPE(frame) == TYPE_PAIR);
1420            assert(TYPE(CAR(frame)) == TYPE_PAIR);
1421            assert(TYPE(CAAR(frame)) == TYPE_SYMBOL);
1422            if(CAAR(frame) == symbol)
1423              return CAR(frame);
1424            frame = CDR(frame);
1425          @}
(gdb) print CAAR(frame)->type.type
$3 = 13
@end example

The number 13 is the value @code{TYPE_PAD}. So instead of the
expected symbol, @code{CAAR(frame)} points to a @ref{67,,padding object}.

You might guess at this point that the symbol had not been fixed, and
since you know that the frame is referenced by the @code{car} of
the first pair in the environment, that’s the suspect reference. But
in a more complex situation this might not yet be clear. In such a
situation it can be useful to look at the sequence of events leading
up to the detection of the error. See @ref{db,,Telemetry}.

@geindex bug; allocating with wrong size

@node Example allocating with wrong size,What next?<3>,Example underscanning,Debugging with the Memory Pool System
@anchor{guide/debug example-allocating-with-wrong-size}@anchor{dc}@anchor{guide/debug guide-debug-size}@anchor{dd}
@subsection Example: allocating with wrong size


Here’s another kind of mistake: an off-by-one error in
@code{make_string()} leading to the allocation of string objects with
the wrong size:

@example
static obj_t make_string(size_t length, const char *string)
@{
  obj_t obj;
  mps_addr_t addr;
  size_t size = ALIGN_OBJ(offsetof(string_s, string) + length /* oops, forgot +1 */);
  do @{
    mps_res_t res = mps_reserve(&addr, obj_ap, size);
    if (res != MPS_RES_OK) error("out of memory in make_string");
    obj = addr;
    obj->string.type = TYPE_STRING;
    obj->string.length = length;
    if (string) memcpy(obj->string.string, string, length+1);
    else memset(obj->string.string, 0, length+1);
  @} while(!mps_commit(obj_ap, addr, size));
  total += size;
  return obj;
@}
@end example

Here’s a test case that exercises this bug:

@example
(define (church n f a) (if (eqv? n 0) a (church (- n 1) f (f a))))
(church 1000 (lambda (s) (string-append s "x")) "")
@end example

And here’s how it shows up in the debugger:

@example
$ gdb -q ./scheme
Reading symbols from ./scheme...done.
(gdb) run < test.scm
Starting program: /home/grees/github.com/mps/example/scheme/scheme < test.scm
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
MPS Toy Scheme Example
The prompt shows total allocated bytes and number of collections.
Try (vector-length (make-vector 100000 1)) to see the MPS in action.
You can force a complete garbage collection with (gc).
If you recurse too much the interpreter may crash from using too much C stack.
13248, 0> church
14104, 0> scheme: scheme.c:4067: obj_skip: Assertion `0' failed.

Program received signal SIGABRT, Aborted.
__GI_raise (sig=sig@@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:51
51  ../sysdeps/unix/sysv/linux/raise.c: No such file or directory.
(gdb) backtrace
#0  __GI_raise (sig=sig@@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:51
#1  0x00007ffff78058b1 in __GI_abort () at abort.c:79
#2  0x00007ffff77f542a in __assert_fail_base (fmt=0x7ffff797ca38 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n", assertion=assertion@@entry=0x555555603e0f "0", file=file@@entry=0x555555603c32 "scheme.c", line=line@@entry=4067, function=function@@entry=0x555555605568 <__PRETTY_FUNCTION__.4815> "obj_skip") at assert.c:92
#3  0x00007ffff77f54a2 in __GI___assert_fail (assertion=0x555555603e0f "0", file=0x555555603c32 "scheme.c", line=4067, function=0x555555605568 <__PRETTY_FUNCTION__.4815> "obj_skip") at assert.c:101
#4  0x000055555556434b in obj_skip (base=0x7ffff58af898) at scheme.c:4067
#5  0x00005555555e15bf in amcSegScanNailedRange (totalReturn=0x7fffffffd4a0, moreReturn=0x7fffffffd4a4, ss=0x7fffffffd5f0, amc=0x7ffff57f73f8, board=0x7ffff57f8a40, base=0x7ffff58ae000, limit=0x7ffff58afff0) at ../../code/poolamc.c:1278
#6  0x00005555555e177b in amcSegScanNailedOnce (totalReturn=0x7fffffffd4a0, moreReturn=0x7fffffffd4a4, ss=0x7fffffffd5f0, seg=0x7ffff57f89a8, amc=0x7ffff57f73f8) at ../../code/poolamc.c:1325
#7  0x00005555555e187c in amcSegScanNailed (totalReturn=0x7fffffffd5d0, ss=0x7fffffffd5f0, pool=0x7ffff57f73f8, seg=0x7ffff57f89a8, amc=0x7ffff57f73f8) at ../../code/poolamc.c:1355
#8  0x00005555555e1bd3 in amcSegScan (totalReturn=0x7fffffffd5d0, seg=0x7ffff57f89a8, ss=0x7fffffffd5f0) at ../../code/poolamc.c:1413
#9  0x0000555555599188 in SegScan (totalReturn=0x7fffffffd5d0, seg=0x7ffff57f89a8, ss=0x7fffffffd5f0) at ../../code/seg.c:778
#10 0x000055555558c926 in traceScanSegRes (ts=1, rank=1, arena=0x7ffff7ff7000, seg=0x7ffff57f89a8) at ../../code/trace.c:1148
#11 0x000055555558cb2d in traceScanSeg (ts=1, rank=1, arena=0x7ffff7ff7000, seg=0x7ffff57f89a8) at ../../code/trace.c:1223
#12 0x000055555558e24d in TraceAdvance (trace=0x7ffff7ff7ac0) at ../../code/trace.c:1664
#13 0x000055555558e792 in TracePoll (workReturn=0x7fffffffd7b0, collectWorldReturn=0x7fffffffd78c, globals=0x7ffff7ff7008, collectWorldAllowed=1) at ../../code/trace.c:1784
#14 0x000055555557c990 in ArenaPoll (globals=0x7ffff7ff7008) at ../../code/global.c:760
#15 0x00005555555690ed in mps_ap_fill (p_o=0x7fffffffd940, mps_ap=0x7ffff57f7928, size=24) at ../../code/mpsi.c:1111
#16 0x0000555555559c93 in make_pair (car=0x7ffff58afbf0, cdr=0x7ffff5880000) at scheme.c:457
#17 0x000055555555d605 in eval_list (env=0x7ffff58afed0, op_env=0x7ffff58afee8, list=0x7ffff5883828, message=0x5555556041f8 "eval: badly formed argument list") at scheme.c:1564
#18 0x000055555555d94b in eval_args_rest (name=0x555555604e02 "string-append", env=0x7ffff58afed0, op_env=0x7ffff58afee8, operands=0x7ffff5883828, restp=0x7fffffffdb00, n=0) at scheme.c:1637
#19 0x0000555555562870 in entry_string_append (env=0x7ffff58afed0, op_env=0x7ffff58afee8, operator=0x7ffff5882340, operands=0x7ffff5883828) at scheme.c:3396
#20 0x000055555555d420 in eval (env=0x7ffff58afed0, op_env=0x7ffff58afee8, exp=0x7ffff5883810) at scheme.c:1511
#21 0x000055555555dbc8 in entry_interpret (env=0x7ffff58af9e0, op_env=0x7ffff58af9f8, operator=0x7ffff5883700, operands=0x7ffff5883670) at scheme.c:1713
#22 0x000055555555d420 in eval (env=0x7ffff58af9e0, op_env=0x7ffff58af9f8, exp=0x7ffff5883598) at scheme.c:1511
#23 0x0000555555564fab in start (argc=0, argv=0x7fffffffe0d0) at scheme.c:4341
#24 0x0000555555565799 in main (argc=0, argv=0x7fffffffe0d0) at scheme.c:4489
(gdb) frame 4
#4  0x000055555556434b in obj_skip (base=0x7ffff58af898) at scheme.c:4067
4067            assert(0);
(gdb) list
4062            break;
4063          case TYPE_PAD1:
4064            base = (char *)base + ALIGN_WORD(sizeof(pad1_s));
4065            break;
4066          default:
4067            assert(0);
4068            fflush(stdout);
4069            fprintf(stderr, "Unexpected object on the heap\n");
4070            abort();
4071          @}
@end example

The object being skipped is corrupt:

@example
(gdb) print obj->type.type
$1 = -175623000
@end example

What happened to it? It’s often helpful in these situations to have a
look at nearby memory.

@example
(gdb) x/20gx obj
0x7ffff58af898:     0x00007ffff58834a8      0x00007ffff58af7c8
0x7ffff58af8a8:     0x0000000000000000      0x00007ffff58af890
0x7ffff58af8b8:     0x00007ffff58af660      0x0000000000000000
0x7ffff58af8c8:     0x00007ffff58836e8      0x00007ffff5880000
0x7ffff58af8d8:     0x0000000000000000      0x00007ffff58af5d0
0x7ffff58af8e8:     0x00007ffff58af8c0      0x0000000000000000
0x7ffff58af8f8:     0x00007ffff58af5b8      0x00007ffff58af8d8
0x7ffff58af908:     0x0000000000000000      0x00007ffff5880090
0x7ffff58af918:     0x00007ffff58af8f0      0x0000000000000000
0x7ffff58af928:     0x00007ffff58834f0      0x00007ffff5880000
@end example

You can see that this is a region of memory containing pairs, which
have type @code{TYPE_PAIR} = 0 and consist of three words. But
what’s that at the start of the region, where @code{obj}'s tag
should be? It looks like a pointer. So what’s in the memory just below
@code{obj}? Let’s look at the previous region of memory:

@example
(gdb) x/30gx (mps_word_t*)obj-28
0x7ffff58af7b8:     0x00007ffff5883840      0x00007ffff5880000
0x7ffff58af7c8:     0x0000000000000005      0x00000000000000b8
0x7ffff58af7d8:     0x7878787878787878      0x7878787878787878
0x7ffff58af7e8:     0x7878787878787878      0x7878787878787878
0x7ffff58af7f8:     0x7878787878787878      0x7878787878787878
0x7ffff58af808:     0x7878787878787878      0x7878787878787878
0x7ffff58af818:     0x7878787878787878      0x7878787878787878
0x7ffff58af828:     0x7878787878787878      0x7878787878787878
0x7ffff58af838:     0x7878787878787878      0x7878787878787878
0x7ffff58af848:     0x7878787878787878      0x7878787878787878
0x7ffff58af858:     0x7878787878787878      0x7878787878787878
0x7ffff58af868:     0x7878787878787878      0x7878787878787878
0x7ffff58af878:     0x7878787878787878      0x7878787878787878
0x7ffff58af888:     0x7878787878787878      0x0000000000000000
0x7ffff58af898:     0x00007ffff58834a8      0x00007ffff58af7c8
@end example

In this region we can see a string starting at address
@code{0x7ffff58af7c8}. Its type is @code{TYPE_STRING} = 5, its length
is 0xb8 = 184, and its contents is 184 repetitions of the byte 0x78
(ASCII for “x”) resulting from the repeated @code{(string-append s "x")}
in the test code. The string is followed by a pair (with type 0) at
the address @code{0x7ffff58af890}, which is one word before
@code{obj}. So it looks as though @code{obj} should be pointing
at the pair, but its value is one word too low.

The value in @code{obj} comes from skipping the string object:

@example
(gdb) print obj_skip(0x7ffff58af7c8)
$3 = (void *) 0x7ffff58af898
@end example

So either @code{obj_skip()} has skipped one word too far, or the
string object is one word too short. This should be enough evidence to
track down the cause.

@node What next?<3>,,Example allocating with wrong size,Debugging with the Memory Pool System
@anchor{guide/debug what-next}@anchor{de}
@subsection What next?


If you tracked down all your bugs, then the next step is the chapter
@ref{bc,,Tuning the Memory Pool System for performance}.

But if you’re still struggling, please @ref{d8,,contact us} and
see if we can help.

@geindex Memory Pool System; performance
@geindex performance
@geindex generation; choosing size

@node Tuning the Memory Pool System for performance,Advanced topics,Debugging with the Memory Pool System,Guide
@anchor{guide/perf doc}@anchor{df}@anchor{guide/perf guide-perf}@anchor{bc}@anchor{guide/perf tuning-the-memory-pool-system-for-performance}@anchor{e0}
@section Tuning the Memory Pool System for performance


@cartouche
@quotation Note 
When developing a benchmark to profile your program against, bear
in mind that the benchmark should allocate several times the
amount of physical memory that you expect to be available to the
process. If the total allocation fits into the available memory,
there’s no point running a garbage collector at all: you might as
well just allocate and never collect.
@end quotation
@end cartouche

The most important aspect of tuning the MPS is to choose good sizes
for the @ref{e1,,generations} in your @ref{e2,,generation chain}. The
ideal size of a generation should be such that when it is collected,
most of the blocks allocated in that generation should be found to be
@ref{49,,dead} (and so the cost of @ref{65,,scanning} and
@ref{e3,,copying} them can be avoided
entirely). If a generation is collected when its blocks are mostly
alive, that is a waste of time.

In the tables below I give the execution time of @code{test-leaf.scm} in
the toy Scheme interpreter under different settings for its generation
chain. (This test case allocates hundreds of millions of small
short-lived objects.)

First, the effect of varying the capacity of a chain with a single
generation.


@multitable {xxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Capacity

@tab

Execution time (user+sys)

@item

100

@tab

362.6

@item

200

@tab

354.9

@item

400

@tab

349.7

@item

800

@tab

314.4

@item

1600

@tab

215.7

@item

3200

@tab

94.0

@item

6400

@tab

53.5

@item

12800

@tab

79.6

@item

25600

@tab

77.6

@end multitable


Second, the effect of varying the number of generations (all
generations being identical).


@multitable {xxxxxxxxxxxxx} {xxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Generations

@tab

Capacity

@tab

Execution time (user+sys)

@item

1

@tab

6400

@tab

53.5

@item

2

@tab

6400

@tab

42.4

@item

3

@tab

6400

@tab

42.1

@item

4

@tab

6400

@tab

42.2

@item

5

@tab

6400

@tab

42.2

@end multitable


These tables suggest that:


@enumerate 

@item 
The improvement in performance to be gained by getting generation
sizes right is dramatic: much bigger than the small improvements to
gained from other techniques.

@item 
You can make generations too big as well as too small.

@item 
There are rapidly diminishing returns to be gained from adding
generations.
@end enumerate

@cartouche
@quotation Note 
@ref{db,,Telemetry} can be used to discover when generations
are being collected and what proportion of blocks were found to be
alive.
@end quotation
@end cartouche

The table below shows the effect of varying the initial allocation of
address space to the arena (using three generations each with capacity
6400 kB).


@multitable {xxxxxxxxxxxxxxx} {xxxxxxxxxxxx} {xxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Address space

@tab

Extensions

@tab

Collections

@tab

Execution time (user+sys)

@item

2

@tab

32

@tab

371

@tab

52.0

@item

4

@tab

21

@tab

370

@tab

47.0

@item

8

@tab

0

@tab

@footnote{
With this initial allocation of address space, the test
case failed to run to completion after thousands of seconds
and tens of thousands of garbage collection cycles.
}

@tab

@footnote{
With this initial allocation of address space, the test
case failed to run to completion after thousands of seconds
and tens of thousands of garbage collection cycles.
}

@item

14

@tab

0

@tab

@footnote{
With this initial allocation of address space, the test
case failed to run to completion after thousands of seconds
and tens of thousands of garbage collection cycles.
}

@tab

@footnote{
With this initial allocation of address space, the test
case failed to run to completion after thousands of seconds
and tens of thousands of garbage collection cycles.
}

@item

16

@tab

0

@tab

2436

@tab

160.5

@item

18

@tab

0

@tab

1135

@tab

89.1

@item

20

@tab

0

@tab

673

@tab

60.6

@item

22

@tab

0

@tab

484

@tab

48.7

@item

24

@tab

0

@tab

400

@tab

43.1

@item

32

@tab

0

@tab

368

@tab

41.2

@item

64

@tab

0

@tab

368

@tab

43.1

@item

128

@tab

0

@tab

368

@tab

46.4

@item

256

@tab

0

@tab

368

@tab

46.3

@item

512

@tab

0

@tab

368

@tab

49.3

@item

1024

@tab

0

@tab

368

@tab

42.0

@item

2048

@tab

0

@tab

368

@tab

43.2

@item

4096

@tab

0

@tab

368

@tab

43.5

@item

8192

@tab

0

@tab

368

@tab

46.1

@item

16384

@tab

0

@tab

368

@tab

49.2

@item

32768

@tab

0

@tab

368

@tab

57.1

@item

65536

@tab

0

@tab

368

@tab

71.1

@item

131072

@tab

0

@tab

368

@tab

101.3

@item

262144

@tab

0

@tab

368

@tab

161.3

@item

524288

@tab

0

@tab

368

@tab

273.0

@item

1048576

@tab

0

@tab

368

@tab

504.6

@end multitable


@cartouche
@quotation Note 
@end quotation
@end cartouche

The lesson here is that the allocation of address space has to be
comfortably larger than the working set of the program, but that a
very large address space is ruinous to performance.

@node Advanced topics,Implementing malloc and free,Tuning the Memory Pool System for performance,Guide
@anchor{guide/advanced doc}@anchor{e4}@anchor{guide/advanced advanced-topics}@anchor{e5}@anchor{guide/advanced guide-advanced}@anchor{e6}
@section Advanced topics


@geindex finalization; example
@geindex Scheme; finalization
@geindex Scheme; ports

@menu
* Finalization:: 
* Location dependency:: 
* Weak hash tables:: 
* Global symbol table:: 
* Segregation of objects:: 

@end menu

@node Finalization,Location dependency,,Advanced topics
@anchor{guide/advanced finalization}@anchor{e7}
@subsection Finalization


In Scheme, an open file is represented by a `port'. In the toy Scheme
interpreter, a port is a wrapper around a standard C file handle:

@example
typedef struct port_s @{
    type_t type;                    /* TYPE_PORT */
    obj_t name;                     /* name of stream */
    FILE *stream;
@} port_s;
@end example

Operating systems limit the number of files that a process can have open
simultaneously, so to avoid running out of file handles, it is necessary
to close ports when you are done with them. If a Scheme program fails to
call @code{close-input-file}, then the underlying file handle should still
be closed when the port object @ref{49,,dies}. This procedure is
known as @ref{b,,finalization}.

Any block in an @ref{9,,automatically managed} @ref{18,,pool} can be registered for finalization by calling
@ref{e8,,mps_finalize()}. In the toy Scheme interpreter, this can be done
in @code{make_port()}:

@example
 static obj_t make_port(obj_t name, FILE *stream)
 @{
     mps_addr_t port_ref;
     obj_t obj;
     mps_addr_t addr;
     size_t size = ALIGN_OBJ(sizeof(port_s));
     do @{
         mps_res_t res = mps_reserve(&addr, obj_ap, size);
         if (res != MPS_RES_OK) error("out of memory in make_port");
         obj = addr;
         obj->port.type = TYPE_PORT;
         obj->port.name = name;
         obj->port.stream = stream;
     @} while(!mps_commit(obj_ap, addr, size));
     total += sizeof(port_s);

     port_ref = obj;
     mps_finalize(arena, &port_ref);

     return obj;
 @}
@end example

The MPS implements finalization by posting a @ref{e9,,message} to the
arena’s @ref{ea,,message queue} when an object that has been registered
for finalization is about to die.

If you want to finalize your objects, you must first enable
finalization messages by calling @ref{eb,,mps_message_type_enable()}:

@example
mps_message_type_enable(arena, mps_message_type_finalization());
@end example

You must then poll the arena’s message queue at times that are
convenient for you, call @ref{ec,,mps_message_get()} to pick up a
finalization message from the queue, call
@ref{ed,,mps_message_finalization_ref()} to access the finalized object,
and finally call @ref{ee,,mps_message_discard()} on the finalization
message. The finalized object is then subject to the normal rules of
life and death: it continues to live as long as it is strongly
reachable.

In the toy Scheme interpreter, the most convenient moment to process the
message queue is at the start of the read–eval–print loop. When a
finalization message is found, the associated file handle is closed
(unless it has been closed already), and the message is discarded.

@example
 mps_message_type_t type;

 while (mps_message_queue_type(&type, arena)) @{
     mps_message_t message;
     mps_bool_t b;
     b = mps_message_get(&message, arena, type);
     assert(b); /* we just checked there was one */

     if (type == mps_message_type_finalization()) @{
         mps_addr_t port_ref;
         obj_t port;
         mps_message_finalization_ref(&port_ref, arena, message);
         port = port_ref;
         assert(TYPE(port) == TYPE_PORT);
         if(port->port.stream) @{
             printf("Port to file \"%s\" is dying. Closing file.\n",
                    port->port.name->string.string);
             (void)fclose(port->port.stream);
             port->port.stream = NULL;
         @}
     @} else @{
         /* ... handle other message types ... */
     @}

     mps_message_discard(arena, message);
 @}
@end example

Here’s an example session showing finalization taking place:

@example
 MPS Toy Scheme Example
 9960, 0> (open-input-file "scheme.c")
 #[port "scheme.c"]
 10064, 0> (gc)
 Collection started.
   Why: Client requests: immediate full collection.
   Clock: 3401
 Port to file "scheme.c" is dying. Closing file.
 Collection finished.
     live 10040
     condemned 10088
     not_condemned 0
     clock: 3807
@end example

It’s wise not to depend on finalization as the only method for
releasing resources (see the @ref{ef,,Cautions}
section in @ref{f0,,Finalization}), because the garbage collector
does not promise to collect particular objects at particular times,
and in any case it does so only when it can prove that the object is
@ref{49,,dead}. So it is best to provide a reliable mechanism for
releasing the resource (here, the Scheme function
@code{close-input-port}), and use finalization as a backup strategy.

But this raises the possibility that a port will be closed twice: once
via @code{close-input-port} and a second time via finalization. So it’s
necessary to make ports robust against being closed multiple times.
The toy Scheme interpreter does so by setting @code{stream} to
@code{NULL}: this ensures that the file handle won’t be closed
more than once.

@example
static void port_close(obj_t port)
@{
    assert(TYPE(port) == TYPE_PORT);
    if(port->port.stream != NULL) @{
        fclose(port->port.stream);
        port->port.stream = NULL;
    @}
@}
@end example

Note that because finalization messages are processed synchronously
via the message queue (and the Scheme interpreter is single-threaded)
there is no need for a lock here.

It’s still possible that the toy Scheme interpreter might run out of
open file handles despite having some or all of its port objects being
finalizable. That’s because the arena’s message queue is only polled
after evaluating an expression at top level: if the expression itself
opens too many file handles, the finalization messages will queue up and
not be processed in time. For example:

@example
MPS Toy Scheme Example
9960, 0> (define (repeat n f _) (if (eqv? n 0) '() (repeat (- n 1) f (f))))
repeat
10840, 0> (repeat 300 (lambda () (open-input-file "scheme.c")) 0)
open-input-file: cannot open input file
@end example

A less naïve interpreter might process finalization messages on a more
regular schedule, or might take emergency action in the event of running
out of open file handles by carrying out a full garbage collection and
processing any finalization messages that are posted as a result.

@ref{f0,,Finalization}, @ref{f1,,Messages}.

@geindex location dependency; example
@geindex hash table; address-based example
@geindex Scheme; address-based hash table
@geindex Scheme; location dependency

@node Location dependency,Weak hash tables,Finalization,Advanced topics
@anchor{guide/advanced guide-advanced-location}@anchor{f2}@anchor{guide/advanced location-dependency}@anchor{f3}
@subsection Location dependency


The toy Scheme interpreter contains an address-based (@code{eq?}) hash
table implementation. It hashes the addresses of its keys, and so needs
to take account of the possibility that a @ref{5d,,moving garbage collector} might move the keys. If it fails to take account of this, the
hash table might become invalid after a garbage collection.

In the interaction shown below (with a naïve version of the code) you’ll
see that although the keys remain present in the table after garbage
collection, they cannot be found. This is because their locations (and
hence their hashes) have changed, but their positions in the table have
not been updated to match.

@example
MPS Toy Scheme Example
10240, 0> (define ht (make-eq-hashtable))
ht
10584, 0> (hashtable-set! ht 'one 1)
10768, 0> (hashtable-set! ht 'two 2)
10952, 0> (hashtable-set! ht 'three 3)
11136, 0> ht
#[hashtable (two 2) (three 3) (one 1)]
11136, 0> (hashtable-ref ht 'two #f)
2
11280, 0> (gc)
11304, 1> (hashtable-ref ht 'one #f)
#f
11448, 1> (hashtable-ref ht 'two #f)
#f
11592, 1> (hashtable-ref ht 'three #f)
#f
11736, 1> ht
#[hashtable (two 2) (three 3) (one 1)]
@end example

The MPS solves this problem with its `location dependency'
feature: a structure of type @ref{f4,,mps_ld_s} encapsulates a set of
dependencies on the locations of blocks. You add addresses to the
location dependency, and then later test an address to see if it is
`stale': that is, if the block at that address might have moved
since its location was depended upon.

You need to provide space for the @ref{f4,,mps_ld_s} structure. In the
case of a hash table, it is most convenient to inline it in the hash
table’s metadata:

@example
typedef struct table_s @{
  type_t type;                  /* TYPE_TABLE */
  hash_t hash;                  /* hash function */
  cmp_t cmp;                    /* comparison function */
  mps_ld_s ld;                  /* location dependency */
  obj_t buckets;                /* hash buckets */
@} table_s;
@end example

Before being used, the location dependency must be reset to indicate
that nothing is depended upon, by calling @ref{f5,,mps_ld_reset()}.

For example:

@example
static obj_t make_table(size_t length, hash_t hashf, cmp_t cmpf)
@{
    obj_t obj;
    mps_addr_t addr;
    size_t l, size = ALIGN_OBJ(sizeof(table_s));
    do @{
        mps_res_t res = mps_reserve(&addr, obj_ap, size);
        if (res != MPS_RES_OK) error("out of memory in make_table");
        obj = addr;
        obj->table.type = TYPE_TABLE;
        obj->table.buckets = NULL;
    @} while(!mps_commit(obj_ap, addr, size));
    total += size;
    obj->table.hash = hashf;
    obj->table.cmp = cmpf;
    /* round up to next power of 2 */
    for(l = 1; l < length; l *= 2);
    obj->table.buckets = make_buckets(l);
    mps_ld_reset(&obj->table.ld, arena);
    return obj;
@}
@end example

`Before' the hash table becomes dependent on the location of a block,
the address of the block must be added to its location dependency by
calling @ref{f6,,mps_ld_add()}. In particular, you must call
@ref{f6,,mps_ld_add()} before computing the hash of the address. (If you
wait until afterwards, it might be too late: a garbage collection might
have taken place after the hash was computed but before you added the
dependency.)

In the toy Scheme interpreter, this is done just before the computation
of the hash of the address.

@example
static unsigned long eq_hash(obj_t obj, mps_ld_t ld)
@{
    union @{char s[sizeof(obj_t)]; obj_t addr;@} u;
    if (ld) mps_ld_add(ld, arena, obj);
    u.addr = obj;
    return hash(u.s, sizeof(obj_t));
@}
@end example

By adding the dependency at this point in the code, the implementation
avoids adding unnecessary dependencies on a location. For example, an
@code{eqv?} hash table does not need to depend on the location of numbers
and characters:

@example
static unsigned long eqv_hash(obj_t obj, mps_ld_t ld)
@{
    switch(TYPE(obj)) @{
        case TYPE_INTEGER:
            return obj->integer.integer;
        case TYPE_CHARACTER:
            return obj->character.c;
        default:
            return eq_hash(obj, ld);
    @}
@}
@end example

and a @code{string=?} hash table does not need to depend on the location of
any of its keys.

@cartouche
@quotation Note 
The garbage collector may run at any time, so a key may become
stale at any time after calling @ref{f6,,mps_ld_add()}, perhaps even
before you’ve added it!

It’s best to postpone worrying about this until this key is actually
looked up, when the staleness will be discovered. After all, it may
never be looked up.
@end quotation
@end cartouche

If you look up a key in an address-based hash table and fail to find it
there, that might be because the table’s dependency on the location of
the key is stale: that is, if the garbage collector moved the key. The
function @ref{f7,,mps_ld_isstale()} tells you if a block whose
location you depended upon since the last call to
@ref{f5,,mps_ld_reset()} might have moved.

In the toy Scheme interpreter this behaviour is encapsulated into
@code{table_find()}:

@example
static struct bucket_s *table_find(obj_t tbl, obj_t key, int add)
@{
    struct bucket_s *b;
    assert(TYPE(tbl) == TYPE_TABLE);
    b = buckets_find(tbl, tbl->table.buckets, key, add);
    if ((b == NULL || b->key == NULL || b->key == obj_deleted)
        && mps_ld_isstale(&tbl->table.ld, arena, key))
    @{
        b = table_rehash(tbl, tbl->table.buckets->buckets.length, key);
    @}
    return b;
@}
@end example

It’s important to test @ref{f7,,mps_ld_isstale()} only in case of
failure. The function may report a false positive (returning true
despite the block not having moved). So if @code{key} has not moved,
then if you tested @ref{f7,,mps_ld_isstale()} first, it might return
true and so you’d end up unnecessarily rehashing the whole table.
(It’s crucial, however, to actually test that @code{key} appears in
the table, not just that some key with the same hash does.)

When a table is rehashed, call @ref{f5,,mps_ld_reset()} to clear the
location dependency, and then @ref{f6,,mps_ld_add()} for each key before
it is added back to the table.

@cartouche
@quotation Note 
After @ref{f7,,mps_ld_isstale()} has returned true, and after
rehashing the table, I don’t just repeat the usual lookup by
calling @code{buckets_find()}. That’s because the table might
have become stale again already.

Instead, @code{table_rehash()} finds and returns the bucket
containing @code{key}. (Since it has to loop over all the
entries in the table anyway, it might as well find this bucket
too.)
@end quotation
@end cartouche

By adding the line:

@example
puts("stale!");
@end example

in @code{table_find()} after @ref{f7,,mps_ld_isstale()} returns true,
it’s possible to see when the location dependency becomes stale and
the table has to be rehashed:

@example
MPS Toy Scheme Example
10240, 0> (define ht (make-eq-hashtable))
ht
10584, 0> (hashtable-set! ht 'one 1)
10768, 0> ht
#[hashtable (one 1)]
10768, 0> (gc)
10792, 1> (hashtable-ref ht 'one #f)
stale!
1
11080, 1> (hashtable-set! ht 'two 2)
11264, 1> (gc)
11288, 2> (hashtable-ref ht 'one #f)
stale!
1
11576, 2> (hashtable-set! ht 'three 3)
11760, 2> (hashtable-ref ht 'two #f)
2
11904, 2> (gc)
11928, 3> (hashtable-ref ht 'one #f)
1
12072, 3> (hashtable-ref ht 'two #f)
stale!
2
12360, 3> (hashtable-ref ht 'three #f)
3
@end example

@cartouche
@quotation Note 
In case you’re puzzled by the highlighted lines: the symbol
@code{'one} must not have been moved by the collection, and so was
found in the table at the correct location. Thus
@ref{f7,,mps_ld_isstale()} was not called. The symbol @code{'two} did
move in the collection, so it’s not found in the table, and that
causes @ref{f7,,mps_ld_isstale()} to be tested.
@end quotation
@end cartouche

Don’t forget to check the location dependency for staleness when
setting a value for key in a hash table, and when deleting a key from
a hash table. Here’s an interaction with the toy Scheme interpreter
showing a key being found to be stale when setting and when deleting
it:

@example
MPS Toy Scheme Example
13248, 0> (define ht (make-eq-hashtable))
ht
13624, 0> (hashtable-set! ht 'a 1)
13808, 0> (gc)
13832, 1> (hashtable-set! ht 'a 2)
stale!
13832, 1> (hashtable-delete! ht 'one)
stale!
14152, 1> (gc)
14176, 2> (hashtable-delete! ht 'a)
stale!
14456, 2> ht
#[hashtable]
@end example

@cartouche
@quotation Note 
If the hash table is being used to implement a `set' (that is,
there are no values, only keys), and if it doesn’t matter that the
same key appears twice in the table (under the hashes of its old
and new addresses) then you may be able to skip the staleness
check when adding a key. This is a delicate optimization, however:
if you needed to iterate over the keys, or maintain a count of
keys, then it would not work.
@end quotation
@end cartouche

@ref{f8,,Location dependency}.

@geindex weak reference; example
@geindex hash table; weak example
@geindex Scheme; weak hash table

@node Weak hash tables,Global symbol table,Location dependency,Advanced topics
@anchor{guide/advanced guide-advanced-weak}@anchor{f9}@anchor{guide/advanced weak-hash-tables}@anchor{fa}
@subsection Weak hash tables


A @ref{fb,,weak-key hash table} has @ref{c,,weak references (1)} to its
keys. If the key dies, the value corresponding to that key is
automatically deleted from the table too. Similarly, a
@ref{fc,,weak-value hash table} has weak references to its values, and a
@ref{fd,,doubly weak hash table} has weak references to both.

In this section, I’ll describe how to add all three types of weak hash
table to the toy Scheme interpreter. This requires a few far-reaching
changes to the code, so in order to keep the basic integration
understandable by newcomers to the MPS, I’ve made these changes in a
separate version of the code:

@code{scheme-advanced.c}

@quotation

The Scheme interpreter after a number of “advanced” features,
including weak hash tables, have been implemented.
@end quotation

The MPS supports weak references only in @ref{97,,roots} and in blocks
allocated in pools belonging to the @ref{fe,,AWL (Automatic Weak Linked)} pool class. Roots
aren’t convenient for this use case: it’s necessary for hash tables
to be automatically reclaimed when they die. So AWL it is.

@cartouche
@quotation Note 
This isn’t a design limitation of the MPS: it’s just that up until
now the only uses our customers have had for weak references are the
ones supported by AWL. (In particular, AWL was designed around the
requirements of weak hash tables in Open Dylan@footnote{https://opendylan.org/}.) If you need more general handling of
weak references, @ref{d8,,contact us}.
@end quotation
@end cartouche

All the references in a @ref{23,,formatted object} belong to the same
@ref{9e,,rank}: that is, they are all @ref{61,,exact},
@ref{c,,weak}, or @ref{9f,,ambiguous references}. In
AWL, the rank of references is specified when creating an
@ref{63,,allocation point}. This has consequences for the design of the
hash table data structure: in weak-key strong-value hash tables, the
keys need to be in one object and the values in another (and the same is
true in the strong-key weak-value case). So instead of having one vector
of buckets with alternate keys and values, hash tables must have two
vectors, one for the keys and the other for the values, to allow keys
and values to have different ranks.

These vectors will be allocated from an AWL pool with two allocation
points, one for strong references, and one for weak references:

@example
static mps_pool_t buckets_pool; /* pool for hash table buckets */
static mps_ap_t strong_buckets_ap; /* allocation point for strong buckets */
static mps_ap_t weak_buckets_ap; /* allocation point for weak buckets */
@end example

@cartouche
@quotation Note 
It’s not necessary to allocate the strong buckets from the same pool
as the weak buckets, but we’ll see below that they have to be
allocated in a `non-moving' pool such as AWL.
@end quotation
@end cartouche

The MPS `splats' a weak reference in a @ref{23,,formatted object} by
replacing it with a null pointer when it is @ref{b4,,fixed} by the object
format’s @ref{73,,scan method}. So the scan method for the buckets is
going to have the following structure. (See below for the actual code.)

@example
static mps_res_t buckets_scan(mps_ss_t ss, mps_addr_t base, mps_addr_t limit)
@{
    MPS_SCAN_BEGIN(ss) @{
        while (base < limit) @{
            buckets_t buckets = base;
            size_t length = buckets->length;
            for (i = 0; i < length; ++i) @{
                mps_addr_t p = buckets->bucket[i];
                if (MPS_FIX1(ss, p)) @{
                    mps_res_t res = MPS_FIX2(ss, &p);
                    if (res != MPS_RES_OK) return res;
                    if (p == NULL) @{
                        /* TODO: key/value was splatted: splat value/key too */
                    @}
                    buckets->bucket[i] = p;
                @}
            @}
            base = (char *)base +
                ALIGN_OBJ(offsetof(buckets_s, bucket) +
                          length * sizeof(buckets->bucket[0]));
        @}
    @} MPS_SCAN_END(ss);
    return MPS_RES_OK;
@}
@end example

But how can the corresponding key/value be splatted? A format method is
not normally allowed to access memory managed by the MPS in pools that
might protect their objects (see the @ref{c0,,Cautions}
section in @ref{6a,,Object formats}). The AWL pool class relaxes this
constraint by allowing each object in the pool to have a
@ref{ff,,dependent object}. When @ref{65,,scanning} an object in an
AWL pool, the MPS ensures that the dependent object is not protected.
The dependent object does not have to be in the same pool as the
original object, but must be in a non-moving pool. See
@ref{100,,Dependent objects}.

So the value buckets will be the dependent object of the key buckets,
and vice versa.

The AWL pool determines an object’s dependent object by calling a
function that you supply when creating the pool. This means that each
object needs to have a reference to its dependent object:

@example
static mps_addr_t buckets_find_dependent(mps_addr_t addr)
@{
    buckets_t buckets = addr;
    return buckets->dependent;
@}
@end example

There’s one final requirement to take into account before revealing the
new buckets structure, which is that each word in an object in an AWL
pool must either be a valid word-aligned reference, or else the bottom
bits of the word must be non-zero so that it does not look like an
aligned pointer. So the sizes stored in the buckets structure (the
length of the array of buckets, and the counts of used and deleted
buckets) must be tagged so that they cannot be mistaken for pointers.
See the @ref{101,,Caution} section in @ref{fe,,AWL (Automatic Weak Linked)}.

A one-bit tag suffices here:

@example
#define TAG_COUNT(i) (((i) << 1) + 1)
#define UNTAG_COUNT(i) ((i) >> 1)

typedef struct buckets_s @{
    struct buckets_s *dependent;  /* the dependent object */
    size_t length;                /* number of buckets (tagged) */
    size_t used;                  /* number of buckets in use (tagged) */
    size_t deleted;               /* number of deleted buckets (tagged) */
    obj_t bucket[1];              /* hash buckets */
@} buckets_s, *buckets_t;
@end example

Now the full details of the scan method can be given, with the revised
code highlighted:

@example
static mps_res_t buckets_scan(mps_ss_t ss, mps_addr_t base, mps_addr_t limit)
@{
    MPS_SCAN_BEGIN(ss) @{
        while (base < limit) @{
            buckets_t buckets = base; /* see note 1 */
            size_t i, length = UNTAG_COUNT(buckets->length);
            FIX(buckets->dependent);
            if(buckets->dependent != NULL)
                assert(buckets->dependent->length == buckets->length);
            for (i = 0; i < length; ++i) @{
                mps_addr_t p = buckets->bucket[i];
                if (MPS_FIX1(ss, p)) @{
                    mps_res_t res = MPS_FIX2(ss, &p);
                    if (res != MPS_RES_OK) return res;
                    if (p == NULL) @{
                        /* key/value was splatted: splat value/key too */
                        p = obj_deleted; /* see note 3 */
                        buckets->deleted = TAG_COUNT(UNTAG_COUNT(buckets->deleted) + 1);
                        if (buckets->dependent != NULL) @{ /* see note 2 */
                            buckets->dependent->bucket[i] = p;
                            buckets->dependent->deleted
                                = TAG_COUNT(UNTAG_COUNT(buckets->dependent->deleted) + 1);
                        @}
                    @}
                    buckets->bucket[i] = p;
                @}
            @}
            base = (char *)base + ALIGN_OBJ(offsetof(buckets_s, bucket) +
                                            length * sizeof(buckets->bucket[0]));
        @}
    @} MPS_SCAN_END(ss);
    return MPS_RES_OK;
@}
@end example

@cartouche
@quotation Note 

@enumerate 

@item 
There’s no need to dispatch on the type of the buckets object (or
even to store a type at all) because buckets are the only objects
to be stored in this pool.

@item 
The dependent object must be @ref{b4,,fixed}, and because the
reference to it might be weak, it might be splatted. This means
that even if you are confident that you will always initialize
this field, you still have to guard access to it, as here.

@item 
This hash table implementation uses @code{NULL} to mean
“never used” and @code{obj_deleted} to mean “formerly used
but then deleted”. So when a key is splatted it is necessary to
replace it with @code{obj_deleted}.
@end enumerate
@end quotation
@end cartouche

The @ref{81,,skip method} is straightforward:

@example
static mps_addr_t buckets_skip(mps_addr_t base)
@{
    buckets_t buckets = base;
    size_t length = UNTAG_SIZE(buckets->length);
    return (char *)base + ALIGN_OBJ(offsetof(buckets_s, bucket) +
                                    length * sizeof(buckets->bucket[0]));
@}
@end example

Now we can create the object format, the pool and the allocation
points:

@example
/* Create the buckets format. */
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_FMT_ALIGN, ALIGNMENT);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_SCAN, buckets_scan);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_SKIP, buckets_skip);
    res = mps_fmt_create_k(&buckets_fmt, arena, args);
@} MPS_ARGS_END(args);
if (res != MPS_RES_OK) error("Couldn't create buckets format");

/* Create an Automatic Weak Linked (AWL) pool to manage the hash table
   buckets. */
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_FORMAT, buckets_fmt);
    MPS_ARGS_ADD(args, MPS_KEY_AWL_FIND_DEPENDENT, buckets_find_dependent);
    res = mps_pool_create_k(&buckets_pool, arena, mps_class_awl(), args);
@} MPS_ARGS_END(args);
if (res != MPS_RES_OK) error("Couldn't create buckets pool");

/* Create allocation points for weak and strong buckets. */
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_RANK, mps_rank_exact());
    res = mps_ap_create_k(&strong_buckets_ap, buckets_pool, args);
@} MPS_ARGS_END(args);
if (res != MPS_RES_OK) error("Couldn't create strong buckets allocation point");
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_RANK, mps_rank_weak());
    res = mps_ap_create_k(&weak_buckets_ap, buckets_pool, args);
@} MPS_ARGS_END(args);
if (res != MPS_RES_OK) error("Couldn't create weak buckets allocation point");
@end example

By adding the line:

@example
puts("splat!");
@end example

at the point in @code{buckets_scan()} where the splatting of a weak
reference is detected, we can see this happening:

@example
MPS Toy Scheme Example
24624, 0> (define ht (make-doubly-weak-hashtable string-hash string=?))
ht
25264, 0> (hashtable-set! ht "one" 1)
25456, 0> (hashtable-set! ht "two" 2)
25648, 0> (hashtable-set! ht "three" 3)
25840, 0> ht
#[hashtable ("two" 2) ("one" 1) ("three" 3)]
25864, 0> (gc)
splat!
splat!
splat!
25912, 1> ht
#[hashtable]
@end example

@ref{102,,Weak references}, @ref{fe,,AWL (Automatic Weak Linked)}.

@geindex Scheme; global symbol table

@node Global symbol table,Segregation of objects,Weak hash tables,Advanced topics
@anchor{guide/advanced global-symbol-table}@anchor{103}
@subsection Global symbol table


In the original (non-MPS) version of the toy Scheme interpreter, the
global symbol table was implemented as a key-only hash table, and each
symbol stored its own name.

But now that we have weak hash tables, it makes sense to re-implement
the global symbol table as a strong-key weak-value hash table mapping
strings to symbols. Each symbol will now contain a reference to its name
as a string object, instead of containing the name itself.


@float Figure

@image{MemoryPoolSystem-figures/symbol-table,,,Diagram: Global symbol table design (weak references shown as dashed lines).,svg}

@caption{Global symbol table design (weak references shown as dashed lines).}

@end float


This design depends on the string object containing the symbol name
being immutable. As it happens, all strings are immutable, because the
toy Scheme interpreter doesn’t implement @code{string-set!}, but if it did
then some care would need to be taken. (Either by marking these strings
as immutable in some way, or by ensuring that these strings are
“private”: that is, that Scheme programs never get hold of references to
them.)

When there are no more strong references to a symbol:


@enumerate 

@item 
the reference to the symbol from the “values” array may be splatted;

@item 
that’s detected by the buckets scan method, which deletes the
corresponding entry in the “keys” array;

@item 
which may in turn cause the symbol name to die, unless there are
other strong references keeping it alive.
@end enumerate

Here’s the new symbol structure:

@example
typedef struct symbol_s @{
    type_t type;                  /* TYPE_SYMBOL */
    obj_t name;                   /* its name (a string) */
@} symbol_s;
@end example

and the new implementation of @code{intern()}:

@example
static obj_t intern_string(obj_t name)
@{
    obj_t symbol;
    assert(TYPE(name) == TYPE_STRING);
    symbol = table_ref(symtab, name);
    if(symbol == NULL) @{
        symbol = make_symbol(name);
        table_set(symtab, name, symbol);
    @}
    return symbol;
@}

static obj_t intern(char *string)
@{
    return intern_string(make_string(strlen(string), string));
@}
@end example

The symbol table now becomes a very simple @ref{97,,root}, that only has
to be registered once (not @ref{94,,every time it is rehashed}, as previously):

@example
mps_addr_t ref;
symtab = NULL;
ref = &symtab;
res = mps_root_create_table(&symtab_root, arena, mps_rank_exact(), 0,
                            ref, 1);
if(res != MPS_RES_OK) error("Couldn't register symtab root");
symtab = make_table(16, string_hash, string_equalp, 0, 1);
@end example

@cartouche
@quotation Note 
The order of operations is important here. The global variable
@code{symtab} must be registered as a root before creating the
symbol table, otherwise the symbol table might be collected in
the interval between creation and registration. But we must also
ensure that @code{symtab} is valid (that is, scannable) before
registering it (in this case, by setting it to @code{NULL}).
@end quotation
@end cartouche

By printing @code{splat!} when the splatting of a weak reference is
detected by the scan method, we can see when symbols are dying:

@example
MPS Toy Scheme Example
24624, 0> (define a 1)
a
24832, 0> '(a b c d)
(a b c d)
25144, 0> (gc)
splat!
splat!
splat!
@end example

Here, the symbols @code{b}, @code{c} and @code{d} died, but @code{a} was kept alive
by the reference from the environment.

@geindex Scheme; segregation

@node Segregation of objects,,Global symbol table,Advanced topics
@anchor{guide/advanced guide-advanced-segregation}@anchor{104}@anchor{guide/advanced segregation-of-objects}@anchor{105}
@subsection Segregation of objects


When objects of different types have different properties (different
sizes, lifetimes, references, layouts) it makes sense to segregate
them into pools of appropriate classes. The garbage collector in the
MPS is designed to work efficiently with many pools: it traces
references between objects in different pools, and it coordinates the
scanning of the @ref{26,,registers} and @ref{27,,control stacks} (see
@ref{106,,Thread roots}).

For example, the toy Scheme interpreter has a mixture of object types,
some of which contain references to other objects (for example, pairs)
that must be @ref{65,,scanned}, and some of which do not (for
example, strings). If the @ref{107,,leaf objects} are segregated into a
pool of an appropriate class, the cost of scanning them can be
avoided.

Here the appropriate class is @ref{89,,AMCZ (Automatic Mostly-Copying Zero-rank)}, and the necessary code
changes are straightforward. First, global variables for the new pool
and its @ref{63,,allocation point}:

@example
static mps_pool_t leaf_pool;    /* pool for leaf objects */
static mps_ap_t leaf_ap;        /* allocation point for leaf objects */
@end example

Second, the leaf objects must be allocated on @code{leaf_ap} instead
of @code{obj_ap}. And third, the pool and its allocation point must
be created:

@example
/* Create an Automatic Mostly-Copying Zero-rank (AMCZ) pool to
   manage the leaf objects. */
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_CHAIN, obj_chain);
    MPS_ARGS_ADD(args, MPS_KEY_FORMAT, obj_fmt);
    res = mps_pool_create_k(&leaf_pool, arena, mps_class_amcz(), args);
@} MPS_ARGS_END(args);
if (res != MPS_RES_OK) error("Couldn't create leaf pool");

/* Create allocation point for leaf objects. */
res = mps_ap_create_k(&leaf_ap, leaf_pool, mps_args_none);
if (res != MPS_RES_OK) error("Couldn't create leaf objects allocation point");
@end example

Note that the new pool shares a @ref{e2,,generation chain} with the old
pool. This is important, because the leaf objects live and die along
with the non-leaf objects of similar ages.

As an initial step in making this change, the new pool uses the same
@ref{39,,object format}. However, we normally wouldn’t stop there: we’d
take advantage of the segregation to simplify the scanning of the
objects that have been left behind.

@ref{89,,AMCZ (Automatic Mostly-Copying Zero-rank)}.

@geindex malloc; implementing
@geindex free; implementing

@node Implementing malloc and free,,Advanced topics,Guide
@anchor{guide/malloc doc}@anchor{108}@anchor{guide/malloc guide-malloc}@anchor{109}@anchor{guide/malloc implementing-malloc-and-free}@anchor{10a}
@section Implementing malloc and free


The MPS function @ref{1f,,mps_free()} is unlike the Standard C Library
function @code{free()} in that it takes a @code{size} argument.
That’s because it’s nearly always the case that either the size of a
block is known statically based on its type (for example, a
structure), or else the size of the block is easily computed from
information that needs to be stored anyway (for example, a vector),
and so memory can be saved by not storing the size separately. It’s
also better for virtual memory performance, as a block does not have
to be touched in order to free it.

But sometimes you need to interact with @ref{10b,,foreign code} which
requires @code{malloc()} and @code{free()} (or a pair of functions
with the same interface). In this situation you can implement this
interface using a global pool variable, and putting the size of each
block into its header, like this:

@example
#include "mps.h"

static mps_pool_t malloc_pool;

typedef union @{
    size_t size;
    char alignment[MPS_PF_ALIGN]; /* see note below */
@} header_u;

void *malloc(size_t size) @{
    mps_res_t res;
    mps_addr_t p;
    header_u *header;
    size += sizeof *header;
    res = mps_alloc(&p, malloc_pool, size);
    if (res != MPS_RES_OK)
        return NULL;
    header = p;
    header->size = size;
    return header + 1;
@}

void free(void *p) @{
    if (p) @{
        header_u *header = ((header_u *)p) - 1;
        mps_free(malloc_pool, header, header->size);
    @}
@}
@end example

The @code{alignment} member of the @code{header_u} union
ensures that allocations are aligned to the platform’s @ref{70,,natural alignment} (see @ref{6c,,Alignment}).

The pool needs to belong to a @ref{8,,manually managed} pool class, for example @ref{10c,,MVFF (Manual Variable First Fit)} (or its
@ref{10d,,debugging counterpart}):

@example
#include "mpscmvff.h"

void malloc_pool_init(mps_arena_t arena) @{
    mps_res_t res;
    res = mps_pool_create_k(&malloc_pool, arena, mps_class_mvff(), mps_args_none);
    if (res != RES_OK)
        abort();
@}
@end example

@node Reference,Pool reference,Guide,Top
@anchor{topic/index doc}@anchor{10e}@anchor{topic/index id1}@anchor{10f}@anchor{topic/index reference}@anchor{30}
@chapter Reference


@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mmdoc/protocol/mps/interface-types/>`_
@c `<https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mmdoc/doc/mps/ref-man/if-conv/>`_
@c `<https://info.ravenbrook.com/project/mps/master/design/interface-c/>`_

@geindex interface; introduction

@menu
* Interface conventions:: 
* Keyword arguments:: 
* Error handing:: 
* Arenas:: 
* Pools:: 
* Allocation: Allocation<2>. 
* Object formats:: 
* Scanning:: 
* Threads: Threads<2>. 
* Roots: Roots<2>. 
* Garbage collection:: 
* Messages:: 
* Finalization: Finalization<2>. 
* Location dependency: Location dependency<2>. 
* Segregated allocation caches:: 
* Allocation patterns:: 
* Allocation frames:: 
* Debugging pools:: 
* Telemetry:: 
* Weak references:: 
* Transforms:: 
* Plinth:: 
* Platforms: Platforms<2>. 
* Porting the MPS:: 
* Deprecated interfaces:: 
* Security issues:: 

@end menu

@node Interface conventions,Keyword arguments,,Reference
@anchor{topic/interface doc}@anchor{110}@anchor{topic/interface interface-conventions}@anchor{111}@anchor{topic/interface topic-interface}@anchor{112}
@section Interface conventions


This document describes the conventions used in the programming
interface to the Memory Pool System. It also contains our @ref{113,,policy for support for the public identifiers} and
@ref{114,,definitions of general types} that
appear throughout the interface.

@geindex interface; support policy

@menu
* Support policy:: 
* Language:: 
* Headers:: 
* Identifiers:: 
* Types:: 
* Functions:: 
* Type punning:: 
* Macros:: 
* General types:: 

@end menu

@node Support policy,Language,,Interface conventions
@anchor{topic/interface support-policy}@anchor{115}@anchor{topic/interface topic-interface-support}@anchor{113}
@subsection Support policy



@enumerate 

@item 
We support the documented behaviour of public symbols in the MPS
interface. We will only remove these symbols or change their
behaviour in a new version, and not in a patch release. Normally
we will give one version’s notice before removing a symbol or
changing a particular documented behaviour: that is, there will be
a version in which the symbol (or reliance on some of its
behaviour) is deprecated.

Symbols may be deprecated in their old place in the reference
manual, or they may be moved to the @ref{116,,Deprecated interfaces}
chapter.

@cartouche
@quotation Note 
If you are relying on a feature and you see that it’s
deprecated, please @ref{d8,,contact us}. It makes a
difference if we know that someone is using a feature.
@end quotation
@end cartouche

@item 
Behaviour that is not documented in the @ref{3,,Guide},
@ref{30,,Reference}, or @ref{22,,Pool reference} is not supported and may change
without notice in future releases. In particular, private
identifiers may disappear or their behaviour be changed without
notice in future releases.
@end enumerate

@geindex interface; language

@node Language,Headers,Support policy,Interface conventions
@anchor{topic/interface language}@anchor{117}
@subsection Language



@enumerate 

@item 
The MPS public interface conforms to @ref{118,,ANSI/ISO Standard C (IEC 9899;1990)}.
@end enumerate

@geindex interface; headers

@node Headers,Identifiers,Language,Interface conventions
@anchor{topic/interface headers}@anchor{119}
@subsection Headers



@enumerate 

@item 
The main interface is in the header @code{mps.h}. This header
contains all the core MPS interfaces. In practice, you always need
at least one arena class and one pool class header file as well.

@item 
We will always prefix public header file names with @code{mps} to
avoid clashes. We reserve the right to create new headers
with names beginning with @code{mps} in future versions.

@item 
@ref{10,,Pool class} headers have names beginning with @code{mpsc}. For
example, the header for @ref{62,,AMC (Automatic Mostly-Copying)} is @code{mpscamc.h}.

@item 
@ref{11a,,Arena class} headers have names beginning with @code{mpsa}. For
example, the header for the @ref{4f,,virtual memory arena} class is
@code{mpsavm.h}.
@end enumerate

@geindex interface; identifiers

@node Identifiers,Types,Headers,Interface conventions
@anchor{topic/interface identifiers}@anchor{11b}
@subsection Identifiers



@enumerate 

@item 
Identifiers are in lower case, except for preprocessor constants
and macros that do not behave like functions, which are in upper
case. Words are joined by underscores.

@item 
All identifiers are either `public' or `private'.

@item 
The names of public types, functions, variables, and macros start
with @code{mps_} or @code{MPS_}. The names of public structure members
start with any letter.

@item 
Private identifiers start with an underscore @code{_}.

@item 
Type names end with @code{_t}, except for structure and union types.

@item 
The names of structure types and tags end with @code{_s}.

@item 
The names of union types and tags end with @code{_u}.
@end enumerate

@geindex interface; types

@node Types,Functions,Identifiers,Interface conventions
@anchor{topic/interface types}@anchor{11c}
@subsection Types


There are two kinds of types declared in the MPS interface:
`transparent types' and `opaque types'.


@enumerate 

@item 
A `transparent type' is an alias defined using @code{typedef}, and this
is documented so that the @ref{d0,,client program} can rely on that
fact. For example, @ref{11d,,mps_addr_t} is a transparent alias for
@code{void *}. Transparent types express intentions in the interface:
in the case of @ref{11d,,mps_addr_t} it represents a pointer that
is under the control of the MPS.

@item 
An `opaque type' is a pointer to an incomplete structure type. The
client program must not rely on details of its implementation. For
example, the type @ref{11e,,mps_arena_t} is an alias for @code{struct
mps_arena_s *}, but the implementation of @code{struct mps_arena_s}
is not public.

There are a few structure types that are declared in @code{mps.h} but
whose implementation is not public. These only exist so that code
can be inlined using macros. The most important of these is the
@ref{79,,scan state} structure @code{mps_ss_s}, which is accessed by
scanning macros such as @ref{7a,,MPS_SCAN_BEGIN} and
@ref{77,,MPS_FIX12()}.
@end enumerate

@geindex interface; functions

@node Functions,Type punning,Types,Interface conventions
@anchor{topic/interface functions}@anchor{11f}
@subsection Functions



@enumerate 

@item 
Operations that might fail return a @ref{59,,result code}, rather
than a “special value” of the return type. See @ref{5b,,Error handing}.

@item 
A function that needs to return a value as well as a result code
returns the value via an @ref{58,,out parameter}, a parameter that
points to a location to store the result.

@item 
A function that stores a result in the location pointed to by an
out parameter only does so if the function is successful (that is,
if the function returns @ref{5a,,MPS_RES_OK}).

@item 
The value in the location pointed to by an out parameter is not
read by the function.

@item 
Out parameters have names ending with @code{_o}.

@item 
A function that both needs to read a value stored in a location and
update the value does so via an @ref{120,,in/out parameter}, which is
the same as an out parameter except that the location it points to
is read by the function. See for example @ref{77,,MPS_FIX12()}.

@item 
In/out parameters have names ending with @code{_io}.

@item 
A function that takes optional arguments does so in the form of an
array of keyword argument structures. These functions have names
ending with @code{_k}. See @ref{57,,Keyword arguments}.
@end enumerate

@geindex interface; type punning
@geindex punning; type
@geindex type punning

@node Type punning,Macros,Functions,Interface conventions
@anchor{topic/interface topic-interface-pun}@anchor{121}@anchor{topic/interface type-punning}@anchor{122}
@subsection Type punning


It’s tempting to use a type cast to change the type of an in/out or
out parameter, like this:

@example
/* allocate a struct foo */
struct foo *fp;
res = mps_alloc((mps_addr_t *)&fp, pool, sizeof(struct foo));
@end example

This is known as @ref{a5,,type punning}, and its behaviour is not
defined in ANSI/ISO Standard C. See @ref{118,,ISO/IEC 9899;1990}
§6.3.2.3, which defines the conversion of a pointer from one type to
another: the behaviour of this cast is not covered by any of the cases
in the standard.

Instead, we recommend this approach:

@example
mps_addr_t p;
struct foo *fp;
res = mps_alloc(&p, pool, sizeof(struct foo));
if (res != MPS_RES_OK)
    /* handle error case */;
fp = p;
@end example

This has defined behaviour because conversion from @code{void *} to any
other @ref{6e,,object pointer} type is defined by @ref{118,,ISO/IEC 9899;1990} §6.3.2.3.1.

@geindex interface; macros

@node Macros,General types,Type punning,Interface conventions
@anchor{topic/interface macros}@anchor{123}
@subsection Macros



@enumerate 

@item 
For function-like macros, the MPS follows the same convention as
the Standard C library. To quote @ref{118,,ISO/IEC 9899;1990}
§7.1.7:

@quotation

Any function declared in a header may additionally be
implemented as a macro defined in the header, so a library
function should not be declared explicitly if its header is
included. Any macro definition of a function can be suppressed
locally by enclosing the name of the function in parentheses,
because the name is then not followed by the left parenthesis
that indicates expansion of a macro function name. […] Any
invocation of a library function that is implemented as a
macro shall expand to code that evaluates each of its
arguments exactly once, fully protected by parentheses where
necessary, so it is generally safe to use arbitrary
expressions as arguments.
@end quotation

@item 
Some function-like macros evaluate an argument more than once, so
it is not safe to have a side effect in an argument of such a
method. These special cases are documented. For example,
@ref{b0,,mps_reserve()}.

@item 
If you need the function rather than the macro, there are two
approaches. You can undefine the macro:

@example
#undef mps_reserve
res = mps_reserve(...);  /* calls function */
@end example

Or you can put the name in parentheses:

@example
res = (mps_reserve)(...);  /* calls function */
@end example

@item 
Statement-like macros have names in uppercase, for example
@ref{124,,MPS_RESERVE_BLOCK}. These macros behave like statements
rather than expressions, so that you cannot write:

@example
(MPS_RESERVE_BLOCK(res, p, ap, size), 0)
@end example

@item 
Details of the macro expansion, although visible in the header
file, are not part of the MPS interface, and might change between
releases. Don’t rely on them, unless they are documented
separately.
@end enumerate

@node General types,,Macros,Interface conventions
@anchor{topic/interface general-types}@anchor{125}@anchor{topic/interface topic-interface-general}@anchor{114}
@subsection General types


@geindex mps_addr_t (C type)
@anchor{topic/interface c mps_addr_t}@anchor{11d}
@deffn {C Type} type mps_addr_t

The type of @ref{126,,addresses} managed by the MPS, and also the
type of @ref{24,,references}.

It is a @ref{127,,transparent alias} for @code{void *}.

It is used in the MPS interface for any pointer that is under the
control of the MPS. In accordance with standard @ref{1c,,C}
practice, null pointers of type @ref{11d,,mps_addr_t} will never be
used to represent a reference to a block.
@end deffn

@geindex mps_align_t (C type)
@anchor{topic/interface c mps_align_t}@anchor{128}
@deffn {C Type} type mps_align_t

The type of an @ref{68,,alignment}.

It is a @ref{127,,transparent alias} for @code{size_t}.

An alignment must be a positive power of 2.
@end deffn

@geindex mps_bool_t (C type)
@anchor{topic/interface c mps_bool_t}@anchor{129}
@deffn {C Type} type mps_bool_t

The type of a Boolean value.

It is a @ref{127,,transparent alias} for @code{int}.

When used as an input parameter to the MPS, a value of 0 means
“false” and any other value means “true”. As an output parameter
or function return from the MPS, 0 means “false”, and 1 means
“true”.
@end deffn

@geindex mps_clock_t (C type)
@anchor{topic/interface c mps_clock_t}@anchor{12a}
@deffn {C Type} type mps_clock_t

The type of a processor time.

It is a @ref{127,,transparent alias} for
@ref{6d,,mps_word_t}.

This is the type returned by the plinth function
@ref{12b,,mps_clock()}.
@end deffn

@geindex mps_fun_t (C type)
@anchor{topic/interface c mps_fun_t}@anchor{12c}
@deffn {C Type} type mps_fun_t

The type of a generic function pointer.

It is a @ref{127,,transparent alias} for
@code{void (*)(void)}.
@end deffn

@geindex mps_label_t (C type)
@anchor{topic/interface c mps_label_t}@anchor{12d}
@deffn {C Type} type mps_label_t

The type of a @ref{12e,,telemetry label}.

It is an unsigned integral type.
@end deffn

@geindex mps_word_t (C type)
@anchor{topic/interface c mps_word_t}@anchor{6d}
@deffn {C Type} type mps_word_t

An unsigned integral type that is the same size as an
@ref{6e,,object pointer}, so that @code{sizeof(mps_word_t) ==
sizeof(void *)}.

The exact identity of this type is
@ref{12f,,platform}-dependent. Typical identities are @code{unsigned
long} and @code{unsigned __int_64}.

@ref{130,,Platforms}.
@end deffn

@geindex arguments; keyword

@node Keyword arguments,Error handing,Interface conventions,Reference
@anchor{topic/keyword doc}@anchor{131}@anchor{topic/keyword keyword-arguments}@anchor{132}@anchor{topic/keyword topic-keyword}@anchor{57}
@section Keyword arguments


Some functions in the MPS interface take @ref{53,,keyword arguments} in
order to pass values that might be optional, or are only required in
some circumstances. For example, the function
@ref{52,,mps_arena_create_k()} creates any class of @ref{16,,arena}, but
@ref{4d,,client arenas} require you to specify a base address. These
arguments are passed in a keyword argument array, like this:

@example
mps_res_t res;
mps_arena_t arena;
mps_arg_s args[3];
args[0].key = MPS_KEY_ARENA_SIZE;
args[0].val.size = 6553600;
args[1].key = MPS_KEY_ARENA_CL_BASE;
args[1].val.addr = base_address;
args[2].key = MPS_KEY_ARGS_END;
res = mps_arena_create_k(&arena, mps_arena_class_cl(), args);
@end example

Each keyword argument in the array is a structure of type
@ref{56,,mps_arg_s}.

For convenience and robustness, the MPS interface includes macros to
help with forming keyword argument lists:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_ARENA_SIZE, 6553600);
    MPS_ARGS_ADD(args, MPS_KEY_ARENA_CL_BASE, base_address);
    res = mps_arena_create_k(&arena, mps_arena_class_cl(), args);
@} MPS_ARGS_END(args);
@end example

The argument array must not be @code{NULL}, and must end with
@code{MPS_KEY_ARGS_END}. If you don’t want to pass any arguments,
you can pass @ref{133,,mps_args_none}.

When a function that takes keyword arguments returns, the keyword
argument array has been `modified' to remove any arguments that have
been used. If all arguments have been used, the first element key is
now @code{MPS_KEY_ARGS_END}.

@geindex mps_arg_s (C type)
@anchor{topic/keyword c mps_arg_s}@anchor{56}
@deffn {C Type} type mps_arg_s

The type of the structure used to represent a single
@ref{53,,keyword argument} to a function.

@example
typedef struct mps_arg_s @{
    mps_key_t key;
    union @{ /* many fields; see table below */ @} val;
@} mps_arg_s;
@end example

@code{key} identifies the key. It must be one of the values listed in
the documentation for the type @ref{134,,mps_key_t}.

@code{val} is the corresponding value. This union contains many
fields: one for each keyword argument type. The table given in the
documentation for @ref{134,,mps_key_t} below indicates which
structure field is used by each keyword.

@cartouche
@quotation Note 
If you use the convenience macro @ref{135,,MPS_ARGS_ADD} then
you don’t need to know the name of the field.
@end quotation
@end cartouche
@end deffn

@geindex mps_args_none (C macro)
@anchor{topic/keyword c mps_args_none}@anchor{133}
@deffn {C Macro} mps_args_none

An array of @ref{56,,mps_arg_s} representing the empty list of
keyword arguments. Equivalent to:

@example
mps_arg_s mps_args_none[] = @{@{MPS_KEY_ARGS_END@}@};
@end example
@end deffn

@geindex mps_key_t (C type)
@anchor{topic/keyword c mps_key_t}@anchor{134}
@deffn {C Type} type mps_key_t

The type of @ref{53,,keyword argument} keys. Must take one of the
following values:


@multitable {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Keyword

@tab

Type & field in @code{arg.val}

@tab

See

@item

@code{MPS_KEY_ARGS_END}

@tab

`none'

@tab

`see above'

@item

@code{MPS_KEY_ALIGN}

@tab

@ref{128,,mps_align_t}             @code{align}

@tab

@ref{136,,mps_class_mvff()}, @ref{137,,mps_class_mvt()}

@item

@code{MPS_KEY_AMS_SUPPORT_AMBIGUOUS}

@tab

@ref{129,,mps_bool_t}              @code{b}

@tab

@ref{138,,mps_class_ams()}

@item

@code{MPS_KEY_ARENA_CL_BASE}

@tab

@ref{11d,,mps_addr_t}              @code{addr}

@tab

@ref{4e,,mps_arena_class_cl()}

@item

@code{MPS_KEY_ARENA_GRAIN_SIZE}

@tab

@code{size_t}                  @code{size}

@tab

@ref{50,,mps_arena_class_vm()}, @ref{4e,,mps_arena_class_cl()}

@item

@code{MPS_KEY_ARENA_SIZE}

@tab

@code{size_t}                  @code{size}

@tab

@ref{50,,mps_arena_class_vm()}, @ref{4e,,mps_arena_class_cl()}

@item

@code{MPS_KEY_AWL_FIND_DEPENDENT}

@tab

@code{void *(*)(void *)}             @code{addr_method}

@tab

@ref{139,,mps_class_awl()}

@item

@code{MPS_KEY_CHAIN}

@tab

@ref{13a,,mps_chain_t}             @code{chain}

@tab

@ref{13b,,mps_class_amc()}, @ref{13c,,mps_class_amcz()}, @ref{138,,mps_class_ams()}, @ref{139,,mps_class_awl()}, @ref{13d,,mps_class_lo()}

@item

@code{MPS_KEY_COMMIT_LIMIT}

@tab

@code{size_t}                  @code{size}

@tab

@ref{50,,mps_arena_class_vm()}, @ref{4e,,mps_arena_class_cl()}

@item

@code{MPS_KEY_EXTEND_BY}

@tab

@code{size_t}                  @code{size}

@tab

@ref{13b,,mps_class_amc()}, @ref{13c,,mps_class_amcz()}, @ref{13e,,mps_class_mfs()}, @ref{136,,mps_class_mvff()}

@item

@code{MPS_KEY_FMT_ALIGN}

@tab

@ref{128,,mps_align_t}             @code{align}

@tab

@ref{13f,,mps_fmt_create_k()}

@item

@code{MPS_KEY_FMT_CLASS}

@tab

@ref{140,,mps_fmt_class_t}         @code{fmt_class}

@tab

@ref{13f,,mps_fmt_create_k()}

@item

@code{MPS_KEY_FMT_FWD}

@tab

@ref{86,,mps_fmt_fwd_t}           @code{fmt_fwd}

@tab

@ref{13f,,mps_fmt_create_k()}

@item

@code{MPS_KEY_FMT_HEADER_SIZE}

@tab

@code{size_t}                  @code{size}

@tab

@ref{13f,,mps_fmt_create_k()}

@item

@code{MPS_KEY_FMT_ISFWD}

@tab

@ref{8d,,mps_fmt_isfwd_t}         @code{fmt_isfwd}

@tab

@ref{13f,,mps_fmt_create_k()}

@item

@code{MPS_KEY_FMT_PAD}

@tab

@ref{91,,mps_fmt_pad_t}           @code{fmt_pad}

@tab

@ref{13f,,mps_fmt_create_k()}

@item

@code{MPS_KEY_FMT_SCAN}

@tab

@ref{74,,mps_fmt_scan_t}          @code{fmt_scan}

@tab

@ref{13f,,mps_fmt_create_k()}

@item

@code{MPS_KEY_FMT_SKIP}

@tab

@ref{82,,mps_fmt_skip_t}          @code{fmt_skip}

@tab

@ref{13f,,mps_fmt_create_k()}

@item

@code{MPS_KEY_FORMAT}

@tab

@ref{141,,mps_fmt_t}               @code{format}

@tab

@ref{13b,,mps_class_amc()}, @ref{13c,,mps_class_amcz()}, @ref{138,,mps_class_ams()}, @ref{139,,mps_class_awl()}, @ref{13d,,mps_class_lo()} , @ref{142,,mps_class_snc()}

@item

@code{MPS_KEY_GEN}

@tab

@code{unsigned}                      @code{u}

@tab

@ref{138,,mps_class_ams()}, @ref{139,,mps_class_awl()}, @ref{13d,,mps_class_lo()}

@item

@code{MPS_KEY_INTERIOR}

@tab

@ref{129,,mps_bool_t}              @code{b}

@tab

@ref{13b,,mps_class_amc()}, @ref{13c,,mps_class_amcz()}

@item

@code{MPS_KEY_MEAN_SIZE}

@tab

@code{size_t}                  @code{size}

@tab

@ref{137,,mps_class_mvt()}, @ref{136,,mps_class_mvff()}

@item

@code{MPS_KEY_MFS_UNIT_SIZE}

@tab

@code{size_t}                  @code{size}

@tab

@ref{13e,,mps_class_mfs()}

@item

@code{MPS_KEY_MIN_SIZE}

@tab

@code{size_t}                  @code{size}

@tab

@ref{137,,mps_class_mvt()}

@item

@code{MPS_KEY_MVFF_ARENA_HIGH}

@tab

@ref{129,,mps_bool_t}              @code{b}

@tab

@ref{136,,mps_class_mvff()}

@item

@code{MPS_KEY_MVFF_FIRST_FIT}

@tab

@ref{129,,mps_bool_t}              @code{b}

@tab

@ref{136,,mps_class_mvff()}

@item

@code{MPS_KEY_MVFF_SLOT_HIGH}

@tab

@ref{129,,mps_bool_t}              @code{b}

@tab

@ref{136,,mps_class_mvff()}

@item

@code{MPS_KEY_MVT_FRAG_LIMIT}

@tab

@ref{6d,,mps_word_t}              @code{count}

@tab

@ref{137,,mps_class_mvt()}

@item

@code{MPS_KEY_MVT_RESERVE_DEPTH}

@tab

@ref{6d,,mps_word_t}              @code{count}

@tab

@ref{137,,mps_class_mvt()}

@item

@code{MPS_KEY_PAUSE_TIME}

@tab

@code{double}                        @code{d}

@tab

@ref{50,,mps_arena_class_vm()}, @ref{4e,,mps_arena_class_cl()}

@item

@code{MPS_KEY_POOL_DEBUG_OPTIONS}

@tab

@ref{143,,mps_pool_debug_option_s} @code{*pool_debug_options}

@tab

@ref{144,,mps_class_ams_debug()}, @ref{145,,mps_class_mvff_debug()}

@item

@code{MPS_KEY_RANK}

@tab

@ref{146,,mps_rank_t}              @code{rank}

@tab

@ref{138,,mps_class_ams()}, @ref{139,,mps_class_awl()}, @ref{142,,mps_class_snc()}

@item

@code{MPS_KEY_SPARE}

@tab

@code{double}                        @code{d}

@tab

@ref{50,,mps_arena_class_vm()}, @ref{136,,mps_class_mvff()}

@item

@ref{147,,MPS_KEY_SPARE_COMMIT_LIMIT}

@tab

@code{size_t}                  @code{size}

@tab

@ref{50,,mps_arena_class_vm()}

@item

@code{MPS_KEY_VMW3_TOP_DOWN}

@tab

@ref{129,,mps_bool_t}              @code{b}

@tab

@ref{50,,mps_arena_class_vm()}

@end multitable

@end deffn

@geindex MPS_ARGS_BEGIN (C macro)
@anchor{topic/keyword c MPS_ARGS_BEGIN}@anchor{148}
@deffn {C Macro} MPS_ARGS_BEGIN (args)

Start construction of a list of keyword arguments. This macro must
be used like this:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_ARENA_SIZE, 6553600);
    MPS_ARGS_ADD(args, MPS_KEY_ARENA_CL_BASE, base_address);
    res = mps_arena_create_k(&arena, mps_arena_class_cl(), args);
@} MPS_ARGS_END(args);
@end example

That is, you must call @ref{135,,MPS_ARGS_ADD} (or
@ref{149,,MPS_ARGS_ADD_FIELD}) zero or more times, and then pass
the arguments to a function.

@code{args} is the name of the array that contains the keyword
arguments. The array is stack-allocated, and exists between
@ref{148,,MPS_ARGS_BEGIN} and @ref{14a,,MPS_ARGS_END}.

It is safe to nest blocks created by @ref{148,,MPS_ARGS_BEGIN} and
@ref{14a,,MPS_ARGS_END}.
@end deffn

@geindex MPS_ARGS_ADD (C macro)
@anchor{topic/keyword c MPS_ARGS_ADD}@anchor{135}
@deffn {C Macro} MPS_ARGS_ADD (args, key, value)

Add an argument to a list of keyword arguments. This macro must be
used only between @ref{148,,MPS_ARGS_BEGIN} and
@ref{14a,,MPS_ARGS_END}.

@code{args} is the name of array that contains the keyword arguments.
It must match the argument to the preceding call to
@ref{148,,MPS_ARGS_BEGIN}.

@code{key} is the keyword identifying this argument. It must be one
of the key names starting with @code{MPS_KEY_} that are listed in the
table in the documentation for @ref{134,,mps_key_t}.

@code{value} is the value for this argument.
@end deffn

@geindex MPS_ARGS_ADD_FIELD (C macro)
@anchor{topic/keyword c MPS_ARGS_ADD_FIELD}@anchor{149}
@deffn {C Macro} MPS_ARGS_ADD_FIELD (args, key, field, value)

Add an argument to a list of keyword arguments. This macro must be
used only between @ref{148,,MPS_ARGS_BEGIN} and
@ref{14a,,MPS_ARGS_END}.

@code{args} is the name of array that contains the keyword arguments.
It must match the argument to the preceding call to
@ref{148,,MPS_ARGS_BEGIN}.

@code{key} is the keyword identifying this argument.

@code{field} is the name of the field in the @code{val} union in the
structure @code{mps_args_s}.

@code{value} is the value for this argument.

@cartouche
@quotation Note 
You should prefer to use @ref{135,,MPS_ARGS_ADD}, because then
you don’t need to look up the name of the field.
@end quotation
@end cartouche
@end deffn

@geindex MPS_ARGS_END (C macro)
@anchor{topic/keyword c MPS_ARGS_END}@anchor{14a}
@deffn {C Macro} MPS_ARGS_END (args)

Finish using a list of keyword arguments whose construction was
started by @ref{148,,MPS_ARGS_BEGIN}.

@code{args} is the name of array that contains the keyword arguments.
It must match the argument to the preceding call to
@ref{148,,MPS_ARGS_BEGIN}.
@end deffn

@geindex error handling; introduction
@geindex result code

@node Error handing,Arenas,Keyword arguments,Reference
@anchor{topic/error doc}@anchor{14b}@anchor{topic/error error-handing}@anchor{14c}@anchor{topic/error topic-error}@anchor{5b}
@section Error handing


Operations in the Memory Pool System that might fail return a
@ref{59,,result code} of type @ref{14d,,mps_res_t}. Success is always
indicated by the result code @ref{5a,,MPS_RES_OK}, which is defined
to be zero. Other result codes indicate failure, and are non-zero. The
MPS never uses a “special value” of some other type to indicate
failure (such as returning @code{NULL} for a pointer result, or −1 for a
size result).

@cartouche
@quotation Note 
The MPS does not throw or catch exceptions. (This is necessary
for the MPS to be portable to systems that have only a
@ref{14e,,freestanding} implementation of the C language.)
@end quotation
@end cartouche

The modular nature of the MPS means that it is not usually possible
for a function description to list the possible error codes that it
might return. A function in the public interface typically calls
methods of an @ref{11a,,arena class} and one or more @ref{10,,pool classes}, any of which might fail. The MPS is extensible with new
arena and pool classes, which might fail in new and interesting ways,
so the only future-proof behaviour is for a @ref{d0,,client program} to
assume that any MPS function that returns a result code can return
`any' result code.

@geindex mps_res_t (C type)
@anchor{topic/error c mps_res_t}@anchor{14d}
@deffn {C Type} type mps_res_t

The type of @ref{59,,result codes}. It is a
@ref{127,,transparent alias} for @code{int}, provided
for convenience and clarity.

A result code indicates the success or failure of an operation,
along with the reason for failure. As with error numbers in Unix,
the meaning of a result code depends on the call that returned it.
Refer to the documentation of the function for the exact meaning
of each result code.

The result codes are:


@itemize *

@item 
@ref{5a,,MPS_RES_OK}: operation succeeded.

@item 
@ref{14f,,MPS_RES_FAIL}: operation failed.

@item 
@ref{150,,MPS_RES_IO}: an input/output error occurred.

@item 
@ref{151,,MPS_RES_LIMIT}: an internal limitation was exceeded.

@item 
@ref{152,,MPS_RES_MEMORY}: needed memory could not be obtained.

@item 
@ref{153,,MPS_RES_RESOURCE}: a needed resource could not be
obtained.

@item 
@ref{154,,MPS_RES_UNIMPL}: operation is not implemented.

@item 
@ref{155,,MPS_RES_COMMIT_LIMIT}: the arena’s @ref{156,,commit limit} would be exceeded.

@item 
@ref{157,,MPS_RES_PARAM}: an invalid parameter was passed.
@end itemize
@end deffn

@menu
* Result codes:: 
* Assertions:: 
* Varieties:: 

@end menu

@node Result codes,Assertions,,Error handing
@anchor{topic/error result-codes}@anchor{158}@anchor{topic/error topic-result-codes}@anchor{159}
@subsection Result codes


@geindex MPS_RES_COMMIT_LIMIT (C macro)
@anchor{topic/error c MPS_RES_COMMIT_LIMIT}@anchor{155}
@deffn {C Macro} MPS_RES_COMMIT_LIMIT

A @ref{59,,result code} indicating that an operation could not be
completed as requested without exceeding the @ref{156,,commit limit}.

You need to deallocate something or allow the @ref{20,,garbage collector} to reclaim something to make more space, or increase
the commit limit by calling @ref{15a,,mps_arena_commit_limit_set()}.
@end deffn

@geindex MPS_RES_FAIL (C macro)
@anchor{topic/error c MPS_RES_FAIL}@anchor{14f}
@deffn {C Macro} MPS_RES_FAIL

A @ref{59,,result code} indicating that something went wrong that
does not fall under the description of any other result code.
@end deffn

@geindex MPS_RES_IO (C macro)
@anchor{topic/error c MPS_RES_IO}@anchor{150}
@deffn {C Macro} MPS_RES_IO

A @ref{59,,result code} indicating that an input/output error
occurred in the @ref{15b,,telemetry system}.
@end deffn

@geindex MPS_RES_LIMIT (C macro)
@anchor{topic/error c MPS_RES_LIMIT}@anchor{151}
@deffn {C Macro} MPS_RES_LIMIT

A @ref{59,,result code} indicating that an operation could not be
completed as requested because of an internal limitation of the
MPS.
@end deffn

@geindex MPS_RES_MEMORY (C macro)
@anchor{topic/error c MPS_RES_MEMORY}@anchor{152}
@deffn {C Macro} MPS_RES_MEMORY

A @ref{59,,result code} indicating that an operation could not be
completed because there wasn’t enough memory available.

You need to deallocate something or allow the @ref{20,,garbage collector} to reclaim something to free enough memory, or extend
the @ref{16,,arena} (if you’re using an arena for which that does
not happen automatically).

@cartouche
@quotation Note 
Failing to acquire enough memory because the @ref{156,,commit limit} would have been exceeded is indicated by returning
@ref{155,,MPS_RES_COMMIT_LIMIT}, not @code{MPS_RES_MEMORY}.

Running out of @ref{54,,address space} (as might happen in
@ref{51,,virtual memory} systems) is indicated by returning
@ref{153,,MPS_RES_RESOURCE}, not @code{MPS_RES_MEMORY}.
@end quotation
@end cartouche
@end deffn

@geindex MPS_RES_OK (C macro)
@anchor{topic/error c MPS_RES_OK}@anchor{5a}
@deffn {C Macro} MPS_RES_OK

A @ref{59,,result code} indicating that an operation succeeded.

If a function takes an @ref{58,,out parameter} or an @ref{120,,in/out parameter}, this parameter will only be updated if
@ref{5a,,MPS_RES_OK} is returned. If any other result code is
returned, the parameter will be left untouched by the function.

@ref{5a,,MPS_RES_OK} is zero.
@end deffn

@geindex MPS_RES_PARAM (C macro)
@anchor{topic/error c MPS_RES_PARAM}@anchor{157}
@deffn {C Macro} MPS_RES_PARAM

A @ref{59,,result code} indicating that an operation could not be
completed as requested because an invalid parameter was passed to
the operation.
@end deffn

@geindex MPS_RES_RESOURCE (C macro)
@anchor{topic/error c MPS_RES_RESOURCE}@anchor{153}
@deffn {C Macro} MPS_RES_RESOURCE

A @ref{59,,result code} indicating that an operation could not be
completed as requested because the MPS could not obtain a needed
resource. It can be returned when the MPS runs out of
@ref{54,,address space}. If this happens, you need to reclaim memory
within your process (as for the result code
@ref{152,,MPS_RES_MEMORY}).

Two special cases have their own result codes: when the MPS runs
out of committed memory, it returns @ref{152,,MPS_RES_MEMORY}, and
when it cannot proceed without exceeding the @ref{156,,commit limit},
it returns @ref{155,,MPS_RES_COMMIT_LIMIT}.
@end deffn

@geindex MPS_RES_UNIMPL (C macro)
@anchor{topic/error c MPS_RES_UNIMPL}@anchor{154}
@deffn {C Macro} MPS_RES_UNIMPL

A @ref{59,,result code} indicating that an operation, or some vital
part of it, is not implemented.

This might be returned by functions that are no longer supported,
or by operations that are included for future expansion, but not
yet supported.
@end deffn

@geindex assertion
@geindex error handling; assertion

@node Assertions,Varieties,Result codes,Error handing
@anchor{topic/error assertions}@anchor{15c}@anchor{topic/error topic-error-assertion}@anchor{15d}
@subsection Assertions


Bugs in the @ref{d0,,client program} may violate the invariants that the
MPS relies on. Most functions in the MPS (in most `varieties'; see
below) assert the correctness of their data structures, so these bugs
will often be discovered by an assertion failure in the MPS. The
section @ref{cb,,Common assertions and their causes} below lists commonly encountered
assertions and explains the kinds of client program bugs that can
provoke these assertions.

It is very rare for an assertion to indicate a bug in the MPS rather
than the client program, but it is not unknown, so if you have made
every effort to track down the cause (see @ref{b6,,Debugging with the Memory Pool System}) without
luck, @ref{d8,,get in touch}.

@geindex assertion
@geindex error handling; assertion; assertion handling

@menu
* Assertion handling:: 
* Common assertions and their causes:: 

@end menu

@node Assertion handling,Common assertions and their causes,,Assertions
@anchor{topic/error assertion-handling}@anchor{15e}@anchor{topic/error topic-error-assertion-handling}@anchor{15f}
@subsubsection Assertion handling


When the MPS detects an assertion failure, it calls the @ref{160,,plinth}
function @ref{161,,mps_lib_assert_fail()}. Unless you have replaced the plinth, this behaves as follows:


@itemize -

@item 
In the @ref{c8,,cool} @ref{c9,,variety}, print the assertion message to
standard error and terminate the program by calling @code{abort()}.

@item 
In the @ref{162,,hot} and @ref{163,,rash} varieties, print the assertion
message to standard error and do `not' terminate the program.
@end itemize

You can change this behaviour by providing your own plinth, or using
@ref{164,,mps_lib_assert_fail_install()}.

In many applications, users don’t want their program terminated when
the MPS detects an error, no matter how severe. A lot of MPS
assertions indicate that the program is going to crash very soon, but
there still may be a chance for a user to get some useful results or
save their work. This is why the default assertion handler only
terminates in the @ref{c8,,cool} @ref{c9,,variety}.

@geindex assertion; common causes

@node Common assertions and their causes,,Assertion handling,Assertions
@anchor{topic/error common-assertions-and-their-causes}@anchor{165}@anchor{topic/error topic-error-cause}@anchor{cb}
@subsubsection Common assertions and their causes


This section lists some commonly encountered assertions and suggests
likely causes. If you encounter an assertion not listed here (or an
assertion that is listed here but for which you discovered a different
cause), please @ref{d8,,let us know} so that we can improve
this documentation.

@code{arg.c: MPS_KEY_...}

@quotation

A required @ref{53,,keyword argument} was omitted from a call to
@ref{af,,mps_ap_create_k()}, @ref{52,,mps_arena_create_k()},
@ref{13f,,mps_fmt_create_k()}, or @ref{166,,mps_pool_create_k()}.
@end quotation

@code{buffer.c: BufferIsReady(buffer)}

@quotation

The client program called @ref{b0,,mps_reserve()} twice on the same
@ref{63,,allocation point} without calling @ref{b2,,mps_commit()}. See
@ref{ae,,Allocation point protocol}.
@end quotation

@code{dbgpool.c: fencepost check on free}

@quotation

The client program wrote to a location after the end, or before
the beginning of an allocated block. See @ref{10d,,Debugging pools}.
@end quotation

@code{dbgpool.c: free space corrupted on release}

@quotation

The client program used an object after it was reclaimed. See
@ref{10d,,Debugging pools}.
@end quotation

@code{format.c: SigCheck Format: format}

@quotation

The client program called @ref{166,,mps_pool_create_k()} for a
@ref{10,,pool class} like @ref{62,,AMC (Automatic Mostly-Copying)} that requires a
@ref{39,,object format}, but passed something other than a
@ref{141,,mps_fmt_t} for this argument.
@end quotation

@code{format.c: format->poolCount == 0}

@quotation

The client program called @ref{167,,mps_fmt_destroy()} on a format
that was still being used by a pool. It is necessary to call
@ref{168,,mps_pool_destroy()} first.
@end quotation

@code{global.c: RingIsSingle(&arena->chainRing)}

@quotation

The client program called @ref{169,,mps_arena_destroy()} without
destroying all the @ref{e2,,generation chains} belonging to the
arena. It is necessary to call @ref{16a,,mps_chain_destroy()} first.
@end quotation

@code{global.c: RingIsSingle(&arena->formatRing)}

@quotation

The client program called @ref{169,,mps_arena_destroy()} without
destroying all the @ref{39,,object formats} belonging to the arena.
It is necessary to call @ref{167,,mps_fmt_destroy()} first.
@end quotation

@code{global.c: RingIsSingle(&arenaGlobals->rootRing)}

@quotation

The client program called @ref{169,,mps_arena_destroy()} without
destroying all the @ref{97,,roots} belonging to the arena.
It is necessary to call @ref{a2,,mps_root_destroy()} first.
@end quotation

@code{global.c: RingIsSingle(&arena->threadRing)}

@quotation

The client program called @ref{169,,mps_arena_destroy()} without
deregistering all the @ref{99,,threads} belonging to the arena.
It is necessary to call @ref{16b,,mps_thread_dereg()} first.
@end quotation

@code{global.c: RingLength(&arenaGlobals->poolRing) == arenaGlobals->systemPools}

@quotation

The client program called @ref{169,,mps_arena_destroy()} without
destroying all the @ref{18,,pools} belonging to the arena.
It is necessary to call @ref{168,,mps_pool_destroy()} first.
@end quotation

@code{global.c: PoolHasAttr(pool, AttrGC)}

@quotation

The client program called @ref{e8,,mps_finalize()} on a reference
that does not belong to an @ref{9,,automatically managed} @ref{18,,pool}.
@end quotation

@code{lockix.c: res == 0}

@code{lockw3.c: lock->claims == 0}

@quotation

The client program has made a re-entrant call into the MPS. Look
at the backtrace to see what it was. Common culprits are signal
handlers, assertion handlers, and @ref{69,,format methods}.
@end quotation

@code{locus.c: gen->activeTraces == TraceSetEMPTY}

@quotation

The client program called @ref{16a,,mps_chain_destroy()}, but there
was a garbage collection in progress on that chain. Park the arena
before destroying the chain, by calling @ref{b9,,mps_arena_park()}.
@end quotation

@code{mpsi.c: SizeIsAligned(size, BufferPool(buf)->alignment)}

@quotation

The client program reserved a block by calling
@ref{b0,,mps_reserve()} but neglected to round the size up to the
alignment required by the pool’s @ref{39,,object format}.
@end quotation

@code{poolams.c: AMS_ALLOCED(seg, i)}

@quotation

The client program tried to @ref{b4,,fix} a @ref{24,,reference} to a
block in an @ref{16c,,AMS (Automatic Mark and Sweep)} pool that died. This may mean that
there was a previous collection in which a reference that should
have kept the block alive failed to be scanned. Perhaps a
@ref{23,,formatted object} was updated in some way that has a race
condition?
@end quotation

@code{poolsnc.c: foundSeg}

@quotation

The client program passed an incorrect @code{frame} argument to
@ref{16d,,mps_ap_frame_pop()}. This argument must be the result from
a previous call to @ref{16e,,mps_ap_frame_push()} on the same
allocation point.
@end quotation

@code{seg.c: gcseg->buffer == NULL}

@quotation

The client program destroyed a pool without first destroying all
the allocation points created on that pool. The allocation points
must be destroyed first.
@end quotation

@code{trace.c: ss->rank < RankEXACT}

@quotation

The client program destroyed a pool containing objects registered
for finalization, and then continued to run the garbage collector.
See @ref{ef,,Cautions} under
@ref{f0,,Finalization}, which says, “You must destroy these
pools by following the ‘safe tear-down’ procedure described under
@ref{168,,mps_pool_destroy()}.”
@end quotation

@code{trace.c: RefSetSub(ScanStateUnfixedSummary(ss), SegSummary(seg))}

@quotation

The client program’s @ref{73,,scan method} failed to update a
reference to an object that moved. See
@ref{16f,,Scanning protocol}, which says, “If @ref{76,,MPS_FIX2()}
returns @ref{5a,,MPS_RES_OK}, it may have updated the reference.
Make sure that the updated reference is stored back to the region
being scanned.”
@end quotation

@geindex error handling; varieties
@geindex variety

@node Varieties,,Assertions,Error handing
@anchor{topic/error topic-error-variety}@anchor{170}@anchor{topic/error varieties}@anchor{171}
@subsection Varieties


The MPS has three `varieties' which have different levels of internal
checking, @ref{15d,,Assertions} and @ref{db,,Telemetry}. The
variety can be selected at compile time, by defining one of the
following preprocessor constants. If none is specified then
@ref{172,,CONFIG_VAR_HOT} is the default.

@geindex cool variety
@geindex variety; cool

@geindex CONFIG_VAR_COOL (C macro)
@anchor{topic/error c CONFIG_VAR_COOL}@anchor{ca}
@deffn {C Macro} CONFIG_VAR_COOL

The `cool variety' is intended for development and testing.

All functions check the consistency of their data structures and may
assert, including functions on the @ref{7c,,critical path}.
Furthermore, in the default ANSI Library the default assertion
handler will terminate the program.  See
@ref{164,,mps_lib_assert_fail_install()}.

All events are sent to the @ref{ba,,telemetry stream}, including
events on the @ref{7c,,critical path}.
@end deffn

@geindex hot variety
@geindex variety; hot

@geindex CONFIG_VAR_HOT (C macro)
@anchor{topic/error c CONFIG_VAR_HOT}@anchor{172}
@deffn {C Macro} CONFIG_VAR_HOT

The `hot variety' is intended for production and deployment.

Some functions check the consistency of their data structures and
may assert, namely those not on the @ref{7c,,critical path}.  However,
in the default ANSI Library, the default assertion handler will not
terminate the program.  See @ref{164,,mps_lib_assert_fail_install()}.

Some events are sent to the @ref{ba,,telemetry stream}, namely those
not on the @ref{7c,,critical path}.
@end deffn

@geindex rash variety
@geindex variety; rash

@geindex CONFIG_VAR_RASH (C macro)
@anchor{topic/error c CONFIG_VAR_RASH}@anchor{173}
@deffn {C Macro} CONFIG_VAR_RASH

The `rash variety' is intended for mature integrations, or for
developers who like living dangerously.

No functions check the consistency of their data structures and
consequently there are no assertions.

No events are sent to the @ref{ba,,telemetry stream}.
@end deffn

@c sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mmdoc/protocol/mps/arena/>`_
@c `<https://info.ravenbrook.com/project/mps/master/design/arena/>`_

@geindex arena

@node Arenas,Pools,Error handing,Reference
@anchor{topic/arena doc}@anchor{174}@anchor{topic/arena arenas}@anchor{175}@anchor{topic/arena topic-arena}@anchor{19}
@section Arenas


An arena is an object that encapsulates the state of the Memory Pool
System, and tells it where to get the memory it manages. You typically
start a session with the MPS by creating an arena with
@ref{52,,mps_arena_create_k()} and end the session by destroying it with
@ref{169,,mps_arena_destroy()}. The only functions you might need to call
before making an arena are @ref{15b,,telemetry system} functions like
@ref{176,,mps_telemetry_set()} and the @ref{160,,plinth} function
@ref{164,,mps_lib_assert_fail_install()}.

Before destroying an arena, you must first destroy all objects and
data in it, as usual for abstract data types in the MPS. If you can’t
destroy the arena properly (for example, because your program has
crashed and you are at the debugger prompt), you can still call
@ref{177,,mps_telemetry_flush()} explicitly.

Other types of objects in the MPS are created “in the arena”. They are
part of the world within the arena, and may interact and affect each
other.

@geindex arena; multiple

@cartouche
@quotation Note 
The MPS allows creation of multiple arenas, but you would only do
this in unusual circumstances, for example during the integration
of two pieces of software that each independently uses the MPS.

Arenas do not normally interact, but they compete with each other
for resources, and references from one arena to another are not
traced, though you `can' declare @ref{97,,roots} pointing
from one arena to another. It is not efficient to have multiple
arenas containing @ref{9,,automatically managed} @ref{18,,pools}: if you find yourself in this
situation it’s best to find a way to move all the automatically
managed pools to one arena.
@end quotation
@end cartouche

The open source MPS comes with two classes of arena,
@ref{178,,Client arenas} and @ref{179,,Virtual memory arenas}. These differ in
the way that they acquire the memory to be managed.

@cartouche
@quotation Note 
The MPS is designed to be extensible with new arena classes. If
you need features that are not provided by any of the open source
arena classes, @ref{d8,,contact us}.
@end quotation
@end cartouche

@geindex mps_arena_t (C type)
@anchor{topic/arena c mps_arena_t}@anchor{11e}
@deffn {C Type} type mps_arena_t

The type of @ref{16,,arenas}.

An arena is responsible for requesting @ref{17,,memory (3)} from
the operating system, making it available to @ref{18,,pools},
and for @ref{f,,garbage collection}.
@end deffn

@geindex mps_arena_class_t (C type)
@anchor{topic/arena c mps_arena_class_t}@anchor{17a}
@deffn {C Type} type mps_arena_class_t

The type of @ref{11a,,arena classes}.
@end deffn

@geindex mps_arena_create_k (C function)
@anchor{topic/arena c mps_arena_create_k}@anchor{52}
@deffn {C Function} @ref{14d,,mps_res_t} mps_arena_create_k (mps_arena_t *arena_o, mps_arena_class_t arena_class, mps_arg_s args[])

Create an @ref{16,,arena}.

@code{arena_o} points to a location that will hold a pointer to the new
arena.

@code{arena_class} is the @ref{11a,,arena class}.

@code{args} are @ref{53,,keyword arguments} specific to the arena
class. See the documentation for the arena class.

Returns @ref{5a,,MPS_RES_OK} if the arena is created
successfully, or another @ref{59,,result code} otherwise.

The arena persists until it is destroyed by calling
@ref{169,,mps_arena_destroy()}.
@end deffn

@geindex mps_arena_destroy (C function)
@anchor{topic/arena c mps_arena_destroy}@anchor{169}
@deffn {C Function} void mps_arena_destroy (mps_arena_t arena)

Destroy an @ref{16,,arena}.

@code{arena} is the arena to destroy.

This function checks the consistency of the arena, flushes the
@ref{ba,,telemetry stream} and destroys the arena’s internal control
structures. Additionally, @ref{4f,,virtual memory arenas} return
their reserved address space to the operating system if possible.

It is an error to destroy an arena without first destroying all
@ref{e2,,generation chains}, @ref{39,,object formats}, @ref{18,,pools}
and @ref{97,,roots} created in the arena, and deregistering all
@ref{99,,threads} registered with the arena.
@end deffn

@geindex arena class; client
@geindex client arena class

@menu
* Client arenas:: 
* Virtual memory arenas:: 
* Arena properties:: 
* Arena states:: 
* Running garbage collections:: 
* Using idle time for collection:: 
* Arena introspection and debugging:: 
* Arena extension callbacks:: 

@end menu

@node Client arenas,Virtual memory arenas,,Arenas
@anchor{topic/arena client-arenas}@anchor{17b}@anchor{topic/arena topic-arena-client}@anchor{178}
@subsection Client arenas


@example
#include "mpsacl.h"
@end example

@geindex mps_arena_class_cl (C function)
@anchor{topic/arena c mps_arena_class_cl}@anchor{4e}
@deffn {C Function} @ref{17a,,mps_arena_class_t} mps_arena_class_cl (void)

Return the @ref{11a,,arena class} for a @ref{4d,,client arena}.

A client arena gets its managed memory from the @ref{d0,,client program}. This memory chunk is passed when the arena is created.

When creating a client arena, @ref{52,,mps_arena_create_k()} requires two
@ref{53,,keyword arguments}:


@itemize *

@item 
@code{MPS_KEY_ARENA_CL_BASE} (type @ref{11d,,mps_addr_t}) is
the @ref{126,,address} of the chunk of memory that will be managed
by the arena.

@item 
@code{MPS_KEY_ARENA_SIZE} (type @code{size_t}) is its
size.
@end itemize

It also accepts five optional keyword arguments:


@itemize *

@item 
@code{MPS_KEY_COMMIT_LIMIT} (type @code{size_t}) is
the maximum amount of memory, in @ref{17c,,bytes (1)}, that the MPS
will use out of the provided chunk (or chunks, if the arena is
extended). See @ref{17d,,mps_arena_commit_limit()} for details. The
default commit limit is the maximum value of the
@code{size_t} type.

@item 
@code{MPS_KEY_ARENA_GRAIN_SIZE} (type @code{size_t},
default 8192) is the granularity with which the arena will
manage memory internally. It must be a power of 2, and at least
@code{sizeof(void *)}. Larger granularity reduces overheads, but
increases @ref{17e,,fragmentation} and @ref{17f,,retention}.

@item 
@code{MPS_KEY_PAUSE_TIME} (type @code{double}, default 0.1) is
the maximum time, in seconds, that operations within the arena
may pause the @ref{d0,,client program} for. See
@ref{180,,mps_arena_pause_time_set()} for details.

@item 
@code{MPS_KEY_ARENA_EXTENDED} (type @ref{12c,,mps_fun_t}) is
a function that will be called immediately after the arena is
`extended': that is, just after it acquires a new chunk of address
space from the operating system. See @ref{181,,Arena extension callbacks}
for details.

@item 
@code{MPS_KEY_ARENA_CONTRACTED} (type @ref{12c,,mps_fun_t})
is a function that will be called immediately before the arena is
`contracted': that is, just before it finishes with a chunk of
address space and returns it to the operating system. See
@ref{181,,Arena extension callbacks} for details.
@end itemize

For example:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_ARENA_CL_BASE, base);
    MPS_ARGS_ADD(args, MPS_KEY_ARENA_SIZE, size);
    res = mps_arena_create_k(&arena, mps_arena_class_cl(), args);
@} MPS_ARGS_END(args);
@end example

If the chunk is too small to hold the internal arena structures,
@ref{52,,mps_arena_create_k()} returns @ref{152,,MPS_RES_MEMORY}. In
this case, you need to use a (much) larger chunk.

@cartouche
@quotation Note 
You don’t have to provide all the memory up front: you can
call @ref{182,,mps_arena_extend()} later on.

Client arenas have no mechanism for returning unused memory.
@end quotation
@end cartouche
@end deffn

@geindex mps_arena_extend (C function)
@anchor{topic/arena c mps_arena_extend}@anchor{182}
@deffn {C Function} @ref{14d,,mps_res_t} mps_arena_extend (mps_arena_t arena, mps_addr_t base, size_t size)

Extend a @ref{4d,,client arena} with another block of memory.

@code{base} is the @ref{126,,address} of the block of memory that will be
managed by the arena.

@code{size} is its @ref{183,,size}.

Return @ref{5a,,MPS_RES_OK} if successful, or another
@ref{59,,result code} if it fails.
@end deffn

@geindex arena class; virtual memory
@geindex virtual memory arena class

@node Virtual memory arenas,Arena properties,Client arenas,Arenas
@anchor{topic/arena topic-arena-vm}@anchor{179}@anchor{topic/arena virtual-memory-arenas}@anchor{184}
@subsection Virtual memory arenas


@example
#include "mpsavm.h"
@end example

@geindex mps_arena_class_vm (C function)
@anchor{topic/arena c mps_arena_class_vm}@anchor{50}
@deffn {C Function} @ref{17a,,mps_arena_class_t} mps_arena_class_vm (void)

Return the @ref{11a,,arena class} for a @ref{4f,,virtual memory arena}.

A virtual memory arena uses the operating system’s @ref{51,,virtual memory} interface to allocate memory. The chief consequence of
this is that the arena can manage many more virtual addresses than
it needs to commit memory to. This gives it flexibility as to
where to place @ref{185,,blocks}, which reduces
@ref{17e,,fragmentation} and helps make @ref{f,,garbage collection}
more efficient.

When creating a virtual memory arena, @ref{52,,mps_arena_create_k()}
accepts five optional @ref{53,,keyword arguments} on all platforms:


@itemize *

@item 
@code{MPS_KEY_ARENA_SIZE} (type @code{size_t}, default
256 @ref{186,,megabytes}) is the initial amount of virtual address
space, in @ref{17c,,bytes (1)}, that the arena will reserve (this
space is initially reserved so that the arena can subsequently
use it without interference from other parts of the program, but
most of it is not committed, so it doesn’t require any RAM or
backing store). The arena may allocate more virtual address
space beyond this initial reservation as and when it deems it
necessary. The MPS is most efficient if you reserve an address
space that is several times larger than your peak memory usage.

If you specify a value for @code{MPS_KEY_ARENA_SIZE} that’s
too small for the virtual memory arena, then the MPS rounds it
up to the minimum and continues. The minimum size for the
virtual memory arena is @ref{187,,MPS_WORD_WIDTH} ×
@code{MPS_KEY_ARENA_GRAIN_SIZE} bytes. For example, on a
64-bit platform with a 4 @ref{188,,kilobyte} page size, this is
256 @ref{188,,kilobytes}.

@cartouche
@quotation Note 
The MPS asks for more address space if it runs out, but the
more times it has to extend its address space, the less
efficient garbage collection will become.
@end quotation
@end cartouche

@item 
@code{MPS_KEY_COMMIT_LIMIT} (type @code{size_t}) is
the maximum amount of main memory, in @ref{17c,,bytes (1)}, that
the MPS will obtain from the operating system. See
@ref{17d,,mps_arena_commit_limit()} for details. The default commit
limit is the maximum value of the @code{size_t} type.

@item 
@code{MPS_KEY_ARENA_GRAIN_SIZE} (type @code{size_t}) is
the granularity with which the arena will manage memory
internally. It must be a power of 2. If not provided, the
operating system’s page size is used. Larger granularity reduces
overheads, but increases @ref{17e,,fragmentation} and
@ref{17f,,retention}.

If you specify a value of @code{MPS_KEY_ARENA_GRAIN_SIZE}
that’s smaller than the operating system page size, the MPS
rounds it up to the page size and continues.

@item 
@code{MPS_KEY_SPARE} (type @code{double}, default 0.75) is the
maximum proportion of committed memory that the arena will keep
spare for future allocations. If the proportion of spare
committed memory exceeds this, then the arena will return some
of it to the operating system for use by other processes. See
@ref{189,,mps_arena_spare()} for details.

@item 
@code{MPS_KEY_PAUSE_TIME} (type @code{double}, default 0.1) is
the maximum time, in seconds, that operations within the arena
may pause the @ref{d0,,client program} for. See
@ref{180,,mps_arena_pause_time_set()} for details.
@end itemize

A sixth optional @ref{53,,keyword argument} may be passed, but it
only has any effect on the Windows operating system:


@itemize *

@item 
@code{MPS_KEY_VMW3_TOP_DOWN} (type @ref{129,,mps_bool_t},
default false). If true, the arena will allocate address space
starting at the highest possible address and working downwards
through memory.

@cartouche
@quotation Note 
This causes the arena to pass the @code{MEM_TOP_DOWN} flag to
VirtualAlloc@footnote{http://msdn.microsoft.com/en-us/library/windows/desktop/aa366887%28v=vs.85%29.aspx}.
@end quotation
@end cartouche
@end itemize

If the MPS fails to reserve adequate address space to place the
arena in, @ref{52,,mps_arena_create_k()} returns
@ref{153,,MPS_RES_RESOURCE}. Possibly this means that other parts
of the program are reserving too much virtual memory.

If the MPS fails to allocate memory for the internal arena
structures, @ref{52,,mps_arena_create_k()} returns
@ref{152,,MPS_RES_MEMORY}. Either @code{MPS_KEY_ARENA_SIZE}
was far too small or the operating system refused to provide
enough memory.

For example:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_ARENA_SIZE, size);
    res = mps_arena_create_k(&arena, mps_arena_class_vm(), args);
@} MPS_ARGS_END(args);
@end example
@end deffn

@geindex arena; properties

@node Arena properties,Arena states,Virtual memory arenas,Arenas
@anchor{topic/arena arena-properties}@anchor{18a}
@subsection Arena properties


@geindex mps_collections (C function)
@anchor{topic/arena c mps_collections}@anchor{18b}
@deffn {C Function} @ref{6d,,mps_word_t} mps_collections (mps_arena_t arena)

Return the number of garbage collections (technically, the number
of @ref{18c,,flips}) in which objects might have moved, that have
taken place in an @ref{16,,arena} since it was created.

@code{arena} is the arena.

@cartouche
@quotation Note 
If you are only using non-moving pool classes like
@ref{16c,,AMS (Automatic Mark and Sweep)}, then @ref{18b,,mps_collections()} will always
return 0. To find out about these collections, consider
enabling garbage collection messages: see
@ref{18d,,mps_message_type_gc()}.
@end quotation
@end cartouche
@end deffn

@geindex mps_arena_commit_limit (C function)
@anchor{topic/arena c mps_arena_commit_limit}@anchor{17d}
@deffn {C Function} size_t mps_arena_commit_limit (mps_arena_t arena)

Return the current @ref{156,,commit limit} for
an arena.

@code{arena} is the arena to return the commit limit for.

Returns the commit limit in @ref{17c,,bytes (1)}.

For a @ref{4d,,client arena}, this this the maximum amount of
memory, in @ref{17c,,bytes (1)}, that the MPS will use out of the
chunks provided by the client to the arena.

For a @ref{4f,,virtual memory arena}, this is the maximum amount of
memory that the MPS will map to RAM via the operating system’s
virtual memory interface.

The commit limit can be set by passing the
@code{MPS_KEY_COMMIT_LIMIT} @ref{53,,keyword argument} to
@ref{52,,mps_arena_create_k()}. It can be changed by calling
@ref{15a,,mps_arena_commit_limit_set()}. The
commit limit cannot be set to a value that is lower than the
number of bytes that the MPS is using. If an attempt is made to
set the commit limit to a value greater than or equal to that
returned by @ref{18e,,mps_arena_committed()} then it will succeed. If
an attempt is made to set the commit limit to a value less than
that returned by @ref{18e,,mps_arena_committed()} then it will
succeed only if the amount committed by the MPS can be reduced by
reducing the amount of spare committed memory; in such a case the
spare committed memory will be reduced appropriately and the
attempt will succeed.

@cartouche
@quotation Note 
The commit limit puts a limit on all memory committed by the
MPS. The @ref{18f,,spare committed memory} (that is, memory
committed by the MPS but not currently in use, neither by the
@ref{d0,,client program}, or by the MPS itself) can be limited
separately; see @ref{189,,mps_arena_spare()}. Note that “spare
committed” memory is subject to both limits; the proportion of
spare committed memory can’t exceed the spare commit limit,
and there can’t be so much spare committed memory that there
is more committed memory than the commit limit.
@end quotation
@end cartouche
@end deffn

@geindex mps_arena_commit_limit_set (C function)
@anchor{topic/arena c mps_arena_commit_limit_set}@anchor{15a}
@deffn {C Function} @ref{14d,,mps_res_t} mps_arena_commit_limit_set (mps_arena_t arena, size_t limit)

Change the @ref{156,,commit limit} for an @ref{16,,arena}.

@code{arena} is the arena to change the commit limit for.

@code{limit} is the new commit limit in @ref{17c,,bytes (1)}.

Returns @ref{5a,,MPS_RES_OK} if successful, or another
@ref{59,,result code} if not.

To effectively remove any commit limit, pass the maximum value of
the @code{size_t} type for the @ref{15a,,limit} argument, that
is, @code{((size_t)-1)}, or @code{SIZE_MAX} in C99 or later.

See @ref{17d,,mps_arena_commit_limit()} for details.
@end deffn

@geindex mps_arena_committed (C function)
@anchor{topic/arena c mps_arena_committed}@anchor{18e}
@deffn {C Function} size_t mps_arena_committed (mps_arena_t arena)

Return the total @ref{190,,committed} memory for an
@ref{16,,arena}.

@code{arena} is the arena.

Returns the total amount of memory that has been committed for use
by the MPS, in @ref{17c,,bytes (1)}.

For a @ref{4f,,virtual memory arena}, this is the amount of memory
mapped to RAM by the operating system’s virtual memory interface.

For a @ref{4d,,client arena}, this is the amount of memory marked as
in use in the arena’s page tables. This is not particularly
meaningful by itself, but it corresponds to the amount of mapped
memory that the MPS would use if switched to a virtual memory
arena.

The committed memory is generally larger than the sum of the sizes
of the allocated @ref{185,,blocks}. The reasons for this are:


@itemize *

@item 
some memory is used internally by the MPS to manage its own data
structures and to record information about allocated blocks
(such as free lists, page tables, colour tables, statistics, and
so on);

@item 
operating systems (and hardware) typically restrict programs to
requesting and releasing memory with a certain granularity (for
example, @ref{92,,pages}), so extra memory is committed
when this rounding is necessary;

@item 
there might also be @ref{18f,,spare committed memory}: see
@ref{191,,mps_arena_spare_committed()}.
@end itemize

The amount of committed memory is a good measure of how much
virtual memory resource (“swap space”) the MPS is using from the
operating system.

The function @ref{18e,,mps_arena_committed()} may be called whatever
state the arena is in. If it is called when the arena is in
the @ref{192,,unclamped state} then the value may change after this
function returns. A possible use might be to call it just after
@ref{ce,,mps_arena_collect()} to estimate the size of the heap.

If you want to know how much memory the MPS is using then you’re
probably interested in the value @ref{18e,,mps_arena_committed()} −
@ref{191,,mps_arena_spare_committed()}.

The amount of committed memory can be limited with the function
@ref{17d,,mps_arena_commit_limit()}.
@end deffn

@geindex mps_arena_pause_time (C function)
@anchor{topic/arena c mps_arena_pause_time}@anchor{193}
@deffn {C Function} double mps_arena_pause_time (mps_arena_t arena)

Return the maximum time, in seconds, that operations within the
arena may pause the @ref{d0,,client program} for.

@code{arena} is the arena.

See @ref{180,,mps_arena_pause_time_set()} for details.
@end deffn

@geindex mps_arena_pause_time_set (C function)
@anchor{topic/arena c mps_arena_pause_time_set}@anchor{180}
@deffn {C Function} void mps_arena_pause_time_set (mps_arena_t arena, double pause_time)

Set the maximum time, in seconds, that operations within an arena
may pause the @ref{d0,,client program} for.

@code{arena} is the arena.

@code{pause_time} is the new maximum pause time, in seconds. It must
be non-negative.

The MPS makes more efficient use of processor time when it is
allowed longer pauses, up to the maximum time it takes to collect
the entire arena (see @ref{ce,,mps_arena_collect()}).

When the pause time is short, the MPS needs to take more slices of
time in order to make @ref{f,,garbage collection} progress, and
make more use of @ref{60,,barriers (1)} to support
@ref{d,,incremental garbage collection}. This increases time
overheads, and especially operating system overheads.

The pause time may be set to zero, in which case the MPS returns
as soon as it can, without regard for overall efficiency.  This
value is suitable for applications that require high
responsiveness, but where overall run time is unimportant.

For interactive applications, set this to the longest pause that a
user won’t notice. The default setting of 100ms is intended for
this kind of application.

The pause time may be set to infinity, in which case the MPS
completes all outstanding @ref{f,,garbage collection} work before
returning from an operation. The consequence is that the MPS will
be able to save on the overheads due to @ref{d,,incremental garbage collection}, leading to lower total time spent in collection. This
value is suitable for non-interactive applications where total
time is important.

The MPS makes a best effort to return to the @ref{d0,,client program} from any operation on the arena within the maximum pause
time, but does not guarantee to do so. This is for three reasons:


@enumerate 

@item 
many operations in the MPS necessarily take some minimum amount
time that’s logarithmic in the amount of @ref{194,,memory (2)}
being managed (so if you set the maximum pause time to zero,
then every operation will exceed it);

@item 
some operations in the MPS call functions in the @ref{d0,,client program} (for example, the @ref{69,,format methods}), and the MPS
has no control over how long these functions take;

@item 
none of the operating systems supported by the MPS provide
real-time guarantees (for example, the process may have to wait
for @ref{194,,memory (2)} to be @ref{195,,paged in}).
@end enumerate

In other words, the MPS is a “soft” real-time system.
@end deffn

@geindex mps_arena_reserved (C function)
@anchor{topic/arena c mps_arena_reserved}@anchor{196}
@deffn {C Function} size_t mps_arena_reserved (mps_arena_t arena)

Return the total @ref{54,,address space} reserved by an
@ref{16,,arena}, in @ref{17c,,bytes (1)}.

@code{arena} is the arena.

For a @ref{4f,,virtual memory arena}, this is the total address space
reserved via the operating system’s virtual memory interface.

For a @ref{4d,,client arena}, this is the sum of the usable portions
of the chunks of memory passed to the arena by the @ref{d0,,client program} via @ref{52,,mps_arena_create_k()} and
@ref{182,,mps_arena_extend()}.

@cartouche
@quotation Note 
For a @ref{4d,,client arena}, the reserved address space may be
lower than the sum of the @code{MPS_KEY_ARENA_SIZE}
keyword argument passed to @ref{52,,mps_arena_create_k()} and
the @code{size} arguments passed to @ref{182,,mps_arena_extend()},
because the arena may be unable to use the whole of each chunk
for reasons of alignment.
@end quotation
@end cartouche
@end deffn

@geindex mps_arena_spare (C function)
@anchor{topic/arena c mps_arena_spare}@anchor{189}
@deffn {C Function} double mps_arena_spare (mps_arena_t arena)

Return the current @ref{197,,spare commit limit} for an
@ref{16,,arena}.

@code{arena} is the arena to return the spare commit limit for.

Returns the spare commit limit fraction. The spare
commit limit is the maximum fraction of @ref{18f,,spare committed memory} (that is, memory committed by the MPS but not currently in
use, neither by the @ref{d0,,client program}, or by the MPS itself)
the MPS is allowed to have.

For example, setting the @ref{197,,spare commit limit} to 0.5 will
allow the arena to retain up to 50% of @ref{190,,committed}
memory as @ref{18f,,spare committed memory}.

The spare commit limit can be set by passing the
@code{MPS_KEY_SPARE} @ref{53,,keyword argument} to
@ref{52,,mps_arena_create_k()}. It can be changed by calling
@ref{198,,mps_arena_spare_set()}. Setting it to a value lower than
the current fraction of spare committed memory causes spare
committed memory to be uncommitted so as to bring the value under
the limit. In particular, setting it to 0.0 will mean that the MPS
will have no spare committed memory.
@end deffn

@geindex mps_arena_spare_committed (C function)
@anchor{topic/arena c mps_arena_spare_committed}@anchor{191}
@deffn {C Function} size_t mps_arena_spare_committed (mps_arena_t arena)

Return the total @ref{18f,,spare committed memory} for an
@ref{16,,arena}.

@code{arena} is the arena.

Returns the number of bytes of spare committed memory.

Spare committed memory is memory which the arena is managing as
free memory (not in use by any pool and not otherwise in use for
internal reasons) but which remains committed (mapped to RAM by
the operating system). It is used by the arena to (attempt to)
avoid calling the operating system to repeatedly map and unmap
areas of @ref{51,,virtual memory} as the amount of memory in use
goes up and down. Spare committed memory is counted as committed
memory by @ref{18e,,mps_arena_committed()} and is restricted by
@ref{17d,,mps_arena_commit_limit()}.

The amount of “spare committed” memory can be limited passing the
@code{MPS_KEY_SPARE} @ref{53,,keyword argument} to
@ref{52,,mps_arena_create_k()} or by calling
@ref{198,,mps_arena_spare_set()}. The value of the limit can be
retrieved with @ref{189,,mps_arena_spare()}. This is analogous to the
functions for limiting the amount of @ref{190,,committed}
memory.

@cartouche
@quotation Note 
@ref{4d,,Client arenas} do not use spare committed memory, and
so this function always returns 0.
@end quotation
@end cartouche
@end deffn

@geindex mps_arena_spare_set (C function)
@anchor{topic/arena c mps_arena_spare_set}@anchor{198}
@deffn {C Function} void mps_arena_spare_set (mps_arena_t arena, double spare)

Change the @ref{197,,spare commit limit} for an @ref{16,,arena}.

@code{arena} is the arena to change the spare commit limit for.

@code{spare} is the new spare commit limit as a fraction of
@ref{190,,committed} memory. It must be between 0.0 and 1.0
inclusive.

Non-virtual-memory arena classes (for example, a @ref{4d,,client arena}) do not have spare committed memory. For these arenas, this
function sets a value but has no other effect.

Initially the spare commit limit is a configuration-dependent
value. The value of the limit can be retrieved by the function
@ref{189,,mps_arena_spare()}.
@end deffn

@geindex arena; states

@node Arena states,Running garbage collections,Arena properties,Arenas
@anchor{topic/arena arena-states}@anchor{199}
@subsection Arena states


An arena is always in one of four states.


@enumerate 

@item 
@geindex arena; unclamped state
@geindex unclamped state

In the `unclamped state', garbage collection may take place,
objects may move in memory, references may be updated,
@ref{19a,,location dependencies} may become stale, virtual memory may
be requested from or returned to the operating system, and other
kinds of background activity may occur. This is the normal state.

@item 
@geindex arena; clamped state
@geindex clamped state

In the `clamped state', objects do not move in memory, references
do not change, the staleness of @ref{19a,,location dependencies} does
not change, and memory occupied by @ref{21,,unreachable} objects is
not recycled.

However, a @ref{f,,garbage collection} may be in progress and
incremental collection may still occur, but it will not be visible
to the @ref{d0,,client program} and no new collections will begin.

@item 
@geindex arena; parked state
@geindex parked state

The `parked state' is the same as the clamped state, with the
additional constraint that no garbage collections are in progress.

@item 
@geindex arena; postmortem state
@geindex postmortem state

In the `postmortem state', incremental collection does not take
place, objects do not move in memory, references do not change, the
staleness of @ref{19a,,location dependencies} does not change, and
memory occupied by @ref{21,,unreachable} objects is not recycled.
Additionally, all memory protection is removed, and memory may be
in an inconsistent state.

@cartouche
@quotation Warning 
In this state, memory managed by the arena is not in a
consistent state, and so it is not safe to continue running the
client program. This state is intended for postmortem debugging
only.
@end quotation
@end cartouche
@end enumerate

Here’s a summary:


@multitable {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

State

@tab

unclamped

@tab

clamped

@tab

parked

@tab

postmortem

@item

Collections may be running?

@tab

yes

@tab

yes

@tab

no

@tab

yes

@item

New collections may start?

@tab

yes

@tab

no

@tab

no

@tab

no

@item

Objects may move?

@tab

yes

@tab

no

@tab

no

@tab

no

@item

Location dependencies may become stale?

@tab

yes

@tab

no

@tab

no

@tab

no

@item

Memory may be returned to the OS?

@tab

yes

@tab

no

@tab

no

@tab

no

@item

Safe to continue running?

@tab

yes

@tab

yes

@tab

yes

@tab

no

@item

Functions that leave the arena in this state

@tab

@ref{52,,mps_arena_create_k()},
@ref{cf,,mps_arena_release()},
@ref{19b,,mps_arena_start_collect()},
@ref{19c,,mps_arena_step()}

@tab

@ref{19d,,mps_arena_clamp()},
@ref{19c,,mps_arena_step()}

@tab

@ref{b9,,mps_arena_park()},
@ref{ce,,mps_arena_collect()}

@tab

@ref{d6,,mps_arena_postmortem()}

@end multitable


The clamped and parked states are important when introspecting and
debugging. If you are examining the contents of the heap, you don’t
want data moving under your feet. So for example, if your program is
stopped in GDB you might type:

@example
(gdb) print mps_arena_clamp(arena)
@end example

before inspecting memory, and:

@example
(gdb) print mps_arena_release(arena)
@end example

afterwards.

The results of introspection functions like
@ref{d2,,mps_arena_has_addr()} only remain valid while the arena remains
in the parked state, and functions like @ref{19e,,mps_arena_roots_walk()}
can only be called in this state.

@geindex mps_arena_clamp (C function)
@anchor{topic/arena c mps_arena_clamp}@anchor{19d}
@deffn {C Function} void mps_arena_clamp (mps_arena_t arena)

Put an @ref{16,,arena} into the @ref{19f,,clamped state}.

@code{arena} is the arena.

In the clamped state, no object motion will occur and the
staleness of @ref{19a,,location dependencies} will not change. All
references to objects loaded while the arena is clamped will keep
the same binary representation until after it is released by
calling @ref{cf,,mps_arena_release()}.

In a clamped arena, incremental collection may still occur, but it
will not be visible to the mutator and no new collections will
begin. Space used by unreachable objects will not be recycled
until the arena is unclamped.
@end deffn

@geindex mps_arena_park (C function)
@anchor{topic/arena c mps_arena_park}@anchor{b9}
@deffn {C Function} void mps_arena_park (mps_arena_t arena)

Put an @ref{16,,arena} into the @ref{b8,,parked state}.

@code{arena} is the arena.

While an arena is parked, no object motion will occur and the
staleness of @ref{19a,,location dependencies} will not change. All
references to objects loaded while the arena is parked will keep
the same binary representation until after it is released.

Any current collection is run to completion before the arena is
parked, and no new collections will start. When an arena is in the
parked state, it is necessarily not in the middle of a collection.
@end deffn

@geindex mps_arena_release (C function)
@anchor{topic/arena c mps_arena_release}@anchor{cf}
@deffn {C Function} void mps_arena_release (mps_arena_t arena)

Put an arena into the @ref{192,,unclamped state}.

@code{arena} is the arena.

While an arena is unclamped, @ref{f,,garbage collection}, object
motion, and other background activity can take place.
@end deffn

@geindex mps_arena_postmortem (C function)
@anchor{topic/arena c mps_arena_postmortem}@anchor{d6}
@deffn {C Function} void mps_arena_postmortem (mps_arena_t arena)

Put an arena into the @ref{d5,,postmortem state}.

@code{arena} is the arena.

In the postmortem state, incremental collection does not take
place, objects do not move in memory, references do not change,
the staleness of @ref{19a,,location dependencies} does not change,
and memory occupied by @ref{21,,unreachable} objects is not
recycled. Additionally, all memory protection is removed, and
memory may be in an inconsistent state.

@cartouche
@quotation Warning 

@enumerate 

@item 
After calling this function, memory managed by the arena is
not in a consistent state, and so it is no longer safe to
continue running the client program. This function is
intended for postmortem debugging only.

@item 
This function must be called from the thread that holds the
arena lock (if any thread holds it). This is the case if the
program is single-threaded, or if it is called from an MPS
assertion handler. When calling this function from the
debugger, check the stack to see which thread has the MPS
arena lock.
@end enumerate
@end quotation
@end cartouche
@end deffn

@geindex garbage collection; running
@geindex collection; running

@node Running garbage collections,Using idle time for collection,Arena states,Arenas
@anchor{topic/arena running-garbage-collections}@anchor{1a0}
@subsection Running garbage collections


The Memory Pool System’s garbage collector runs @ref{a1,,asynchronously} and @ref{d,,incrementally}. This means that it is not normally
necessary to tell it when to start garbage collections, or to wait
until it has finished collecting. (But if your program has idle time
that could be productively spent by the MPS, see
@ref{1a1,,Using idle time for collection} below.)

However, during development and testing it is useful to be able to
request that MPS run a full @ref{1a2,,collection cycle}. For example, you
might run frequent collections in an attempt to detect bugs in your
allocation and scanning code.

@geindex mps_arena_collect (C function)
@anchor{topic/arena c mps_arena_collect}@anchor{ce}
@deffn {C Function} void mps_arena_collect (mps_arena_t arena)

Collect an arena and put it into the @ref{b8,,parked state}.

@code{arena} is the arena to collect.

The collector attempts to recycle as many unreachable objects as
possible and reduce the size of the arena as much as possible
(though in some cases it may increase because it becomes more
fragmented). Note that the collector may not be able to recycle
some objects (such as those near the destination of ambiguous
references) even though they are not reachable.

If you do not want the arena to remain in the parked state, you
must explicitly call @ref{cf,,mps_arena_release()} afterwards.

@cartouche
@quotation Note 
It is not normally necessary to call this function: in the
@ref{192,,unclamped state}, collections start automatically.
However, it may be useful during development and debugging:
the more frequently the collector runs, the sooner and more
reliably errors are discovered. See @ref{c7,,General debugging advice}.
@end quotation
@end cartouche
@end deffn

@geindex mps_arena_start_collect (C function)
@anchor{topic/arena c mps_arena_start_collect}@anchor{19b}
@deffn {C Function} @ref{14d,,mps_res_t} mps_arena_start_collect (mps_arena_t arena)

Request an @ref{16,,arena} to start a full @ref{1a2,,collection cycle}.

@code{arena} is the arena.

Returns @ref{5a,,MPS_RES_OK} if a collection is started, or
another @ref{59,,result code} if not.

This function puts @code{arena} into the @ref{192,,unclamped state} and
requests that it start a full collection cycle. The call to
@ref{19b,,mps_arena_start_collect()} returns quickly, leaving the
collection to proceed incrementally (as for a collection that is
scheduled automatically).

@cartouche
@quotation Note 
Contrast with @ref{ce,,mps_arena_collect()}, which does not
return until the collection has completed.
@end quotation
@end cartouche
@end deffn

@geindex garbage collection; limiting pause
@geindex garbage collection; using idle time
@geindex idle time; using for garbage collection
@geindex pause; limiting

@node Using idle time for collection,Arena introspection and debugging,Running garbage collections,Arenas
@anchor{topic/arena topic-arena-idle}@anchor{1a1}@anchor{topic/arena using-idle-time-for-collection}@anchor{1a3}
@subsection Using idle time for collection


Some types of program have “idle time” in which they are waiting for
an external event such as user input or network activity. The MPS
provides a function, @ref{19c,,mps_arena_step()}, for making use of idle
time to make memory management progress.

Here’s an example illustrating the use of this function in a program’s
event loop.

@example
for (;;) @{ /* event loop */
    for (;;) @{
        if (client_is_waiting()) @{
            perform_client_action();
        @} else if (!mps_arena_step(arena, 0.010, 0.0)) @{
            /* no incremental MPS work remaining */
            break;
        @}
    @}

    if (!block_on_client_with_timeout(2.0)) @{
        /* Perhaps the user has gone for a cup of coffee? Allow the
         * MPS to start a big piece of work, but don't actually pause
         * for more than 10 ms. */
        mps_arena_step(arena, 0.010, 100.0);
    @}
@}
@end example

When the program is idle (there are no client actions to perform), it
requests that the MPS spend up to 10 milliseconds on incremental work,
by calling @code{mps_arena_step(arena, 0.010, 0.0)}. When this returns
false to indicate that there is no more work to do, the program blocks
on the client for two seconds: if this times out, it predicts that the
user will remain idle for at least a further second, so it calls
@code{mps_arena_step(arena, 0.010, 100.0)} to tell that it’s a good time
to start a collection taking up to 10 ms × 100 = 1 second, but not to
pause for more than 10 ms.

The program remains responsive: the MPS doesn’t take control for more
than a few milliseconds at a time (at most 10). But at the same time,
major collection work can get done at times when the program would
otherwise be idle. Of course the numbers here are only for
illustration; they should be chosen based on the requirements of the
application.

@geindex mps_arena_step (C function)
@anchor{topic/arena c mps_arena_step}@anchor{19c}
@deffn {C Function} @ref{129,,mps_bool_t} mps_arena_step (mps_arena_t arena, double interval, double multiplier)

Request an @ref{16,,arena} to do some work during a period where the
@ref{d0,,client program} is idle.

@code{arena} is the arena.

@code{interval} is the time, in seconds, the MPS is permitted to
take. It must not be negative, but may be @code{0.0}.

@code{multiplier} is the number of further similar calls that the
client program expects to make during this idle period.

Returns true if there was work for the MPS to do in @code{arena}
(regardless of whether or not it did any) or false if there was
nothing to do.

@ref{19c,,mps_arena_step()} allows the client program to make use of
idle time to do some garbage collection, for example when it is
waiting for interactive input. The MPS makes every effort to
return from this function within @code{interval} seconds, but cannot
guarantee to do so, as it may need to call your own scanning
code. It uses @code{multiplier} to decide whether to commence
long-duration operations that consume CPU (such as a full
collection): it will only start such an operation if it is
expected to be completed within @code{multiplier * interval} seconds.

If the arena was in the @ref{b8,,parked state} or the @ref{19f,,clamped state} before @ref{19c,,mps_arena_step()} was called, it is in the
clamped state afterwards. It it was in the @ref{192,,unclamped state}, it remains there.
@end deffn

@geindex arena; introspection
@geindex arena; debugging

@node Arena introspection and debugging,Arena extension callbacks,Using idle time for collection,Arenas
@anchor{topic/arena arena-introspection-and-debugging}@anchor{1a4}
@subsection Arena introspection and debugging


@cartouche
@quotation Note 
Introspection functions covered in other chapters are:


@itemize *

@item 
@ref{1a5,,mps_addr_fmt()}: determine the @ref{39,,object format} to
which an address belongs;

@item 
@ref{1a6,,mps_pool_walk()}: visit all areas of @ref{23,,formatted objects} in a @ref{18,,pool};

@item 
@ref{19e,,mps_arena_roots_walk()}: visit all references in
@ref{97,,roots} registered with an arena; and

@item 
@ref{d3,,mps_addr_pool()}: determine the @ref{18,,pool} to which an
address belongs.
@end itemize
@end quotation
@end cartouche

@geindex mps_arena_busy (C function)
@anchor{topic/arena c mps_arena_busy}@anchor{1a7}
@deffn {C Function} @ref{129,,mps_bool_t} mps_arena_busy (mps_arena_t arena)

Return true if an @ref{16,,arena} is part of the way through
execution of an operation, false otherwise.

@code{arena} is the arena.

@cartouche
@quotation Note 
This function is intended to assist with debugging fatal
errors in the @ref{d0,,client program}. It is not expected to be
needed in normal use. If you find yourself wanting to use this
function other than in the use case described below, there may
be a better way to meet your requirements: please
@ref{d8,,contact us}.

A debugger running on Windows on x86-64 needs to decode the
call stack, which it does by calling a callback that was
previously installed in the dynamic function table using
RtlInstallFunctionTableCallback()@footnote{https://docs.microsoft.com/en-gb/windows/win32/api/winnt/nf-winnt-rtlinstallfunctiontablecallback}. If the debugger is entered
while the arena is busy, and if the callback needs to read
from MPS-managed memory, then it may attempt to re-enter the
MPS, which will fail as the MPS is not re-entrant.

If this happens, in order to allow the debugger to finish
decoding the call stack, the only remedy is to put the arena
into the @ref{d5,,postmortem state}, so that memory is
@ref{1a8,,unprotected} and objects do not move. So in your
dynamic function table callback, you might write:

@example
if (mps_arena_busy(arena)) @{
    mps_arena_postmortem(arena);
@}
@end example
@end quotation
@end cartouche

@cartouche
@quotation Warning 
This function only gives a reliable result in single-threaded
programs, and in multi-threaded programs where all threads but
one are known to be stopped (as they are when the debugger is
decoding the call stack in the use case described above).
@end quotation
@end cartouche
@end deffn

@geindex mps_arena_has_addr (C function)
@anchor{topic/arena c mps_arena_has_addr}@anchor{d2}
@deffn {C Function} @ref{129,,mps_bool_t} mps_arena_has_addr (mps_arena_t arena, mps_addr_t addr)

Test whether an @ref{126,,address} is managed by an @ref{16,,arena}.

@code{arena} is an arena.

@code{addr} is an address.

Returns true if @code{addr} is managed by @code{arena}; false otherwise.

An arena manages a portion of @ref{54,,address space}. No two arenas
overlap, so for any particular address this function will return
true for at most one arena.

In general, not all addresses are managed by any arena. This is
what allows the MPS to cooperate with other memory managers,
shared object loaders, memory mapped file input/output, and so on:
it does not steal the whole address space.

@cartouche
@quotation Note 
The result from this function is valid only at the instant at
which the function returned. In some circumstances the result
may immediately become invalidated (for example, a
@ref{f,,garbage collection} may occur, the address in question
may become free, the arena may choose to unmap the address and
return storage to the operating system). For reliable results
call this function and interpret the result while the arena is
in the @ref{b8,,parked state}.
@end quotation
@end cartouche


@subsubheading See also


To find out which @ref{18,,pool} the address belongs to, use
@ref{d3,,mps_addr_pool()}, and to find out which @ref{39,,object format} describes the object at the address, use
@ref{1a5,,mps_addr_fmt()}.

@end deffn

@geindex mps_addr_object (C function)
@anchor{topic/arena c mps_addr_object}@anchor{1a9}
@deffn {C Function} @ref{14d,,mps_res_t} mps_addr_object (mps_addr_t *p_o, mps_arena_t arena, mps_addr_t addr)

Find the @ref{1aa,,base pointer} of an @ref{1ab,,object} if provided with an
@ref{1ac,,interior pointer} to that object, or the object’s base pointer,
provided the object exists in a pool that supports this feature.

@code{p_o} points to a location that will hold the object’s base pointer.

@code{arena} is an arena.

@code{addr} is an address that might be an interior or base pointer.

Returns MPS_RES_OK if a base pointer to an object into which @code{addr}
points was successfully returned.

Returns MPS_RES_FAIL if @code{addr} points to memory not managed by the
@code{arena} or if @code{addr} points to the interior of an object which has
been moved by a @ref{1ad,,moving memory manager}.

Returns MPS_RES_UNIMPL if @code{addr} is found to be managed by a @ref{18,,pool}
which does not currently implement this feature.

@ref{1a9,,mps_addr_object()} allows client programs that allocate
code on the heap to implement debugging and stack tracing, in that it provides
a way to unwind a client program’s stack by finding the block of code to which the
program counter or function return addresses currently point. It can be called
multiple times as needed to build a complete trace of the client program’s stack.

This function does not support debugging in situations where the arena
itself has encountered a runtime error. For cases where the MPS encounters
runtime errors, see @ref{d6,,mps_arena_postmortem()}.

@cartouche
@quotation Note 
This function is intended to assist with debugging fatal
errors in the @ref{d0,,client program}. It is not expected to be
needed in normal use, i.e. as part of the regular operation of code in
production, since it is not optimized for performance. If you find yourself
wanting to use this function other than in the use case described, there may
be a better way to meet your requirements: please
@ref{d8,,contact us}.

If you would like this function to work in a pool in which it’s currently
unimplemented, please @ref{d8,,contact us}.
@end quotation
@end cartouche
@end deffn

@geindex arena extension callbacks; introduction
@geindex extension callbacks; introduction
@geindex arena contraction callbacks; introduction
@geindex contraction callbacks; introduction

@node Arena extension callbacks,,Arena introspection and debugging,Arenas
@anchor{topic/arena arena-extension-callbacks}@anchor{1ae}@anchor{topic/arena topic-arena-extension}@anchor{181}
@subsection Arena extension callbacks


There are situations in which the @ref{d0,,client program} needs to be
informed about the chunks of address space that an @ref{16,,arena} is
managing. To support this, the MPS allows the client program to
specify two callback functions when creating a @ref{4f,,virtual memory arena}: one function is called when the arena is `extended' (that is,
when it acquires a new chunk of address space from the operating
system), and the other when the arena is `contracted' (that is, when
it returns a chunk of address space to the operating system).

The use case that this feature is designed to support is debugging of
dynamically generated code in 64-bit Windows. Microsoft’s
documentation for RtlInstallFunctionTableCallback()@footnote{https://docs.microsoft.com/en-gb/windows/win32/api/winnt/nf-winnt-rtlinstallfunctiontablecallback} says:

@quotation

Function tables are used on 64-bit Windows to determine how to
unwind or walk the stack. These tables are usually generated by
the compiler and stored as part of the image. However,
applications must provide the function table for dynamically
generated code.
@end quotation

An application may install a dynamic function table by calling
RtlInstallFunctionTableCallback()@footnote{https://docs.microsoft.com/en-gb/windows/win32/api/winnt/nf-winnt-rtlinstallfunctiontablecallback}, passing the region of memory in
which the dynamically generated functions can be found, and may later
delete the table by calling RtlDeleteFunctionTable()@footnote{https://docs.microsoft.com/en-gb/windows/win32/api/winnt/nf-winnt-rtldeletefunctiontable}.

So if the client program is storing dynamically generated functions in
MPS-managed memory, then it could define callback functions that
install and delete the function table callback for the dynamically
generated code, like this:

@example
void arena_extended(mps_arena_t arena, void *base, size_t size)
@{
    RtlInstallFunctionTableCallback(...);
@}

void arena_contracted(mps_arena_t arena, void *base, size_t size)
@{
    RtlDeleteFunctionTable(...);
@}
@end example

and then pass these two functions using @ref{53,,keyword arguments} to
@ref{52,,mps_arena_create_k()}:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_ARENA_EXTENDED, (mps_fun_t)arena_extended);
    MPS_ARGS_ADD(args, MPS_KEY_ARENA_CONTRACTED, (mps_fun_t)arena_contracted);
    /* ... other keyword arguments ... */
    res = mps_arena_create_k(&arena, mps_arena_class_vm(), args);
@} MPS_ARGS_END(args);
@end example

The callback functions receive three arguments: @code{arena} (the arena
being extended or contracted), @code{base} (the base address of the chunk
of address space that has just been acquired from, or is about to be
returned to, the operating system), and @code{size} (the size of the
chunk, in bytes). They must not call any function in the MPS, and must
not access any memory managed by the MPS.

@cartouche
@quotation Note 
The extension callback is also called immediately after the arena
is created, in other words, the creation of the arena is treated as
a special example of an extension of the arena.

The contraction callback is called on all remaining chunks when
the arena is destroyed.  There will be at least one callback.

Every contraction of the arena will match one-to-one with the arena
extensions that have already taken place. After creation, any
contractions performed by the arena will be the same size as the
extensions that have already taken place. Contractions never occur as
amalgamations nor as fractions of previous arena extensions.

Arena extension callbacks are only supported by @ref{4f,,virtual memory arenas}.
@end quotation
@end cartouche

@geindex pool; creating

@node Pools,Allocation<2>,Arenas,Reference
@anchor{topic/pool doc}@anchor{1af}@anchor{topic/pool pools}@anchor{1b0}@anchor{topic/pool topic-pool}@anchor{1e}
@section Pools


Within an @ref{16,,arena} a client program creates one or more pools. A
pool is responsible for requesting memory from the @ref{16,,arena} and
making it available for allocation.

@geindex mps_pool_t (C type)
@anchor{topic/pool c mps_pool_t}@anchor{1b1}
@deffn {C Type} type mps_pool_t

The type of @ref{18,,pools}.

A pool is responsible for requesting memory from the @ref{16,,arena}
and making it available to the @ref{d0,,client program} via
@ref{ad,,mps_alloc()} or via an @ref{63,,allocation point}.
@end deffn

@geindex mps_pool_create_k (C function)
@anchor{topic/pool c mps_pool_create_k}@anchor{166}
@deffn {C Function} @ref{14d,,mps_res_t} mps_pool_create_k (mps_pool_t *pool_o, mps_arena_t arena, mps_pool_class_t pool_class, mps_arg_s args[])

Create a @ref{18,,pool} in an @ref{16,,arena}.

@code{pool_o} points to a location that will hold a pointer to the new
pool.

@code{arena} is the arena in which to create the pool.

@code{pool_class} is the @ref{10,,pool class} of the new pool.

@code{args} are @ref{53,,keyword arguments} specific to the pool class.
See the documentation for the pool class.

Returns @ref{5a,,MPS_RES_OK} if the pool is created successfully,
or another @ref{59,,result code} otherwise.

The pool persists until it is destroyed by calling
@ref{168,,mps_pool_destroy()}.
@end deffn

@geindex mps_pool_destroy (C function)
@anchor{topic/pool c mps_pool_destroy}@anchor{168}
@deffn {C Function} void mps_pool_destroy (mps_pool_t pool)

Destroy a @ref{18,,pool}.

@code{pool} is the pool to destroy.

This function checks the consistency of the pool, destroys the
pool’s internal control structures and causes the pool’s memory to
be returned to the @ref{16,,arena} for reuse by other pools, or to
be returned to the operating system.  Blocks allocated from the
pool may no longer be used.

It is an error to destroy a pool without first destroying all
@ref{63,,allocation points} and @ref{1b2,,segregated allocation caches}
created in the pool.

@cartouche
@quotation Warning 
It is not safe to carry on running the @ref{20,,garbage collector} after destroying an @ref{9,,automatically managed} pool that contains any objects
that are @ref{96,,reachable} from your roots, or any objects
that have been registered for @ref{b,,finalization} but not yet
finalized.

Our recommended approach is to destroy automatically managed
pools just before destroying the arena, and then only while
the arena is in the @ref{b8,,parked state}. Thus a safe
tear-down sequence looks like this:

@example
mps_arena_park(arena);
/* destroy threads and roots belonging to the arena */
/* destroy allocation points and caches belonging to the pool */
mps_pool_destroy(pool);
/* destroy chains and formats belonging to the arena */
mps_arena_destroy(arena);
@end example
@end quotation
@end cartouche
@end deffn

@geindex pool class

@menu
* Pool classes:: 
* Pool introspection:: 

@end menu

@node Pool classes,Pool introspection,,Pools
@anchor{topic/pool pool-classes}@anchor{1b3}
@subsection Pool classes


Pools belong to @ref{10,,pool classes} that specify policies for how
their memory is managed. Some pools are @ref{8,,manually managed} (you must call @ref{1f,,mps_free()} to
return a block of memory to the pool) and others are
@ref{9,,automatically managed} (the
@ref{20,,garbage collector} reclaims @ref{21,,unreachable} blocks).

See the @ref{22,,Pool reference} for a list of pool classes.

@geindex mps_pool_class_t (C type)
@anchor{topic/pool c mps_pool_class_t}@anchor{1b4}
@deffn {C Type} type mps_pool_class_t

The type of @ref{10,,pool classes}.
@end deffn

@geindex pool; introspection

@node Pool introspection,,Pool classes,Pools
@anchor{topic/pool pool-introspection}@anchor{1b5}
@subsection Pool introspection


@geindex mps_pool_total_size (C function)
@anchor{topic/pool c mps_pool_total_size}@anchor{1b6}
@deffn {C Function} size_t mps_pool_total_size (mps_pool_t pool)

Return the total memory allocated from the arena and managed by
the pool.

@code{pool} is the pool.

The result includes memory in use by the client program, memory
that’s available for use by the client program, and memory
that’s lost to fragmentation. It does not include memory used by
the pool’s internal control structures.
@end deffn

@geindex mps_pool_free_size (C function)
@anchor{topic/pool c mps_pool_free_size}@anchor{1b7}
@deffn {C Function} size_t mps_pool_free_size (mps_pool_t pool)

Return the free memory: memory managed by the pool but not in use
by the client program.

@code{pool} is the pool.

The result includes memory that’s available for use by the client
program, and memory that’s lost to fragmentation. It does not
include memory used by the pool’s internal control structures.
@end deffn

@geindex mps_addr_pool (C function)
@anchor{topic/pool c mps_addr_pool}@anchor{d3}
@deffn {C Function} @ref{129,,mps_bool_t} mps_addr_pool (mps_pool_t *pool_o, mps_arena_t arena, mps_addr_t addr)

Determine the @ref{18,,pool} to which an address belongs.

@code{pool_o} points to a location that will hold the address of the
pool, if one is found.

@code{arena} is the arena whose pools will be considered.

@code{addr} is the address.

If @code{addr} is the address of a location inside a block allocated
from a pool in @code{arena}, then update the location pointed to by
@code{pool_o} with the address of the pool, and return true.

If @code{addr} points to a location that is not managed by @code{arena},
return false.

If neither of the above conditions is satisfied,
@ref{d3,,mps_addr_pool()} may return either true or false.

@cartouche
@quotation Note 
This function might return a false positive by returning true
if you ask about an address that happens to be inside memory
managed by a pool, but which is not inside a block allocated
by that pool. It never returns a false negative.

The result from this function is valid only at the instant at
which the function returned. In some circumstances the result
may immediately become invalidated. For reliable results call
this function and interpret the result while the arena is in
the @ref{b8,,parked state}.
@end quotation
@end cartouche


@subsubheading See also


To find out which @ref{39,,object format} describes the object
at the address, use @ref{1a5,,mps_addr_fmt()}. If you only care
whether the address belongs to a particular @ref{16,,arena}, use
@ref{d2,,mps_arena_has_addr()}.

@end deffn

@geindex mps_pool_walk (C function)
@anchor{topic/pool c mps_pool_walk}@anchor{1a6}
@deffn {C Function} @ref{14d,,mps_res_t} mps_pool_walk (mps_pool_t pool, mps_area_scan_t scan_area, void *closure)

Visit all @ref{23,,formatted objects} in a @ref{18,,pool}. The pool
must be @ref{9,,automatically managed}. The pool’s @ref{16,,arena} must be in the
@ref{b8,,parked state}.

@ref{1a6,,pool} is the pool whose formatted objects are visited.

@ref{1a6,,scan_area} is an area scanning function. See
@ref{1b8,,Area scanners}.

@ref{1a6,,closure} is an arbitrary pointer that will be passed to
@ref{1a6,,scan_area}.

The scanning function is called multiple times with disjoint areas
of memory that cover all formatted objects in the pool. The areas
may also include @ref{67,,padding objects} if the pool’s format has
a @ref{90,,padding method}, but never includes @ref{66,,forwarding objects} since the arena is in the parked state.

The scanning function must follow the
@ref{16f,,Scanning protocol}. In particular, it must @ref{b4,,fix}
every @ref{24,,reference} in the area. The scanning function may
return @ref{5a,,MPS_RES_OK} to continue visiting areas of
formatted objects, or return other @ref{159,,Result codes} to
stop visiting and return to the caller.

@cartouche
@quotation Note 
If the scanning function modifies a reference, it must scan
the modified reference. It is safe to scan the original
reference as well, but this may lead to unwanted
@ref{17f,,retention}.
@end quotation
@end cartouche
@end deffn

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mmdoc/protocol/mps/alloc-point/>`_
@c `<https://info.ravenbrook.com/project/mps/master/manual/wiki/apguide.html>`_
@c `<https://info.ravenbrook.com/project/mps/master/design/buffer/>`_

@geindex allocation

@node Allocation<2>,Object formats,Pools,Reference
@anchor{topic/allocation doc}@anchor{1b9}@anchor{topic/allocation allocation}@anchor{1ba}@anchor{topic/allocation topic-allocation}@anchor{2b}
@section Allocation


@geindex allocation; manual
@geindex manual allocation

@menu
* Manual allocation:: 
* Allocation points:: 
* Allocation point protocol:: 
* Example; allocating a symbol: Example allocating a symbol. 
* Cautions:: 
* Example; inserting into a doubly linked list: Example inserting into a doubly linked list. 
* Allocation point implementation:: 

@end menu

@node Manual allocation,Allocation points,,Allocation<2>
@anchor{topic/allocation manual-allocation}@anchor{1bb}
@subsection Manual allocation


@cartouche
@quotation Note 
Not all @ref{10,,pool classes} support this interface:
@ref{9,,automatically managed} pools
typically support none of it, and even @ref{8,,manually managed} pools may not support the whole
interface. Consult the pool class documentation for details. For
example, the @ref{1bc,,MVT (Manual Variable Temporal)} pool class supports deallocation via
@ref{1f,,mps_free()} but allocation must use allocation points, as
described below.
@end quotation
@end cartouche

@geindex mps_alloc (C function)
@anchor{topic/allocation c mps_alloc}@anchor{ad}
@deffn {C Function} @ref{14d,,mps_res_t} mps_alloc (mps_addr_t *p_o, mps_pool_t pool, size_t size)

Allocate a @ref{185,,block} of memory in a @ref{18,,pool}.

@code{p_o} points to a location that will hold the address of the
allocated block.

@code{pool} the pool to allocate in.

@code{size} is the @ref{183,,size} of the block to allocate. If it is
unaligned, it will be rounded up to the pool’s @ref{68,,alignment}
(unless the pool documentation says otherwise).

@cartouche
@quotation Note 
It is tempting to call @ref{ad,,mps_alloc()} with a cast from
the desired pointer type to @code{mps_addr_t *}, like this:

@example
my_object *obj;
res = mps_alloc((mps_addr_t *)&obj, pool, sizeof *obj);
if (res != MPS_RES_OK)
    error(...);
@end example

but this is @ref{a5,,type punning}, and its behaviour is not
defined in ANSI/ISO Standard C. See @ref{121,,Type punning}
for more details.
@end quotation
@end cartouche
@end deffn

@geindex mps_free (C function)
@anchor{topic/allocation c mps_free}@anchor{1f}
@deffn {C Function} void mps_free (mps_pool_t pool, mps_addr_t addr, size_t size)

Free a @ref{185,,block} of memory to a @ref{18,,pool}.

@code{pool} is the pool the block belongs to.

@code{addr} is the address of the block to be freed.

@code{size} is the @ref{183,,size} of the block to be freed. If it is
unaligned, it will be rounded up to the pool’s @ref{68,,alignment}
(unless the pool documentation says otherwise).

The freed block of memory becomes available for allocation by the
pool, or the pool might decide to make it available to other
pools, or it may be returned to the operating system.

@cartouche
@quotation Note 
@ref{1f,,mps_free()} takes a @code{size} parameter because it is
most efficient to do so. In most programs, the type of an
object is known at the point in the code that frees it, hence
the size is trivially available. In such programs, storing the
size on the MPS side would cost time and memory, and make it
hard to get good virtual memory behaviour because of the need
to touch the object in order to free it. As it is, the
deallocation code doesn’t have to touch the dead object at
all.
@end quotation
@end cartouche
@end deffn

@geindex allocation point

@node Allocation points,Allocation point protocol,Manual allocation,Allocation<2>
@anchor{topic/allocation allocation-points}@anchor{1bd}@anchor{topic/allocation topic-allocation-point}@anchor{1be}
@subsection Allocation points


@ref{63,,Allocation points} provide fast, @ref{a,,inline}, nearly @ref{1bf,,lock-free} allocation.
They allow code to allocate without calling an allocation function:
this is vital for performance in languages or programs that allocate
many small objects. They must be used according to the
@ref{ae,,Allocation point protocol}.

@geindex mps_ap_t (C type)
@anchor{topic/allocation c mps_ap_t}@anchor{1c0}
@deffn {C Type} type mps_ap_t

The type of @ref{63,,allocation points}. It is a
@ref{127,,transparent alias} for a pointer to
@ref{1c1,,mps_ap_s}.
@end deffn

@geindex mps_ap_create_k (C function)
@anchor{topic/allocation c mps_ap_create_k}@anchor{af}
@deffn {C Function} @ref{14d,,mps_res_t} mps_ap_create_k (mps_ap_t *ap_o, mps_pool_t pool, mps_arg_s args[])

Create an @ref{63,,allocation point} in a @ref{18,,pool}.

@code{ap_o} points to a location that will hold the address of the
allocation point, if successful.

@code{pool} is the pool.

@code{args} are @ref{53,,keyword arguments} specific to the pool class
to which @code{pool} belong. See the documentation for that pool
class. (Most pool classes don’t take any keyword arguments; in
those cases you can pass @ref{133,,mps_args_none}.)

Returns @ref{5a,,MPS_RES_OK} if successful, or another
@ref{59,,result code} if not.

@cartouche
@quotation Warning 
An allocation point must not be used by more than one
@ref{99,,thread}: each thread must create its own allocation
point or points.
@end quotation
@end cartouche
@end deffn

@geindex mps_ap_destroy (C function)
@anchor{topic/allocation c mps_ap_destroy}@anchor{1c2}
@deffn {C Function} void mps_ap_destroy (mps_ap_t ap)

Destroy an @ref{63,,allocation point}.

@code{ap} is the allocation point to destroy.

Destroying an allocation point has no effect on blocks that were
allocated from it, so long as they were successfully
@ref{b1,,committed (2)} by @ref{b2,,mps_commit()}.
@end deffn

@geindex allocation point protocol

@node Allocation point protocol,Example allocating a symbol,Allocation points,Allocation<2>
@anchor{topic/allocation allocation-point-protocol}@anchor{1c3}@anchor{topic/allocation topic-allocation-point-protocol}@anchor{ae}
@subsection Allocation point protocol


This protocol is designed to work with @ref{d,,incremental garbage collection} and multiple @ref{99,,threads}, where between any
two instructions in the @ref{d0,,client program}, the MPS may run part
of a @ref{f,,garbage collection}, @ref{1ad,,move}
blocks in memory, rewrite pointers, and reclaim space. In order to
reliably handle this, the allocation point protocol consists of (at
least) two steps, a `reserve' followed by a `commit'.

@cartouche
@quotation Note 
The description of the protocol assumes that you have declared
your threads’ @ref{27,,control stacks} and @ref{26,,registers} to be
@ref{1c4,,ambiguous roots}, by calling
@ref{a9,,mps_root_create_thread()}. This is the simplest way to write
a client, but other scenarios are possible. Please @ref{d8,,contact us} if your use case is not covered here (for example,
if you need an exact collector).
@end quotation
@end cartouche

When the client program is initializing a newly allocated object, you
can think of it as being “in a race” with the MPS. Until the object is
initialized, the MPS cannot manage it in the usual way: in particular,
it cannot ensure that the new object remains correct if other objects
move during its initialization. So if other objects `do' move, the MPS
tells the client program that it has “lost the race”: the
partially-initialized object may be invalid, and the client must
initialize it again from scratch.

The allocation point protocol is as follows:


@enumerate 

@item 
Call @ref{b0,,mps_reserve()} to reserve a block of memory on an
allocation point. The size of the block must be a multiple of the
@ref{68,,alignment} of the pool in which the allocation point was
created.

If @ref{b0,,mps_reserve()} returns @ref{5a,,MPS_RES_OK}, go to step 2.

Otherwise, the block cannot be reserved (this might happen if the
MPS is out of memory).

@item 
Initialize the block. During this step the block must not be
referenced by an @ref{61,,exact reference}, and references stored in
it must not be followed.

The block need not be initialized completely, but if the pool has
an @ref{39,,object format}, then by the end of this step, the block
must be capable of being passed to the format’s @ref{73,,scan method}
and @ref{81,,skip method}.

@item 
Call @ref{b2,,mps_commit()} to attempt to commit the object to the
care of the MPS.

If @ref{b2,,mps_commit()} returns true, this means that the object is
valid, and is now under the management of the MPS. The client program
may rely on references stored in the object, and may store references
to the new object in its other objects.

If @ref{b2,,mps_commit()} returns false, this means that the block is
invalid. It is usual in this case to go back to step 1 and re-reserve
and re-initialize it, but other courses of action are permitted.

@cartouche
@quotation Note 
In this case, the reason the block is invalid because a
@ref{18c,,flip} took place after the call to
@ref{b0,,mps_reserve()} and before the call to
@ref{b2,,mps_commit()}. This means that references in the block
may point to the old location of blocks that moved.
@end quotation
@end cartouche
@end enumerate

The usual implementation of the allocation point protocol in @ref{1c,,C}
is thus:

@example
mps_addr_t p;
obj_t obj;
size_t aligned_size = ALIGN(size); /* see note 1 */
do @{
    mps_res_t res = mps_reserve(&p, ap, aligned_size);
    if (res != MPS_RES_OK)
        /* handle the error */;
    /* p is now an ambiguous reference to the reserved block */
    obj = p;
    /* initialize obj */
@} while (!mps_commit(ap, p, aligned_size)); /* see note 2 */
/* obj is now valid and managed by the MPS */
@end example

@cartouche
@quotation Note 

@enumerate 

@item 
Here @code{ALIGN()} represents a function or macro that
rounds @code{size} up to the necessary alignment, which should be
at least as big as the alignment of the pool. (The reason that
the MPS does not do this rounding up for you is to provide more
opportunities for optimization: in many cases the required
alignment will be a constant that’s known at compilation time.)

@item 
@ref{b2,,mps_commit()} returns false only if a garbage collection
@ref{18c,,flip} occurs after @ref{b0,,mps_reserve()}.  This is a very
rare event, especially if the object initialization is short.
@end enumerate
@end quotation
@end cartouche

@geindex mps_reserve (C function)
@anchor{topic/allocation c mps_reserve}@anchor{b0}
@deffn {C Function} @ref{14d,,mps_res_t} mps_reserve (mps_addr_t *p_o, mps_ap_t ap, size_t size)

Reserve a @ref{185,,block} of memory on an @ref{63,,allocation point}.

@code{p_o} points to a location that will hold the address of the
reserved block.

@code{ap} is the allocation point.

@code{size} is the @ref{183,,size} of the block to allocate. It must be
a multiple of the @ref{68,,alignment} of the pool (or of the pool’s
@ref{39,,object format} if it has one).

Returns @ref{5a,,MPS_RES_OK} if the block was reserved
successfully, or another @ref{59,,result code} if not.

The reserved block may be initialized but must not otherwise be
used

Until it has been @ref{b1,,committed (2)} via a successful call to
@ref{b2,,mps_commit()}, the reserved block may be:


@itemize *

@item 
initialized;

@item 
referenced by an @ref{9f,,ambiguous reference};
@end itemize

but:


@itemize *

@item 
it must not be referenced by an @ref{61,,exact reference};

@item 
references stored in it must not be followed;

@item 
it is not scanned, moved, or protected (even if it belongs to a
pool with these features).
@end itemize

@cartouche
@quotation Note 
@ref{b0,,mps_reserve()} must only be called according to the
@ref{ae,,Allocation point protocol}.

@ref{b0,,mps_reserve()} is implemented as a macro for speed. It
may evaluate its arguments multiple times.

There is an alternative, @ref{124,,MPS_RESERVE_BLOCK}, which
may generate faster code on some compilers.
@end quotation
@end cartouche
@end deffn

@geindex MPS_RESERVE_BLOCK (C macro)
@anchor{topic/allocation c MPS_RESERVE_BLOCK}@anchor{124}
@deffn {C Macro} MPS_RESERVE_BLOCK (res_v, p_v, ap, size)

An alternative to @ref{b0,,mps_reserve()}. On compilers that do not
perform common-subexpression elimination, it may generate faster
code than @ref{b0,,mps_reserve()} (but may not). It may only be used
in statement context (not as an expression).

The second argument is an lvalue @code{p_v}, which is assigned the
address of the reserved block. It takes an additional first
argument, the lvalue @code{res_v}, which is assigned the
@ref{59,,result code}.
@end deffn

@geindex mps_commit (C function)
@anchor{topic/allocation c mps_commit}@anchor{b2}
@deffn {C Function} @ref{129,,mps_bool_t} mps_commit (mps_ap_t ap, mps_addr_t p, size_t size)

@ref{b1,,Commit} a reserved @ref{185,,block} on an
@ref{63,,allocation point}.

@code{ap} is an allocation point.

@code{p} points to a block that was reserved by @ref{b0,,mps_reserve()}
but has not yet been committed.

@code{size} is the @ref{183,,size} of the block to allocate. It must be
the same size that was passed to @ref{b0,,mps_reserve()}.

If @ref{b2,,mps_commit()} returns true, the block was successfully
committed, which means that the @ref{d0,,client program} may use it,
create references to it, and rely on references from it. It also
means that the MPS may scan it, move it, protect it, or reclaim it
(if @code{ap} was attached to a pool with those features).

If @ref{b2,,mps_commit()} returns false, the block was not
committed. This means that the client program must not create
references to the block, rely on references from it, or otherwise
use it. It is normal to attempt the reserve operation again when
this happens.

It is very rare for @ref{b2,,mps_commit()} to return false: this
only happens if there was a @ref{18c,,flip} between the call to
@ref{b0,,mps_reserve()} and the call to
@ref{b2,,mps_commit()}. Nonetheless, it can happen, so it is
important not to perform operations with side effects (that you
aren’t prepared to repeat) between calling @ref{b0,,mps_reserve()}
and @ref{b2,,mps_commit()}. Also, the shorter the interval, the less
likely @ref{b2,,mps_commit()} is to return false.

@cartouche
@quotation Note 
@ref{b2,,mps_commit()} must only be called according to the
@ref{ae,,Allocation point protocol}.

@ref{b2,,mps_commit()} is implemented as a macro for speed. It
may evaluate its arguments multiple times.
@end quotation
@end cartouche
@end deffn

@geindex allocation point protocol; example

@node Example allocating a symbol,Cautions,Allocation point protocol,Allocation<2>
@anchor{topic/allocation example-allocating-a-symbol}@anchor{1c5}
@subsection Example: allocating a symbol


@example
typedef struct symbol_s @{
    type_t type;                  /* TYPE_SYMBOL */
    size_t length;                /* length of symbol string (excl. NUL) */
    char string[1];               /* symbol string, NUL terminated */
@} symbol_s, *symbol_t;

symbol_t make_symbol(size_t length, char string[])
@{
    symbol_t symbol;
    mps_addr_t addr;
    size_t size = ALIGN(offsetof(symbol_s, string) + length+1);
    do @{
        mps_res_t res = mps_reserve(&addr, ap, size);
        if (res != MPS_RES_OK) error("out of memory in make_symbol");
        symbol = addr;
        symbol->type = TYPE_SYMBOL;
        symbol->length = length;
        memcpy(symbol->string, string, length+1);
    @} while (!mps_commit(ap, addr, size));
    return symbol;
@}
@end example

@geindex allocation point protocol; cautions

@node Cautions,Example inserting into a doubly linked list,Example allocating a symbol,Allocation<2>
@anchor{topic/allocation cautions}@anchor{1c6}@anchor{topic/allocation topic-allocation-cautions}@anchor{1c7}
@subsection Cautions


While a block is reserved but not yet committed:


@enumerate 

@item 
The client program must not create an @ref{61,,exact reference} to
the reserved block (for example, by referring to the reserved block
from a @ref{23,,formatted object}). All references to it must be
ambiguous (for example, local variables).

@item 
Similar restrictions apply to a reference that has been stored in
the reserved block. Such a reference might be invalid, and must
not be copied to an @ref{61,,exact reference} or dereferenced. It is
safe to copy such a reference if it remains ambiguous (for
example, copying to a local variable or to another part of the new
block).
@end enumerate

Before calling @ref{b2,,mps_commit()}:


@enumerate 

@item 
The new block must be validly formatted. If it belongs to an
@ref{39,,object format}, then it must be correctly recognized by the
format methods (the @ref{81,,skip method} must return the object’s
correct size; the @ref{73,,scan method} must scan it; the
@ref{8c,,is-forwarded method} must report that it is not a
forwarding object, and so on).

@item 
All exact references in the new block (references that are
@ref{b4,,fixed} by scanning functions) must contain valid
references or null pointers.

@item 
The new object must be ambiguously @ref{96,,reachable}.
@end enumerate

You do not have to initialize the whole block so long as you satisfy
these conditions. For example, it is permissible to defer
initialization completely (for example, by writing
@code{TYPE_UNINITIALIZED} into a tag field), so long as you handle this
correctly in the format methods.

However, if you do not initialize the whole block then you should
beware: the uninitialized contents of the block is likely to consist
of dead objects. If, due to a bug, you created an exact reference into
the middle of the uninitialized block, this might by bad luck point to
a dead object, which would be resurrected (and it might well contain
further exact references to other dead objects). To ensure detection
of such a bug promptly you should consider filling the uninitialized
object with dummy values that cannot be mistaken for part of a valid
formatted object (at least in the debugging version of your program).

@cartouche
@quotation Note 
Some @ref{10,,pool classes} have debugging counterparts that
automatically overwrite free space with a pattern of bytes of your
choosing. See @ref{10d,,Debugging pools}.
@end quotation
@end cartouche

@geindex allocation point protocol; bugs
@geindex bug; allocation point protocol

@node Example inserting into a doubly linked list,Allocation point implementation,Cautions,Allocation<2>
@anchor{topic/allocation example-inserting-into-a-doubly-linked-list}@anchor{1c8}
@subsection Example: inserting into a doubly linked list


This example contains several mistakes. See the highlighted lines:

@example
typedef struct link_s @{
    type_t type;                       /* TYPE_LINK */
    /* all three of these pointers are fixed: */
    struct link_s *prev;
    struct link_s *next;
    obj_t obj;
@} link_s, *link_t;

/* insert 'obj' into the doubly-linked list after 'head' */
link_t insert_link(link_t head, obj_t obj)
@{
    mps_addr_t p;
    link_t link;
    size_t size = ALIGN(sizeof(link_s));
    do @{
        mps_res_t res = mps_reserve(&p, ap, size);
        if (res != MPS_RES_OK) error("out of memory");
        link = p;
        link->type = TYPE_LINK;
        link->prev = head;
        link->next = link->prev->next; /* (1) */
        head->next = link;             /* (2) */
        link->next->prev = link;       /* (3) */
    @} while (!mps_commit(ap, p, size));
    link->obj = obj;                   /* (4) */
    return link;
@}
@end example

The mistakes are:


@enumerate 

@item 
Dereferencing a reference (here, @code{link->prev}) that was stored in
the reserved block.

@item 
Making an exact reference to the reserved block (here,
@code{head->next} becomes an exact reference to @code{link}). This must
be deferred until after a successful commit.

@item 
This line makes both mistakes made by lines (1) and (2).

@item 
The @code{obj} slot contains an exact reference that gets fixed by the
scan method, so it must be initialized before the call to commit.
@end enumerate

A correct version of @code{insert_link} looks like this:

@example
link_t insert_link(link_t head, obj_t obj)
@{
    mps_addr_t p;
    link_t link;
    size_t size = ALIGN(sizeof(link_s));
    do @{
        mps_res_t res = mps_reserve(&p, ap, size);
        if (res != MPS_RES_OK) error("out of memory");
        link = p;
        link->type = TYPE_LINK;
        link->prev = head;
        link->next = head->next;
        link->obj = obj;
    @} while (!mps_commit(ap, p, size));
    head->next->prev = link;
    head->next = link;
    return link;
@}
@end example

@geindex allocation points; implementation

@node Allocation point implementation,,Example inserting into a doubly linked list,Allocation<2>
@anchor{topic/allocation allocation-point-implementation}@anchor{1c9}@anchor{topic/allocation topic-allocation-point-implementation}@anchor{1ca}
@subsection Allocation point implementation


An allocation point consists of a structure of type @ref{1c1,,mps_ap_s}
and an associated @ref{1cb,,buffer}.


@float Figure

@image{MemoryPoolSystem-figures/ap-buffer,,,Diagram: Allocation point and its associated buffer.,svg}

@caption{Allocation point and its associated buffer.}

@end float


The buffer is structured as shown in the figure, with free space at
the end of the buffer, `committed' blocks at the beginning, and
(possibly) one `reserved' block in the middle. The @ref{1c1,,mps_ap_s}
structure contains three addresses into the associated buffer:
@code{limit} points to the end of the buffer, @code{alloc} points to the
beginning of the free space, and @code{init} points to the end of the
initialized blocks.

Allocation points are fast and nearly lock-free because in order to
reserve space for a new block, the client program first checks that
@code{ap->alloc + size <= ap->limit} and in the common case that it is,
it takes a copy of @code{ap->init} (which now points to the reserved
block) and sets @code{ap->alloc += size}.

What happens when @code{ap->alloc + size > ap->limit}, that is, when the
new block won’t fit in the buffer? Then the buffer needs to be
`refilled' by calling @ref{1cc,,mps_ap_fill()}, with typical results
shown in the diagram below.


@float Figure

@image{MemoryPoolSystem-figures/ap-fill,,,Diagram: Allocation point after refilling.,svg}

@caption{Allocation point after refilling.}

@end float


Refilling is why allocation points are only `nearly' lock-free:
@ref{1cc,,mps_ap_fill()} has to take locks on internal MPS data
structures.

Note that @ref{1cc,,mps_ap_fill()} reserves the requested block as well
as refilling the buffer.

The `reserve' operation thus looks like this:

@example
if (ap->alloc + size <= ap->limit) @{
    ap->alloc += size;
    p = ap->init;
@} else @{
    res = mps_ap_fill(&p, ap, size);
    if (res != MPS_RES_OK) @{
        /* handle error */;
    @}
@}
@end example

The critical path consists of three loads, an add, two stores, and a
branch (and branch prediction should work well since the test usually
succeeds).

@cartouche
@quotation Note 
Normally the client program would use the macro
@ref{b0,,mps_reserve()} to perform this operation, as described
above, rather than directly accessing the fields of the allocation
point structure. But there are use cases where direct access is
needed to generate the fastest code (for example, in the case of a
compiler generating machine code that needs to interface with the
MPS), and it is for these use cases that the details of
@ref{1c1,,mps_ap_s} are made public and supported.
@end quotation
@end cartouche

When the new block has been initialized it must be @ref{b1,,committed (2)}. To do this, set @code{ap->init = ap->alloc} and then check to see
if the allocation point has been `trapped': that is, if the garbage
collector might have moved some objects since the new block was
reserved. The garbage collector traps an allocation point by setting
@code{ap->limit = 0}, so if this case is found, then the reserved block
may have been invalidated, and must be discarded and re-reserved, and
the buffer must be refilled. The function @ref{1cd,,mps_ap_trip()}
determines whether or not this case applies, returning true if the
block is valid, false if not.

The `commit' operation thus looks like this:

@example
ap->init = ap->alloc;
if (ap->limit == 0 && !mps_ap_trip(ap, p, size)) @{
    /* p is invalid */
@} else @{
    /* p is valid */
@}
@end example

The critical path here consists of three loads, a store and a branch
(and again, branch prediction should work well since the test almost
never fails).

@cartouche
@quotation Note 
Normally the client program would use @ref{b2,,mps_commit()} to
perform this operation, as described above, rather than directly
accessing the fields of the allocation point structure. But direct
access is supported by the MPS.
@end quotation
@end cartouche

@cartouche
@quotation Note 
The commit operation relies on atomic ordered access to words in
memory to detect a @ref{18c,,flip} that occurs between the assignment
@code{ap->init = ap->alloc} and the test @code{ap->limit == 0}. A
compiler or processor that reordered these two instructions would
break the protocol. On some processor architectures and some
compilers, it may be necessary to insert a memory barrier
instruction at this point.
@end quotation
@end cartouche

@geindex mps_ap_s (C type)
@anchor{topic/allocation c mps_ap_s}@anchor{1c1}
@deffn {C Type} type mps_ap_s

The type of the structure used to represent @ref{63,,allocation points}:

@example
typedef struct mps_ap_s @{
    mps_addr_t init;
    mps_addr_t alloc;
    mps_addr_t limit;
@} mps_ap_s;
@end example

@code{init} is the limit of initialized memory.

@code{alloc} is the limit of allocated memory.

@code{limit} is the limit of available memory.

An allocation point is an interface to a @ref{18,,pool} which
provides very fast allocation, and defers the need for
synchronization in a multi-threaded environment.

Create an allocation point for a pool by calling
@ref{af,,mps_ap_create_k()}, and allocate memory via one by calling
@ref{b0,,mps_reserve()} and @ref{b2,,mps_commit()}.
@end deffn

@geindex mps_ap_fill (C function)
@anchor{topic/allocation c mps_ap_fill}@anchor{1cc}
@deffn {C Function} @ref{14d,,mps_res_t} mps_ap_fill (mps_addr_t *p_o, mps_ap_t ap, size_t size)

Reserve a @ref{185,,block} of memory on an @ref{63,,allocation point}
when the allocation point has insufficient space.

@ref{1cc,,mps_ap_fill()} has same interface as @ref{b0,,mps_reserve()}.

@cartouche
@quotation Note 
@ref{1cc,,mps_ap_fill()} must only be called according to the
@ref{ae,,Allocation point protocol}.
@end quotation
@end cartouche
@end deffn

@geindex mps_ap_trip (C function)
@anchor{topic/allocation c mps_ap_trip}@anchor{1cd}
@deffn {C Function} @ref{129,,mps_bool_t} mps_ap_trip (mps_ap_t ap, mps_addr_t p, size_t size)

Test whether a reserved block was successfully @ref{b1,,committed (2)} when an @ref{63,,allocation point} was trapped.

@ref{1cd,,mps_ap_trip()} has the same interface as @ref{b2,,mps_commit()}.

@cartouche
@quotation Note 
@ref{1cd,,mps_ap_trip()} must only be called according to the
@ref{ae,,Allocation point protocol}.
@end quotation
@end cartouche
@end deffn

@c sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mmdoc/protocol/mps/format/index.html>`_

@geindex object format; introduction
@geindex format; object

@node Object formats,Scanning,Allocation<2>,Reference
@anchor{topic/format doc}@anchor{1ce}@anchor{topic/format object-formats}@anchor{1cf}@anchor{topic/format topic-format}@anchor{6a}
@section Object formats


The need for some means of describing objects in the @ref{d0,,client program} comes from @ref{4b,,tracing} and @ref{1ad,,moving}. During tracing, when an object is @ref{65,,scanned}, all the @ref{24,,references} in the object must be
identified so that the objects they point to can be scanned in their
turn. When an object has moved, references to that object must be
identified so that they can be updated to point to the new location of
the object.

In general, only the client program can say which fields in an object
are references, and only the client program knows how references are
represented (for example, are they tagged?). `Object formats' provide
the means by which the client program communicates this information to
the MPS.

An object format is a collection of @ref{69,,format methods} and other
(usually scalar) values which together describe programmatically the
layout of objects belonging to the format. Format methods include the
@ref{81,,skip method} (which calculates an object’s size), the
@ref{73,,scan method} (which @ref{b4,,fixes} references in the
object), and the @ref{85,,forward method} (which replaces an object that
has moved with a @ref{66,,forwarding object}).

Not every @ref{10,,pool class} supports @ref{23,,formatted objects}.

@geindex object format; interface

@menu
* Interface:: 
* In-band headers:: 
* Cautions: Cautions<2>. 
* Format methods:: 
* Object format introspection:: 

@end menu

@node Interface,In-band headers,,Object formats
@anchor{topic/format interface}@anchor{1d0}
@subsection Interface


@geindex mps_fmt_t (C type)
@anchor{topic/format c mps_fmt_t}@anchor{141}
@deffn {C Type} type mps_fmt_t

The type of an @ref{39,,object format}.
@end deffn

@geindex mps_fmt_create_k (C function)
@anchor{topic/format c mps_fmt_create_k}@anchor{13f}
@deffn {C Function} void mps_fmt_create_k (mps_fmt_t *mps_fmt_o, mps_arena_t arena, mps_arg_s args[])

Create an @ref{39,,object format}.

@code{fmt_o} points to a location that will hold the address of the new
object format.

@code{arena} is the arena in which to create the format.

@code{args} are @ref{53,,keyword arguments} describing the format. Each
@ref{10,,pool class} requires a particular subset of these keyword
arguments: see the documentation for that pool class.


@itemize *

@item 
@code{MPS_KEY_FMT_ALIGN} (type @ref{128,,mps_align_t},
default @ref{6f,,MPS_PF_ALIGN}) is an integer value specifying
the alignment of objects allocated with this format. It should
be large enough to satisfy the alignment requirements of any
field in the objects, and it must not be larger than the pool
alignment.

@item 
@code{MPS_KEY_FMT_HEADER_SIZE} (type @code{size_t},
default 0) is an integer value specifying the header size for
objects with @ref{1d1,,in-band headers}. See
@ref{1d2,,In-band headers} below.

@item 
@code{MPS_KEY_FMT_SCAN} (type @ref{74,,mps_fmt_scan_t}) is a
@ref{73,,scan method} that identifies references within objects
belonging to this format. See @ref{74,,mps_fmt_scan_t}.

@item 
@code{MPS_KEY_FMT_SKIP} (type @ref{82,,mps_fmt_skip_t}) is a
@ref{81,,skip method} that skips over objects belonging to this
format. See @ref{82,,mps_fmt_skip_t}.

@item 
@code{MPS_KEY_FMT_FWD} (type @ref{86,,mps_fmt_fwd_t}) is a
@ref{85,,forward method} that stores relocation information for an
object belonging to this format that has moved. See
@ref{86,,mps_fmt_fwd_t}.

@item 
@code{MPS_KEY_FMT_ISFWD} (type @ref{8d,,mps_fmt_isfwd_t}) is
a @ref{8c,,is-forwarded method} that determines if an object
belonging to this format has been moved. See
@ref{8d,,mps_fmt_isfwd_t}.

@item 
@code{MPS_KEY_FMT_PAD} (type @ref{91,,mps_fmt_pad_t}) is a
@ref{90,,padding method} that creates @ref{67,,padding objects}
belonging to this format. See @ref{91,,mps_fmt_pad_t}.

@item 
@code{MPS_KEY_FMT_CLASS} (type @ref{140,,mps_fmt_class_t}) is
a method that returns an address that is related to the class or
type of the object, for inclusion in the @ref{ba,,telemetry stream} for some events relating to the object. See
@ref{140,,mps_fmt_class_t}.
@end itemize

@ref{13f,,mps_fmt_create_k()} returns @ref{5a,,MPS_RES_OK} if
successful. The MPS may exhaust some resource in the course of
@ref{13f,,mps_fmt_create_k()} and will return an appropriate
@ref{59,,result code} if so.

The object format pointed to by @code{fmt_o} persists until it is
destroyed by calling @ref{167,,mps_fmt_destroy()}.

For example:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_FMT_ALIGN, ALIGNMENT);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_SCAN, obj_scan);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_SKIP, obj_skip);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_FWD, obj_fwd);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_ISFWD, obj_isfwd);
    MPS_ARGS_ADD(args, MPS_KEY_FMT_PAD, obj_pad);
    res = mps_fmt_create_k(&obj_fmt, arena, args);
@} MPS_ARGS_END(args);
if (res != MPS_RES_OK) error("Couldn't create obj format");
@end example
@end deffn

@geindex mps_fmt_destroy (C function)
@anchor{topic/format c mps_fmt_destroy}@anchor{167}
@deffn {C Function} void mps_fmt_destroy (mps_fmt_t fmt)

Destroy an @ref{39,,object format}.

@code{fmt} is the object format to destroy.

It is an error to destroy an object format if there exists a
@ref{18,,pool} using the format. The pool must be destroyed first.
@end deffn

@geindex object format; in-band headers
@geindex object format; headers

@node In-band headers,Cautions<2>,Interface,Object formats
@anchor{topic/format in-band-headers}@anchor{1d3}@anchor{topic/format topic-format-headers}@anchor{1d2}
@subsection In-band headers


There are use cases in which it is convenient for the @ref{d0,,client program’s} pointers to point some distance into the
memory @ref{185,,block} containing the object. This typically happens
when the objects have a common @ref{1d1,,in-band header} used for memory
management or class system purposes, but this situation also arises
when the low bits of a pointer are used for a tag. The MPS does not
care what the reason is, only about the offset of the pointer in
relation to the memory block.

If you have one of these use cases, you should pass the
@code{MPS_KEY_FMT_HEADER_SIZE} @ref{53,,keyword argument} to
@ref{13f,,mps_fmt_create_k()}, specifying the size of the header: that
is, the offset of a @ref{1d4,,client pointer} from the base of the memory
block.

There are some cautions to be observed when using in-band headers:


@enumerate 

@item 
The format methods (other than the @ref{90,,padding method}) receive
@ref{1d4,,client pointers} (that is, pointers past the header) but all
other MPS functions expect to receive and return @ref{1aa,,base pointers} (that is, pointers to the base of the block where the
header is stored).

In particular, @ref{b0,,mps_reserve()} and @ref{ad,,mps_alloc()} always
hand out base pointers, and @ref{1f,,mps_free()} expects to receive
one.

@item 
Formatted objects must be longer than the header. In other words,
objects consisting of only a header are not supported.

@item 
Even if the header size is larger than or equal to
@ref{68,,alignment}, the @ref{90,,padding method} must still be able to
create @ref{67,,padding objects} down to the alignment size.

@item 
Not all @ref{10,,pool classes} support objects with in-band headers.
See the documentation for the pool class.
@end enumerate

@cartouche
@quotation Note 
A @ref{d0,,client program} that allocates objects with
@ref{1d1,,in-band headers} has to make a choice about how to
represent references to those objects. It can represent them using
@ref{1aa,,base pointers} (which is convenient for allocation, since
@ref{b0,,mps_reserve()} returns a base pointer, but requires
decoding when scanning) or using @ref{1d4,,client pointers} (which is
convenient for scanning, since the @ref{73,,scan method} takes a
client pointer, but requires encoding on allocation). Either
approach will work, but @ref{1d4,,client pointers} are normally the
better choice, since scanning is normally more
performance-critical than allocation.
@end quotation
@end cartouche

@geindex object format; cautions

@node Cautions<2>,Format methods,In-band headers,Object formats
@anchor{topic/format cautions}@anchor{1d5}@anchor{topic/format topic-format-cautions}@anchor{c0}
@subsection Cautions



@enumerate 

@item 
The MPS guarantees that format methods have exclusive access to the
object for the duration of the call. This guarantee may entail
suspending arbitrary threads. The methods that manipulate the
object must not perform any sort of inter-thread locking or
communication.

@item 
The MPS may call format methods in the context of an exception
handler or a signal handler. For example, the following sequence of
events is common:


@enumerate a

@item 
the MPS places a @ref{1d6,,read barrier} on a block of memory;

@item 
the client program attempts to read from this block;

@item 
the hardware raises a @ref{1d7,,protection fault};

@item 
the MPS signal handler is called;

@item 
the MPS ensures that the contents of the block are correct and
consistent: this may involve inspection of formatted objects in
the block (or indeed, elsewhere), and so

@item 
the MPS calls format methods.
@end enumerate

Therefore, the format methods must be able to be run at any time,
including asynchronously or in parallel with the rest of the
program. On POSIX systems, this means that format methods must be
async-signal-safe.

@item 
Format methods must be re-entrant.

@item 
Format methods must use no more than 64 words of stack space.

This restriction is necessary to avoid stack overflow in the MPS;
see @ref{1d8,,Stack probe} for details. If your application has format
methods that need more stack space than this, @ref{d8,,contact us}.

@item 
Format methods must not:


@enumerate a

@item 
call library code;

@item 
access MPS-managed memory in pools that protect their contents;

@item 
perform a non-local exit (for example, by throwing an exception,
or calling @code{longjmp()});

@item 
call any functions or macros in the MPS other than
@ref{7a,,MPS_SCAN_BEGIN}, @ref{7b,,MPS_SCAN_END},
@ref{75,,MPS_FIX1()}, @ref{77,,MPS_FIX12()}, @ref{76,,MPS_FIX2()}, and
@ref{1d9,,MPS_FIX_CALL}.
@end enumerate

It’s permissible to call other functions in the client program, but
see @ref{1d9,,MPS_FIX_CALL} for a restriction on passing the
@ref{79,,scan state}.

@item 
Subject to the above constraints, format methods can freely access:


@enumerate a

@item 
memory inside the object or block that they have been asked to
look at;

@item 
MPS-managed memory in pools that do not protect their contents;

@item 
memory not managed by the MPS.
@end enumerate
@end enumerate

@geindex format method
@geindex object format; format method

@node Format methods,Object format introspection,Cautions<2>,Object formats
@anchor{topic/format format-methods}@anchor{1da}
@subsection Format methods


@geindex mps_fmt_class_t (C type)
@anchor{topic/format c mps_fmt_class_t}@anchor{140}
@deffn {C Type} typedef @ref{11d,,mps_addr_t} (*mps_fmt_class_t)(@ref{11d,,mps_addr_t} addr)

The type of the class method of an @ref{39,,object format}.

@code{addr} is the address of the object whose class is of interest.

Returns an address that is related to the class or type of the
object, or a null pointer if this is not possible.

It is recommended that a null pointer be returned for
@ref{67,,padding objects} and @ref{66,,forwarding objects}.
@end deffn

@geindex mps_fmt_fwd_t (C type)
@anchor{topic/format c mps_fmt_fwd_t}@anchor{86}
@deffn {C Type} typedef void (*mps_fmt_fwd_t)(@ref{11d,,mps_addr_t} old, @ref{11d,,mps_addr_t} new)

The type of the @ref{85,,forward method} of an @ref{39,,object format}.

@code{old} is the address of an object.

@code{new} is the address to where the object has been moved.

The MPS calls the forward method for an object format when it has
relocated an object belonging to that format. The forward method
must replace the object at @code{old} with a @ref{1db,,forwarding marker}
that points to the address ‘new’. The forwarding marker must meet
the following requirements:


@enumerate 

@item 
It must be possible for the MPS to call other methods in the
object format (the @ref{73,,scan method}, the @ref{81,,skip method}
and so on) with the address of a forwarding marker as the
argument.

@item 
The forwarding marker must be the same size as the old object.
That is, when the @ref{81,,skip method} is called on the
forwarding marker, it must return the same address as when it
was called on the old object.

@item 
It must be possible for the @ref{8c,,is-forwarded method} of the
object format to distinguish the forwarding marker from
ordinary objects, and the is-forwarded method method must
return the address @code{new}. See @ref{8d,,mps_fmt_isfwd_t}.
@end enumerate

@cartouche
@quotation Note 
This method is never invoked by the @ref{20,,garbage collector}
on an object in a @ref{5e,,non-moving} @ref{18,,pool}.
@end quotation
@end cartouche
@end deffn

@geindex mps_fmt_isfwd_t (C type)
@anchor{topic/format c mps_fmt_isfwd_t}@anchor{8d}
@deffn {C Type} typedef @ref{11d,,mps_addr_t} (*mps_fmt_isfwd_t)(@ref{11d,,mps_addr_t} addr)

The type of the @ref{8c,,is-forwarded method} of an @ref{39,,object format}.

@code{addr} is the address of a candidate object.

If the @code{addr} is the address of a @ref{66,,forwarding object}, return
the address where the object was moved to. This must be the value
of the @code{new} argument supplied to the @ref{85,,forward method} when
the object was moved. If not, return a null pointer.

@cartouche
@quotation Note 
This method is never invoked by the @ref{20,,garbage collector}
on an object in a @ref{5e,,non-moving} @ref{18,,pool}.
@end quotation
@end cartouche
@end deffn

@geindex mps_fmt_pad_t (C type)
@anchor{topic/format c mps_fmt_pad_t}@anchor{91}
@deffn {C Type} typedef void (*mps_fmt_pad_t)(@ref{11d,,mps_addr_t} addr, size_t size)

The type of the @ref{90,,padding method} of an @ref{39,,object format}.

@code{addr} is the address at which to create a @ref{67,,padding object}.

@code{size} is the @ref{183,,size} of the padding object to be created.

The MPS calls a padding method when it wants to create a padding
object. Typically the MPS creates padding objects to fill in
otherwise unused gaps in memory; they allow the MPS to pack
objects into fixed-size units (such as operating system
@ref{92,,pages}).

The padding method must create a padding object of the specified
size at the specified address. The size can be any aligned (to the
format alignment) size. A padding object must be acceptable to
other methods in the format (the @ref{73,,scan method}, the
@ref{81,,skip method}, and so on).

@cartouche
@quotation Note 
The padding method always receives a base pointer, even if the
object format has a non-zero
@code{MPS_KEY_FMT_HEADER_SIZE}.
@end quotation
@end cartouche

@cartouche
@quotation Note 
The MPS will ask for padding objects of any size aligned to
the pool alignment, no matter what size objects the pool
holds.  For example, a pool holding only two-word objects may
still be asked to create padding objects 2048 bytes long.
@end quotation
@end cartouche
@end deffn

@geindex mps_fmt_scan_t (C type)
@anchor{topic/format c mps_fmt_scan_t}@anchor{74}
@deffn {C Type} typedef @ref{14d,,mps_res_t} (*mps_fmt_scan_t)(@ref{1dc,,mps_ss_t} ss, @ref{11d,,mps_addr_t} base, @ref{11d,,mps_addr_t} limit)

The type of the @ref{73,,scan method} of an @ref{39,,object format}.

@code{ss} is the @ref{79,,scan state}. It must be passed to
@ref{7a,,MPS_SCAN_BEGIN} and @ref{7b,,MPS_SCAN_END} to delimit a
sequence of fix operations, and to the functions
@ref{75,,MPS_FIX1()} and @ref{76,,MPS_FIX2()} when fixing a
@ref{24,,reference}.

@code{base} points to the first @ref{23,,formatted object} in the block
of memory to be scanned.

@code{limit} points to the location just beyond the end of the block to
be scanned. Note that there might not be any object at this
location.

Returns a @ref{59,,result code}. If a fix function returns a value
other than @ref{5a,,MPS_RES_OK}, the scan method must return that
value, and may return without fixing any further references.
Generally, it is better if it returns as soon as possible. If the
scanning is completed successfully, the function should return
@ref{5a,,MPS_RES_OK}.

The scan method for an object format is called when the MPS needs
to scan objects in a block of memory containing objects belonging
to that format. The scan method is called with a scan state and
the base and limit of the block of objects to scan. It must then
indicate references within the objects by calling
@ref{75,,MPS_FIX1()} and @ref{76,,MPS_FIX2()}.

If the object format is capable of creating forwarding objects or
padding objects, the scan method must be able to scan these
objects. (In the case of the forwarding object, the scan method
should not fix the pointer to the new location.)


@subsubheading See also


@ref{25,,Scanning}.

@end deffn

@geindex mps_fmt_skip_t (C type)
@anchor{topic/format c mps_fmt_skip_t}@anchor{82}
@deffn {C Type} typedef @ref{11d,,mps_addr_t} (*mps_fmt_skip_t)(@ref{11d,,mps_addr_t} addr)

The type of the @ref{81,,skip method} of an @ref{39,,object format}.

@code{addr} is the address of the object to be skipped.

Returns the address of the “next object”. In an object format
without @ref{1d1,,in-band headers}, this is the address just past the
end of this object. In an object format with in-band headers, it’s
the address just past where the header of next object would be, if
there were one.

@cartouche
@quotation Note 
In either case, the result is the sum of @code{addr} and the size
of the block containing the object.
@end quotation
@end cartouche

If the object format is capable of creating forwarding objects or
padding objects, the skip method must be able to skip these
objects.

A skip method is not allowed to fail.

@cartouche
@quotation Note 
The MPS uses this method to determine the size of objects (by
subtracting @code{addr} from the result) as well as skipping over
them.
@end quotation
@end cartouche
@end deffn

@geindex object format; introspection

@node Object format introspection,,Format methods,Object formats
@anchor{topic/format object-format-introspection}@anchor{1dd}
@subsection Object format introspection


@geindex mps_addr_fmt (C function)
@anchor{topic/format c mps_addr_fmt}@anchor{1a5}
@deffn {C Function} @ref{129,,mps_bool_t} mps_addr_fmt (mps_fmt_t *fmt_o, mps_arena_t arena, mps_addr_t addr)

Determine the @ref{39,,object format} to which an address belongs.

@code{fmt_o} points to a location that will hold the address of the
object format, if one is found.

@code{arena} is the arena whose object formats will be considered.

@code{addr} is the address.

If @code{addr} is the address of a location inside a block allocated
from a pool in @code{arena}, and that pool has an object format, then
update the location pointed to by @code{fmt_o} with the address of
the object format, and return true.

If @code{addr} is the address of a location inside a block allocated
from a pool in @code{arena}, but that pool has no object format,
return false.

If @code{addr} points to a location that is not managed by @code{arena},
return false.

If none of the above conditions is satisfied,
@ref{1a5,,mps_addr_fmt()} may return either true or false.

@cartouche
@quotation Note 
This function might return a false positive by returning true
if you ask about an address that happens to be inside memory
managed by a pool with an object format, but which is not
inside a block allocated by that pool. It never returns a
false negative.
@end quotation
@end cartouche
@end deffn

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mmdoc/protocol/mps/scanning/>`_

@geindex scanning; introduction
@geindex object format; scan method

@node Scanning,Threads<2>,Object formats,Reference
@anchor{topic/scanning doc}@anchor{1de}@anchor{topic/scanning scanning}@anchor{1df}@anchor{topic/scanning topic-scanning}@anchor{25}
@section Scanning


@ref{65,,Scanning} is the process of identifying the
@ref{24,,references} in a block of memory and
@ref{b4,,“fixing”} them. It’s the process at the heart of the
Memory Pool System, and the most critical of the memory management
functions that have to be implemented by the @ref{d0,,client program}.

Scanning is used to carry out three tasks:


@enumerate 

@item 
During @ref{4b,,tracing}, blocks are scanned in order to
follow references, and so determine which blocks are
@ref{96,,reachable} and which are not.

@item 
After objects have been moved in memory, blocks are scanned in
order to identify references that need to be updated to point to
the new locations of these objects.

@item 
When iterating over allocated blocks in a pool using
@ref{1a6,,mps_pool_walk()}, blocks are scanned in order to keep data
structures consistent when references are updated.
@end enumerate

All these tasks use the same protocol, described here.

@geindex scanning; protocol

@menu
* Scanning protocol:: 
* Tagged references:: 
* Critical path:: 
* Ambiguous references:: 
* Unfixed references:: 
* Example; Scheme objects: Example Scheme objects. 
* Scanning interface:: 
* Fixing interface:: 
* Area scanners:: 

@end menu

@node Scanning protocol,Tagged references,,Scanning
@anchor{topic/scanning scanning-protocol}@anchor{1e0}@anchor{topic/scanning topic-scanning-protocol}@anchor{16f}
@subsection Scanning protocol


There are several types of scanning functions (the @ref{73,,scan method}
in an @ref{39,,object format}, of type @ref{74,,mps_fmt_scan_t}, and
root scanning functions of various types) but all take a @ref{79,,scan state} argument of type @ref{1dc,,mps_ss_t}, and a description of a
region to be scanned. They must carry out the following steps:


@enumerate 

@item 
Call the macro @ref{7a,,MPS_SCAN_BEGIN} on the scan state.

@item 
For each reference in the region:


@enumerate 

@item 
Call @ref{75,,MPS_FIX1()}, passing the scan state and the
reference.

@item 
If @ref{75,,MPS_FIX1()} returns false, the reference is not of
interest to the MPS. Proceed to the next reference in the
region.

@item 
If @ref{75,,MPS_FIX1()} returns true, the reference is of interest
to the MPS. Call @ref{76,,MPS_FIX2()}, passing the scan state and
a pointer to a location containing the reference.

@item 
If @ref{76,,MPS_FIX2()} returns a @ref{59,,result code} other than
@ref{5a,,MPS_RES_OK}, return this result code from the scanning
function as soon as practicable.

@item 
If @ref{76,,MPS_FIX2()} returns @ref{5a,,MPS_RES_OK}, it may have
updated the reference. Make sure that the updated reference is
stored back into the region being scanned.
@end enumerate

@item 
Call the macro @ref{7b,,MPS_SCAN_END} on the scan state.

@item 
Return @ref{5a,,MPS_RES_OK}.
@end enumerate

This description of the protocol simplifies a number of important
details, which are covered in the following sections.

@geindex scanning; tagged reference

@node Tagged references,Critical path,Scanning protocol,Scanning
@anchor{topic/scanning tagged-references}@anchor{1e1}@anchor{topic/scanning topic-scanning-tag}@anchor{7e}
@subsection Tagged references


If your references are @ref{7d,,tagged} (or otherwise
“encrypted”), then you must remove the tag (or decrypt them) before
passing them to @ref{75,,MPS_FIX1()} and @ref{76,,MPS_FIX2()}.

The reference passed to @ref{76,,MPS_FIX2()} must be the address of the
base of the block referred to (unless the referent belongs to an
@ref{39,,object format} with @ref{1d1,,in-band headers}, in which case it
must be a reference to the address just after the header).

However, @ref{75,,MPS_FIX1()} allows some leeway: if you pass it a
reference to the interior of an allocated block, then
@ref{75,,MPS_FIX1()} correctly determines whether a reference to the
block is of interest to the MPS.

This means that if your tag is in the low bits of the reference, you
may not have to remove it before calling @ref{75,,MPS_FIX1()}. For
example, if you use three tag bits, then your reference is at most
`base' + 7, and if your objects are at least 8 bytes long, then the
reference is within the object and need not be stripped. So your code
might look like this:

@example
if (MPS_FIX1(ss, obj->ref)) @{
    /* strip the tag */
    mps_addr_t p = obj->ref & ~0x7;
    mps_res_t res = MPS_FIX2(ss, &p);
    if (res != MPS_RES_OK) return res;
    /* restore the tag and update reference */
    mps_word_t tag = obj->ref & 0x7;
    obj->ref = (obj_t)((char *)p + tag);
@}
@end example

This saves the cost of stripping the tag in the case that @code{obj->ref}
is not of interest to the MPS.

Similarly, if you use interior pointers, you do not need to convert
them to base pointers before calling @ref{75,,MPS_FIX1()} (or, indeed,
before calling @ref{76,,MPS_FIX2()}, if the target of the referent
belongs to an @ref{39,,object format} with @ref{1d1,,in-band headers}).

@geindex scanning; critical path

@node Critical path,Ambiguous references,Tagged references,Scanning
@anchor{topic/scanning critical-path}@anchor{1e2}
@subsection Critical path


Scanning is an operation on the critical path of the MPS and so it is
vital that it runs fast. The scanning protocol is designed to ensure
that as much of the scanning code can be run inline in the client
program as possible. In particular, the macro @ref{75,,MPS_FIX1()} does
not need to call into the MPS.

The purpose of @ref{75,,MPS_FIX1()} is to provide a fast check as to
whether a reference is “of interest” to the MPS. It is legitimate to
call this on any word: it does not even have to be an address. So if
you have a mixture of references and non-references, it might turn out
to be faster to call @ref{75,,MPS_FIX1()} on each word before you even
determine whether or not the word is a reference.

Whether this is in fact an optimization depends on the proportion of
references to non-references, on how often genuine references turn out
to be “of interest”, and what kind of code the compiler has
generated. There is no substitute for measurement.

See @ref{1e3,,The critical path through the MPS}.

@cartouche
@quotation Note 
In one application with a high proportion of @ref{48,,unboxed}
values, it turned out to be fastest to check the tag and reject
non-references before calling @ref{75,,MPS_FIX1()}.
@end quotation
@end cartouche

@cartouche
@quotation Warning 
If you passed a word that might not be a reference to
@ref{75,,MPS_FIX1()}, and it returned true, this might be a false
positive. You must be certain that the alleged reference is
genuine as well as “of interest” before passing it to
@ref{76,,MPS_FIX2()}.
@end quotation
@end cartouche

Another technique that can speed up scanning is to segregate objects
into pools whose object formats contain different scan methods. In
particular, if you can segregate objects that do not contain any
references into @ref{107,,leaf object} pools like @ref{89,,AMCZ (Automatic Mostly-Copying Zero-rank)}, these
objects do not need to be scanned at all.

@geindex scanning; ambiguous reference

@node Ambiguous references,Unfixed references,Critical path,Scanning
@anchor{topic/scanning ambiguous-references}@anchor{1e4}
@subsection Ambiguous references


If the references in the object being scanned are @ref{9f,,ambiguous} then @ref{76,,MPS_FIX2()} does not update the
reference (because it can’t know if it’s a genuine reference). The MPS
handles an ambiguous reference by @ref{1e5,,pinning} the block pointed to
so that it cannot move.

You could use this fact to optimize the scan by avoiding the need to
reassemble and store the updated reference after calling
@ref{76,,MPS_FIX2()}.

@cartouche
@quotation Note 
The MPS currently has no pools that support ambiguous references,
so this cannot arise for the @ref{73,,scan method} in an
@ref{39,,object format}, but @ref{97,,root} scanning functions may
encounter this case.
@end quotation
@end cartouche

@geindex scanning; unfixed reference

@node Unfixed references,Example Scheme objects,Ambiguous references,Scanning
@anchor{topic/scanning unfixed-references}@anchor{1e6}
@subsection Unfixed references


The MPS does not require you to @ref{b4,,fix} all your @ref{24,,references}. But if a reference is not fixed:


@enumerate 

@item 
it does not keep its target alive (this might be acceptable if you
know that the target is being kept alive for another reason, for
example if it is in a @ref{8,,manually managed} pool, or if there is always another reference to the
target that `is' fixed);

@item 
it does not get updated if the target moves (this might be
acceptable if you know that the target cannot move, for example if
it is in a @ref{1e7,,non-moving} pool, or
if it is @ref{1e5,,pinned} by an @ref{9f,,ambiguous reference}).
@end enumerate

These optimizations can be tricky to make correct, and can make the
system fragile (for example, it may break if you start using a
different @ref{10,,pool class}), so it is usually safest to fix all
references.

@geindex scanning; example
@geindex Scheme; scanning

@node Example Scheme objects,Scanning interface,Unfixed references,Scanning
@anchor{topic/scanning example-scheme-objects}@anchor{1e8}
@subsection Example: Scheme objects


Scanning tends to be a repetitive procedure and so you’ll find it is
usually helpful to define macros to reduce the size of the source
code. The MPS provides a convenience macro @ref{77,,MPS_FIX12()} for the
common case of calling @ref{75,,MPS_FIX1()} and then immediately calling
@ref{76,,MPS_FIX2()} if the reference is “of interest”.

@cartouche
@quotation Note 
Some compilers generate better code if you use
@ref{77,,MPS_FIX12()}, and some if you use @ref{75,,MPS_FIX1()} and
@ref{76,,MPS_FIX2()}. There’s no substitute for measurement.
@end quotation
@end cartouche

Here’s the macro @code{FIX} defined by the toy Scheme interpreter:

@example
#define FIX(ref)                                                        \
    do @{                                                                \
        mps_addr_t _addr = (ref); /* copy to local to avoid type pun */ \
        mps_res_t res = MPS_FIX12(ss, &_addr);                          \
        if (res != MPS_RES_OK) return res;                              \
        (ref) = _addr;                                                  \
    @} while(0)
@end example

@cartouche
@quotation Note 
The comment refers to a temptation to write non-portable code that
presents itself here. @ref{76,,MPS_FIX2()} takes a pointer to a
location containing the reference (an argument of type
@code{mps_addr_t *}). It is tempting to take the address of the
reference and cast it to this type. The behaviour of such a cast
is not defined by the C standard. See @ref{121,,Type punning}.
@end quotation
@end cartouche

Here’s the Scheme scanner:

@example
static mps_res_t obj_scan(mps_ss_t ss, mps_addr_t base, mps_addr_t limit)
@{
    MPS_SCAN_BEGIN(ss) @{
        while (base < limit) @{
            obj_t obj = base;
            switch (obj->type.type) @{
                case TYPE_PAIR:
                    FIX(obj->pair.car);
                    FIX(obj->pair.cdr);
                    base = (char *)base + ALIGN(sizeof(pair_s));
                    break;
                case TYPE_VECTOR: @{
                    size_t i;
                    for (i = 0; i < obj->vector.length; ++i)
                        FIX(obj->vector.vector[i]);
                    base = (char *)base +
                        ALIGN(offsetof(vector_s, vector) +
                              obj->vector.length * sizeof(obj->vector.vector[0]));
                    break;
                @}
                /* ... and so on for the other types ... */
                default:
                    assert(0);
                    fprintf(stderr, "Unexpected object on the heap\n");
                    abort();
                    return MPS_RES_FAIL;
            @}
        @}
    @} MPS_SCAN_END(ss);
    return MPS_RES_OK;
@}
@end example

@cartouche
@quotation Note 
This scanner is a simple example intended to make the process
clear to the reader. The scanning code and the object layout are
not at all optimized.
@end quotation
@end cartouche

@geindex scanning; interface

@node Scanning interface,Fixing interface,Example Scheme objects,Scanning
@anchor{topic/scanning scanning-interface}@anchor{1e9}
@subsection Scanning interface


@geindex mps_ss_t (C type)
@anchor{topic/scanning c mps_ss_t}@anchor{1dc}
@deffn {C Type} type mps_ss_t

The type of @ref{79,,scan states}.

A scan state represents the state of the current @ref{65,,scan}. The
MPS passes a scan state to the @ref{73,,scan method} of an
@ref{39,,object format} when it needs to @ref{65,,scan} for
@ref{24,,references} within a region of memory. The scan
method must pass the scan state to @ref{7a,,MPS_SCAN_BEGIN} and
@ref{7b,,MPS_SCAN_END} to delimit a sequence of fix operations,
and to the functions @ref{75,,MPS_FIX1()}, @ref{76,,MPS_FIX2()} and
@ref{77,,MPS_FIX12()} when fixing a @ref{24,,reference}.
@end deffn

@geindex MPS_SCAN_BEGIN (C macro)
@anchor{topic/scanning c MPS_SCAN_BEGIN}@anchor{7a}
@deffn {C Macro} MPS_SCAN_BEGIN (ss)

Within a @ref{73,,scan method}, set up local information required
by @ref{75,,MPS_FIX1()}, @ref{76,,MPS_FIX2()} and
@ref{77,,MPS_FIX12()}. The local information persists until
@ref{7b,,MPS_SCAN_END}.

@code{ss} is the @ref{79,,scan state} that was passed to the scan method.

@cartouche
@quotation Note 
Between @ref{7a,,MPS_SCAN_BEGIN} and @ref{7b,,MPS_SCAN_END},
the scan state is in a special state, and must not be passed
to a function. If you really need to do so, for example
because you have an embedded structure shared between two scan
methods, you must wrap the call with @ref{1d9,,MPS_FIX_CALL} to
ensure that the scan state is passed correctly.
@end quotation
@end cartouche
@end deffn

@geindex MPS_SCAN_END (C macro)
@anchor{topic/scanning c MPS_SCAN_END}@anchor{7b}
@deffn {C Macro} MPS_SCAN_END (ss)

Within a @ref{73,,scan method}, terminate a block started by
@ref{7a,,MPS_SCAN_BEGIN}.

@code{ss} is the @ref{79,,scan state} that was passed to the scan
method.

@cartouche
@quotation Note 
@ref{7b,,MPS_SCAN_END} ensures that the scan is completed, so
successful termination of a scan must invoke it. However, in
case of an error it is allowed to return from the scan
method without invoking @ref{7b,,MPS_SCAN_END}.
@end quotation
@end cartouche

@cartouche
@quotation Note 
Between @ref{7a,,MPS_SCAN_BEGIN} and @ref{7b,,MPS_SCAN_END}, the
scan state is in a special state, and must not be passed to a
function. If you really need to do so, for example because you
have an embedded structure shared between two scan methods, you
must wrap the call with @ref{1d9,,MPS_FIX_CALL} to ensure that the
scan state is passed correctly.
@end quotation
@end cartouche
@end deffn

@geindex MPS_FIX_CALL (C macro)
@anchor{topic/scanning c MPS_FIX_CALL}@anchor{1d9}
@deffn {C Macro} MPS_FIX_CALL (ss, call)

Call a function to do some scanning, from within a @ref{73,,scan method}, between @ref{7a,,MPS_SCAN_BEGIN} and
@ref{7b,,MPS_SCAN_END}, passing the @ref{79,,scan state} correctly.

@code{ss} is the scan state that was passed to the scan method.

@code{call} is an expression containing a function call where @code{ss}
is one of the arguments.

Between @ref{7a,,MPS_SCAN_BEGIN} and @ref{7b,,MPS_SCAN_END}, the
scan state is in a special state, and must not be passed to a
function. If you really need to do so, for example because you
have a structure shared between two @ref{39,,object formats}, you
must wrap the call with @ref{1d9,,MPS_FIX_CALL} to ensure that the
scan state is passed correctly.

The function being called must use @ref{7a,,MPS_SCAN_BEGIN} and
@ref{7b,,MPS_SCAN_END} appropriately.

In example below, the scan method @code{obj_scan} fixes the object’s
@code{left} and @code{right} references, but delegates the scanning of
references inside the object’s @code{data} member to the function
@code{data_scan}. In order to ensure that the scan state is passed
correctly to @code{data_scan}, the call must be wrapped in
@ref{1d9,,MPS_FIX_CALL}.

@example
mps_res_t obj_scan(mps_ss_t ss, mps_addr_t base, mps_addr_t limit)
@{
    obj_t obj;
    mps_res_t res;
    MPS_SCAN_BEGIN(ss) @{
        for (obj = base; obj < limit; obj++) @{
            res = MPS_FIX12(ss, &obj->left);
            if (res != MPS_RES_OK)
                return res;
            MPS_FIX_CALL(ss, res = data_scan(ss, &obj->data));
            if (res != MPS_RES_OK)
                return res;
            res = MPS_FIX12(ss, &obj->right);
            if (res != MPS_RES_OK)
                return res;
        @}
    @} MPS_SCAN_END(ss);
    return MPS_RES_OK;
@}
@end example

@cartouche
@quotation Warning 
Use of @ref{1d9,,MPS_FIX_CALL} is best avoided, as it may
force values out of registers (depending on compiler
optimisations such as inlining). The gains in simplicity of
the code ought to be measured against the loss in
performance.
@end quotation
@end cartouche
@end deffn

@geindex scanning; fixing
@geindex fixing; interface

@node Fixing interface,Area scanners,Scanning interface,Scanning
@anchor{topic/scanning fixing-interface}@anchor{1ea}
@subsection Fixing interface


@geindex MPS_FIX1 (C function)
@anchor{topic/scanning c MPS_FIX1}@anchor{75}
@deffn {C Function} @ref{129,,mps_bool_t} MPS_FIX1 (mps_ss_t ss, mps_addr_t ref)

Determine whether a @ref{24,,reference} needs to be passed to
@ref{76,,MPS_FIX2()}.

@code{ss} is the @ref{79,,scan state} that was passed to the
@ref{73,,scan method}.

@code{ref} is the reference.

Returns a truth value (@ref{129,,mps_bool_t}) indicating whether
@code{ref} is “interesting” to the MPS. If it returns true, the scan
method must invoke @ref{76,,MPS_FIX2()} to @ref{b4,,fix} @code{ref}.

This macro must only be used within a @ref{73,,scan method}, between
@ref{7a,,MPS_SCAN_BEGIN} and @ref{7b,,MPS_SCAN_END}.

@cartouche
@quotation Note 
If your reference is @ref{7d,,tagged} or
otherwise “encrypted”, you must ensure that it points to a
location within the target block before calling
@ref{75,,MPS_FIX1()}. (Therefore, a small tag in the low bits
need not be stripped.)
@end quotation
@end cartouche

@cartouche
@quotation Note 
In the case where the scan method does not need to do anything
between @ref{75,,MPS_FIX1()} and @ref{76,,MPS_FIX2()}, you can use
the convenience macro @ref{77,,MPS_FIX12()}.
@end quotation
@end cartouche
@end deffn

@geindex MPS_FIX12 (C function)
@anchor{topic/scanning c MPS_FIX12}@anchor{77}
@deffn {C Function} @ref{14d,,mps_res_t} MPS_FIX12 (mps_ss_t ss, mps_addr_t *ref_io)

@ref{b4,,Fix} a @ref{24,,reference}.

This macro is a convenience for the case where @ref{75,,MPS_FIX1()}
is immediately followed by @ref{76,,MPS_FIX2()}. The interface is
the same as @ref{76,,MPS_FIX2()}.
@end deffn

@geindex MPS_FIX2 (C function)
@anchor{topic/scanning c MPS_FIX2}@anchor{76}
@deffn {C Function} @ref{14d,,mps_res_t} MPS_FIX2 (mps_ss_t ss, mps_addr_t *ref_io)

@ref{b4,,Fix} a @ref{24,,reference}.

@code{ss} is the @ref{79,,scan state} that was passed to the
@ref{73,,scan method}.

@code{ref_io} points to the reference.

Returns @ref{5a,,MPS_RES_OK} if successful. In this case the
reference may have been updated, and so the scan method must store
the updated reference back to the region being scanned. The scan
method must continue to scan the @ref{185,,block}.

If it returns any other result, the scan method must return that
result as soon as possible, without fixing any further references.

This macro must only be used within a @ref{73,,scan method}, between
@ref{7a,,MPS_SCAN_BEGIN} and @ref{7b,,MPS_SCAN_END}.

@cartouche
@quotation Note 
If your reference is @ref{7d,,tagged} (or
otherwise “encrypted”), you must remove the tag (or otherwise
decrypt the reference) before calling @ref{76,,MPS_FIX2()}, and
restore the tag to the (possibly updated) reference
afterwards.

The only exception is for references to objects belonging to a
format with @ref{1d1,,in-band headers}: the header size must not
be subtracted from these references.
@end quotation
@end cartouche

@cartouche
@quotation Note 
In the case where the scan method does not need to do anything
between @ref{75,,MPS_FIX1()} and @ref{76,,MPS_FIX2()}, you can use
the convenience macro @ref{77,,MPS_FIX12()}.
@end quotation
@end cartouche
@end deffn

@geindex scanning; area scanners
@geindex area; scanning

@node Area scanners,,Fixing interface,Scanning
@anchor{topic/scanning area-scanners}@anchor{1eb}@anchor{topic/scanning topic-scanning-area}@anchor{1b8}
@subsection Area scanners


An area scanner @ref{65,,scans} an area of memory for
@ref{24,,references}. Various functions in the MPS interface, such as
@ref{1ec,,mps_root_create_thread_tagged()}, accept area scanners as
arguments so that the @ref{d0,,client program} can specify how to scan
special areas such as the @ref{27,,control stack}.

The MPS provides some area scanners for common situations (such as an
area which is a vector of words with references identified by
@ref{88,,tag bits}) but the @ref{d0,,client program} can provide
its own.

If you want to develop your own area scanner you can start by adapting
the scanners, found in @code{scan.c} in the MPS source code.

@geindex mps_area_scan_t (C type)
@anchor{topic/scanning c mps_area_scan_t}@anchor{1ed}
@deffn {C Type} type mps_area_scan_t

The type of area scanning functions, which are all of the form:

@example
mps_res_t scan(mps_ss_t ss,
               void *base, void *limit,
               void *closure);
@end example

@code{ss} is the @ref{79,,scan state}.

@code{base} points to the first location to be scanned.

@code{limit} points to the location just beyond the end of the area to be scanned.

@code{closure} is a pointer to an arbitrary @ref{1ee,,closure} object that
contains parameters for the scan.  The object passed depends on the
context.  For example, if the scanner was originally registered with
@ref{1ec,,mps_root_create_thread_tagged()} then it is the value of
the @code{closure} argument originally passed to that function.

@cartouche
@quotation Note 
The reason that @code{base} and @code{limit} have type
@code{void *} and not @ref{11d,,mps_addr_t} is that the
latter is used only for @ref{126,,addresses} managed by the MPS,
but @ref{1ed,,mps_area_scan_t} may also be used to scan
@ref{97,,roots} that are not managed by the MPS.
@end quotation
@end cartouche

@cartouche
@quotation Warning 
Area scanning functions are subject to the same set of
restrictions as format scanning functions, described under
@ref{c0,,Cautions}.
@end quotation
@end cartouche
@end deffn

@geindex mps_scan_area (C function)
@anchor{topic/scanning c mps_scan_area}@anchor{1ef}
@deffn {C Function} @ref{14d,,mps_res_t} mps_scan_area (mps_ss_t ss, void *base, void *limit, void *closure)

Scan an area of memory @ref{b4,,fixing} every word.
@code{closure} is ignored.  Expects @code{base} and @code{limit} to be
word-aligned.

This scanner is appropriate for use when all words in the area are
simple untagged references.
@end deffn

@geindex mps_scan_tag_t (C type)
@anchor{topic/scanning c mps_scan_tag_t}@anchor{1f0}
@deffn {C Type} type mps_scan_tag_t

The type of a scan closure that is passed to the tagged area
scanners in order to specify the format of the @ref{7d,,tagged references} in the area.

It is a pointer to a @ref{1f1,,mps_scan_tag_s} structure.
@end deffn

@geindex mps_scan_tag_s (C type)
@anchor{topic/scanning c mps_scan_tag_s}@anchor{1f1}
@deffn {C Type} type mps_scan_tag_s

The type of the structure used to represent @ref{88,,tag bits} in @ref{7d,,tagged references}

@example
typedef struct mps_scan_tag_s @{
    mps_word_t mask;
    mps_word_t pattern;
@} mps_scan_tag_s;
@end example

@code{mask} is bit mask that is applied to words in the area to find
the tag.  For example, a mask of 0b111 (decimal 7) specifies that
the tag is stored in the least-significant three bits of the word.

@code{pattern} is a bit pattern that is compared to the bits extracted
by the @code{mask} to determine if the word is a reference.  The exact
interpretation depends on which area scanner it is passed to.  See
the documentation for the individual area scanners.
@end deffn

@geindex mps_scan_area_masked (C function)
@anchor{topic/scanning c mps_scan_area_masked}@anchor{1f2}
@deffn {C Function} @ref{14d,,mps_res_t} mps_scan_area_masked (mps_ss_t ss, void *base, void *limit, void *closure)

Scan an area of memory @ref{b4,,fixing} every word, but remove
tag bits before fixing references, and restore them afterwards.
@code{closure} must point to an @ref{1f1,,mps_scan_tag_s}.  Expects
@code{base} and @code{limit} to be word-aligned.

For example, if @code{mask} is 0b111 (decimal 7), then this scanner
will clear the bottom three bits of each word before fixing.  A word
such as 0xC1374823 would be detagged to 0xC1374820 before fixing.
If it were fixed to 0xC812BC88 then it would be tagged back to
0xC812BC8B before being stored.

This scanner is useful when all words in the area must be treated as
references no matter what tag they have.  This can be especially
useful if you are debugging your tagging scheme.
@end deffn

@geindex mps_scan_area_tagged (C function)
@anchor{topic/scanning c mps_scan_area_tagged}@anchor{1f3}
@deffn {C Function} @ref{14d,,mps_res_t} mps_scan_area_tagged (mps_ss_t ss, void *base, void *limit, void *closure)

Scan an area of memory @ref{b4,,fixing} only words whose
masked bits match a particular tag pattern.  @code{closure} must
point to a @ref{1f1,,mps_scan_tag_s}.  Expects @code{base} and
@code{limit} to be word-aligned.

For example, if @code{mask} is 7 and @code{pattern} is 5, then this
scanner will only fix words whose low order bits are 0b101.

Tags are masked off and restored as in @ref{1f2,,mps_scan_area_masked()}.

This scanner is useful when you have a single tag pattern that
distinguishes references, especially when that pattern is zero.

@cartouche
@quotation Warning 
A risk of using tagged pointers in registers and on the stack is
that in some circumstances, an optimizing compiler might
optimize away the tagged pointer, keeping only the untagged
version of the pointer.  See
@ref{1ec,,mps_root_create_thread_tagged()}.
@end quotation
@end cartouche
@end deffn

@geindex mps_scan_area_tagged_or_zero (C function)
@anchor{topic/scanning c mps_scan_area_tagged_or_zero}@anchor{1f4}
@deffn {C Function} @ref{14d,,mps_res_t} mps_scan_area_tagged_or_zero (mps_ss_t ss, void *base, void *limit, void *closure)

Scan an area of memory @ref{b4,,fixing} only words whose
masked bits are zero or match a particular tag pattern.
@code{closure} must point to a @ref{1f1,,mps_scan_tag_s}.  Expects
@code{base} and @code{limit} to be word-aligned.

For example, if @code{mask} is 7 and @code{pattern} is 3, then this
scanner will fix words whose low order bits are 0b011 and words
whose low order bits are 0b000, but not any others.

This scanner is most useful for ambiguously scanning the stack and
registers when using an optimising C compiler and non-zero tags on
references, since the compiler is likely to leave untagged addresses
of objects around which must not be ignored.
@end deffn

@c sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/master/design/thread-safety/>`_

@geindex thread

@node Threads<2>,Roots<2>,Scanning,Reference
@anchor{topic/thread doc}@anchor{1f5}@anchor{topic/thread threads}@anchor{1f6}@anchor{topic/thread topic-thread}@anchor{29}
@section Threads


@geindex thread safety

@menu
* Thread safety:: 
* Thread registration:: 
* Signal and exception handling issues:: 
* Fork safety:: 
* Thread interface:: 

@end menu

@node Thread safety,Thread registration,,Threads<2>
@anchor{topic/thread thread-safety}@anchor{1f7}
@subsection Thread safety


The MPS is designed to run in an environment with multiple threads all
calling into the MPS. Some code is known to operate with exclusive
access to the data it manipulates (for example, allocation via
@ref{63,,allocation points}, in the common case where the buffer does
not need to be refilled, and @ref{19a,,location dependencies}), so this
code is safe. For the rest of the code, shared data structures are
locked by the use of a single lock per @ref{16,,arena}. This lock is
claimed on entry to the MPS and released on exit from it. So there is
at most a single thread (per arena) running “inside” the MPS at a
time.

@geindex thread; registration

@node Thread registration,Signal and exception handling issues,Thread safety,Threads<2>
@anchor{topic/thread thread-registration}@anchor{1f8}@anchor{topic/thread topic-thread-register}@anchor{1f9}
@subsection Thread registration


In order to scan a thread’s registers for references (which happens at
each @ref{18c,,flip}), the MPS needs to be able to suspend that thread,
and in order to gain exclusive atomic access to memory in order to
scan it, the MPS needs to be able to suspend all threads that might
access that memory. This means that threads must be registered with
the MPS by calling @ref{a8,,mps_thread_reg()} (and thread roots created;
see @ref{106,,Thread roots}).

A thread must be registered with an @ref{16,,arena} if:


@itemize *

@item 
its @ref{27,,control stack} and @ref{26,,registers} form a root (this is
enforced by @ref{a9,,mps_root_create_thread()}); or

@item 
it reads or writes from a location in an @ref{9,,automatically managed} @ref{18,,pool} in the arena.
@end itemize

However, some automatically managed pool classes may be more liberal
than this. See the documentation for the pool class.

@geindex signal; handling
@geindex exception; handling
@geindex thread; signal handling
@geindex thread; exception handling

@node Signal and exception handling issues,Fork safety,Thread registration,Threads<2>
@anchor{topic/thread signal-and-exception-handling-issues}@anchor{1fa}@anchor{topic/thread topic-thread-signal}@anchor{d1}
@subsection Signal and exception handling issues


@cartouche
@quotation Warning 
On Linux and FreeBSD, the MPS suspends and resumes threads by
sending them signals. There’s a shortage of available signals that
aren’t already dedicated to other purposes (for example, ValGrind
uses @code{SIGUSR1} and @code{SIGUSR2}), so the MPS uses @code{SIGXCPU} and
@code{SIGXFSZ}. This means that programs must not mask or handle
either of these signals.

If your program needs to mask or handle either of these signals,
then you can configure the MPS to use another pair of signals of
your choosing, by defining these preprocessor constants:

@geindex CONFIG_PTHREADEXT_SIGSUSPEND (C macro)
@anchor{topic/thread c CONFIG_PTHREADEXT_SIGSUSPEND}@anchor{1fb}
@deffn {C Macro} CONFIG_PTHREADEXT_SIGSUSPEND

If this preprocessor constant is defined, its definition names
the signal used to suspend a thread. For example:

@example
cc -DCONFIG_PTHREADEXT_SIGSUSPEND=SIGUSR1 -c mps.c
@end example
@end deffn

@geindex CONFIG_PTHREADEXT_SIGRESUME (C macro)
@anchor{topic/thread c CONFIG_PTHREADEXT_SIGRESUME}@anchor{1fc}
@deffn {C Macro} CONFIG_PTHREADEXT_SIGRESUME

If this preprocessor constant is defined, its definition names
the signal used to resume a thread. For example:

@example
cc -DCONFIG_PTHREADEXT_SIGSUSPEND=SIGUSR2 -c mps.c
@end example
@end deffn

The MPS sets the @code{SA_RESTART} flag when installing the
handlers for these signals, so that most blocking system calls are
automatically restarted after the delivery of the signal. However,
on Linux, not all blocking system calls are automatically
restarted after a signal is handle, so the @ref{d0,,client program}
must be prepared to handle @code{EINTR} from @code{poll()},
@code{nanosleep()} and so on. See the signal(7)@footnote{https://man7.org/linux/man-pages/man7/signal.7.html} manual for a list
of affected system calls.
@end quotation
@end cartouche

@cartouche
@quotation Warning 
The MPS uses @ref{60,,barriers (1)} to @ref{1fd,,protect}
memory from the @ref{d0,,client program} and handles the signals that
result from barrier hits.


@itemize *

@item 
On Linux and FreeBSD, your program must not mask or handle @code{SIGSEGV}.

@item 
On Windows, you must not install a first-chance exception handler.

@item 
On macOS, you must not install a thread-local Mach exception handler
for @code{EXC_BAD_ACCESS} exceptions.
@end itemize

All of these things are, in fact, possible, but your program must
co-operate with the MPS. At present, there’s no documented mechanism
for co-operating: if you are in this situation, please @ref{d8,,contact us}.
@end quotation
@end cartouche

@geindex fork safety

@node Fork safety,Thread interface,Signal and exception handling issues,Threads<2>
@anchor{topic/thread fork-safety}@anchor{1fe}@anchor{topic/thread topic-thread-fork}@anchor{1ff}
@subsection Fork safety


On Linux, FreeBSD and macOS, the MPS makes a best-effort attempt to
continue running in the child process after a call to @code{fork()},
even if the @ref{d0,,client program} was running multiple
@ref{99,,threads} at the point where the call is made to @code{fork()}.

@cartouche
@quotation Warning 
POSIX offers little or nothing in the way of guarantees about the
situation of a child process running after a multi-threaded parent
forked. The specification@footnote{https://pubs.opengroup.org/onlinepubs/9699919799/functions/fork.html} says:

@quotation

A process shall be created with a single thread. If a
multi-threaded process calls @code{fork()}, the new process shall
contain a replica of the calling thread and its entire address
space, possibly including the states of mutexes and other
resources. Consequently, to avoid errors, the child process may
only execute async-signal-safe operations until such time as one
of the @code{exec()} functions is called.
@end quotation
@end quotation
@end cartouche

@cartouche
@quotation Note 
Although only one thread is created in the child process, any
threads in the parent process that were registered with the MPS by
calling @ref{a8,,mps_thread_reg()} must still be deregistered, by
calling @ref{16b,,mps_thread_dereg()}, before the arena is destroyed.
@end quotation
@end cartouche

@geindex thread; interface

@node Thread interface,,Fork safety,Threads<2>
@anchor{topic/thread thread-interface}@anchor{200}
@subsection Thread interface


@geindex mps_thr_t (C type)
@anchor{topic/thread c mps_thr_t}@anchor{201}
@deffn {C Type} type mps_thr_t

The type of registered @ref{99,,thread} descriptions.

In a multi-threaded environment where @ref{d,,incremental garbage collection} is used, threads must be registered with the MPS by
calling @ref{a8,,mps_thread_reg()} so that the MPS can suspend them
as necessary in order to have exclusive access to their state.

Even in a single-threaded environment it may be necessary to
register a thread with the MPS so that its @ref{27,,control stack}
and @ref{26,,registers} can be registered as a @ref{97,,root} by
calling @ref{a9,,mps_root_create_thread()}.
@end deffn

@geindex mps_thread_reg (C function)
@anchor{topic/thread c mps_thread_reg}@anchor{a8}
@deffn {C Function} @ref{14d,,mps_res_t} mps_thread_reg (mps_thr_t *thr_o, mps_arena_t arena)

Register the current @ref{99,,thread} with an @ref{16,,arena}.

@code{thr_o} points to a location that will hold the address of the
registered thread description, if successful.

@code{arena} is the arena.

Returns @ref{5a,,MPS_RES_OK} if successful, or another
@ref{59,,result code} if not.

A thread must be registered with an arena if it ever uses a
pointer to a location in an @ref{9,,automatically managed} @ref{18,,pool} belonging to that
arena.

@cartouche
@quotation Note 
It is recommended that all threads be registered with all
arenas.
@end quotation
@end cartouche

It is an error if a thread terminates while it is registered. The
client program must call @ref{16b,,mps_thread_dereg()} first.
@end deffn

@geindex mps_thread_dereg (C function)
@anchor{topic/thread c mps_thread_dereg}@anchor{16b}
@deffn {C Function} void mps_thread_dereg (mps_thr_t thr)

Deregister a @ref{99,,thread}.

@code{thr} is the description of the thread.

After calling this function, the thread whose registration with an
@ref{16,,arena} was recorded in @code{thr} must not read or write from
a location in an @ref{9,,automatically managed} @ref{18,,pool} belonging to that arena.

@cartouche
@quotation Note 
Some pool classes may be more liberal about what a thread may
do after it has been deregistered. See the documentation for
the pool class.
@end quotation
@end cartouche

@cartouche
@quotation Note 
It is recommended that threads be deregistered only when they
are just about to exit.
@end quotation
@end cartouche
@end deffn

@c sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mmdoc/protocol/mps/root/>`_

@geindex root; introduction

@node Roots<2>,Garbage collection,Threads<2>,Reference
@anchor{topic/root doc}@anchor{202}@anchor{topic/root roots}@anchor{203}@anchor{topic/root topic-root}@anchor{28}
@section Roots


@ref{97,,Roots} tell the @ref{20,,garbage collector} where to start
@ref{4b,,tracing}. The garbage collector determines which blocks
are @ref{96,,reachable} from the roots, and (in @ref{9,,automatically managed} @ref{18,,pools}) reclaims
the @ref{21,,unreachable} blocks. This is quite efficient and can be a
very good approximation to @ref{78,,liveness}.

It is therefore important that all @ref{24,,references} that the
@ref{d0,,client program} can directly access are registered as roots,
otherwise the garbage collector might recycle an object that would be
used in the future. Some collectors, for example Boehm’s, assume that
all references stored in static data are roots; the Memory Pool System
is more flexible, but requires the client program to declare which
references are roots.

@geindex root; registering

@menu
* Registering roots:: 
* Cautions: Cautions<3>. 
* Thread roots:: 
* Ranks:: 
* Root modes:: 
* Root interface:: 
* Root introspection:: 

@end menu

@node Registering roots,Cautions<3>,,Roots<2>
@anchor{topic/root registering-roots}@anchor{204}
@subsection Registering roots


You can register a root at any time by calling one of the
@code{mps_root_create} functions. Roots may not be registered twice, and
no two roots may overlap (that is, each reference is @ref{b4,,fixed} by
at most one root). Roots may be:


@enumerate 

@item 
in @ref{26,,registers};

@item 
on the program’s @ref{27,,control stack};

@item 
in the program’s static data;

@item 
in @ref{47,,heap} not managed by the MPS (provided that you destroy
the root before freeing it; see @ref{a4,,the Scheme interpreter’s global symbol table} for an example);

@item 
in @ref{8,,manually managed} pools
(provided that you remove the root before freeing it).
@end enumerate

Roots must not be in memory that is subject to @ref{f,,garbage collection} (and so roots must not be in @ref{9,,automatically managed} pools).

When you register a root you describe to the MPS how to @ref{65,,scan}
it for references, providing your own scanning function in the cases
of @ref{9c,,mps_root_create()} and @ref{205,,mps_root_create_fmt()}. Such a
root scanning function must follow the @ref{16f,,Scanning protocol}.

All the references in a root are of the same @ref{9e,,rank} (just as in
a @ref{23,,formatted object}). So they are all @ref{61,,exact}, @ref{9f,,ambiguous} or @ref{c,,weak}.

@cartouche
@quotation Note 
If the rank of the root is @ref{61,,exact}, or
@ref{c,,weak}, the references in the root must
always be valid while the root is registered: that is, they must
be references to actual objects or null pointers. This could be
immediately after the root is registered, so the root must be
valid before it is registered.
@end quotation
@end cartouche

@cartouche
@quotation Note 
As with @ref{25,,scanning} in general, it’s safe to
@ref{b4,,fix} references that point to memory not managed by the
MPS. These will be ignored.
@end quotation
@end cartouche

Roots can be deregistered at any time by calling
@ref{a2,,mps_root_destroy()}. All roots registered in an @ref{16,,arena}
must be deregistered before the arena is destroyed.

There are four ways to register a root, depending on how you need to
scan it for references:


@enumerate 

@item 
@ref{9c,,mps_root_create()} if you need a custom root scanning
function (of type @ref{9b,,mps_root_scan_t});

@item 
@ref{205,,mps_root_create_fmt()} if the root consists of a block of
objects belonging to an @ref{39,,object format}, which can be scanned
by the format’s @ref{73,,scan method} (of type
@ref{74,,mps_fmt_scan_t});

@item 
@ref{206,,mps_root_create_area()} if the root consists of an area
of memory;

@item 
@ref{a9,,mps_root_create_thread()} if the root consists of the
@ref{26,,registers} and @ref{27,,control stack} of a thread. See
@ref{106,,Thread roots} below.
@end enumerate

Several of these categories of roots have variants for dealing with
@ref{7d,,tagged references}.  See @ref{7e,,Tagged references}.

@geindex root; cautions

@node Cautions<3>,Thread roots,Registering roots,Roots<2>
@anchor{topic/root cautions}@anchor{207}
@subsection Cautions


Creating a root and then registering is similar to reserving a block
and then committing it (in the
@ref{ae,,Allocation point protocol}), and similar @ref{1c7,,cautions} apply. Before registering a root:


@enumerate 

@item 
The root must be valid (that is, the appropriate root scanning
function can scan it).

@item 
All @ref{61,,exact references} in the root (references that are
@ref{b4,,fixed} by the root scanning function) must contain valid
references or null pointers.

@item 
You must not store a reference in the root to a block in an
automatically managed pool (such a reference is hidden from the MPS
until you register the root, and may become invalid).
@end enumerate

So the typical sequence of operations when creating a root is:


@enumerate 

@item 
Initialize references in the root with null pointers or other safe
values.

@item 
Register the root.

@item 
Fill in the references in the root.
@end enumerate

@geindex root; thread

@node Thread roots,Ranks,Cautions<3>,Roots<2>
@anchor{topic/root thread-roots}@anchor{208}@anchor{topic/root topic-root-thread}@anchor{106}
@subsection Thread roots


Every thread’s @ref{26,,registers} and @ref{27,,control stack} potentially
contain references to allocated objects, so should be registered as a
root by calling @ref{a9,,mps_root_create_thread()}.

The MPS’s stack scanner needs to know how to find the @ref{aa,,cold end}
of the part of the stack to scan. The @ref{aa,,cold end} of the relevant
part of the stack can be found by taking the address of a local
variable in the function that calls the main work function of your
thread. You should take care to ensure that the work function is not
inlined so that the address is definitely in the stack frame below any
potential roots.

@geindex Scheme; thread root

For example, here’s the code from the toy Scheme interpreter that
registers a thread root and then calls the program:

@example
mps_thr_t thread;
mps_root_t stack_root;
int exit_code;
void *cold = &cold;

res = mps_thread_reg(&thread, arena);
if (res != MPS_RES_OK) error("Couldn't register thread");

res = mps_root_create_thread(&stack_root, arena, thread, cold);
if (res != MPS_RES_OK) error("Couldn't create root");

exit_code = start(argc, argv);

mps_root_destroy(stack_root);
mps_thread_dereg(thread);
@end example

@geindex root; rank

@node Ranks,Root modes,Thread roots,Roots<2>
@anchor{topic/root ranks}@anchor{209}
@subsection Ranks


@geindex mps_rank_t (C type)
@anchor{topic/root c mps_rank_t}@anchor{146}
@deffn {C Type} type mps_rank_t

The type of @ref{9e,,ranks}. It is a @ref{127,,transparent alias} for @code{unsigned int}, provided for convenience
and clarity.
@end deffn

@geindex mps_rank_ambig (C function)
@anchor{topic/root c mps_rank_ambig}@anchor{20a}
@deffn {C Function} @ref{146,,mps_rank_t} mps_rank_ambig (void)

Return the @ref{9e,,rank} of @ref{1c4,,ambiguous roots}.
@end deffn

@geindex mps_rank_exact (C function)
@anchor{topic/root c mps_rank_exact}@anchor{9d}
@deffn {C Function} @ref{146,,mps_rank_t} mps_rank_exact (void)

Return the @ref{9e,,rank} of @ref{20b,,exact roots}.
@end deffn

@geindex mps_rank_weak (C function)
@anchor{topic/root c mps_rank_weak}@anchor{20c}
@deffn {C Function} @ref{146,,mps_rank_t} mps_rank_weak (void)

Return the @ref{9e,,rank} of @ref{20d,,weak roots}.
@end deffn

@geindex root; mode

@node Root modes,Root interface,Ranks,Roots<2>
@anchor{topic/root root-modes}@anchor{20e}
@subsection Root modes


The root mode provides a way for the client to declare various facts
about a root that allow the MPS to make optimizations. Roots that are
declared to be `constant' need not be re-scanned, and roots that are
declared to be `protectable' may have barriers placed on them,
allowing the MPS to detect whether they have changed.

@cartouche
@quotation Note 
The MPS does not currently perform either of these optimizations,
so root modes have no effect. These features may be added in a
future release.
@end quotation
@end cartouche

@geindex mps_rm_t (C type)
@anchor{topic/root c mps_rm_t}@anchor{20f}
@deffn {C Type} type mps_rm_t

The type of @ref{a0,,root modes}.

It should be zero (meaning neither constant or protectable), or
the sum of some of @ref{210,,MPS_RM_CONST},
@ref{211,,MPS_RM_PROT}, and @ref{212,,MPS_RM_PROT_INNER}.
@end deffn

@geindex MPS_RM_CONST (C macro)
@anchor{topic/root c MPS_RM_CONST}@anchor{210}
@deffn {C Macro} MPS_RM_CONST

starting with version 1.111.

This was introduced in the hope of being able to maintain a
@ref{213,,remembered set} for the root without needing a
@ref{214,,write barrier}, but it can’t work as described, since
you can’t reliably create a valid registered constant root that
contains any references. (If you add the references before
registering the root, they may have become invalid; but you
can’t add them afterwards because the root is supposed to be
constant.)

The @ref{a0,,root mode} for @ref{215,,constant roots}.
This tells the MPS that the @ref{d0,,client program} will not change
the @ref{97,,root} after it is registered: that is, scanning the
root will produce the same set of @ref{24,,references}
every time. Furthermore, for roots registered by
@ref{205,,mps_root_create_fmt()} and @ref{206,,mps_root_create_area()},
the client program will not write to the root at all.
@end deffn

@geindex MPS_RM_PROT (C macro)
@anchor{topic/root c MPS_RM_PROT}@anchor{211}
@deffn {C Macro} MPS_RM_PROT

The @ref{a0,,root mode} for @ref{216,,protectable roots}. This tells
the MPS that it may place a @ref{60,,barrier (1)} on any
@ref{92,,page} containing any part of the @ref{97,,root}. No
@ref{69,,format method} or @ref{73,,scan method} (except for the one
for this root) may write data in this root. They may read it.

@cartouche
@quotation Note 
You must not specify @code{MPS_RM_PROT} on a root allocated by
the MPS.

No page may contain parts of two or more protectable roots.
You mustn’t specify @code{MPS_RM_PROT} if the @ref{d0,,client program} or anything other than (this instance of) the MPS is
going to protect or unprotect the relevant pages.

This mode may not be suitable if the @ref{d0,,client program}
wants the operating system to be able to access the root. Many
operating systems can’t cope with writing to protected pages.
@end quotation
@end cartouche
@end deffn

@geindex MPS_RM_PROT_INNER (C macro)
@anchor{topic/root c MPS_RM_PROT_INNER}@anchor{212}
@deffn {C Macro} MPS_RM_PROT_INNER

The @ref{a0,,root mode} for @ref{216,,protectable roots} whose inner
pages (only) may be protected. This mode must not be specified
unless @ref{211,,MPS_RM_PROT} is also specified. It tells the MPS
that it may not place a @ref{60,,barrier (1)} on a @ref{92,,page}
that’s partly (but not wholly) covered by the @ref{97,,root}.
@end deffn

@geindex root; interface

@node Root interface,Root introspection,Root modes,Roots<2>
@anchor{topic/root root-interface}@anchor{217}
@subsection Root interface


@geindex mps_root_t (C type)
@anchor{topic/root c mps_root_t}@anchor{98}
@deffn {C Type} type mps_root_t

The type of @ref{97,,root} descriptions.

The @ref{16,,arena} uses root descriptions to find
@ref{24,,references} within the @ref{d0,,client program’s} roots.
@end deffn

@geindex mps_root_create (C function)
@anchor{topic/root c mps_root_create}@anchor{9c}
@deffn {C Function} @ref{14d,,mps_res_t} mps_root_create (mps_root_t *root_o, mps_arena_t arena, mps_rank_t rank, mps_rm_t rm, mps_root_scan_t root_scan, void *p, size_t s)

Register a @ref{97,,root} that consists of the @ref{24,,references} fixed by a scanning function.

@code{root_o} points to a location that will hold the address of the
new root description.

@code{arena} is the arena.

@code{rank} is the @ref{9e,,rank} of references in the root.

@code{rm} is the @ref{a0,,root mode}.

@code{root_scan} is the root scanning function. See
@ref{9b,,mps_root_scan_t}.

@code{p} and @code{s} are arguments that will be passed to @code{root_scan} each
time it is called. This is intended to make it easy to pass, for
example, an array and its size as parameters.

Returns @ref{5a,,MPS_RES_OK} if the root was registered
successfully, @ref{152,,MPS_RES_MEMORY} if the new root
description could not be allocated, or another @ref{59,,result code}
if there was another error.

The registered root description persists until it is destroyed by
calling @ref{a2,,mps_root_destroy()}.

This is the most general kind of root, but gives the MPS the least
information to use for optimisation.  Use a more specialized kind
of root whenever possible.
@end deffn

@geindex mps_root_scan_t (C type)
@anchor{topic/root c mps_root_scan_t}@anchor{9b}
@deffn {C Type} typedef @ref{14d,,mps_res_t} (*mps_root_scan_t)(@ref{1dc,,mps_ss_t} ss, void *p, size_t s)

The type of root scanning functions for @ref{9c,,mps_root_create()}.

@code{ss} is the @ref{79,,scan state}. It must be passed to
@ref{7a,,MPS_SCAN_BEGIN} and @ref{7b,,MPS_SCAN_END} to delimit a
sequence of fix operations, and to the functions
@ref{75,,MPS_FIX1()} and @ref{76,,MPS_FIX2()} when fixing a
@ref{24,,reference}.

@code{p} and @code{s} are the corresponding values that were passed to
@ref{9c,,mps_root_create()}.

Returns a @ref{59,,result code}. If a fix function returns a value
other than @ref{5a,,MPS_RES_OK}, the scan method must return that
value, and may return without fixing any further references.
Generally, it is better if it returns as soon as possible. If the
scanning is completed successfully, the function should return
@ref{5a,,MPS_RES_OK}.
@end deffn

@geindex mps_root_create_fmt (C function)
@anchor{topic/root c mps_root_create_fmt}@anchor{205}
@deffn {C Function} @ref{14d,,mps_res_t} mps_root_create_fmt (mps_root_t *root_o, mps_arena_t arena, mps_rank_t rank, mps_rm_t rm, mps_fmt_scan_t fmt_scan, mps_addr_t base, mps_addr_t limit)

Register a @ref{97,,root} that consists of the @ref{24,,references} fixed by a scanning function in a block of
@ref{23,,formatted objects}.

@code{root_o} points to a location that will hold the address of the
new root description.

@code{arena} is the arena.

@code{rank} is the @ref{9e,,rank} of references in the root.

@code{rm} is the @ref{a0,,root mode}.

@code{fmt_scan} is a scanning function. See @ref{74,,mps_fmt_scan_t}.

@code{base} is the address of the base of the block of formatted
objects.

@code{limit} is the address just beyond the end of the block of
formatted objects.

Returns @ref{5a,,MPS_RES_OK} if the root was registered
successfully, @ref{152,,MPS_RES_MEMORY} if the new root
description could not be allocated, or another @ref{59,,result code}
if there was another error.

The registered root description persists until it is destroyed by
calling @ref{a2,,mps_root_destroy()}.
@end deffn

@geindex mps_root_create_thread (C function)
@anchor{topic/root c mps_root_create_thread}@anchor{a9}
@deffn {C Function} @ref{14d,,mps_res_t} mps_root_create_thread (mps_root_t *root_o, mps_arena_t arena, mps_thr_t thr, void *cold)

Register a @ref{97,,root} that consists of the @ref{24,,references} in
a @ref{99,,thread’s} registers and stack that are word aligned.
This is the most common kind of thread root.

This function is equivalent to calling:

@example
mps_root_create_thread_tagged(root_o,
                              arena,
                              mps_rank_ambig(),
                              (mps_rm_t)0,
                              thr,
                              mps_scan_area_tagged,
                              sizeof(mps_word_t) - 1,
                              0,
                              cold);
@end example
@end deffn

@geindex mps_root_create_thread_tagged (C function)
@anchor{topic/root c mps_root_create_thread_tagged}@anchor{1ec}
@deffn {C Function} @ref{14d,,mps_res_t} mps_root_create_thread_tagged (mps_root_t *root_o, mps_arena_t arena, mps_rank_t rank, mps_rm_t rm, mps_thr_t thr, mps_area_scan_t scan_area, mps_word_t mask, mps_word_t pattern, void *cold)

Register a @ref{97,,root} that consists of the @ref{24,,references} in
a @ref{99,,thread’s} registers and stack that match a
binary pattern, for instance tagged as pointers.

@code{root_o} points to a location that will hold the address of the
new root description.

@code{arena} is the arena.

@code{rank} is the @ref{9e,,rank} of references in the root.

@code{rm} is the @ref{a0,,root mode}.

@code{thr} is the thread.

@code{scan_area} is an tagged area scanning function that will be used
to scan the threads registers and stack, for example
@ref{1f3,,mps_scan_area_tagged()} or
@ref{1f4,,mps_scan_area_tagged_or_zero()}.  See
@ref{1b8,,Area scanners}.

@code{mask} is a @ref{218,,bitmask} that is passed to @code{scan_area} to
be applied to the thread’s registers and stack to locate the
@ref{88,,tag}.

@code{pattern} is passed to @code{scan_area} to determine whether to
consider a word as a reference.  For example,
@ref{1f3,,mps_scan_area_tagged()} will not consider any word that is
unequal to this (after masking with @code{mask}) to be a reference.

@code{cold} is a pointer to the @ref{aa,,cold end} of stack to be
scanned. On platforms where the stack grows downwards (currently,
all supported platforms), locations below this address will be
scanned.

Returns @ref{5a,,MPS_RES_OK} if the root was registered
successfully, @ref{152,,MPS_RES_MEMORY} if the new root
description could not be allocated, or another @ref{59,,result code}
if there was another error.

The registered root description persists until it is destroyed by
calling @ref{a2,,mps_root_destroy()}.

@cartouche
@quotation Warning 
@quotation

A risk of using tagged pointers in registers and on the stack
is that in some circumstances, an optimizing compiler might
optimize away the tagged pointer, keeping only the untagged
version of the pointer. In this situation the pointer would be
ignored and if it was the last reference to the object the MPS
might incorrectly determine that it was dead.

You can avoid this risk in several ways:


@enumerate 

@item 
Choose to tag pointers with zero, setting @code{scan_area} to
@ref{1f3,,mps_scan_area_tagged()} and setting @code{pattern} to
zero.

@item 
Set @code{scan_area} to @ref{1f4,,mps_scan_area_tagged_or_zero()}
so that untagged pointers are scanned.  This may lead to
some additional scanning and retention.

@item 
Use @ref{219,,mps_root_create_thread_scanned()} and set
@code{scan_area} to @ref{1ef,,mps_scan_area()}: in this case all
words in registers and on the stack are scanned, leading to
possible additional scanning and retention.

@item 
Write your own compiler with complete control over register
contents and stack format, use
@ref{219,,mps_root_create_thread_scanned()} and set
@code{scan_area} to your own custom scanner, derived from the
source code of @ref{1ef,,mps_scan_area()}, that knows the
format.
@end enumerate
@end quotation

@cartouche
@quotation Note 
An optimization that may be worth considering is setting some
of the top bits in @code{mask} and @code{pattern} so that addresses
that cannot be allocated by the MPS are rejected quickly. This
requires expertise with the platform’s virtual memory
interface.
@end quotation
@end cartouche
@end quotation
@end cartouche
@end deffn

@geindex mps_root_create_thread_scanned (C function)
@anchor{topic/root c mps_root_create_thread_scanned}@anchor{219}
@deffn {C Function} @ref{14d,,mps_res_t} mps_root_create_thread_scanned (mps_root_t *root_o, mps_arena_t arena, mps_rank_t rank, mps_rm_t rm, mps_thr_t thread, mps_area_scan_t scan_area, void *closure, void *cold)

Register a @ref{97,,root} that consists of the @ref{24,,references} in
a @ref{99,,thread’s} registers and stack, scanned by an
arbitrary area scanning function.

@code{root_o} points to a location that will hold the address of the
new root description.

@code{arena} is the arena.

@code{rank} is the @ref{9e,,rank} of references in the root.

@code{rm} is the @ref{a0,,root mode}.

@code{thr} is the thread.

@code{scan_area} is an area scanning function that will be used to
scan the threads registers and stack, for example
@ref{1ef,,mps_scan_area()}, or a similar user-defined function. See
@ref{1b8,,Area scanners}.

@code{closure} is an arbitrary pointer that will be passed to
@code{scan_area} and is intended to point to any parameters it needs.
Ensure anything it points to exists as long as the root exists.

@code{cold} is a pointer to the @ref{aa,,cold end} of stack to be
scanned. On platforms where the stack grows downwards (currently,
all supported platforms), locations below this address will be
scanned.

Returns @ref{5a,,MPS_RES_OK} if the root was registered
successfully, @ref{152,,MPS_RES_MEMORY} if the new root
description could not be allocated, or another @ref{59,,result code}
if there was another error.

The registered root description persists until it is destroyed by
calling @ref{a2,,mps_root_destroy()}.
@end deffn

@geindex mps_root_create_area (C function)
@anchor{topic/root c mps_root_create_area}@anchor{206}
@deffn {C Function} @ref{14d,,mps_res_t} mps_root_create_area (mps_root_t *root_o, mps_arena_t arena, mps_rank_t rank, mps_rm_t rm, void *base, void *limit, mps_area_scan_t scan_area, void *closure)

Register a @ref{97,,root} that consists of an area of memory scanned
by an area scanning function.

@code{root_o} points to a location that will hold the address of the
new root description.

@code{arena} is the arena.

@code{rank} is the @ref{9e,,rank} of references in the root.

@code{rm} is the @ref{a0,,root mode}.

@code{base} points to the first word to be scanned.

@code{limit} points to the location just beyond the end of the area
to be scanned.

@code{scan_area} is an area scanning function, for example
@ref{1ef,,mps_scan_area()}, or a similar user-defined function. See
@ref{1b8,,Area scanners}.

@code{closure} is an arbitrary pointer that will be passed to
@code{scan_area} and intended to point to any parameters it needs.
Ensure anything it points to exists as long as the root exists.

Returns @ref{5a,,MPS_RES_OK} if the root was registered
successfully, @ref{152,,MPS_RES_MEMORY} if the new root
description could not be allocated, or another @ref{59,,result code}
if there was another error.

The registered root description persists until it is destroyed by
calling @ref{a2,,mps_root_destroy()}.
@end deffn

@geindex mps_root_create_area_tagged (C function)
@anchor{topic/root c mps_root_create_area_tagged}@anchor{21a}
@deffn {C Function} @ref{14d,,mps_res_t} mps_root_create_area_tagged (mps_root_t *root_o, mps_arena_t arena, mps_rank_t rank, mps_rm_t rm, void *base, void *limit, mps_area_scan_t scan_area, mps_word_t mask, mps_word_t pattern)

Register a @ref{97,,root} that consists of an area of memory scanned by
a tagged area scanning function.

@code{root_o} points to a location that will hold the address of the
new root description.

@code{arena} is the arena.

@code{rank} is the @ref{9e,,rank} of references in the root.

@code{rm} is the @ref{a0,,root mode}.

@code{base} points to a vector of tagged references.

@code{limit} points to the location just beyond the end of the vector
of tagged references.

@code{scan_area} is an tagged area scanning function that will be
used to scan the area, for example @ref{1f3,,mps_scan_area_tagged()}
or @ref{1f4,,mps_scan_area_tagged_or_zero()}.  The @code{closure}
argument to @code{scan_area} is a @ref{1f0,,mps_scan_tag_t} cast to
@code{void *} See @ref{1b8,,Area scanners}.

@code{mask} is a @ref{218,,bitmask} that is passed to @code{scan_area} to
be applied to the words in the vector to locate the @ref{88,,tag}.

@code{pattern} is passed to @code{scan_area} to determine whether to
consider a word as a reference.  For example,
@ref{1f3,,mps_scan_area_tagged()} will not consider any word that is
unequal to this (after masking with @code{mask}) to be a reference.

Returns @ref{5a,,MPS_RES_OK} if the root was registered
successfully, @ref{152,,MPS_RES_MEMORY} if the new root
description could not be allocated, or another @ref{59,,result code}
if there was another error.

The registered root description persists until it is destroyed by
calling @ref{a2,,mps_root_destroy()}.

For example:

@example
#define TAG_MASK 0x3            /* bottom two bits */
#define TAG_PATTERN 0x1         /* bottom bit set for references */

/* Global symbol table. */
size_t symtab_size;
struct @{
    obj_t symbol;
    obj_t value;
@} *symtab;

mps_res_t res;
mps_root_t root;
res = mps_root_create_area_tagged(&root, arena,
                                  mps_rank_exact(),
                                  0,
                                  symtab, symtab + symtab_size,
                                  mps_scan_area_tagged,
                                  TAG_MASK, TAG_PATTERN);
if (res != MPS_RES_OK) error("can't create symtab root");
@end example
@end deffn

@geindex mps_root_destroy (C function)
@anchor{topic/root c mps_root_destroy}@anchor{a2}
@deffn {C Function} void mps_root_destroy (mps_root_t root)

Deregister a @ref{97,,root} and destroy its description.

@code{root} is the root.
@end deffn

@geindex root; introspection

@node Root introspection,,Root interface,Roots<2>
@anchor{topic/root root-introspection}@anchor{21b}
@subsection Root introspection


@geindex mps_arena_roots_walk (C function)
@anchor{topic/root c mps_arena_roots_walk}@anchor{19e}
@deffn {C Function} void mps_arena_roots_walk (mps_arena_t arena, mps_roots_stepper_t f, void *p, size_t s)

starting with version 1.111.

If you think you need this, there’s probably a better way to
achieve what you’re trying to do. @ref{d8,,Contact us}.

Visit references in registered @ref{97,,roots} in an
@ref{16,,arena}.

@code{arena} is the arena whose roots you want to visit.

@code{f} is a function that will be called for each reference to an
object in an @ref{9,,automatically}
managed @ref{10,,pool class} that was found in a registered root
belonging to the arena. It takes four arguments: @code{ref} is the
address of a reference to an object in the arena, @code{root} is the
root in which @code{ref} was found, and @code{p} and @code{s} are the
corresponding arguments that were passed to
@ref{19e,,mps_arena_roots_walk()}.

@code{p} and @code{s} are arguments that will be passed to @code{f} each time it
is called. This is intended to make it easy to pass, for example,
an array and its size as parameters.

This function may only be called when the arena is in the
@ref{b8,,parked state}.


@subsubheading See also


@ref{19,,Arenas}.


@cartouche
@quotation Note 
If a root is @ref{1c4,,ambiguous} then the
reference might not be to the start of an object; the
@ref{d0,,client program} should handle this case. There is no
guarantee that the reference corresponds to the actual
location that holds the pointer to the object (since this
might be a register, for example), but the actual location
will be passed if possible. This may aid analysis of roots via
a debugger.
@end quotation
@end cartouche
@end deffn

@geindex mps_roots_stepper_t (C type)
@anchor{topic/root c mps_roots_stepper_t}@anchor{21c}
@deffn {C Type} typedef void (*mps_roots_stepper_t)(@ref{11d,,mps_addr_t} *ref, @ref{98,,mps_root_t} root, void *p, size_t s)

The type of a @ref{97,,root} @ref{21d,,stepper function}.

A function of this type can be passed to
@ref{19e,,mps_arena_roots_walk()}, in which case it will be called
for each reference into the @ref{16,,arena} from a root registered
with the arena. It receives four arguments:

@code{ref} points to a reference in a root. The reference points to
something in the arena. If the root is @ref{61,,exact} then the reference points to the start of an allocated
block, but if the root is @ref{9f,,ambiguous}
it might point to somewhere in the middle of an allocated block.

@code{root} is the description of the root which contains @code{ref}.

@code{p} and @code{s} are the corresponding values that were passed to
@ref{19e,,mps_arena_roots_walk()}.
@end deffn

@c sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/master/design/message-gc/>`_
@c `<https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mminfo/strategy/lisp-machine/>`_

@geindex collection
@geindex garbage collection

@node Garbage collection,Messages,Roots<2>,Reference
@anchor{topic/collection doc}@anchor{21e}@anchor{topic/collection garbage-collection}@anchor{21f}@anchor{topic/collection topic-collection}@anchor{2c}
@section Garbage collection


The @ref{16,,arena} contains a @ref{20,,garbage collector} that
coordinates the collection of garbage in all of its
@ref{9,,automatically managed}
@ref{18,,pools}. The collector efficiently traces references between
@ref{97,,roots} and pools, and between objects in different pools. It is
capable of collecting many automatically managed pools simultaneously.

@geindex chain; generation
@geindex generation chain

@menu
* Generation chains:: 
* Scheduling of collections:: 
* Garbage collection start messages:: 
* Garbage collection messages:: 

@end menu

@node Generation chains,Scheduling of collections,,Garbage collection
@anchor{topic/collection generation-chains}@anchor{220}
@subsection Generation chains


A @ref{e2,,generation chain} describes a sequence of @ref{e1,,generations}
used by a set of @ref{9,,automatically managed} @ref{18,,pools}.

A generation is a set of blocks that are managed together by the
@ref{20,,garbage collector}: they are @ref{221,,condemned}
together, and in @ref{1ad,,moving} pools they are
moved together. If two pools allocate blocks that are expected to live
and die together, then it is efficient for them to share a chain.

Typically blocks are allocated in the first generation in the chain,
the @ref{222,,nursery generation} (though you can change this using the
@code{MPS_KEY_GEN} keyword argument to
@ref{166,,mps_pool_create_k()}), and each time a block survives one
collection then it is @ref{223,,promoted} to the next
generation. Thus a generation contains a set of blocks of similar
ages.

By default, all pools in an arena share the same generation chain
(“the arena’s default generation chain”), but if this doesn’t meet
your requirements, then when creating an automatically managed pool,
you can choose which chain it should use by passing the
@code{MPS_KEY_CHAIN} keyword argument to
@ref{166,,mps_pool_create_k()}.

Create a generation chain by preparing an array of
@ref{224,,mps_gen_param_s} structures giving the `capacity' (in
kilobytes) and `initial predicted mortality' (between 0 and 1
inclusive) of each generation, and passing them to
@ref{225,,mps_chain_create()}.

When the `new size' of a generation exceeds its capacity, the MPS will
be prepared to start collecting the chain to which the generation
belongs. See @ref{226,,Scheduling of collections} below.

For example:

@example
mps_gen_param_s gen_params[] = @{
    @{ 1024, 0.8 @},
    @{ 2048, 0.4 @},
@};

mps_chain_t chain;
mps_res_t res;
res = mps_chain_create(&chain, arena,
                       sizeof(gen_params) / sizeof(gen_params[0]),
                       gen_params);
if (res != MPS_RES_OK) error("Couldn't create chain");
@end example

@geindex mps_chain_t (C type)
@anchor{topic/collection c mps_chain_t}@anchor{13a}
@deffn {C Type} type mps_chain_t

The type of @ref{e2,,generation chains}. A generation chain
describes the structure of @ref{e1,,generations} in a set of
@ref{18,,pools}.
@end deffn

@geindex mps_gen_param_s (C type)
@anchor{topic/collection c mps_gen_param_s}@anchor{224}
@deffn {C Type} type mps_gen_param_s

The type of the structure used to specify a @ref{e1,,generation} in
a @ref{e2,,generation chain}.

@example
typedef struct mps_gen_param_s @{
    size_t mps_capacity;
    double mps_mortality;
@} mps_gen_param_s;
@end example

@code{mps_capacity} is the capacity of the generation, in
@ref{188,,kilobytes}. When the size of the generation exceeds this,
the MPS will be prepared to start collecting it.

@cartouche
@quotation Note 
The name `capacity' is somewhat misleading. When a generation
reaches its capacity the MPS may not be able to collect it
immediately (for example because some other generation is
being collected), but this does not prevent allocation into
the generation, and so the size of a generation will often
exceed its capacity.
@end quotation
@end cartouche

@code{mps_mortality} is the initial predicted mortality of the
generation: the proportion (between 0 and 1 inclusive) of bytes in
the generation that are expected to be @ref{49,,dead} when the
generation is collected.

@cartouche
@quotation Note 
This value is only used as an initial estimate. The MPS
measures the mortality each time it collects the generation,
and maintains a moving average. So it is not important to
provide an accurate estimate here.
@end quotation
@end cartouche
@end deffn

@geindex mps_chain_create (C function)
@anchor{topic/collection c mps_chain_create}@anchor{225}
@deffn {C Function} @ref{14d,,mps_res_t} mps_chain_create (mps_chain_t *chain_o, mps_arena_t arena, size_t gen_count, mps_gen_param_s *gen_params)

Create a @ref{e2,,generation chain}.

@code{chain_o} points to a location that will hold a pointer to the
new generation chain.

@code{arena} is the arena to which the generation chain will belong.

@code{gen_count} is the number of @ref{e1,,generations} in
the chain.

@code{gen_params} points to an array describing the generations.

Returns @ref{5a,,MPS_RES_OK} if the generation chain is created
successfully, or another @ref{59,,result code} if it fails.

The generation chain persists until it is destroyed by calling
@ref{16a,,mps_chain_destroy()}.
@end deffn

@geindex mps_chain_destroy (C function)
@anchor{topic/collection c mps_chain_destroy}@anchor{16a}
@deffn {C Function} void mps_chain_destroy (mps_chain_t chain)

Destroy a @ref{e2,,generation chain}.

@code{chain} is the generation chain.

It is an error to destroy a generation chain if there is a garbage
collection in progress on the chain, or if there are any
@ref{18,,pools} using the chain. Before calling this function, the
arena should be parked (by calling @ref{b9,,mps_arena_park()}) to
ensure that there are no collections in progress, and pools using
the chain must be destroyed.
@end deffn

@geindex collection; scheduling
@geindex garbage collection; scheduling

@node Scheduling of collections,Garbage collection start messages,Generation chains,Garbage collection
@anchor{topic/collection scheduling-of-collections}@anchor{227}@anchor{topic/collection topic-collection-schedule}@anchor{226}
@subsection Scheduling of collections


@cartouche
@quotation Note 
It’s likely that the algorithm the MPS uses to schedule its
collections will change in future releases. There’s a lot of room
for improvement here.
@end quotation
@end cartouche

The `new size' of a generation is the total size of the newly
allocated (in generation 0) or newly promoted (in other generations)
blocks in that generation. These are the blocks that have not been
@ref{221,,condemned} since they were allocated or
promoted into this generation. In pools like @ref{62,,AMC (Automatic Mostly-Copying)} where the
survivors get promoted to the next generation in the chain, the `new
size' of each generation (other than the topmost) is the same as its
total size, but in pools like @ref{16c,,AMS (Automatic Mark and Sweep)} where survivors do not
get promoted, the two sizes can be different.

When a generation’s `new size' exceeds its capacity, the MPS considers
collecting the chain to which the generation belongs. (How long it
takes to get around to it depends on which other collections are in
progress.)

@cartouche
@quotation Note 
You can affect the decision as to when to collect the chain by
using the @ref{228,,ramp allocation pattern}.
@end quotation
@end cartouche

If the MPS decides to collect a chain, all generations are collected
up to, and including, the highest generation whose `new size' exceeds
its capacity.

In pools such as @ref{62,,AMC (Automatic Mostly-Copying)}, blocks in generation `g' that
survive collection get promoted to generation `g'+1. If the last
generation in the chain is collected, the survivors are promoted into
an @ref{16,,arena}-wide “top” generation.

@geindex garbage collection; start message
@geindex message; garbage collection start

@node Garbage collection start messages,Garbage collection messages,Scheduling of collections,Garbage collection
@anchor{topic/collection garbage-collection-start-messages}@anchor{229}
@subsection Garbage collection start messages


@geindex mps_message_type_gc_start (C function)
@anchor{topic/collection c mps_message_type_gc_start}@anchor{22a}
@deffn {C Function} @ref{22b,,mps_message_type_t} mps_message_type_gc_start (void)

Return the @ref{22c,,message type} of garbage collection start
messages.

Garbage collection start messages contain information about why
the @ref{f,,garbage collection} started.

The access method specific to a @ref{e9,,message} of this message
type is:


@itemize *

@item 
@ref{22d,,mps_message_gc_start_why()} returns a string that
describes why the garbage collection started.
@end itemize


@subsubheading See also


@ref{f1,,Messages}.

@end deffn

@geindex mps_message_gc_start_why (C function)
@anchor{topic/collection c mps_message_gc_start_why}@anchor{22d}
@deffn {C Function} const char *mps_message_gc_start_why (mps_arena_t arena, mps_message_t message)

Return a string that describes why the @ref{f,,garbage collection}
that posted a @ref{e9,,message} started.

@code{arena} is the arena which posted the message.

@code{message} is a message retrieved by @ref{ec,,mps_message_get()} and
not yet discarded.  It must be a garbage collection message: see
@ref{18d,,mps_message_type_gc()}.

Returns a pointer to a string that is describes (in English) why
this collection started. The contents of the string must not be
modified by the client. The string and the pointer are valid until
the message is discarded with @ref{ee,,mps_message_discard()}.


@subsubheading See also


@ref{f1,,Messages}.

@end deffn

@geindex garbage collection; message

@node Garbage collection messages,,Garbage collection start messages,Garbage collection
@anchor{topic/collection garbage-collection-messages}@anchor{22e}
@subsection Garbage collection messages


@geindex mps_message_type_gc (C function)
@anchor{topic/collection c mps_message_type_gc}@anchor{18d}
@deffn {C Function} @ref{22b,,mps_message_type_t} mps_message_type_gc (void)

Return the @ref{22c,,message type} of garbage collection statistic
messages.

Garbage collection statistic messages are used by the MPS to give
the @ref{d0,,client program} information about a @ref{f,,garbage collection} that has taken place. Such information may be useful in
analysing the client program’s memory usage over time.

The access methods specific to a message of this type are:


@itemize *

@item 
@ref{22f,,mps_message_gc_live_size()} returns the total size of the
@ref{221,,condemned set} that survived the garbage collection that
generated the message;

@item 
@ref{230,,mps_message_gc_condemned_size()} returns the approximate
size of @ref{221,,condemned set} in the garbage collection that
generated the message;

@item 
@ref{231,,mps_message_gc_not_condemned_size()} returns the
approximate size of the set of blocks that were in collected
@ref{18,,pools}, but were not condemned in the garbage
collection that generated the message.
@end itemize


@subsubheading See also


@ref{f1,,Messages}.

@end deffn

@geindex mps_message_gc_condemned_size (C function)
@anchor{topic/collection c mps_message_gc_condemned_size}@anchor{230}
@deffn {C Function} size_t mps_message_gc_condemned_size (mps_arena_t arena, mps_message_t message)

Return the “condemned size” property of a @ref{e9,,message}.

@code{arena} is the arena which posted the message.

@code{message} is a message retrieved by @ref{ec,,mps_message_get()} and
not yet discarded.  It must be a garbage collection message: see
@ref{18d,,mps_message_type_gc()}.

The “condemned size” property is the approximate @ref{183,,size} of
the @ref{221,,condemned set} in the @ref{f,,garbage collection} that
generated the message.


@subsubheading See also


@ref{f1,,Messages}.

@end deffn

@geindex mps_message_gc_live_size (C function)
@anchor{topic/collection c mps_message_gc_live_size}@anchor{22f}
@deffn {C Function} size_t mps_message_gc_live_size (mps_arena_t arena, mps_message_t message)

Return the “live size” property of a @ref{e9,,message}.

@code{arena} is the arena which posted the message.

@code{message} is a message retrieved by @ref{ec,,mps_message_get()} and
not yet discarded.  It must be a garbage collection message: see
@ref{18d,,mps_message_type_gc()}.

The “live size” property is the total size of the set of blocks
that survived the @ref{f,,garbage collection} that generated the
message.


@subsubheading See also


@ref{f1,,Messages}.

@end deffn

@geindex mps_message_gc_not_condemned_size (C function)
@anchor{topic/collection c mps_message_gc_not_condemned_size}@anchor{231}
@deffn {C Function} size_t mps_message_gc_not_condemned_size (mps_arena_t arena, mps_message_t message)

Return the “not condemned size” property of a @ref{e9,,message}.

@code{arena} is the arena which posted the message.

@code{message} is a message retrieved by @ref{ec,,mps_message_get()} and
not yet discarded.  It must be a garbage collection message: see
@ref{18d,,mps_message_type_gc()}.

The “not condemned size” property is the approximate size of the
set of blocks that were in collected @ref{18,,pools}, but
were not in the @ref{221,,condemned set} in the @ref{f,,garbage collection} that generated the message.


@subsubheading See also


@ref{f1,,Messages}.

@end deffn

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/master/design/message/>`_
@c `<https://info.ravenbrook.com/mail/2005/04/05/13-33-11/0.txt>`_

@geindex message; introduction

@node Messages,Finalization<2>,Garbage collection,Reference
@anchor{topic/message doc}@anchor{232}@anchor{topic/message messages}@anchor{233}@anchor{topic/message topic-message}@anchor{f1}
@section Messages


The MPS sometimes needs to communicate with the @ref{d0,,client program}
about events which occur @ref{a1,,asynchronously}, and so information cannot be returned as function call
results.

`Messages' are the mechanism for this asynchronous communication,
implemented in the form of a @ref{ea,,message queue} attached to each
@ref{16,,arena}.

The client program must enable each message type that it is prepared
to handle, by calling @ref{eb,,mps_message_type_enable()}. Then it must
poll the message queue at regular intervals when it is convenient to
do so, calling @ref{ec,,mps_message_get()} to retrieve each message from
the queue, and finally calling @ref{ee,,mps_message_discard()} when done
with the message.

Messages are thus @ref{8,,manually managed}:
if the client program enables one or more message types, and then
neglects to poll the message queue or neglects to discard the messages
it retrieved, then messages will @ref{234,,leak}.

There is no requirement on the client program to retrieve and discard
messages promptly. However, a client program that allows the number of
garbage collection (or garbage collection start) messages on the
message queue to grow without limit will eventually find that new
garbage collections no longer start until some of these messages are
retrieved and discarded.

@geindex message; finalization

@menu
* Finalization messages:: 
* Example; interactive chatter: Example interactive chatter. 
* Message types:: 
* Message interface:: 
* Message queue interface:: 

@end menu

@node Finalization messages,Example interactive chatter,,Messages
@anchor{topic/message finalization-messages}@anchor{235}
@subsection Finalization messages


@ref{b,,Finalization} is implemented by posting a finalization message
(of type @ref{236,,mps_message_type_finalization()}) to the arena’s
message queue. This allows the @ref{d0,,client program} to perform the
finalization at a convenient time and so avoid synchronization
difficulties.

The block is not actually reclaimed until the finalization message is
removed from the message queue and discarded, by calling
@ref{ec,,mps_message_get()} followed by @ref{ee,,mps_message_discard()}.

See @ref{f0,,Finalization}.

@geindex message; example
@geindex Scheme; interactive chatter

@node Example interactive chatter,Message types,Finalization messages,Messages
@anchor{topic/message example-interactive-chatter}@anchor{237}
@subsection Example: interactive chatter


The toy Scheme interpreter enables garbage collection messages when
started in interactive mode:

@example
mps_message_type_enable(arena, mps_message_type_gc());
mps_message_type_enable(arena, mps_message_type_gc_start());
@end example

Then, after every interactive command finishes, it reads these
messages from the message queue and prints a description of the
contents of each one:

@example
static void mps_chat(void)
@{
    mps_message_type_t type;

    while (mps_message_queue_type(&type, arena)) @{
        mps_message_t message;
        mps_bool_t b;
        b = mps_message_get(&message, arena, type);
        assert(b); /* we just checked there was one */

        if (type == mps_message_type_gc_start()) @{
            printf("Collection started.\n");
            printf("  Why: %s\n", mps_message_gc_start_why(arena, message));
            printf("  Clock: %lu\n", (unsigned long)mps_message_clock(arena, message));
        if (type == mps_message_type_gc()) @{
            /* ... and so on for other message types ... */
        @} else @{
            printf("Unknown message from MPS!\n");
        @}

        mps_message_discard(arena, message);
    @}
@}
@end example

Here’s how this looks in operation:

@example
MPS Toy Scheme Example
9960, 0> (define (make-list n e) (if (eqv? n 0) '() (cons e (make-list (- n 1) e))))
make-list
10824, 0> (length (make-list 1000 #t))
1000
Collection started.
  Why: Generation 0 of a chain has reached capacity: start a minor collection.
  Clock: 6649
507408, 1> (length (make-list 200 #f))
200
Collection finished.
    live 112360
    condemned 196600
    not_condemned 0
    clock: 18431
607192, 1> Bye.
@end example

@cartouche
@quotation Note 
This kind of interactive “chatter” may be useful when testing and
debugging memory management, but should not be used otherwise. The
scheduling of garbage collections is not normally of interest even
to programmers, and chatter of this sort may give the illusion
that a program is spending much more time garbage collecting than
is actually the case.

Versions of GNU Emacs prior to 19.31 (May 1996) used to display
the message “Garbage collecting…” during a collection. Erik
Naggum commented on this feature:

@quotation

I have run some tests at the U of Oslo with about 100
users who generally agreed that Emacs had become faster in
the latest Emacs pretest. All I had done was to remove the
“Garbage collecting” message which people perceive as
slowing Emacs down and tell them that it had been sped up.
@end quotation
@end quotation
@end cartouche

@geindex message; types

@node Message types,Message interface,Example interactive chatter,Messages
@anchor{topic/message message-types}@anchor{238}
@subsection Message types


@geindex mps_message_type_t (C type)
@anchor{topic/message c mps_message_type_t}@anchor{22b}
@deffn {C Type} type mps_message_type_t

The type of @ref{22c,,message types}.

There are three message types:


@enumerate 

@item 
@ref{236,,mps_message_type_finalization()}

@item 
@ref{18d,,mps_message_type_gc()}

@item 
@ref{22a,,mps_message_type_gc_start()}
@end enumerate
@end deffn

@geindex mps_message_type_disable (C function)
@anchor{topic/message c mps_message_type_disable}@anchor{239}
@deffn {C Function} void mps_message_type_disable (mps_arena_t arena, mps_message_type_t message_type)

Restore an @ref{16,,arena} to the default state whereby
@ref{e9,,messages} of the specified @ref{22c,,message type}
are not posted, reversing the effect of an earlier call to
@ref{eb,,mps_message_type_enable()}.

@code{arena} is an arena.

@code{message_type} is the message type to be disabled.

Any existing messages of the specified type are flushed from the
@ref{ea,,message queue} of @code{arena}.

@cartouche
@quotation Note 
It is permitted to call this function when @code{message_type} is
already disabled, in which case it has no effect.
@end quotation
@end cartouche
@end deffn

@geindex mps_message_type_enable (C function)
@anchor{topic/message c mps_message_type_enable}@anchor{eb}
@deffn {C Function} void mps_message_type_enable (mps_arena_t arena, mps_message_type_t message_type)

Enable an @ref{16,,arena} to post @ref{e9,,messages} of a
specified @ref{22c,,message type}.

@code{arena} is an arena.

@code{message_type} is the message type to be enabled.

This function tells the MPS that @code{arena} may post messages of
@code{message_type} to its @ref{ea,,message queue}. By default, the MPS
does not generate any messages of any type.

A @ref{d0,,client program} that enables messages for a message type
must access messages by calling @ref{ec,,mps_message_get()} and
discard them by calling @ref{ee,,mps_message_discard()}, or the
message queue may consume unbounded resources.

The client program may disable the posting of messages by calling
@ref{239,,mps_message_type_disable()}.

@cartouche
@quotation Note 
It is permitted to call this function when @code{message_type} is
already enabled, in which case it has no effect.
@end quotation
@end cartouche
@end deffn

@geindex message; interface

@node Message interface,Message queue interface,Message types,Messages
@anchor{topic/message message-interface}@anchor{23a}
@subsection Message interface


@geindex mps_message_t (C type)
@anchor{topic/message c mps_message_t}@anchor{23b}
@deffn {C Type} type mps_message_t

The type of a @ref{e9,,message}.

Messages are @ref{8,,manually} managed.
They are created at the instigation of the MPS (but see
@ref{eb,,mps_message_type_enable()}), and are deleted by the
@ref{d0,,client program} by calling @ref{ee,,mps_message_discard()}.

An @ref{16,,arena} has a @ref{ea,,message queue} from which messages
can be obtained by calling @ref{ec,,mps_message_get()}.

An @ref{23b,,mps_message_t} is a @ref{24,,reference} into MPS managed
memory, and can safely be @ref{b4,,fixed}.
@end deffn

@geindex mps_message_clock (C function)
@anchor{topic/message c mps_message_clock}@anchor{23c}
@deffn {C Function} @ref{12a,,mps_clock_t} mps_message_clock (mps_arena_t arena, mps_message_t message)

Returns the time at which the MPS posted a @ref{e9,,message}.

@code{arena} is the @ref{16,,arena} which posted the message.

@code{message} is a message retrieved by @ref{ec,,mps_message_get()} and
not yet discarded.

If @code{message} belongs to one of the following supported message,
return the time at which the MPS posted the message:


@itemize *

@item 
@ref{18d,,mps_message_type_gc};

@item 
@ref{22a,,mps_message_type_gc_start}.
@end itemize

For other message types, the value returned is always zero.

Messages are asynchronous: they are posted by the MPS, wait on a
queue, and are later collected by the @ref{d0,,client program}. Each
message (of the supported message types) records the time that it
was posted, and this is what @ref{23c,,mps_message_clock()} returns.

The time returned is the @ref{12a,,mps_clock_t()} value returned by
the @ref{160,,plinth} function @ref{12b,,mps_clock()} at the time the
message was posted. You can subtract one clock value from another
to get the time interval between the posting of two messages.
@end deffn

@geindex mps_message_discard (C function)
@anchor{topic/message c mps_message_discard}@anchor{ee}
@deffn {C Function} void mps_message_discard (mps_arena_t arena, mps_message_t message)

Indicate to the MPS that the @ref{d0,,client program} has no further
use for a @ref{e9,,message} and the MPS can now reclaim any storage
associated with the message.

@code{arena} is the @ref{16,,arena} which posted the message.

@code{message} is the message. After this call, @code{message} is invalid
and should not be passed as an argument to any message functions.

Messages are essentially @ref{8,,manually} managed. This function allows the MPS to reclaim
storage associated with messages. If the client does not discard
messages then the resources used may grow without bound.

As well as consuming resources, messages may have other effects
that require them to be tidied by calling this function. In
particular finalization messages refer to a @ref{23d,,finalized block}, and prevent the object from being reclaimed (subject to
the usual @ref{f,,garbage collection} liveness analysis). A
finalized block cannot be reclaimed until all its finalization
messages have been discarded. See
@ref{236,,mps_message_type_finalization()}.


@subsubheading See also


@ref{f0,,Finalization}.

@end deffn

@geindex mps_message_type (C function)
@anchor{topic/message c mps_message_type}@anchor{23e}
@deffn {C Function} @ref{22b,,mps_message_type_t} mps_message_type (mps_arena_t arena, mps_message_t message)

Return the @ref{22c,,message type} of a @ref{e9,,message}.

@code{arena} is the arena that posted the message.

@code{message} is a message retrieved by @ref{ec,,mps_message_get()} and
not yet discarded.
@end deffn

@geindex message; queue interface

@node Message queue interface,,Message interface,Messages
@anchor{topic/message message-queue-interface}@anchor{23f}
@subsection Message queue interface


@geindex mps_message_get (C function)
@anchor{topic/message c mps_message_get}@anchor{ec}
@deffn {C Function} @ref{129,,mps_bool_t} mps_message_get (mps_message_t *message_o, mps_arena_t arena, mps_message_type_t message_type)

Get a @ref{e9,,message} of a specified type from the @ref{ea,,message queue} for an @ref{16,,arena}.

@code{message_o} points to a location that will hold the address of the
message if the function succeeds.

@code{arena} is the arena.

@code{message_type} is the type of message to return.

If there is at least one message of the specified type on the
message queue of the specified arena, then this function removes
one such message from the queue, stores a pointer to the message
in the location pointed to by @code{message_o}, and returns true.
Otherwise it returns false.
@end deffn

@geindex mps_message_poll (C function)
@anchor{topic/message c mps_message_poll}@anchor{240}
@deffn {C Function} @ref{129,,mps_bool_t} mps_message_poll (mps_arena_t arena)

Determine whether there are currently any @ref{e9,,messages} on a @ref{ea,,message queue} for an @ref{16,,arena}.

@code{arena} is the arena whose message queue will be polled.

Returns true if there is at least one message on the message queue
for @code{arena}, or false if the message queue is empty.

@cartouche
@quotation Note 
If you are interested in a particular type of message, it is
usually simpler to call @ref{ec,,mps_message_get()}.
@end quotation
@end cartouche
@end deffn

@geindex mps_message_queue_type (C function)
@anchor{topic/message c mps_message_queue_type}@anchor{241}
@deffn {C Function} @ref{129,,mps_bool_t} mps_message_queue_type (mps_message_type_t *message_type_o, mps_arena_t arena)

Determine whether there are currently any @ref{e9,,messages} on a @ref{ea,,message queue} for an @ref{16,,arena}, and
return the @ref{22c,,message type} of the first message, if any.

@code{message_type_o} points to a location that will hold the message
type of the first message on the queue, if any.

@code{arena} is the arena whose message queue will be polled.

If there is at least one message on the message queue of @code{arena},
then this function returns true, and also writes the message type
of the first message on the queue into the location pointed to by
@code{message_type_o}. If there are no messages on the message queue,
it returns false.

@cartouche
@quotation Note 
If you are interested in a particular type of message, it is
usually simpler to call @ref{ec,,mps_message_get()}.
@end quotation
@end cartouche
@end deffn

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/master/design/finalize/>`_

@geindex finalization

@node Finalization<2>,Location dependency<2>,Messages,Reference
@anchor{topic/finalization doc}@anchor{242}@anchor{topic/finalization finalization}@anchor{243}@anchor{topic/finalization topic-finalization}@anchor{f0}
@section Finalization


It is sometimes necessary to perform actions when a block of memory
@ref{49,,dies}. For example, a block may represent the
acquisition of an external resource such as a file handle or a network
connection. When the block dies, the corresponding resource must be
released. This procedure is known as @ref{b,,finalization}.

A block requiring finalization must be registered by calling @ref{e8,,mps_finalize()}:

@example
mps_addr_t ref = block_requiring_finalization;
mps_finalize(arena, &ref);
@end example

A block that been registered for finalization becomes `finalizable' as
soon as the @ref{20,,garbage collector} observes that it would otherwise
be @ref{4a,,reclaimed} (that is, the only thing keeping it alive is the
fact that it needs to be finalized). If a block is finalizable the MPS
may choose to finalize it (by posting a finalization message: see
below) at `any' future time.

@cartouche
@quotation Note 
This means that a block that was determined to be finalizable, but
then became unconditionally @ref{78,,live} by the creation of a new
@ref{244,,strong reference} to it, may still be finalized.
@end quotation
@end cartouche

@ref{c,,Weak references (1)} do not prevent blocks
from being finalized. At the point that a block is finalized, weak
references will still validly refer to the block. The fact that a
block is registered for finalization prevents weak references to that
block from being @ref{245,,splatted}. See @ref{102,,Weak references}.

The Memory Pool System finalizes a block by posting a `finalization
message' to the @ref{ea,,message queue} of the @ref{16,,arena} in which
the block was allocated.

@cartouche
@quotation Note 
This design avoids the problems that can result from the
@ref{20,,garbage collector} calling a function in the client program
to do the finalization. In such an implementation, the client
program’s finalization code may end up running concurrently with
other code that accesses the underlying resource, and so access to
the resource needs to be guarded with a lock, but then an unlucky
scheduling of finalization can result in deadlock. See @ref{246,,Boehm (2002)} for a detailed discussion of this issue.
@end quotation
@end cartouche

The @ref{22c,,message type} of finalization messages is
@ref{236,,mps_message_type_finalization()}, and the client program must
enable the posting of these messages by calling
@ref{eb,,mps_message_type_enable()} before any block becomes
finalizable:

@example
mps_message_type_enable(arena, mps_message_type_finalization());
@end example

When a finalization message has been retrieved from the message queue
by calling @ref{ec,,mps_message_get()}, the finalization reference may
be accessed by calling @ref{ed,,mps_message_finalization_ref()}. The
finalization message keeps the block alive until it is discarded by
calling @ref{ee,,mps_message_discard()}.

@cartouche
@quotation Note 
The client program may choose to keep the finalized block alive by
keeping a strong reference to the finalized object after
discarding the finalization message.

This process is known as @ref{247,,resurrection} and in some
finalization systems requires special handling, but in the MPS
this just is just the usual result of the rule that strong
references keep objects alive.

It is fine to re-register a block for finalization after
retrieving its finalization message from the message queue. This
will cause it to be finalized again should all strong references
disappear again.
@end quotation
@end cartouche

@cartouche
@quotation Note 
Calling @ref{ee,,mps_message_discard()} does not reclaim the space
occupied by the finalized block (that happens at the next
collection, if the block is found to be dead at that point), and
so the block must remain validly formatted (@ref{73,,scannable}, @ref{81,,skippable}, and so on). It might
make sense to replace it with a @ref{67,,padding object}.
@end quotation
@end cartouche

See @ref{f1,,Messages} for details of the message mechanism.

@geindex finalization; multiple

@menu
* Multiple finalizations:: 
* Cautions: Cautions<4>. 
* Finalization interface:: 
* Finalization messages: Finalization messages<2>. 

@end menu

@node Multiple finalizations,Cautions<4>,,Finalization<2>
@anchor{topic/finalization multiple-finalizations}@anchor{248}
@subsection Multiple finalizations


A block may be registered for finalization multiple times. A block
that has been registered for finalization `n' times will be finalized
at most `n' times.

This may mean that there are multiple finalization messages on the
queue at the same time, or it may not (it may be necessary for the
client program to discard previous finalization messages for a block
before a new finalization messages for that block are posted to the
message queue). The MPS provides no guarantees either way: a client
program that registers the same block multiple times must cope with
either behaviour.

@geindex finalization; cautions

@node Cautions<4>,Finalization interface,Multiple finalizations,Finalization<2>
@anchor{topic/finalization cautions}@anchor{249}@anchor{topic/finalization topic-finalization-cautions}@anchor{ef}
@subsection Cautions



@enumerate 

@item 
Don’t rely on finalization for your program to work. Treat it as an
optimization that enables the freeing of resources that the
garbage collector can prove are unreachable.

@item 
The MPS provides no guarantees about the promptness of
finalization. The MPS does not finalize a block until it
determines that the block is finalizable, which may require a full
garbage collection in the worst case, and such a collection may
not be @ref{226,,scheduled} for some time.
Or the block may never become finalizable because it is
incorrectly determined to be reachable due to an @ref{9f,,ambiguous reference} pointing to it. Or the block may never become
finalizable because it remains reachable through a reference, even
if that reference might never be used.

@item 
Even when blocks are finalized in a reasonably timely fashion, the
client needs to process the finalization messages in time to avoid
the resource running out. For example, in the Scheme interpreter,
finalization messages are only processed at the end of the
read–eval–print loop, so a program that opens many files may run
out of handles even though the associated objects are all
finalizable, as shown here:

@example
MPS Toy Scheme Example
9960, 0> (define (repeat n f _) (if (eqv? n 0) '() (repeat (- n 1) f (f))))
repeat
10840, 0> (repeat 300 (lambda () (open-input-file "scheme.c")) 0)
open-input-file: cannot open input file
@end example

A less naïve interpreter might process finalization messages on a
more regular schedule, or might take emergency action in the event
of running out of open file handles by carrying out a full garbage
collection and processing any finalization messages that are
posted as a result.

If you are designing a programming language then it is generally a
good idea to provide the programmer with a mechanism for ensuring
prompt release of scarce resources. For example, Scheme provides
the @code{(with-input-from-file)} procedure which specifies that the
created port has @ref{24a,,dynamic extent} (and so can be closed as
soon as the procedure exits, even if it is still reachable).

@item 
The MPS does not finalize objects in the context of
@ref{169,,mps_arena_destroy()} or @ref{168,,mps_pool_destroy()}.
Moreover, if you have pools containing objects registered for
finalization, you must destroy these pools by following the “safe
tear-down” procedure described under @ref{168,,mps_pool_destroy()}.

@cartouche
@quotation Note 
Under normal circumstances, finalization code can assume that
objects referenced by the object being finalized (“object F”)
have themselves not yet been finalized. (Because object F is
keeping them alive.) If finalization code is run at program
exit, this assumption is no longer true. It is much more
difficult to write correct code if it has to run under both
circumstances.

This is why Java’s @code{System.runFinalizersOnExit} is
deprecated. See Appendix A of @ref{246,,Boehm (2002)}
for a discussion of this problem.
@end quotation
@end cartouche

@cartouche
@quotation Note 
The only reliable way to ensure that all finalizable objects
are finalized is to maintain a table of @ref{c,,weak references (1)} to all such objects. The weak references don’t
prevent the objects from being finalized, but you can iterate
over the table at an appropriate point and finalize any
remaining objects yourself.
@end quotation
@end cartouche

@item 
Not all @ref{10,,pool classes} support finalization. In general, only
pools that manage objects whose liveness is determined by garbage
collection do so. See the @ref{22,,Pool reference}.
@end enumerate

@geindex finalization; interface

@node Finalization interface,Finalization messages<2>,Cautions<4>,Finalization<2>
@anchor{topic/finalization finalization-interface}@anchor{24b}
@subsection Finalization interface


@geindex mps_finalize (C function)
@anchor{topic/finalization c mps_finalize}@anchor{e8}
@deffn {C Function} @ref{14d,,mps_res_t} mps_finalize (mps_arena_t arena, mps_addr_t *ref_p)

Register a @ref{185,,block} for @ref{b,,finalization}.

@code{arena} is the arena in which the block lives.

@code{ref_p} points to a @ref{24,,reference} to the block to be
registered for finalization.

Returns @ref{5a,,MPS_RES_OK} if successful, or another
@ref{59,,result code} if not.

This function registers the block pointed to by @code{*ref_p} for
finalization. This block must have been allocated from an
automatically managed @ref{18,,pool} in @code{arena}.

@cartouche
@quotation Note 
This function receives a pointer to a reference. This is to
avoid placing the restriction on the @ref{d0,,client program}
that the C call stack be a @ref{97,,root}.
@end quotation
@end cartouche
@end deffn

@geindex mps_definalize (C function)
@anchor{topic/finalization c mps_definalize}@anchor{24c}
@deffn {C Function} @ref{14d,,mps_res_t} mps_definalize (mps_arena_t arena, mps_addr_t *ref_p)

Deregister a @ref{185,,block} for @ref{b,,finalization}.

@code{arena} is the arena in which the block lives.

@code{ref_p} points to a @ref{24,,reference} to the block to be
deregistered for finalization.

Returns @ref{5a,,MPS_RES_OK} if successful, or
@ref{14f,,MPS_RES_FAIL} if the block was not previously registered
for finalization.

@cartouche
@quotation Note 
This function receives a pointer to a reference. This is to
avoid placing the restriction on the @ref{d0,,client program}
that the C call stack be a @ref{97,,root}.
@end quotation
@end cartouche

@cartouche
@quotation Warning 
Definalization is not yet efficient: the current
implementation just loops over all finalized objects. If you
need efficient definalization, please @ref{d8,,contact us}.
@end quotation
@end cartouche
@end deffn

@geindex finalization; message

@node Finalization messages<2>,,Finalization interface,Finalization<2>
@anchor{topic/finalization finalization-messages}@anchor{24d}
@subsection Finalization messages


@geindex mps_message_type_finalization (C function)
@anchor{topic/finalization c mps_message_type_finalization}@anchor{236}
@deffn {C Function} @ref{22b,,mps_message_type_t} mps_message_type_finalization (void)

Return the @ref{22c,,message type} of finalization messages.

Finalization messages are used by the MPS to implement
@ref{b,,finalization}. When the MPS detects that a block that has
been registered for finalization (by calling
@ref{e8,,mps_finalize()}) is finalizable, it finalizes it by posting
a @ref{e9,,message} of this type.

Note that there might be delays between the block becoming
finalizable, the MPS detecting that, and the message being
posted.

In addition to the usual methods applicable to messages,
finalization messages support the
@ref{ed,,mps_message_finalization_ref()} method which returns a
reference to the block that was registered for finalization.


@subsubheading See also


@ref{f1,,Messages}.

@end deffn

@geindex mps_message_finalization_ref (C function)
@anchor{topic/finalization c mps_message_finalization_ref}@anchor{ed}
@deffn {C Function} void mps_message_finalization_ref (mps_addr_t *ref_o, mps_arena_t arena, mps_message_t message)

Returns the finalization reference for a finalization message.

@code{ref_o} points to a location that will hold the finalization
reference.

@code{arena} is the @ref{16,,arena} which posted the message.

@code{message} is a message retrieved by @ref{ec,,mps_message_get()} and
not yet discarded. It must be a finalization message: see
@ref{236,,mps_message_type_finalization()}.

The reference returned by this method is a reference to the block
that was originally registered for @ref{b,,finalization} by a call
to @ref{e8,,mps_finalize()}.

@cartouche
@quotation Note 
The reference returned is subject to the normal constraints,
such as might be imposed by a @ref{5d,,moving} collection, if appropriate. For this reason, it is
stored into the location pointed to by @code{ref_o} in order to
enable the @ref{d0,,client program} to place it directly into
scanned memory, without imposing the restriction that the C
stack be a @ref{97,,root}.

The message itself is not affected by invoking this method.
Until the client program calls @ref{ee,,mps_message_discard()}
to discard the message, it will refer to the object and
prevent its reclamation.
@end quotation
@end cartouche


@subsubheading See also


@ref{f1,,Messages}.

@end deffn

@c sources:
@c 
@c <https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mmdoc/doc/mps/guide/ld/index.html>`_

@geindex location dependency
@geindex dependency; location

@node Location dependency<2>,Segregated allocation caches,Finalization<2>,Reference
@anchor{topic/location doc}@anchor{24e}@anchor{topic/location location-dependency}@anchor{24f}@anchor{topic/location topic-location}@anchor{f8}
@section Location dependency


Location dependencies provide a means by which the @ref{d0,,client program} can depend on the `location' of blocks (that is, on the
bits in pointers to the blocks) in the presence of a @ref{1ad,,moving memory manager} (where the location of blocks may change and the
client program needs to recognize and correctly deal with such cases).

The interface is intended to support (amongst other things)
address-based hash tables and that will be used as a running example.
See the section @ref{f2,,Location dependency} in the Guide for a more
detailed look at this example.

@menu
* Terminology:: 
* Creating dependencies:: 
* Adding dependencies:: 
* Testing dependencies for staleness:: 
* Thread safety: Thread safety<2>. 
* Location dependency interface:: 

@end menu

@node Terminology,Creating dependencies,,Location dependency<2>
@anchor{topic/location terminology}@anchor{250}
@subsection Terminology


A `location dependency' is represented by an structure of type
@ref{f4,,mps_ld_s}. It encapsulates a set of dependencies on the
locations of blocks. It can be used to determine whether any of the
blocks have been moved by the memory manager.

To `depend' on the location of a block is to perform a computation
whose result depends on the particular representation (that is, the
“bit-pattern”) of a reference to the block. This includes any sort of
hash operation on a pointer to the block (such as treating the
pointer as an integer and taking it modulo 257). It is possible to
depend on the location of more than one block.

A dependency has been made `stale' if the block whose location was
depended on might have moved since the dependency was made. If this is
the case, then computations that depend on the location of a block
may give different results. A location dependency has been made stale
if any of the blocks whose location has been depended on might have
moved since the respective dependency was made.

@geindex location dependency; creating

@node Creating dependencies,Adding dependencies,Terminology,Location dependency<2>
@anchor{topic/location creating-dependencies}@anchor{251}
@subsection Creating dependencies


The @ref{d0,,client program} must provide space for the
@ref{f4,,mps_ld_s} structure. Typically, this will be inlined in some
larger structure. This structure can be in memory managed by the MPS
or elsewhere; that doesn’t matter.

For example, the toy Scheme interpreter inlines the location
dependency in its hash table structure:

@example
typedef struct table_s @{
  type_t type;                  /* TYPE_TABLE */
  hash_t hash;                  /* hash function */
  cmp_t cmp;                    /* comparison function */
  mps_ld_s ld;                  /* location dependency */
  obj_t buckets;                /* hash buckets */
@} table_s;
@end example

Before the first use, the location dependency must be reset by calling
the function @ref{f5,,mps_ld_reset()}.

@cartouche
@quotation Note 
It is not possible to statically create a location dependency that
has been reset.
@end quotation
@end cartouche

You can call @ref{f5,,mps_ld_reset()} at any later point to clear all
dependencies from the structure. For example, this is normally done
whenever @ref{f7,,mps_ld_isstale()} returns true.

@geindex location dependency; adding

@node Adding dependencies,Testing dependencies for staleness,Creating dependencies,Location dependency<2>
@anchor{topic/location adding-dependencies}@anchor{252}
@subsection Adding dependencies


`Before' the location of a block is depended on (for example,
hashed) a reference to the block may be added to a location
dependency by calling @ref{f6,,mps_ld_add()}. Dependencies on many
blocks can be added to the same location dependency.

It is also possible to merge two location dependencies by calling
@ref{253,,mps_ld_merge()}, which has the same effect as adding all of the
references from one dependency to another.

For example, in an address-based hash table implementation, each key
that is added to the table must be added to the dependency before its
address is hashed. In the toy Scheme interpreter this is most easily
done in the function that hashes an address:

@example
static unsigned long eq_hash(obj_t obj, mps_ld_t ld)
@{
    union @{char s[sizeof(obj_t)]; obj_t addr;@} u;
    if (ld) mps_ld_add(ld, arena, obj);
    u.addr = obj;
    return hash(u.s, sizeof(obj_t));
@}
@end example

@geindex location dependency; testing staleness
@geindex staleness; testing

@node Testing dependencies for staleness,Thread safety<2>,Adding dependencies,Location dependency<2>
@anchor{topic/location testing-dependencies-for-staleness}@anchor{254}
@subsection Testing dependencies for staleness


When the location of a block is used, first carry out the computation
in the normal way. For example, when looking up a key in an
address-based hash table, start by hashing the pointer and looking up
the corresponding index in the table.

If this succeeds (for example, the key was found in the table at the
place indicated by the hash of its address), then no further test is
required: the operation can proceed as usual.

But if the operation fails, you might be in one of two cases:


@enumerate 

@item 
the location of the block has not been depended on before (for
example, the key has never been added to the hash table);

@item 
the location of the block has been depended on before (for example,
the key was added to the hash table), but the block has moved and
the dependency has become stale.
@end enumerate

At this point you should call @ref{f7,,mps_ld_isstale()}. If it returns
false, then you know that the block has not moved, so you must be in case
(1).

But if @ref{f7,,mps_ld_isstale()} returns true, you could still be in
either case (1) or case (2). All @ref{f7,,mps_ld_isstale()} tells you is
that the block `might' have moved, not whether the block `has' moved.
At this point you must:


@enumerate 

@item 
reset the location dependency;

@item 
repeat the computation in some way that doesn’t depend on the old
locations of all the blocks that were added to that dependency; and

@item 
re-add a dependency on each block.
@end enumerate

For example, in the case of a hash table you should rehash based on
the new locations of the blocks.

In the toy Scheme interpreter this behaviour is encapsulated into @code{table_find}:

@example
static struct bucket_s *table_find(obj_t tbl, obj_t buckets, obj_t key, int add)
@{
    struct bucket_s *b;
    assert(TYPE(tbl) == TYPE_TABLE);
    b = buckets_find(tbl, tbl->table.buckets, key, add);
    if ((b == NULL || b->key == NULL || b->key == obj_deleted)
        && mps_ld_isstale(&tbl->table.ld, arena, key))
    @{
        b = table_rehash(tbl, tbl->table.buckets->buckets.length, key);
    @}
    return b;
@}
@end example

After @ref{f7,,mps_ld_isstale()} has returned true, and you’ve rehashed
the table, it might be tempting to repeat the usual address-based
lookup. But the MPS does not guarantee that @ref{f7,,mps_ld_isstale()}
will not return true again: if the re-hashing took a long time or
touched lots of memory, there might have been another garbage
collection. (The only time that @ref{f7,,mps_ld_isstale()} guarantees to
return false is immediately after @ref{f5,,mps_ld_reset()}.)

You might put in a loop here, but for reliability it is better to fall
back to a non-address-based version of the computation: here, since
@code{table_rehash} has to loop over all the entries in the table anyway,
it might as well find the bucket containing @code{key} at the same time
and return it.

@cartouche
@quotation Warning 
Don’t forget to check for staleness when setting a key in a table.
If the key is stale then it would be a mistake to add it to the
table as then the key will be present twice, at the positions
given by the hash of its old and new addresses, thus violating the
invariant of the hash table (that a key appears at most once).

Similarly, staleness must be tested when deleting a key from a
table.
@end quotation
@end cartouche

@geindex location dependency; thread safety

@node Thread safety<2>,Location dependency interface,Testing dependencies for staleness,Location dependency<2>
@anchor{topic/location thread-safety}@anchor{255}
@subsection Thread safety


The functions are all thread-safe with respect to operations on
different location dependencies. That means that it is not necessary
for threads to interlock if they are performing operations on
different location dependencies. The descriptions of the individual
functions detail their thread-safety attributes if multiple threads
need to access the same location dependency.

@geindex location dependency; interface

@node Location dependency interface,,Thread safety<2>,Location dependency<2>
@anchor{topic/location location-dependency-interface}@anchor{256}
@subsection Location dependency interface


@geindex mps_ld_t (C type)
@anchor{topic/location c mps_ld_t}@anchor{257}
@deffn {C Type} type mps_ld_t

The type of @ref{19a,,location dependencies}. It is a
@ref{127,,transparent alias} for a pointer to
@ref{f4,,mps_ld_s}.

A location dependency records the fact that the @ref{d0,,client program} depends on the bit patterns of some @ref{24,,references}
(and not merely on the identity of the @ref{185,,block} to which the
reference refers), and provides a function
(@ref{f7,,mps_ld_isstale()}) to find out whether any of these
references have been changed because a block has been @ref{5d,,moved}.

A typical use is in the implementation of a hash table which
hashes blocks by hashing their addresses. After a block has moved,
the table needs to be rehashed, otherwise it will not be
found in the table.
@end deffn

@geindex mps_ld_s (C type)
@anchor{topic/location c mps_ld_s}@anchor{f4}
@deffn {C Type} type mps_ld_s

The type of the structure used to represent a @ref{19a,,location dependency}.

@example
typedef struct mps_ld_s @{
    mps_word_t w0, w1;
@} mps_ld_s;
@end example

It is an opaque structure type: it is supplied so that the
@ref{d0,,client program} can inline the structure (because its size
is known), but the client must not access it other than via the
functions @ref{f6,,mps_ld_add()}, @ref{f7,,mps_ld_isstale()},
@ref{253,,mps_ld_merge()}, and @ref{f5,,mps_ld_reset()}.
@end deffn

@geindex mps_ld_add (C function)
@anchor{topic/location c mps_ld_add}@anchor{f6}
@deffn {C Function} void mps_ld_add (mps_ld_t ld, mps_arena_t arena, mps_addr_t addr)

Add a dependency on a @ref{185,,block} to a @ref{19a,,location dependency}.

@code{ld} is a location dependency.

@code{arena} is the @ref{16,,arena} to which @code{addr} belongs.

@code{addr} is the address of the block.

After calling @ref{f6,,mps_ld_add()}, and until @code{ld} is passed to
@ref{f5,,mps_ld_reset()}, the call

@example
mps_ld_isstale(ld, arena, addr)
@end example

will return true if the block has moved.

@cartouche
@quotation Note 
It is an error to call @ref{f6,,mps_ld_add()} on the same
location dependency with addresses from two different arenas.
If you need to test for staleness against multiple arenas,
then you need at least one location dependency for each arena.

@ref{f6,,mps_ld_add()} is not thread-safe with respect to
@ref{f6,,mps_ld_add()}, @ref{253,,mps_ld_merge()}, or
@ref{f5,,mps_ld_reset()} on the same location dependency, but it
is thread-safe with respect to @ref{f7,,mps_ld_isstale()}
operations. This means that calls to @ref{f6,,mps_ld_add()} from
different @ref{99,,threads} must interlock if they are
using the same location dependency. The practical upshot of
this is that there should be a lock associated with each
location dependency.
@end quotation
@end cartouche
@end deffn

@geindex mps_ld_isstale (C function)
@anchor{topic/location c mps_ld_isstale}@anchor{f7}
@deffn {C Function} @ref{129,,mps_bool_t} mps_ld_isstale (mps_ld_t ld, mps_arena_t arena, mps_addr_t addr)

Determine if a dependency on the location of a block in a
@ref{19a,,location dependency} might be stale with respect to an
@ref{16,,arena}.

@code{ld} is the location dependency.

@code{arena} is the arena to test for staleness against. It must be
the same arena that was passed to all calls to
@ref{f6,,mps_ld_add()} on @code{ld}.

@code{addr} is the address of the block that is to be tested for
staleness.

If there have been no calls to @ref{f6,,mps_ld_add()} on @code{ld}
since the last call to @ref{f5,,mps_ld_reset()}, then return false.

If the block at @code{addr} was formerly added to the location
dependency @code{ld} and subsequently moved by @code{arena}, then return
true.

Otherwise, @ref{f7,,mps_ld_isstale()} may return either true or
false. (The function strives to return true in the case where
@code{addr} was added to the location dependency and subsequently
moved, and false otherwise, but cannot ensure this.)

@cartouche
@quotation Note 
@ref{f7,,mps_ld_isstale()} may report a false positive: it may
return true in the case where @code{addr} was not added to the
location dependency, or in the case where it was added but not
moved. It never reports a false negative.

@ref{f7,,mps_ld_isstale()} is thread-safe with respect to itself
and with respect to @ref{f6,,mps_ld_add()}, but not with respect
to @ref{f5,,mps_ld_reset()}.
@end quotation
@end cartouche
@end deffn

@geindex mps_ld_isstale_any (C function)
@anchor{topic/location c mps_ld_isstale_any}@anchor{258}
@deffn {C Function} @ref{129,,mps_bool_t} mps_ld_isstale_any (mps_ld_t ld, mps_arena_t arena)

Determine if a dependency on the location of `any' block in a
@ref{19a,,location dependency} might be stale with respect to an
@ref{16,,arena}.

@code{ld} is the location dependency.

@code{arena} is the arena to test for staleness against. It must be
the same arena that was passed to all calls to
@ref{f6,,mps_ld_add()} on @code{ld}.

If there have been no calls to @ref{f6,,mps_ld_add()} on @code{ld}
since the last call to @ref{f5,,mps_ld_reset()}, then return false.

If any block added to the location dependency @code{ld} has been
moved by @code{arena}, then return true.

Otherwise, @ref{258,,mps_ld_isstale_any()} may return either true or
false. (The function strives to return true in the case where a
block was added to the location dependency and subsequently moved,
and false otherwise, but cannot ensure this.)

@cartouche
@quotation Note 
@ref{258,,mps_ld_isstale_any()} has the same thread-safety
properties as @ref{f7,,mps_ld_isstale()}.
@end quotation
@end cartouche
@end deffn

@geindex mps_ld_merge (C function)
@anchor{topic/location c mps_ld_merge}@anchor{253}
@deffn {C Function} void mps_ld_merge (mps_ld_t dest_ld, mps_arena_t arena, mps_ld_t src_ld)

Merge one @ref{19a,,location dependency} into another.

@code{dest_ld} is the destination of the merge.

@code{arena} is the @ref{16,,arena} .

@code{src_ld} is the source of the merge.

The effect of this is to add all the addresses that were added to
@code{src_ld} to the @code{dest_ld}.

@cartouche
@quotation Note 
@ref{253,,mps_ld_merge()} has the same thread-safety properties
as @ref{f6,,mps_ld_add()}.
@end quotation
@end cartouche
@end deffn

@geindex mps_ld_reset (C function)
@anchor{topic/location c mps_ld_reset}@anchor{f5}
@deffn {C Function} void mps_ld_reset (mps_ld_t ld, mps_arena_t arena)

Reset a @ref{19a,,location dependency}.

@code{ld} is the location dependency.

@code{arena} is an arena.

After this call, @code{ld} encapsulates no dependencies. After the
call to @ref{f5,,mps_ld_reset()} and prior to any call to
@ref{f6,,mps_ld_add()} on @code{ld}, @ref{f7,,mps_ld_isstale()} on @code{ld}
will return false for all arenas.

@cartouche
@quotation Note 
@ref{f5,,mps_ld_reset()} is not thread-safe with respect to any
other location dependency function.
@end quotation
@end cartouche
@end deffn

@geindex allocation; segregated-fit
@geindex free list; segregated
@geindex segregated allocation cache
@geindex segregated free list

@node Segregated allocation caches,Allocation patterns,Location dependency<2>,Reference
@anchor{topic/cache doc}@anchor{259}@anchor{topic/cache segregated-allocation-caches}@anchor{25a}@anchor{topic/cache topic-cache}@anchor{25b}
@section Segregated allocation caches


A `segregated allocation cache' is a data structure that can be
attached to any @ref{8,,manually managed}
@ref{18,,pool}, that maintains a @ref{25c,,segregated free list}, that is,
a reserve of free blocks segregated by size.

Create a segregated allocation cache by preparing an array of
structures of type @ref{25d,,mps_sac_class_s} and passing them to
@ref{25e,,mps_sac_create()}. The values in these structures are hints as
to the size of the blocks, the number of blocks of each size, and the
relative frequency of allocations and deallocations at that size.

For example, suppose we have a pool where we expect to allocate a
small number of relatively long-lived 128-byte objects, and a large
number of relatively short-lived 8-byte objects, we might create a
cache as follows:

@example
mps_sac_class_s classes[3] = @{@{8, 100, 10@}, @{128, 8, 1@}@};
mps_sac_t sac;

res = mps_sac_create(&sac, pool, sizeof classes / sizeof classes[0], classes);
if (res != MPS_RES_OK)
    error("failed to create allocation cache");
@end example

Allocations through the cache (using @ref{25f,,mps_sac_alloc()} or
@ref{260,,MPS_SAC_ALLOC_FAST}) are serviced from the cache if possible,
otherwise from the pool. Similarly, deallocations through the cache
(using @ref{261,,mps_sac_free()} or @ref{262,,MPS_SAC_FREE_FAST}) return
the block to the appropriate free list for its size. For example:

@example
Foo *foo;
mps_addr_t p;
mps_res_t res;

res = mps_sac_alloc(&p, sac, sizeof *foo, false);
if (res != MPS_RES_OK)
    error("failed to alloc foo");
foo = p;

/* use 'foo' */

mps_sac_free(sac, p, sizeof *foo);
@end example

The macros @ref{260,,MPS_SAC_ALLOC_FAST} and
@ref{262,,MPS_SAC_FREE_FAST} allow allocation and deallocation to be
inlined in the calling functions, in the case where a free block is
found in the cache.

@cartouche
@quotation Note 
It is recommended that you deallocate a block via the same
segregated allocation cache that you allocated it from. However,
the system is more general than that, and in fact a block that was
allocated from cache A can be deallocated via cache B, provided
that:


@enumerate 

@item 
the two caches are attached to the same pool; and

@item 
the two caches have the same `class structure', that is,
they were created by passing identical arrays of @ref{263,,size classes}.
@end enumerate
@end quotation
@end cartouche

@cartouche
@quotation Warning 
Segregated allocation caches work poorly with debugging pool
classes: the debugging checks only happen when blocks are moved
between the cache and the pool.
@end quotation
@end cartouche

@geindex segregated allocation cache; creating

@menu
* Cache interface:: 
* Allocation interface:: 

@end menu

@node Cache interface,Allocation interface,,Segregated allocation caches
@anchor{topic/cache cache-interface}@anchor{264}
@subsection Cache interface


@geindex mps_sac_t (C type)
@anchor{topic/cache c mps_sac_t}@anchor{265}
@deffn {C Type} type mps_sac_t

The type of @ref{1b2,,segregated allocation caches}.
@end deffn

@geindex MPS_SAC_CLASS_LIMIT (C macro)
@anchor{topic/cache c MPS_SAC_CLASS_LIMIT}@anchor{266}
@deffn {C Macro} MPS_SAC_CLASS_LIMIT

The number of @ref{263,,size classes} that @ref{25e,,mps_sac_create()}
is guaranteed to accept.

More might be accepted: in fact, there might not be any limit in
the implementation on the maximum number of size classes, but if
you specify more than this many, you should be prepared to handle
the @ref{59,,result code} @ref{151,,MPS_RES_LIMIT}.
@end deffn

@geindex mps_sac_class_s (C type)
@anchor{topic/cache c mps_sac_class_s}@anchor{25d}
@deffn {C Type} type mps_sac_class_s

The type of the structure describing a @ref{263,,size class} in a
@ref{1b2,,segregated allocation cache}.

@example
typedef struct mps_sac_class_s @{
    size_t   mps_block_size;
    size_t   mps_cached_count;
    unsigned mps_frequency;
@} mps_sac_class_s;
@end example

An array of these structures must be passed to
@ref{25e,,mps_sac_create()} when creating a segregated allocation
cache.

@code{mps_block_size} is the maximum @ref{183,,size} of any @ref{185,,block}
in this size class. It must be a multiple of the alignment of the
@ref{68,,alignment} of the @ref{18,,pool} to which the cache belongs.

@code{mps_cached_count} is the number of blocks of this size class to
cache. It is advice to the MPS on how many blocks to cache, not an
absolute limit. The cache policy tries to accommodate fluctuations
in the population and minimize the cost of responding to client
requests; the purpose of this parameter is to limit how much
memory the @ref{d0,,client program} is willing to set aside for this
purpose. However, a @code{cached_count} of zero prevents any caching of
blocks falling into that size class.

@code{mps_frequency} is a number that describes the frequency of
requests (allocation and deallocation combined) in this size class
relative to the other size classes in the cache.
@end deffn

@geindex mps_sac_create (C function)
@anchor{topic/cache c mps_sac_create}@anchor{25e}
@deffn {C Function} @ref{14d,,mps_res_t} mps_sac_create (mps_sac_t *sac_o, mps_pool_t pool, size_t classes_count, mps_sac_class_s *classes)

Create a @ref{1b2,,segregated allocation cache} for a @ref{18,,pool}.

@code{sac_o} points to a location that will hold the address of the
segregated allocation cache.

@code{pool} is the pool the cache is attached to.

@code{classes_count} is the number of @ref{263,,size classes} in the
cache.

@code{classes} points to an array describing the size classes in the
cache.

Returns @ref{5a,,MPS_RES_OK} if the segregated allocation cache
is created successfully. Returns @ref{152,,MPS_RES_MEMORY} or
@ref{155,,MPS_RES_COMMIT_LIMIT} when it fails to allocate memory
for the internal cache structure. Returns @ref{151,,MPS_RES_LIMIT}
if you ask for too many size classes: in this case, combine some
small adjacent classes.

After this function returns, the array of size classes pointed to
be @code{classes} is no longer needed and may be discarded.  The
segregated allocation cache pointed to by @code{sac_o} persists until
it is destroyed by calling @ref{267,,mps_sac_destroy()}.

This function creates an allocation cache whose @ref{268,,free list}
is segregated into the given size classes. The cache can get more
memory from the given pool, or return memory to it.

Segregated allocation caches can be associated with any pool that
supports @ref{8,,manual} allocation with
the functions @ref{ad,,mps_alloc()} and @ref{1f,,mps_free()}.

The size classes are described by an array of element type
@ref{25d,,mps_sac_class_s}. This array is used to initialize the
segregated allocation cache, and is not needed after
@ref{25e,,mps_sac_create()} returns. The following constraints apply
to the array:


@itemize *

@item 
You must specify at least one size class.

@item 
All size classes must have different sizes.

@item 
The size classes must be given in the order of increasing size.

@item 
The smallest size must be at least as large as @code{sizeof(void *)}.

@item 
Each size must be a multiple of the @ref{68,,alignment} of the
pool.

@item 
There might be a limit on how many classes can be described, but
it will be at least @ref{266,,MPS_SAC_CLASS_LIMIT}.
@end itemize

The MPS automatically provides an “overlarge” size class for
arbitrarily large allocations above the largest size class
described. Allocations falling into the overlarge size class are
not cached.

Any allocations whose size falls between two size classes are
allocated from the larger size class.

@cartouche
@quotation Note 
Too many size classes will slow down allocation; too few size
classes waste more space in internal fragmentation. It is
assumed that overlarge allocations are rare; otherwise, you
would add another size class for them, or even create separate
allocation caches or pools for them.
@end quotation
@end cartouche
@end deffn

@geindex mps_sac_destroy (C function)
@anchor{topic/cache c mps_sac_destroy}@anchor{267}
@deffn {C Function} void mps_sac_destroy (mps_sac_t sac)

Destroy a @ref{1b2,,segregated allocation cache}.

@code{sac} is the segregated allocation cache to destroy.

Returns all memory in the cache to the associated @ref{18,,pool}.
The pool might then return some memory to the @ref{16,,arena}, but
that’s up to the pool’s usual policy.

Destroying the cache has no effect on blocks allocated through it.
@end deffn

@geindex mps_sac_flush (C function)
@anchor{topic/cache c mps_sac_flush}@anchor{269}
@deffn {C Function} void mps_sac_flush (mps_sac_t sac)

Flush a @ref{1b2,,segregated allocation cache}, returning all memory
held in it to the associated @ref{18,,pool}.

@code{sac} is the segregated allocation cache to flush.

This is something that you’d typically do when you know you won’t
be using the segregated allocation cache for awhile, but want to
hold on to the cache itself. Destroying a cache has the effect of
flushing it.

Flushing the segregated allocation cache might well cause the pool
to return some memory to the @ref{16,,arena}, but that’s up to the
pool’s usual policy.

@cartouche
@quotation Note 
The MPS might also decide to take memory from the segregated
allocation cache without the @ref{d0,,client program} requesting
a flush.
@end quotation
@end cartouche

@cartouche
@quotation Note 
The @ref{d0,,client program} is responsible for synchronizing
the access to the cache, but if the cache decides to access
the pool, the MPS will properly synchronize with any other
@ref{99,,threads} that might be accessing the same
pool.
@end quotation
@end cartouche
@end deffn

@geindex segregated allocation cache; allocation

@node Allocation interface,,Cache interface,Segregated allocation caches
@anchor{topic/cache allocation-interface}@anchor{26a}
@subsection Allocation interface


@geindex mps_sac_alloc (C function)
@anchor{topic/cache c mps_sac_alloc}@anchor{25f}
@deffn {C Function} @ref{14d,,mps_res_t} mps_sac_alloc (mps_addr_t *p_o, mps_sac_t sac, size_t size, mps_bool_t unused)

Allocate a @ref{185,,block} using a @ref{1b2,,segregated allocation cache}. If no suitable block exists in the cache, ask for more
memory from the associated @ref{18,,pool}.

@code{p_o} points to a location that will hold the address of the
allocated block.

@code{sac} is the segregated allocation cache.

@code{size} is the @ref{183,,size} of the block to allocate. It does not
have to be one of the @ref{263,,size classes} of the cache; nor does
it have to be aligned.

@code{unused} is obsolete.  Pass false.

Returns @ref{5a,,MPS_RES_OK} if successful: in this case the
address of the allocated block is @code{*p_o}. The allocated block
can be larger than requested. Blocks not matching any size class
are allocated from the next largest class, and blocks larger than
the largest size class are simply allocated at the requested size
(rounded up to alignment, as usual).

Returns @ref{152,,MPS_RES_MEMORY} if there wasn’t enough memory,
@ref{155,,MPS_RES_COMMIT_LIMIT} if the @ref{156,,commit limit} was
exceeded, or @ref{153,,MPS_RES_RESOURCE} if it ran out of
@ref{51,,virtual memory}.

@cartouche
@quotation Note 

@enumerate 

@item 
There’s also a macro @ref{260,,MPS_SAC_ALLOC_FAST} that does
the same thing. The macro is faster, but generates more
code and does less checking.

@item 
The @ref{d0,,client program} is responsible for synchronizing
the access to the cache, but if the cache decides to access
the pool, the MPS will properly synchronize with any other
@ref{99,,threads} that might be accessing the same pool.

@item 
Blocks allocated through a segregated allocation cache
should only be freed through a segregated allocation cache
with the same class structure. Calling @ref{1f,,mps_free()}
on them can cause @ref{234,,memory leaks}, because the size of
the block might be larger than you think. Naturally, the
cache must also be attached to the same pool.

@item 
It is tempting to call @ref{25f,,mps_sac_alloc()} with a cast
from the desired pointer type to @code{mps_addr_t *}, like
this:

@example
my_object *obj;
res = mps_alloc((mps_addr_t *)&obj, sac, sizeof *obj, 0);
if (res != MPS_RES_OK)
    error(...);
@end example

but this is @ref{a5,,type punning}, and its behaviour is not
defined in ANSI/ISO Standard C. See
@ref{121,,Type punning} for more details.
@end enumerate
@end quotation
@end cartouche
@end deffn

@geindex MPS_SAC_ALLOC_FAST (C macro)
@anchor{topic/cache c MPS_SAC_ALLOC_FAST}@anchor{260}
@deffn {C Macro} MPS_SAC_ALLOC_FAST (res_v, p_v, sac, size, unused)

A macro alternative to @ref{25f,,mps_sac_alloc()}. It is faster than
the function, but generates more code, does less checking.

It takes an lvalue @code{p_v} which is assigned the address of the
allocated block (instead of a pointer to a location to store
it). It takes an additional first argument, the lvalue @code{res_v},
which is assigned the @ref{59,,result code}.

@cartouche
@quotation Note 
@ref{260,,MPS_SAC_ALLOC_FAST} may evaluate its arguments
multiple times.
@end quotation
@end cartouche
@end deffn

@geindex mps_sac_free (C function)
@anchor{topic/cache c mps_sac_free}@anchor{261}
@deffn {C Function} void mps_sac_free (mps_sac_t sac, mps_addr_t p, size_t size)

Free a @ref{185,,block} using a @ref{1b2,,segregated allocation cache}. If the cache would become too full, some blocks may be
returned to the associated @ref{18,,pool}.

@code{sac} is the segregated allocation cache.

@code{p} points to the block to be freed. This block must have been
allocated through a segregated allocation cache with the same
class structure, attached to the same pool. (Usually, you’d use
the same cache to allocate and deallocate a block, but the MPS is
more flexible.)

@code{size} is the @ref{183,,size} of the block. It should be the size
that was specified when the block was allocated (the cache knows
what the real size of the block is).

@cartouche
@quotation Note 
The @ref{d0,,client program} is responsible for synchronizing
the access to the cache, but if the cache decides to access
the pool, the MPS will properly synchronize with any other
@ref{99,,threads} that might be accessing the same
pool.
@end quotation
@end cartouche

@cartouche
@quotation Note 
There’s also a macro @ref{262,,MPS_SAC_FREE_FAST} that does the
same thing. The macro is faster, but generates more code and
does no checking.
@end quotation
@end cartouche

@cartouche
@quotation Note 
@ref{261,,mps_sac_free()} does very little checking: it’s
optimized for speed. @ref{26b,,Double frees} and
other mistakes will only be detected when the cache is flushed
(either by calling @ref{269,,mps_sac_flush()} or automatically),
and may not be detected at all, if intervening operations have
obscured symptoms.
@end quotation
@end cartouche
@end deffn

@geindex MPS_SAC_FREE_FAST (C macro)
@anchor{topic/cache c MPS_SAC_FREE_FAST}@anchor{262}
@deffn {C Macro} MPS_SAC_FREE_FAST (sac, p, size)

A macro alternative to @ref{261,,mps_sac_free()} that is faster than
the function but does no checking. The arguments are identical to
the function.
@end deffn

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mmdoc/protocol/mps/alloc-pattern-ramp/>`_

@geindex allocation; pattern

@node Allocation patterns,Allocation frames,Segregated allocation caches,Reference
@anchor{topic/pattern doc}@anchor{26c}@anchor{topic/pattern allocation-patterns}@anchor{26d}@anchor{topic/pattern topic-pattern}@anchor{26e}
@section Allocation patterns


An `allocation pattern' is a hint to the MPS to expect a
particular pattern of allocation on an @ref{63,,allocation point}. The
MPS may use this hint to schedule more effective garbage collection.

There are two allocation patterns, @ref{26f,,mps_alloc_pattern_ramp()}
and @ref{270,,mps_alloc_pattern_ramp_collect_all()}.

@geindex mps_alloc_pattern_t (C type)
@anchor{topic/pattern c mps_alloc_pattern_t}@anchor{271}
@deffn {C Type} type mps_alloc_pattern_t

The type of @ref{272,,allocation patterns}.
@end deffn

@geindex mps_ap_alloc_pattern_begin (C function)
@anchor{topic/pattern c mps_ap_alloc_pattern_begin}@anchor{273}
@deffn {C Function} @ref{14d,,mps_res_t} mps_ap_alloc_pattern_begin (mps_ap_t ap, mps_alloc_pattern_t alloc_pattern)

Start a period of allocation that behaves according to an
@ref{272,,allocation pattern}. The period persists until a
corresponding call to @ref{274,,mps_ap_alloc_pattern_end()}.

@code{ap} is the @ref{63,,allocation point} in which the patterned
allocation will occur.

@code{alloc_pattern} is the allocation pattern.

Returns @ref{5a,,MPS_RES_OK} if the allocation pattern is
supported by this allocation point. At present this is always the
case, but in future this function may return another @ref{59,,result code} if the allocation pattern is not supported by the allocation
point.

@cartouche
@quotation Note 
It is harmless to call @ref{273,,mps_ap_alloc_pattern_begin()}
even if it isn’t supported by the allocation point. The
pattern is simply ignored in that case.
@end quotation
@end cartouche

If @ref{273,,mps_ap_alloc_pattern_begin()} is used multiple times on
the same allocation point without intervening calls to
@ref{274,,mps_ap_alloc_pattern_end()}, the calls match in a
stack-like way, outermost and innermost: that is, allocation
patterns may nest, but not otherwise overlap.

Some allocation patterns may additionally support overlap: if so,
the documentation for the individual pattern types will specify
this.
@end deffn

@geindex mps_ap_alloc_pattern_end (C function)
@anchor{topic/pattern c mps_ap_alloc_pattern_end}@anchor{274}
@deffn {C Function} @ref{14d,,mps_res_t} mps_ap_alloc_pattern_end (mps_ap_t ap, mps_alloc_pattern_t alloc_pattern)

End a period of allocation on an @ref{63,,allocation point} that
behaves according to an @ref{272,,allocation pattern}.

@code{ap} is the allocation point in which the patterned allocation
occurred.

@code{alloc_pattern} is the allocation pattern.

Returns @ref{5a,,MPS_RES_OK} if the period of allocation was
successfully ended, or @ref{14f,,MPS_RES_FAIL} if there was no
matching call to @ref{273,,mps_ap_alloc_pattern_begin()}. Calls match
in a stack-like way, outermost and innermost: that is, allocation
patterns may nest, but not otherwise overlap.

Some allocation patterns may additionally support overlap: if so,
the documentation for the individual pattern types will specify
this.
@end deffn

@geindex mps_ap_alloc_pattern_reset (C function)
@anchor{topic/pattern c mps_ap_alloc_pattern_reset}@anchor{275}
@deffn {C Function} @ref{14d,,mps_res_t} mps_ap_alloc_pattern_reset (mps_ap_t ap)

End all @ref{272,,patterned allocation} on an
@ref{63,,allocation point}.

@code{ap} is the allocation point on which to end all patterned
allocation.

Returns @ref{5a,,MPS_RES_OK}. It may fail in future if certain
allocation patterns cannot be ended for that allocation point at
that point in time.

This function may be used to recover from error conditions.
@end deffn

@geindex allocation; ramp pattern
@geindex ramp allocation

@menu
* Ramp allocation:: 

@end menu

@node Ramp allocation,,,Allocation patterns
@anchor{topic/pattern ramp-allocation}@anchor{276}@anchor{topic/pattern topic-pattern-ramp}@anchor{228}
@subsection Ramp allocation


`Ramp allocation' a pattern of allocation whereby the
@ref{d0,,client program} builds up an increasingly large data structure,
the live size of which increases until a particular time, at which
time most of the data structure is discarded, resulting in sharp
cutoff and decline in the live size.

This pattern is useful if you are building a structure that involves
temporarily allocating much more memory than will fit into your
@ref{222,,nursery generation}. By applying the ramp allocation pattern,
the collection of that generation can be deferred until the ramp
allocation is over.

In detail: if the ramp allocation pattern is applied to an
@ref{63,,allocation point}, then allocation on that AP is ignored by the
MPS when it is deciding whether to schedule a collection of the chain
containing the generation into which the AP is allocating. See @ref{226,,Scheduling of collections}.

@cartouche
@quotation Note 
This does not prevent the generation from being collected
altogether: there may be other APs allocating into the generation,
or the MPS may have to collect the generation in order to avoid
running out of memory.
@end quotation
@end cartouche

@cartouche
@quotation Note 
Ramp allocation is only supported by @ref{62,,AMC (Automatic Mostly-Copying)}.
@end quotation
@end cartouche

@geindex mps_alloc_pattern_ramp (C function)
@anchor{topic/pattern c mps_alloc_pattern_ramp}@anchor{26f}
@deffn {C Function} @ref{271,,mps_alloc_pattern_t} mps_alloc_pattern_ramp (void)

Return an @ref{272,,allocation pattern} indicating that allocation
will follow a @ref{277,,ramp allocation} pattern.

This indicates to the MPS that most of the blocks allocated after
the call to @ref{273,,mps_ap_alloc_pattern_begin()} are likely to be
@ref{49,,dead} by the time of the corresponding call to
@ref{274,,mps_ap_alloc_pattern_end()}.
@end deffn

@geindex mps_alloc_pattern_ramp_collect_all (C function)
@anchor{topic/pattern c mps_alloc_pattern_ramp_collect_all}@anchor{270}
@deffn {C Function} @ref{271,,mps_alloc_pattern_t} mps_alloc_pattern_ramp_collect_all (void)

Return an @ref{272,,allocation pattern} indicating that allocation
will follow a @ref{277,,ramp allocation} pattern, and that the next
@ref{f,,garbage collection} following the ramp should be a full
collection.

This indicates to the MPS that most of the blocks allocated after
the call to @ref{273,,mps_ap_alloc_pattern_begin()} are likely to be
@ref{49,,dead} by the time of the corresponding call to
@ref{274,,mps_ap_alloc_pattern_end()}.

This allocation pattern may nest with, but should not otherwise
overlap with, allocation patterns of type
@ref{26f,,mps_alloc_pattern_ramp()}. In this case, the MPS may defer
the full collection until after all ramp allocation patterns have
ended.
@end deffn

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mmdoc/doc/mps/guide/stack-alloc/>`_
@c `<https://info.ravenbrook.com/project/mps/master/design/alloc-frame/>`_

@geindex allocation; frame
@geindex allocation; stack-like
@geindex stack; allocation

@node Allocation frames,Debugging pools,Allocation patterns,Reference
@anchor{topic/frame doc}@anchor{278}@anchor{topic/frame allocation-frames}@anchor{279}@anchor{topic/frame topic-frame}@anchor{27a}
@section Allocation frames


An allocation frame is a marker that can pushed onto an
@ref{63,,allocation point} by calling @ref{16e,,mps_ap_frame_push()}, and
then popped by calling @ref{16d,,mps_ap_frame_pop()} to indicate that all
blocks allocated on the allocation point are @ref{49,,dead} (in the case
of @ref{8,,manual} pools), or very likely
dead (in the case of @ref{9,,automatic}
pools).

Allocation frames can be used by the @ref{d0,,client program} to
efficiently implement stack-like patterns of allocation, for example
in implementations of stack languages like Forth and PostScript, where
some objects are allocated in stack frames and die when the stack is
popped.

@cartouche
@quotation Note 
The only @ref{10,,pool class} in the MPS that supports allocation
frames is @ref{27b,,SNC (Stack No Checking)}.
@end quotation
@end cartouche

@geindex mps_frame_t (C type)
@anchor{topic/frame c mps_frame_t}@anchor{27c}
@deffn {C Type} type mps_frame_t

The type of @ref{27d,,allocation frames}.
@end deffn

@geindex mps_ap_frame_push (C function)
@anchor{topic/frame c mps_ap_frame_push}@anchor{16e}
@deffn {C Function} @ref{14d,,mps_res_t} mps_ap_frame_push (mps_frame_t *frame_o, mps_ap_t ap)

Declare a new @ref{27d,,allocation frame} and push it onto an
@ref{63,,allocation point’s} frame stack.

@code{frame_o} points to a location that will hold the new frame if the
function is successful.

@code{ap} is the allocation point in which the new frame is declared.

Returns a @ref{59,,result code}. The creation of new frames (which
is implicit in the action of this function) can consume resources,
so this function can fail because there are insufficient
resources, or if the correct protocol is not followed by the
@ref{d0,,client program}.
@end deffn

@geindex mps_ap_frame_pop (C function)
@anchor{topic/frame c mps_ap_frame_pop}@anchor{16d}
@deffn {C Function} @ref{14d,,mps_res_t} mps_ap_frame_pop (mps_ap_t ap, mps_frame_t frame)

Declare that a set of @ref{185,,blocks} in a
@ref{27d,,allocation frame} are @ref{49,,dead} or likely to be dead,
and pop the frame from the @ref{63,,allocation point’s} frame stack.

@code{ap} is the allocation point in which @code{frame} was pushed.

@code{frame} is the allocation frame whose blocks are likely to be
dead.

Returns a @ref{59,,result code}.

This function pops @code{frame}, making its parent the current
frame. Popping invalidates @code{frame} and all frames pushed since
@code{frame}. Popping @code{frame} also makes a declaration about the set of
blocks which were allocated in @code{frame} and all frames which were
pushed since @code{frame}.

The interpretation of this declaration depends on the @ref{18,,pool}
that the allocation point belongs to. Typically, @ref{8,,manual} pool classes use this declaration to
mean that the blocks are dead and their space can be reclaimed
immediately, whereas @ref{9,,automatic} pool classes use this declaration to mean that the
blocks are likely to be mostly dead, and may use this declaration
to alter its collection decisions. See the documentation for the
pool class.

In general a frame other than the current frame can be popped (all
frames pushed more recently will be invalidated as well, as
described above), but a pool class may impose the restriction that
only the current frame may be popped. This restriction means that
every push must have a corresponding pop. See the documentation
for the pool class.

It is illegal to pop frames out of order (so the sequence “A =
push; B = push; pop A; pop B” is illegal) or to pop the same frame
twice (so the sequence “A = push, pop A, pop A” is illegal).
@end deffn

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/master/design/object-debug/>`_

@geindex debugging; pool
@geindex pool; debugging

@node Debugging pools,Telemetry,Allocation frames,Reference
@anchor{topic/debugging doc}@anchor{27e}@anchor{topic/debugging debugging-pools}@anchor{27f}@anchor{topic/debugging topic-debugging}@anchor{10d}
@section Debugging pools


Two @ref{10,,pool classes} have debugging counterparts:


@multitable {xxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Pool class

@tab

Debugging counterpart

@item

@ref{16c,,AMS (Automatic Mark and Sweep)}

@tab

@ref{144,,mps_class_ams_debug()}

@item

@ref{10c,,MVFF (Manual Variable First Fit)}

@tab

@ref{145,,mps_class_mvff_debug()}

@end multitable


These debugging pool classes provide two features that are useful for
debugging:


@itemize *

@item 
@geindex debugging; fencepost
@geindex fencepost

`fenceposts' are patterns of data that are written before and
after each allocated block. In @ref{8,,manually managed} pools, fenceposts are checked when the block is
deallocated, to see that they are unchanged. This helps detect
underwriting and @ref{c5,,overwriting errors}. Fenceposts for all
objects in a pool are checked when the pool is destroyed, and can be
checked at any time by calling @ref{280,,mps_pool_check_fenceposts()}.

@item 
@geindex debugging; free space splatting
@geindex free space splatting

`free space splatting' overwrites recycled space with a pattern
of data. If the pattern is designed so that it does not resemble a
live object (and if code checks the consistency of its data
structures), then this helps to detect @ref{281,,dangling pointer}
dereferences. The pattern is checked just before allocation, and
when a block of memory is released from the pool to the arena, to
see that it is unchanged. All free space in a pool can be checked
for the pattern at any time by calling
@ref{282,,mps_pool_check_free_space()}.
@end itemize

The @ref{d0,,client program} may optionally specify templates for both
of these features via the @ref{143,,mps_pool_debug_option_s} structure.
This allows it to specify patterns:


@itemize *

@item 
that mimic illegal data values;

@item 
that cause bus errors if wrongly interpreted as pointers;

@item 
that cause assertions to fire if wrongly interpreted as data values;

@item 
that contain an instruction sequence that wold cause the program to
signal an error or stop if wrongly interpreted as executable code.
@end itemize

For example:

@example
mps_pool_debug_option_s debug_options = @{
   "fencepost", 9,
   "free", 4,
@};
mps_pool_t pool;
mps_res_t res;
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_POOL_DEBUG_OPTIONS, &debug_options);
    MPS_ARGS_ADD(args, MPS_KEY_FORMAT, &fmt);
    res = mps_pool_create_k(&pool, arena, mps_class_ams_debug(), args);
@} MPS_ARGS_END(args);
if (res != MPS_RES_OK) error("can't create debug pool");
@end example

@geindex mps_pool_debug_option_s (C type)
@anchor{topic/debugging c mps_pool_debug_option_s}@anchor{143}
@deffn {C Type} type mps_pool_debug_option_s

The type of the structure passed as the value for the optional
@code{MPS_KEY_POOL_DEBUG_OPTIONS} keyword argument to
@ref{166,,mps_pool_create_k()} when creating a debugging @ref{10,,pool class}.

@example
typedef struct mps_pool_debug_option_s @{
    const void *fence_template;
    size_t fence_size;
    const void *free_template;
    size_t free_size;
@} mps_pool_debug_option_s;
@end example

@code{fence_template} points to a template for @ref{283,,fenceposts}.

@code{fence_size} is the @ref{183,,size} of @code{fence_template} in
@ref{17c,,bytes (1)}, or zero if the debugging pool should not use
fenceposts.

@code{free_template} points to a template for splatting free space.

@code{free_size} is the @ref{183,,size} of @code{free_template} in bytes, or
zero if the debugging pool should not splat free space.

The debugging pool will copy the @code{fence_size} bytes pointed to by
@code{fence_template} in a repeating pattern onto each fencepost during
allocation, and it will copy the bytes pointed to by
@code{free_template} in a repeating pattern over free space after the
space is reclaimed.

The MPS may not always use the whole of a template: it may use
pieces smaller than the given size, for example to pad out part of
a block that was left unused because of alignment requirements.

If the client omits to pass the
@code{MPS_KEY_POOL_DEBUG_OPTIONS} keyword argument to
@ref{166,,mps_pool_create_k()}, then the fencepost template consists
of the four bytes @code{50 4F 53 54} (@code{POST} in ASCII), and the
free space template consists of the four bytes @code{46 52 45 45}
(@code{FREE} in ASCII).
@end deffn

@geindex mps_pool_check_fenceposts (C function)
@anchor{topic/debugging c mps_pool_check_fenceposts}@anchor{280}
@deffn {C Function} void mps_pool_check_fenceposts (mps_pool_t pool)

Check all the @ref{283,,fenceposts} in a @ref{18,,pool}.

@code{pool} is the pool whose fenceposts are to be checked.

If a corrupted fencepost is found, the MPS will @ref{284,,assert}. It is only useful to call this on a @ref{285,,debugging pool} that has fenceposts turned on. It does nothing on
non-debugging pools.
@end deffn

@geindex mps_pool_check_free_space (C function)
@anchor{topic/debugging c mps_pool_check_free_space}@anchor{282}
@deffn {C Function} void mps_pool_check_free_space (mps_pool_t pool)

Check all the free space in a @ref{18,,pool} for @ref{c5,,overwriting errors}.

@code{pool} is the pool whose free space is to be checked.

If corrupted free space is found, the MPS will @ref{284,,assert}. It is only useful to call this on a @ref{285,,debugging pool} that has free space splatting turned on. It does nothing on
non-debugging pools.
@end deffn

@node Telemetry,Weak references,Debugging pools,Reference
@anchor{topic/telemetry doc}@anchor{286}@anchor{topic/telemetry telemetry}@anchor{287}@anchor{topic/telemetry topic-telemetry}@anchor{db}
@section Telemetry


In its @ref{c8,,cool} and @ref{162,,hot} @ref{c9,,varieties}, the MPS is
capable of outputting a configurable stream of events (the
@ref{ba,,telemetry stream}) to assist with debugging and profiling.

The selection of events that appear in the stream is controlled by the
environment variable 
@geindex MPS_TELEMETRY_CONTROL
@geindex environment variable; MPS_TELEMETRY_CONTROL
@ref{288,,MPS_TELEMETRY_CONTROL} (by default
none), and the stream is written to the file named by the environment
variable 
@geindex MPS_TELEMETRY_FILENAME
@geindex environment variable; MPS_TELEMETRY_FILENAME
@ref{289,,MPS_TELEMETRY_FILENAME} (by default @code{mpsio.log}).

The @ref{15b,,telemetry system} writes blocks of binary output, and is
fast enough to be left turned on in production code (the @ref{162,,hot}
variety avoids emitting events on the @ref{7c,,critical path}), which
can be useful for diagnosing memory management problems in production
environments.

The reporting of garbage collection statistics hasn’t always been
suitable for deployment. John McCarthy described the first on-line
demonstration of @ref{28a,,Lisp} in an appendix to his paper
“@ref{28b,,History of Lisp}”:

@quotation

Everything was going well, if slowly, when suddenly the
Flexowriter began to type (at ten characters per second)

@example
THE GARBAGE COLLECTOR HAS BEEN CALLED.
SOME INTERESTING STATISTICS ARE AS FOLLOWS:
@end example

and on and on and on. The garbage collector was quite new at the
time, we were rather proud of it and curious about it, and our
normal output was on a line printer, so it printed a full page
every time it was called giving how many words were marked and how
many were collected and the size of list space, etc. […]

Nothing had ever been said about the garbage collector, and I
could only imagine the reaction of the audience. We were already
behind time on a tight schedule, it was clear that typing out the
garbage collector message would take all the remaining time
allocated to the demonstration, and both the lecturer and the
audience were incapacitated with laughter. I think some of them
thought we were victims of a practical joker.
@end quotation

@geindex telemetry; utilities

@menu
* Telemetry utilities:: 
* Example:: 
* Event categories:: 
* Environment variables:: 
* Decoding the telemetry stream:: 
* Making the telemetry stream readable:: 
* Loading the telemetry stream into SQLite:: 
* Decoding the telemetry stream in Python:: 
* Telemetry events:: 
* Telemetry interface:: 
* Telemetry labels:: 
* Customizing the telemetry system:: 

@end menu

@node Telemetry utilities,Example,,Telemetry
@anchor{topic/telemetry telemetry-utilities}@anchor{28c}@anchor{topic/telemetry topic-telemetry-utilities}@anchor{28d}
@subsection Telemetry utilities


There are four programs that help process telemetry streams:


@itemize *

@item 
@ref{28e,,mpseventcnv} decodes the
machine-dependent binary event stream into a portable text format.
It must be compiled for the same architecture as the MPS-linked
program whose event stream it decodes.

@item 
@ref{28f,,mpseventtxt} takes the output of
@ref{28e,,mpseventcnv} and outputs it in a more
human-readable form.

@item 
@ref{290,,mpseventsql} takes the output of
@ref{28e,,mpseventcnv} and loads it into a
SQLite database for further analysis.

@item 
@ref{291,,mpseventpy} emits Python data
structures and constants for decoding a telemetry stream.
@end itemize

You must build and install these programs as described in
@ref{14,,Building the Memory Pool System}. These programs are described in more detail below.

@geindex telemetry; example
@geindex Scheme; telemetry

@node Example,Event categories,Telemetry utilities,Telemetry
@anchor{topic/telemetry example}@anchor{292}
@subsection Example


Here’s an example of turning on telemetry in the debugger and then
encountering a corrupted object:

@example
$ gdb ./scheme
GNU gdb 6.3.50-20050815 (Apple version gdb-1820) (Sat Jun 16 02:40:11 UTC 2012)
[...]
(gdb) set environment MPS_TELEMETRY_CONTROL=all
(gdb) run
Starting program: example/scheme/scheme
Reading symbols for shared libraries +............................. done
MPS Toy Scheme Example
[...]
7944, 0> (gc)
[...]
7968, 1> foo
Assertion failed: (TYPE(frame) == TYPE_PAIR), function lookup_in_frame, file scheme.c, line 1066.

Program received signal SIGABRT, Aborted.
0x00007fff91aeed46 in __kill ()
@end example

At this point there’s still output in the MPS’s internal event
buffers, which needs to be flushed. It would be a good idea to add a
call to @ref{177,,mps_telemetry_flush()} to the error handler, but for
now we can just call it directly from the debugger:

@example
(gdb) print mps_telemetry_flush()
$1 = void
@end example

The MPS writes the telemetry to the log in an encoded form for speed.
It can be decoded using the @ref{28e,,mpseventcnv}
and @ref{28f,,mpseventtxt} programs:

@example
(gdb) shell mpseventcnv | sort | mpseventtxt > mpsio.txt
@end example

The @code{sort} is useful because the events are not necessarily written
to the telemetry file in time order, but each event starts with a
timestamp so sorting makes a time series. The decoded events look like
this, with the timestamp in the first column, the event type in the
second column, and then addresses or other data related to the event
in the remaining columns. The source of the timestamp depends on the
platform; it may be a low-cost high-resolution processor timer, such
as the Time Stamp Counter@footnote{https://en.wikipedia.org/wiki/Time_Stamp_Counter} on IA-32 and
x86-64, if one is available. All numbers are given in hexadecimal.

@example
000050C3BA05F734 0074 EventInit           major:2 median:3 minor:0 maxCode:143 maxNameLen:19 wordWidth:64 clocksPerSec:00000000000F4240
000050C3BA09FC24 0075 EventClockSync      clock:000000000000086C
000050C3BA0F22B7 002B VMInit              vm:00007FFEECCCB660 base:0000000103062000 limit:0000000103063000
000050C3BA0FA02F 008D GenInit             arena:0000000103062000 gen:00000001030624D8 serial:0 capacity:0000000000000400 mortality:   0.500
000050C3BA168B85 0044 PoolInitMFS         pool:0000000103062360 arena:0000000103062000 extendBy:0000000000001000 extendSelf:False unitSize:0000000000000030
000050C3BA168C3F 0015 PoolInit            pool:0000000103062360 arena:0000000103062000 poolClass:000000010301CD10 serial:0
000050C3BA16BB6F 002B VMInit              vm:00007FFEECCCB520 base:00000001032B3000 limit:000000010369B000
000050C3BA1787FC 0005 ArenaCreateVM       arena:0000000103062000 userSize:00000000003E8000 chunkSize:00000000003E8000 grainSize:0000000000001000 arenaClass:0000000103014DA8 serial:0
@end example

You can search through the telemetry for events related to particular
addresses of interest.

In the example, we might look for events related to the address of the
corrupted @code{frame} object:

@example
(gdb) frame 3
#3  0x0000000100003f55 in lookup_in_frame (frame=0x1003fa7d0, symbol=0x1003faf20) at scheme.c:1066
1066            assert(TYPE(frame) == TYPE_PAIR);
(gdb) print frame
$2 = (obj_t) 0x1003fa7d0
(gdb) shell grep -i 1003fa7d0 mpsio.txt || echo not found
not found
@end example

There are no events related to this address, so in particular this
address was never fixed (no @code{TraceFix} event).

@cartouche
@quotation Note 
You may find it useful to add the command:

@example
set environment MPS_TELEMETRY_CONTROL=all
@end example

to your @code{.gdbinit}.
@end quotation
@end cartouche

@geindex telemetry; event categories
@geindex event category

@node Event categories,Environment variables,Example,Telemetry
@anchor{topic/telemetry event-categories}@anchor{293}@anchor{topic/telemetry topic-telemetry-categories}@anchor{294}
@subsection Event categories


The “bit” column gives the bit number in the @ref{295,,telemetry filter}.
These numbers are liable to change, but the current meanings (zero
being the least significant bit) are:


@multitable {xxxxx} {xxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Bit

@tab

Name

@tab

Description

@item

0

@tab

@code{Arena}

@tab

Per space or @ref{16,,arena}.

@item

1

@tab

@code{Pool}

@tab

Per @ref{18,,pool}.

@item

2

@tab

@code{Trace}

@tab

Per @ref{4b,,trace} or scan.

@item

3

@tab

@code{Seg}

@tab

Per @ref{92,,page} (segment).

@item

4

@tab

@code{Ref}

@tab

Per @ref{24,,reference} or @ref{b4,,fix}.

@item

5

@tab

@code{Object}

@tab

Per allocation, @ref{185,,block}, or @ref{1ab,,object}.

@item

6

@tab

@code{User}

@tab

User-invoked events: see @ref{296,,mps_telemetry_intern()}.

@end multitable


@geindex telemetry; environment variables

@node Environment variables,Decoding the telemetry stream,Event categories,Telemetry
@anchor{topic/telemetry environment-variables}@anchor{297}
@subsection Environment variables


In the ANSI @ref{160,,plinth} (the plinth that comes as default with the
MPS), these two environment variables control the behaviour of the
telemetry feature.

@geindex environment variable; MPS_TELEMETRY_CONTROL
@anchor{topic/telemetry envvar-MPS_TELEMETRY_CONTROL}@anchor{288}
@deffn {Environment Variable} MPS_TELEMETRY_CONTROL

The event categories which should be included in the telemetry
stream.

If its value can be interpreted as a number, then this number
represents the set of event categories as a @ref{298,,bitmap}. For
example, this turns on the @code{Pool} and @code{Seg} event categories:

@example
MPS_TELEMETRY_CONTROL=6
@end example

Otherwise, the value is split into words at spaces, and any word
that names an event category turns it on. For example:

@example
MPS_TELEMETRY_CONTROL="arena pool trace"
@end example

The special event category @code{all} turns on all events.
@end deffn

@geindex environment variable; MPS_TELEMETRY_FILENAME
@anchor{topic/telemetry envvar-MPS_TELEMETRY_FILENAME}@anchor{289}
@deffn {Environment Variable} MPS_TELEMETRY_FILENAME

The name of the file to which the telemetry stream should be
written. Defaults to @code{mpsio.log}. For example:

@example
MPS_TELEMETRY_FILENAME=$(mktemp -t mps)
@end example
@end deffn

In addition, the following environment variable controls the behaviour
of the @ref{290,,mpseventsql} program.

@geindex environment variable; MPS_TELEMETRY_DATABASE
@anchor{topic/telemetry envvar-MPS_TELEMETRY_DATABASE}@anchor{299}
@deffn {Environment Variable} MPS_TELEMETRY_DATABASE

The name of a SQLite database file that will be updated with the
events from the decoded telemetry stream, if it is not specified
with the @code{-d} option. If this variable is not assigned,
@code{mpsevent.db} is used.
@end deffn

@geindex telemetry; decoding event stream

@node Decoding the telemetry stream,Making the telemetry stream readable,Environment variables,Telemetry
@anchor{topic/telemetry decoding-the-telemetry-stream}@anchor{29a}@anchor{topic/telemetry telemetry-mpseventcnv}@anchor{28e}
@subsection Decoding the telemetry stream


The MPS writes the telemetry stream in a binary encoded format for
speed. The encoding is specific to the platform the program was
running on, and so the output needs to be decoded before it can be
processed.

The decoding takes place in two stages. First, the program
@code{mpseventcnv} converts the binary encoded format into a
portable text format suitable for input to one of the second-stage
tools (@ref{28f,,mpseventtxt} and
@ref{290,,mpseventsql}).

@geindex mpseventcnv command line option; -f
@anchor{topic/telemetry cmdoption-mpseventcnv-f}@anchor{29b}
@deffn {Option} @w{-}f <filename>

The name of the file containing the telemetry stream to decode.
Defaults to @code{mpsio.log}.
@end deffn

@geindex mpseventcnv command line option; -h
@anchor{topic/telemetry cmdoption-mpseventcnv-h}@anchor{29c}
@deffn {Option} @w{-}h

Help: print a usage message to standard output.
@end deffn

@cartouche
@quotation Note 
@code{mpseventcnv} can only read telemetry streams that were
written by an MPS compiled on the same platform.
@end quotation
@end cartouche

Here’s some example output. The first column contains the timestamp of
the event, the second column contains the event type, and remaining
columns contain parameters related to the event.

@example
000050C3BA05F734   74 2 3 0 8F 13 40 F4240
000050C3BA09FC24   75 86C
000050C3BA0F22B7   2B 7FFEECCCB660 103062000 103063000
000050C3BA0FA02F   8D 103062000 1030624D8 0 400 0.5
000050C3BA168B85   44 103062360 103062000 1000 0 30
000050C3BA168C3F   15 103062360 103062000 10301CD10 0
000050C3BA16BB6F   2B 7FFEECCCB520 1032B3000 10369B000
000050C3BA1787FC    5 103062000 3E8000 3E8000 1000 103014DA8 0
@end example

@geindex telemetry; making event stream readable

@node Making the telemetry stream readable,Loading the telemetry stream into SQLite,Decoding the telemetry stream,Telemetry
@anchor{topic/telemetry making-the-telemetry-stream-readable}@anchor{29d}@anchor{topic/telemetry telemetry-mpseventtxt}@anchor{28f}
@subsection Making the telemetry stream readable


The output of @ref{28e,,mpseventcnv} can be made
more readable by passing it through @code{mpseventtxt}, which
takes the following options:

@geindex mpseventtxt command line option; -l
@anchor{topic/telemetry cmdoption-mpseventtxt-l}@anchor{29e}
@deffn {Option} @w{-}l <filename>

The name of a file containing telemetry events that have been
decoded by @ref{28e,,mpseventcnv}. Defaults to
standard input.
@end deffn

@geindex mpseventtxt command line option; -h
@anchor{topic/telemetry cmdoption-mpseventtxt-h}@anchor{29f}
@deffn {Option} @w{-}h

Help: print a usage message to standard output.
@end deffn

For example, here’s the result of passing the output shown above
through @code{mpseventtxt}:

@example
000050C3BA05F734 0074 EventInit           major:2 median:3 minor:0 maxCode:143 maxNameLen:19 wordWidth:64 clocksPerSec:00000000000F4240
000050C3BA09FC24 0075 EventClockSync      clock:000000000000086C
000050C3BA0F22B7 002B VMInit              vm:00007FFEECCCB660 base:0000000103062000 limit:0000000103063000
000050C3BA0FA02F 008D GenInit             arena:0000000103062000 gen:00000001030624D8 serial:0 capacity:0000000000000400 mortality:   0.500
000050C3BA168B85 0044 PoolInitMFS         pool:0000000103062360 arena:0000000103062000 extendBy:0000000000001000 extendSelf:False unitSize:0000000000000030
000050C3BA168C3F 0015 PoolInit            pool:0000000103062360 arena:0000000103062000 poolClass:000000010301CD10 serial:0
000050C3BA16BB6F 002B VMInit              vm:00007FFEECCCB520 base:00000001032B3000 limit:000000010369B000
000050C3BA1787FC 0005 ArenaCreateVM       arena:0000000103062000 userSize:00000000003E8000 chunkSize:00000000003E8000 grainSize:0000000000001000 arenaClass:0000000103014DA8 serial:0
@end example

@geindex telemetry; loading into SQLite

@node Loading the telemetry stream into SQLite,Decoding the telemetry stream in Python,Making the telemetry stream readable,Telemetry
@anchor{topic/telemetry loading-the-telemetry-stream-into-sqlite}@anchor{2a0}@anchor{topic/telemetry telemetry-mpseventsql}@anchor{290}
@subsection Loading the telemetry stream into SQLite


The decoded telemetry stream (as output by @ref{28e,,mpseventcnv}) can be loaded into a SQLite database for
further analysis by running @code{mpseventsql}.

@code{mpseventsql} takes the following options:

@geindex mpseventsql command line option; -i
@anchor{topic/telemetry cmdoption-mpseventsql-i}@anchor{2a1}
@deffn {Option} @w{-}i <filename>

The name of a file containing a decoded telemetry stream. Defaults
to standard input.
@end deffn

@geindex mpseventsql command line option; -o
@anchor{topic/telemetry cmdoption-mpseventsql-o}@anchor{2a2}
@deffn {Option} @w{-}o <filename>

The name of a SQLite database file that will be updated with the
events from the decoded telemetry stream specified by the @code{-l}
option. The database will be created if it does not exist. If not
specified, the file named by the environment variable
@geindex MPS_TELEMETRY_DATABASE
@geindex environment variable; MPS_TELEMETRY_DATABASE
@ref{299,,MPS_TELEMETRY_DATABASE} is used; if this variable is not
assigned, @code{mpsevent.db} is used.

Updating a database with events from a file is idempotent unless
the @code{-f} option is specified.
@end deffn

@geindex mpseventsql command line option; -d
@anchor{topic/telemetry cmdoption-mpseventsql-d}@anchor{2a3}
@deffn {Option} @w{-}d

Delete the database before importing.
@end deffn

@geindex mpseventsql command line option; -f
@anchor{topic/telemetry cmdoption-mpseventsql-f}@anchor{2a4}
@deffn {Option} @w{-}f

Forces the database to be updated with events from the decoded
telemetry stream specified by the @code{-i} option, even if those
events have previously been added.
@end deffn

@geindex mpseventsql command line option; -v
@anchor{topic/telemetry cmdoption-mpseventsql-v}@anchor{2a5}
@deffn {Option} @w{-}v

Increase the verbosity. With one or more @code{-v} options,
@code{mpseventsql} prints informative messages to standard
error. Verbosity levels up to 3 (@code{-vvv}) produce successively
more detailed information.

This option implies @code{-p}.
@end deffn

@geindex mpseventsql command line option; -p
@anchor{topic/telemetry cmdoption-mpseventsql-p}@anchor{2a6}
@deffn {Option} @w{-}p

Show progress by printing a dot to standard output for every
100,000 events processed.
@end deffn

@geindex mpseventsql command line option; -t
@anchor{topic/telemetry cmdoption-mpseventsql-t}@anchor{2a7}
@deffn {Option} @w{-}t

Run internal tests.
@end deffn

@geindex mpseventsql command line option; -r
@anchor{topic/telemetry cmdoption-mpseventsql-r}@anchor{2a8}
@deffn {Option} @w{-}r

Rebuild the tables @code{event_kind}, @code{event_type}, and
@code{event_param}. (This is necessary if you changed the event
descriptions in @code{eventdef.h}.)
@end deffn

@geindex telemetry; decoding in Python

@node Decoding the telemetry stream in Python,Telemetry events,Loading the telemetry stream into SQLite,Telemetry
@anchor{topic/telemetry decoding-the-telemetry-stream-in-python}@anchor{2a9}@anchor{topic/telemetry telemetry-mpseventpy}@anchor{291}
@subsection Decoding the telemetry stream in Python


@code{mpseventpy} takes no options, and emits Python code
containing constants and data structures for decoding a telemetry
stream generated by an application on the same platform and using the
same version of the MPS.

To decode an event from a telemetry stream, start by reading and
decoding the header.

@geindex HEADER_SIZE (built-in variable)
@anchor{topic/telemetry HEADER_SIZE}@anchor{2aa}
@deffn {Data} HEADER_SIZE

Number of bytes in an event header. The event header consists of
data that is common to all events, and precedes the event-specific
data.
@end deffn

@geindex HEADER_FORMAT (built-in variable)
@anchor{topic/telemetry HEADER_FORMAT}@anchor{2ab}
@deffn {Data} HEADER_FORMAT

Format string to pass to struct.unpack()@footnote{https://docs.python.org/3/library/struct.html#struct.unpack} to decode an event header.
@end deffn

@geindex HeaderDesc (built-in class)
@anchor{topic/telemetry HeaderDesc}@anchor{2ac}
@deffn {Class} HeaderDesc

Named tuple describing an event header. It has the following
attributes:

@code{code} is the code (an integer) for the event type.

@code{size} is the size of the remainder of event (in bytes).

@code{clock} is when the event occurred (in arbitrary time units).
@end deffn

Using these data structures, you might read an event from a file
@code{f} like this:

@example
header_data = f.read(HEADER_SIZE)
if not header_data:
    # No more telemetry.
header = HeaderDesc(*struct.unpack(HEADER_FORMAT, header_data))
event_data = f.read(header.size)
if not event_data:
    # Telemetry was truncated.
@end example

To decode the individual events, you’ll need the following data structures:

@geindex EVENT (built-in variable)
@anchor{topic/telemetry EVENT}@anchor{2ad}
@deffn {Data} EVENT

Mapping from event code to @ref{2ae,,EventDesc}.
@end deffn

@geindex EventDesc (built-in class)
@anchor{topic/telemetry EventDesc}@anchor{2ae}
@deffn {Class} EventDesc

Named tuple describing an event type. It has the following attributes:

@code{name} is the name of the event type.

@code{code} is the code (an integer) for the event type.

@code{used} is @code{True} if the event is used by the MPS,
@code{False} if it is obsolete.

@code{kind} is the event category (see
:py:@ref{294,,Event categories}), an instance of the
@code{KindDesc} class.

@code{params} is a list of parameters of the event, each being
an instance of the @ref{2af,,EventParam} class.

@code{maxsize} is the maximum size of events of this type (in
bytes).

@code{format} is a format string to pass to struct.unpack()@footnote{https://docs.python.org/3/library/struct.html#struct.unpack} to
decode an event of this type.
@end deffn

@geindex EventParam (built-in class)
@anchor{topic/telemetry EventParam}@anchor{2af}
@deffn {Class} EventParam

Named tuple describing a parameter to an event type. It has
the following attributes:

@code{sort} is a letter indicating the type of the parameter:
@code{P} for a pointer to an internal MPS data structures, @code{A} for
an address in the client program, @code{W} for a word, @code{U} for an
unsigned integer, @code{B} for a Boolean, @code{D} for a
double-precision floating-point number, and @code{S} for a string.

@code{name} is the name of the parameter.

@code{doc} is brief documentation for the parameter.
@end deffn

Using these data structures, you might decode an event like this:

@example
event_desc = EVENT[header.code]
event_namedtuple = namedtuple(event_desc.name, [p.name for p in event_desc.params])
event = event_namedtuple(*struct.unpack(event_desc.format, event_data))
@end example

(In practice you’d want to cache the named tuple and reuse it for
future events belonging to the same event type.)

@geindex telemetry; events

@node Telemetry events,Telemetry interface,Decoding the telemetry stream in Python,Telemetry
@anchor{topic/telemetry telemetry-events}@anchor{2b0}
@subsection Telemetry events


The set of telemetry events is not documented, and varies from version
to version as we discover new requirements. You can see the current
set of events by looking in the header @code{eventdef.h}.

If you have developed a tool that uses MPS telemetry, and would like
to depend on particular telemetry events, @ref{d8,,contact us}.

@geindex telemetry; interface

@node Telemetry interface,Telemetry labels,Telemetry events,Telemetry
@anchor{topic/telemetry telemetry-interface}@anchor{2b1}
@subsection Telemetry interface


@geindex mps_telemetry_flush (C function)
@anchor{topic/telemetry c mps_telemetry_flush}@anchor{177}
@deffn {C Function} void mps_telemetry_flush (void)

Flush the internal event buffers into the @ref{ba,,telemetry stream}.

This function also calls @ref{2b2,,mps_io_flush()} on the event
stream itself. This ensures that even the latest events are now
properly recorded, should the @ref{d0,,client program} terminate
(uncontrollably as a result of a bug, for example) or some
interactive tool require access to the telemetry stream.

@cartouche
@quotation Note 
Unless all @ref{16,,arenas} are properly destroyed (by calling
@ref{169,,mps_arena_destroy()}), there are likely to be unflushed
telemetry events when the program finishes. So in the case of
abnormal program termination such as a fatal exception, you
may want to call @ref{177,,mps_telemetry_flush()} explicitly.
@end quotation
@end cartouche
@end deffn

@geindex mps_telemetry_get (C function)
@anchor{topic/telemetry c mps_telemetry_get}@anchor{2b3}
@deffn {C Function} @ref{6d,,mps_word_t} mps_telemetry_get (void)

Return the @ref{295,,telemetry filter}.
@end deffn

@geindex mps_telemetry_set (C function)
@anchor{topic/telemetry c mps_telemetry_set}@anchor{176}
@deffn {C Function} void mps_telemetry_set (mps_word_t set_mask)

Set bits in the @ref{295,,telemetry filter}.

@code{set_mask} is a @ref{218,,bitmask} indicating the bits in the
telemetry filter that should be set.
@end deffn

@geindex mps_telemetry_reset (C function)
@anchor{topic/telemetry c mps_telemetry_reset}@anchor{2b4}
@deffn {C Function} void mps_telemetry_reset (mps_word_t reset_mask)

Reset bits in the @ref{295,,telemetry filter}.

@code{reset_mask} is a @ref{218,,bitmask} indicating the bits in the
telemetry filter that should be reset.
@end deffn

@geindex telemetry; labels

@node Telemetry labels,Customizing the telemetry system,Telemetry interface,Telemetry
@anchor{topic/telemetry telemetry-labels}@anchor{2b5}
@subsection Telemetry labels


Telemetry labels allow the @ref{d0,,client program} to associate strings
with addresses in the telemetry stream. The string must first be
`interned' by calling @ref{296,,mps_telemetry_intern()}, returning a
label, and then the address can be associated with the label by
calling @ref{2b6,,mps_telemetry_label()}.

Typical uses of telemetry labels include:


@itemize *

@item 
labelling pools with a human-meaningful name;

@item 
labelling allocated objects with their type, class, or other description.
@end itemize

It is necessary to enable @code{User} events in the @ref{295,,telemetry filter} in order for telemetry labels to work. For example:

@example
mps_label_t label;
mps_telemetry_set(1 << 6);
label = mps_telemetry_intern("symbol pool");
mps_telemetry_label(symbol_pool, label);
@end example

Labels are represented by the type @ref{12d,,mps_label_t}. These are
unsigned integers. After processing by @ref{290,,mpseventsql}, the association of addresses with labels
appears in the @code{EVENT_Label} table, and the association of labels
with strings appears in the @code{EVENT_Intern} table. These can then be
used in queries, for example:

@example
/* Pool name and creation time */
SELECT I.string, P.time
FROM EVENT_PoolInit AS P,
     EVENT_Label AS L,
     EVENT_Intern AS I
WHERE I.stringId = L.stringId AND L.address = P.pool;
@end example

@geindex mps_telemetry_intern (C function)
@anchor{topic/telemetry c mps_telemetry_intern}@anchor{296}
@deffn {C Function} @ref{12d,,mps_label_t} mps_telemetry_intern (const char *label)

Registers a string with the MPS, and receives a @ref{12e,,telemetry label}, suitable for passing to @ref{2b6,,mps_telemetry_label()}.

@code{label} is a NUL-terminated string. Its length should not exceed
256 characters, including the terminating NUL.

Returns a telemetry label: a unique identifier that may be used to
represent the string in future.

The intention of this function is to provide an identifier that
can be used to concisely represent a string for the purposes of
@ref{2b6,,mps_telemetry_label()}.

@cartouche
@quotation Note 
If the @code{User} event category is not turned on in the
@ref{295,,telemetry filter} (via @ref{176,,mps_telemetry_set()} or
@geindex MPS_TELEMETRY_CONTROL
@geindex environment variable; MPS_TELEMETRY_CONTROL
@ref{288,,MPS_TELEMETRY_CONTROL}) then the string is not sent
to the @ref{ba,,telemetry stream}. A label is still returned in
this case, but it is useless.
@end quotation
@end cartouche
@end deffn

@geindex mps_telemetry_label (C function)
@anchor{topic/telemetry c mps_telemetry_label}@anchor{2b6}
@deffn {C Function} void mps_telemetry_label (mps_addr_t addr, mps_label_t label)

Associate a telemetry label returned from
@ref{296,,mps_telemetry_intern()} with an address.

@code{addr} is an address.

@code{label} is a @ref{12e,,telemetry label} returned from
@ref{296,,mps_telemetry_intern()}.

The label will be associated with the address when it appears in
the @ref{ba,,telemetry stream}.

@cartouche
@quotation Note 
If the @code{User} event category is not turned on in the
@ref{295,,telemetry filter} (via @ref{176,,mps_telemetry_set()} or
@geindex MPS_TELEMETRY_CONTROL
@geindex environment variable; MPS_TELEMETRY_CONTROL
@ref{288,,MPS_TELEMETRY_CONTROL}) then calling this function
has no effect.
@end quotation
@end cartouche
@end deffn

@geindex telemetry; customizing

@node Customizing the telemetry system,,Telemetry labels,Telemetry
@anchor{topic/telemetry customizing-the-telemetry-system}@anchor{2b7}
@subsection Customizing the telemetry system


If you need the telemetry system to support features not described
here (for example, you need to transmit telemetry data over a network
rather than writing it to a file on the local filesystem) then you may
be able to do so by providing your own implementation of the
@ref{2b8,,I/O module}.

When it first needs to output the @ref{ba,,telemetry stream}, the MPS
calls the plinth function @ref{2b9,,mps_io_create()} to create an I/O
stream. It then calls @ref{2ba,,mps_io_write()} to write binary data to
the stream and @ref{2b2,,mps_io_flush()} to flush the stream in response
to @ref{177,,mps_telemetry_flush()}. By providing your own
implementations of these functions, you can direct the telemetry
stream wherever you like.

See @ref{3b,,Plinth} for details.

@c sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/master/design/poolawl/>`_

@geindex weak references

@node Weak references,Transforms,Telemetry,Reference
@anchor{topic/weak doc}@anchor{2bb}@anchor{topic/weak topic-weak}@anchor{102}@anchor{topic/weak weak-references}@anchor{2bc}
@section Weak references


A `weak reference' is a @ref{24,,reference} that does not keep the
block it refers to @ref{78,,alive}.

The open source MPS supports weak references only:


@enumerate 

@item 
in @ref{97,,roots} that are registered with @ref{9e,,rank}
@ref{20c,,mps_rank_weak()};

@item 
in objects allocated on an @ref{63,,allocation point} in a pool of
class @ref{fe,,AWL (Automatic Weak Linked)} that was created with @ref{9e,,rank}
@ref{20c,,mps_rank_weak()}.
@end enumerate

@cartouche
@quotation Note 
If you need more general handling of weak references,
@ref{d8,,contact us}.
@end quotation
@end cartouche

When the MPS determines that a block is only kept alive by one or more
weak references, it may choose to @ref{245,,splat} those references by
replacing them with null pointers when they are @ref{b4,,fixed}. When
all weak references to the block have been splatted, the block may be
reclaimed.

For example, a @ref{73,,scan method} for objects in an AWL pool might
look like this:

@example
mps_res_t obj_scan(mps_ss_t ss, mps_addr_t base, mps_addr_t limit)
@{
    MPS_SCAN_BEGIN(ss) @{
        while (base < limit) @{
            obj_t obj = base;
            mps_addr_t p = obj->ref;
            if (MPS_FIX1(ss, p)) @{
                mps_res_t res = MPS_FIX2(ss, &p);
                if (res != MPS_RES_OK) return res;
                if (p == NULL) @{
                    /* reference was splatted */
                @}
                obj->ref = p;
            @}
            base += sizeof(*obj);
        @}
    @} MPS_SCAN_END(ss);
    return MPS_RES_OK;
@}
@end example

A reference that passes the “interesting” test @ref{75,,MPS_FIX1()}
can’t be a null pointer, so if the reference is discovered to be null
after calling @ref{76,,MPS_FIX2()} then it must have just been splatted.

@cartouche
@quotation Note 
Because weak references are splatted when they are fixed, not all
weak references to a block are splatted at the same time.
Depending on the decisions the MPS makes about which objects to
scan, a weak reference may live on for some time after other weak
references to the same block have been splatted.
@end quotation
@end cartouche

@cartouche
@quotation Note 
A common way in which weak references are used in programming
languages is in @ref{fb,,weak-key} and
@ref{fc,,weak-value hash tables}. A weak-key hash table contains
weak references to its keys: when it detects that a key has been
splatted, it deletes the corresponding value. The @ref{fe,,AWL (Automatic Weak Linked)}
pool class supports this by allowing you to specify for each
object, a @ref{ff,,dependent object} which may be written to by the
@ref{73,,scan method}. See @ref{100,,Dependent objects}.
@end quotation
@end cartouche

@cartouche
@quotation Note 
Weak references do not prevent blocks from being @ref{b,,finalized}. At the point that a block is finalized, weak
references will still validly refer to the block. The fact that a
block is registered for finalization prevents weak references to
that block from being splatted. See @ref{f0,,Finalization}.
@end quotation
@end cartouche

@geindex transform; introduction

@node Transforms,Plinth,Weak references,Reference
@anchor{topic/transform doc}@anchor{2bd}@anchor{topic/transform topic-transform}@anchor{2be}@anchor{topic/transform transforms}@anchor{2bf}
@section Transforms


In a long-running interactive system, it may be desirable to change
the format of live objects. In some programming languages (notably
Smalltalk), when the programmer edits a class definition, objects
belonging to the class must be updated so that they are valid
instances of the redefined class. This may involve adding or removing
fields from each instance and so changing the size of the allocated
objects.

If the object has grown as a result of the redefinition, this
redefinition can’t be done in-place, so what actually happens is that
for each instance of the old version of the class, a corresponding
instance of the new version of the class is created, and all
@ref{24,,references} to the old instance are rewritten to refer to the new
instance. Discovering “all references” to an object is a task that falls
to the garbage collector.


@table @asis

@item `Transforms' are a general mechanism by which the client program

requests the MPS to replace references to one set of objects (the
`old' objects) with references to another (the `new' objects). The
MPS performs this task by carrying out a complete garbage collection,
in the course of which all references to old objects are discovered
and substituted with references to the corresponding new object.
@end table

@menu
* Cautions: Cautions<5>. 
* Interface: Interface<2>. 

@end menu

@node Cautions<5>,Interface<2>,,Transforms
@anchor{topic/transform cautions}@anchor{2c0}
@subsection Cautions



@enumerate 

@item 
The arena must be @ref{b8,,parked} (for example, by
calling @ref{b9,,mps_arena_park()}) before creating the transform and
not @ref{192,,unclamped} before applying the
transform.

@item 
A transform cannot be applied if there is an @ref{9f,,ambiguous reference} to any of the old objects. (Because the MPS cannot know
whether or not the reference should be updated to point to the new
object.)
@end enumerate

@cartouche
@quotation Warning 
The second caution means that transforms may be unsuitable for
client programs that treat the @ref{26,,registers} and @ref{27,,control stack} as a @ref{97,,root}, by using @ref{a9,,mps_root_create_thread()}
and similar functions, unless the program can guarantee that none of
the old references will be referenced by this root.

An alternative and more robust approach is to segregate the
@ref{23,,formatted objects} that need to be updated into a suitable
@ref{18,,pool}, and iterate over them using the function
@ref{1a6,,mps_pool_walk()}.
@end quotation
@end cartouche

@geindex transform; interface

@node Interface<2>,,Cautions<5>,Transforms
@anchor{topic/transform interface}@anchor{2c1}
@subsection Interface


@example
#include "mps.h"
@end example

@geindex mps_transform_t (C type)
@anchor{topic/transform c mps_transform_t}@anchor{2c2}
@deffn {C Type} type mps_transform_t

The type of @ref{2c3,,transforms}. A transform represents a mapping from `old'
@ref{24,,references} to `new' references.
@end deffn

@geindex mps_transform_create (C function)
@anchor{topic/transform c mps_transform_create}@anchor{2c4}
@deffn {C Function} @ref{14d,,mps_res_t} mps_transform_create (mps_transform_t *transform_o, mps_arena_t arena)

Create an empty @ref{2c3,,transform}.

@code{transform_o} points to a location that will hold the address of
the new transform.

@code{arena} is the @ref{16,,arena} in which to create the transform.

@ref{2c4,,mps_transform_create()} returns @ref{5a,,MPS_RES_OK} if
successful. The MPS may exhaust some resource in the course of
@ref{2c4,,mps_transform_create()} and will return an appropriate
@ref{59,,result code} if so.

@cartouche
@quotation Note 
The arena must be @ref{b8,,parked} (for example,
by calling @ref{b9,,mps_arena_park()}) before creating a
transform, and if @ref{2c5,,mps_transform_apply()} is called on
a transform, it must be called before the arena is
@ref{192,,unclamped}.
@end quotation
@end cartouche
@end deffn

@geindex mps_transform_add_oldnew (C function)
@anchor{topic/transform c mps_transform_add_oldnew}@anchor{2c6}
@deffn {C Function} @ref{14d,,mps_res_t} mps_transform_add_oldnew (mps_transform_t transform, mps_addr_t *old_array, mps_addr_t *new_array, size_t count)

Add mappings from an old @ref{24,,reference} to a new reference to a
@ref{2c3,,transform}.

@code{transform} is the transform to which the mappings will be added.

@code{old_array} points to an array of old references, all of which
must be to objects in pools whose blocks are automatically managed
(see @ref{2c7,,Pool class properties}).

@code{new_array} points to an array of corresponding new references.

@code{count} is the number of references in both arrays.

@ref{2c6,,mps_transform_add_oldnew()} returns @ref{5a,,MPS_RES_OK}
if successful. The MPS may exhaust some resource in the course of
@ref{2c6,,mps_transform_add_oldnew()} and will return an appropriate
@ref{59,,result code} if so.

@cartouche
@quotation Note 
Each old reference must be added at most once to a given
transform.
@end quotation
@end cartouche
@end deffn

@geindex mps_transform_apply (C function)
@anchor{topic/transform c mps_transform_apply}@anchor{2c5}
@deffn {C Function} @ref{14d,,mps_res_t} mps_transform_apply (mps_bool_t *applied_o, mps_transform_t transform)

Attempt to apply a @ref{2c3,,transform}.

@code{applied_o} points to a location that will hold a Boolean
indicating whether or not the transform was applied.

@code{transform} is the transform to apply.

If the @ref{16,,arena} is currently incapable of applying the
transform, then an appropriate @ref{59,,result code} is returned, and
the location pointed to by @code{applied_o} is not updated. Possible
causes are:


@itemize -

@item 
the arena not being in the @ref{b8,,parked state} (in which case
the result code is @ref{151,,MPS_RES_LIMIT})

@item 
a collection having taken place since @code{transform} was created
(in which case the result code is @ref{157,,MPS_RES_PARAM}).
@end itemize

If the arena is `capable' of applying the transform, then the MPS
carries out a @ref{f,,garbage collection}, the arena is left in the
@ref{b8,,parked state}, @ref{2c5,,mps_transform_apply()} returns
@ref{5a,,MPS_RES_OK}, and the location pointed to by @code{applied_o}
is updated.

If in the course of the application, an @ref{9f,,ambiguous reference}
was discovered, then the transform is aborted and @code{*applied_o} is
set to false. In this case, `no' references to the old objects are
updated. (That is, either `all' of the transform is applied, or
`none' of it.)

The transform can only be applied once, and should be destroyed
after use, using @ref{2c8,,mps_transform_destroy()}.
@end deffn

@geindex mps_transform_destroy (C function)
@anchor{topic/transform c mps_transform_destroy}@anchor{2c8}
@deffn {C Function} void mps_transform_destroy (mps_transform_t transform)

Destroy a @ref{2c3,,transform}, allowing its resources to be recycled.

@code{transform} is the transform to destroy.
@end deffn

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/master/design/io/>`_
@c `<https://info.ravenbrook.com/project/mps/master/design/lib/>`_
@c `<https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mmdoc/doc/mps/ref-man/concepts/>`_
@c `<https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mmdoc/doc/mps/guide/interface/>`_
@c `<https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mmdoc/doc/mps/guide/appendix/plinth/>`_

@geindex plinth; introduction
@geindex freestanding environment
@geindex hosted environment
@geindex porting; plinth

@node Plinth,Platforms<2>,Transforms,Reference
@anchor{topic/plinth doc}@anchor{2c9}@anchor{topic/plinth plinth}@anchor{2ca}@anchor{topic/plinth topic-plinth}@anchor{3b}
@section Plinth


The `plinth' is a program module that provides the MPS with the
support it needs from the execution environment. The MPS uses the plinth instead of (say) the Standard C Library because:


@enumerate 

@item 
The MPS is designed to be portable to systems that have only a
@ref{14e,,freestanding} implementation of the C language: that is,
systems which potentially lack some of the facilities of the
Standard C Library, such as standard I/O. The plinth provides a way
to map MPS requirements to the facilities provided on the platform,
whatever they are.

@item 
The plinth gives the @ref{d0,,client program} complete control of
interaction between the MPS and the user, including
@ref{15d,,Assertions} and @ref{db,,Telemetry}.
@end enumerate

The plinth may be provided by the @ref{d0,,client program}; however, a
sample implementation of the plinth using ANSI Standard C Library
facilities is included with the MPS, and this is good enough for most
applications.

There are many reasons why you might want to write your own plinth.
You may be targeting an embedded system with only a
@ref{14e,,freestanding} implementation of the C language. You might need
to write the telemetry stream to a system logging facility, or
transmit it over a serial port or network connection. Or you might
need to direct debugging output to a convenient window in the user
interface.

The plinth is divided into two parts:


@enumerate 

@item 
The @ref{2b8,,I/O module} provides general-purpose I/O
functionality. It is used to output a @ref{ba,,telemetry stream} of
events to assist with debugging and profiling.

@item 
The @ref{2cb,,Library module} provides miscellaneous functionality
that would be available via the Standard C Library on a hosted
platform, including functions for reporting errors and accessing
a processor clock.
@end enumerate

The functions in the plinth module may be called in the context of a
signal handler for a protection fault (or equivalent), so they must
not access memory that is managed by the MPS, and they need to take
into account the restrictions imposed by the operating system. (See
“Defining Signal Handlers@footnote{https://www.gnu.org/software/libc/manual/html_node/Defining-Handlers.html}” in the GNU C Library Reference Manual
for useful advice.)

@geindex CONFIG_PLINTH_NONE (C macro)
@anchor{topic/plinth c CONFIG_PLINTH_NONE}@anchor{2cc}
@deffn {C Macro} CONFIG_PLINTH_NONE

If this preprocessor constant is defined, exclude the ANSI plinth
(@code{mpsioan.c} and @code{mpsliban.c}) from the MPS. For example:

@example
cc -DCONFIG_PLINTH_NONE -c mps.c        (Unix/macOS)
cl /Gs /DCONFIG_PLINTH_NONE /c mps.c    (Windows)
@end example

Having excluded the ANSI plinth, you must of course supply your
own.
@end deffn

@geindex plinth; I/O module
@geindex I/O module
@geindex telemetry; I/O module

@menu
* I/O module:: 
* Library module:: 

@end menu

@node I/O module,Library module,,Plinth
@anchor{topic/plinth i-o-module}@anchor{2cd}@anchor{topic/plinth topic-plinth-io}@anchor{2b8}
@subsection I/O module


@example
#include "mpsio.h"
@end example

@geindex mps_io_t (C type)
@anchor{topic/plinth c mps_io_t}@anchor{2ce}
@deffn {C Type} type mps_io_t

The type of an I/O stream.

This is an alias for a pointer to the incomplete structure
@code{mps_io_s}, which the @ref{160,,plinth} may define if it
needs to. Alternatively, it may leave the structure type undefined
and simply cast its own pointer to and from @ref{2ce,,mps_io_t}.

@cartouche
@quotation Note 
In the ANSI I/O module, @code{mpsioan.c}, this is an alias for
@code{FILE *}.
@end quotation
@end cartouche
@end deffn

@geindex mps_io_create (C function)
@anchor{topic/plinth c mps_io_create}@anchor{2b9}
@deffn {C Function} @ref{14d,,mps_res_t} mps_io_create (mps_io_t *io_o)

A @ref{160,,plinth} function for creating an I/O stream for the
@ref{ba,,telemetry stream}.

@code{io_o} points to a location suitable for storing a pointer to an
I/O stream.

If successful, the function must update this location with a
suitable pointer for the telemetry stream and return
@ref{5a,,MPS_RES_OK}. Otherwise, it must return some other
@ref{59,,result code}.

The MPS calls this function to create the I/O stream for telemetry
output. A typical plinth will use it to open a file for writing,
or to connect to the system logging interface.

@cartouche
@quotation Note 
In the ANSI I/O module, @code{mpsioan.c}, this calls
@code{fopen()} on the file named by the environment variable
@geindex MPS_TELEMETRY_FILENAME
@geindex environment variable; MPS_TELEMETRY_FILENAME
@ref{289,,MPS_TELEMETRY_FILENAME}.
@end quotation
@end cartouche
@end deffn

@geindex mps_io_destroy (C function)
@anchor{topic/plinth c mps_io_destroy}@anchor{2cf}
@deffn {C Function} void mps_io_destroy (mps_io_t io)

A @ref{160,,plinth} function for destroying an I/O stream.

@code{io} is a pointer to the I/O stream to be destroyed. It was
previously created by a call to @ref{2b9,,mps_io_create()}.

After calling this function, the MPS guarantees not to use the
value @code{io} again.

@cartouche
@quotation Note 
In the ANSI I/O module, @code{mpsioan.c}, this calls
@code{fclose()}.
@end quotation
@end cartouche
@end deffn

@geindex mps_io_write (C function)
@anchor{topic/plinth c mps_io_write}@anchor{2ba}
@deffn {C Function} @ref{14d,,mps_res_t} mps_io_write (mps_io_t io, void *buf, size_t size)

A @ref{160,,plinth} function for writing data to an I/O stream.

@code{io} is the I/O stream.

@code{buf} points to the data to write.

@code{size} is the @ref{183,,size} of the data in @ref{17c,,bytes (1)}.

Returns @ref{5a,,MPS_RES_OK} if successful.

@cartouche
@quotation Note 
In the ANSI I/O module, @code{mpsioan.c}, this calls
@code{fwrite()}.
@end quotation
@end cartouche
@end deffn

@geindex mps_io_flush (C function)
@anchor{topic/plinth c mps_io_flush}@anchor{2b2}
@deffn {C Function} @ref{14d,,mps_res_t} mps_io_flush (mps_io_t io)

A @ref{160,,plinth} function for flushing an I/O stream.

@code{io} is the I/O stream.

Returns @ref{5a,,MPS_RES_OK} if successful.

The MPS calls this function when it is done with the
@ref{ba,,telemetry stream}, or when the @ref{d0,,client program} calls
@ref{177,,mps_telemetry_flush()}. This function should ensure that
the buffers of data passed to the latest calls to
@ref{2ba,,mps_io_write()} are properly recorded, should the
@ref{d0,,client program} terminate (uncontrollably as a result of a
bug, for example) or some interactive tool require access to the
event data.

@cartouche
@quotation Note 
In the ANSI I/O module, @code{mpsioan.c}, this calls
@code{fflush()}.
@end quotation
@end cartouche
@end deffn

@geindex plinth; library module
@geindex library module

@node Library module,,I/O module,Plinth
@anchor{topic/plinth library-module}@anchor{2d0}@anchor{topic/plinth topic-plinth-lib}@anchor{2cb}
@subsection Library module


@example
#include "mpslib.h"
@end example

@geindex mps_clock (C function)
@anchor{topic/plinth c mps_clock}@anchor{12b}
@deffn {C Function} @ref{12a,,mps_clock_t} mps_clock (void)

Return the time since some epoch, in units given by
@ref{2d1,,mps_clocks_per_sec()}.

@cartouche
@quotation Note 
The ANSI Library module, @code{mpsliban.c}, calls @code{clock}.
@end quotation
@end cartouche

The MPS calls this function to make scheduling decisions (see
@ref{226,,Scheduling of collections}), and to calibrate the time
stamps on events in the @ref{ba,,telemetry stream}. If your platform
has a low-resolution @code{clock()}, and there are higher-resolution
clocks readily available, then using one of those will improve MPS
scheduling decisions and the quality of telemetry output. For
instance, with @code{getrusage()}:

@example
#include <sys/resource.h>

mps_clock_t mps_clock(void) @{
    struct rusage s;
    int res = getrusage(RUSAGE_SELF, &s);
    if (res != 0) @{
        /* handle error */
    @}
    return ((mps_clock_t)s.ru_utime.tv_sec) * 1000000 + s.ru_utime.tv_usec;
@}
@end example
@end deffn

@geindex mps_clocks_per_sec (C function)
@anchor{topic/plinth c mps_clocks_per_sec}@anchor{2d1}
@deffn {C Function} @ref{12a,,mps_clock_t} mps_clocks_per_sec (void)

Return the number of clock units per second, as returned by
@ref{12b,,mps_clock()}.

@cartouche
@quotation Note 
The ANSI Library module, @code{mpsliban.c}, returns
@code{CLOCKS_PER_SEC}.
@end quotation
@end cartouche
@end deffn

@geindex mps_lib_assert_fail (C function)
@anchor{topic/plinth c mps_lib_assert_fail}@anchor{161}
@deffn {C Function} void mps_lib_assert_fail (const char *message)

Report an assertion failure.

@code{message} is a NUL-terminated string describing the assertion
failure.

@cartouche
@quotation Note 
In the ANSI Library module, @code{mpsliban.c}, this reports the
failure by calling @code{fprintf(stderr, "...%s...", message)},
flushes the @ref{ba,,telemetry stream} by calling
@ref{177,,mps_telemetry_flush()}, and, in the @ref{c8,,cool}
@ref{c9,,variety}, terminates the program by calling
@code{abort()}. You can change this behaviour with
@ref{164,,mps_lib_assert_fail_install()}. For a discussion of the
default behaviour, see @ref{15f,,Assertion handling}.
@end quotation
@end cartouche

@cartouche
@quotation Warning 
This function must not call any function in MPS, and it must
not access memory managed by the MPS.
@end quotation
@end cartouche
@end deffn

@geindex mps_lib_assert_fail_install (C function)
@anchor{topic/plinth c mps_lib_assert_fail_install}@anchor{164}
@deffn {C Function} @ref{2d2,,mps_lib_assert_fail_t} mps_lib_assert_fail_install (mps_lib_assert_fail_t handler)

This function customises the behaviour of the default assertion handler
in the ANSI Library module.  It is not otherwise required by the MPS
and you need not implement it if you are providing an alternative plinth.

If you’re using the ANSI Library module, you can use this function
to change the behaviour of the MPS when an assertion fails.  For
example, you could terminate the program in the @ref{162,,hot}
@ref{c9,,variety} too.  (The MPS test programs do exactly that.)

@code{handler} is the assertion handler to install.

Returns the previously installed handler.

@cartouche
@quotation Warning 
The installed assertion handler must not call any function in
MPS, and it must not access memory managed by the MPS.
@end quotation
@end cartouche
@end deffn

@geindex mps_lib_assert_fail_t (C type)
@anchor{topic/plinth c mps_lib_assert_fail_t}@anchor{2d2}
@deffn {C Type} typedef void (*mps_lib_assert_fail_t)(const char*, unsigned, const char*)

The type of assertion handlers passed to and returned by
@ref{164,,mps_lib_assert_fail_install()}.
@end deffn

@geindex mps_lib_FILE (C type)
@anchor{topic/plinth c mps_lib_FILE}@anchor{2d3}
@deffn {C Type} type mps_lib_FILE

The type of output streams provided by the plinth.

@cartouche
@quotation Note 
In the ANSI Library module, @code{mpsliban.c}, this is an alias
for @code{FILE *}.
@end quotation
@end cartouche
@end deffn

@geindex mps_lib_fputc (C function)
@anchor{topic/plinth c mps_lib_fputc}@anchor{2d4}
@deffn {C Function} int mps_lib_fputc (int c, mps_lib_FILE *stream)

Write a character to an output stream.

@code{c} is the character.

@code{stream} is the stream.

Return the character written if successful, or
@ref{2d5,,mps_lib_get_EOF()} if not.

This function is intended to have the same semantics as the
@code{fputc()} function of the ANSI C Standard (@ref{118,,ISO/IEC 9899;1990} §7.11.7.3).

@cartouche
@quotation Note 
In the ANSI Library module, @code{mpsliban.c}, this is a simple
wrapper around @code{fputc()}.
@end quotation
@end cartouche
@end deffn

@geindex mps_lib_fputs (C function)
@anchor{topic/plinth c mps_lib_fputs}@anchor{2d6}
@deffn {C Function} int mps_lib_fputs (const char *s, mps_lib_FILE *stream)

Write a string to an output stream.

@code{s} is the NUL-terminated string.

@code{stream} is the stream.

This function is intended to have the same semantics as the
@code{fputs()} function of the ANSI C Standard (@ref{118,,ISO/IEC 9899;1990} §7.11.7.4).

Return a non-negative integer if successful, or
@ref{2d5,,mps_lib_get_EOF()} if not.

@cartouche
@quotation Note 
In the ANSI Library module, @code{mpsliban.c}, this is a simple
wrapper around @code{fputs()}.
@end quotation
@end cartouche
@end deffn

@geindex mps_lib_get_EOF (C function)
@anchor{topic/plinth c mps_lib_get_EOF}@anchor{2d5}
@deffn {C Function} int mps_lib_get_EOF (void)

Return the value that is returned from @ref{2d4,,mps_lib_fputc()} and
@ref{2d6,,mps_lib_fputs()} to indicate failure.

@cartouche
@quotation Note 
In the ANSI Library module, @code{mpsliban.c}, this returns
@code{EOF}.
@end quotation
@end cartouche
@end deffn

@geindex mps_lib_get_stderr (C function)
@anchor{topic/plinth c mps_lib_get_stderr}@anchor{2d7}
@deffn {C Function} @ref{2d3,,mps_lib_FILE} *mps_lib_get_stderr (void)

Returns an output stream suitable for reporting errors.

@cartouche
@quotation Note 
In the ANSI Library module, @code{mpsliban.c}, this returns
@code{stderr}.
@end quotation
@end cartouche

@cartouche
@quotation Note 
The MPS does not use this at present, but it may be required
in future.
@end quotation
@end cartouche
@end deffn

@geindex mps_lib_get_stdout (C function)
@anchor{topic/plinth c mps_lib_get_stdout}@anchor{2d8}
@deffn {C Function} @ref{2d3,,mps_lib_FILE} *mps_lib_get_stdout (void)

Returns an output stream suitable for reporting informative
output.

@cartouche
@quotation Note 
In the ANSI Library module, @code{mpsliban.c}, this returns
@code{stdout}.
@end quotation
@end cartouche

@cartouche
@quotation Note 
The MPS does not use this at present, but it may be required
in future.
@end quotation
@end cartouche
@end deffn

@geindex mps_lib_memcmp (C function)
@anchor{topic/plinth c mps_lib_memcmp}@anchor{2d9}
@deffn {C Function} int mps_lib_memcmp (const void *s1, const void *s2, size_t n)

A @ref{160,,plinth} function similar to the standard @ref{1c,,C}
function @code{memcmp()}.

@code{s1} and @code{s2} point to @ref{185,,blocks} of memory to be
compared.

@code{n} is the @ref{183,,size} of the blocks.

Returns an integer that is greater than, equal to, or less than
zero, accordingly as the block pointed to by @code{s1} is greater than,
equal to, or less than the block pointed to by @code{s2}.

This function is intended to have the same semantics as the
@code{memcmp()} function of the ANSI C Standard (@ref{118,,ISO/IEC 9899;1990} §7.11.4.1).

@cartouche
@quotation Note 
In the ANSI Library module, @code{mpsliban.c}, this is a simple
wrapper around @code{memcmp()}.
@end quotation
@end cartouche
@end deffn

@geindex mps_lib_memcpy (C function)
@anchor{topic/plinth c mps_lib_memcpy}@anchor{2da}
@deffn {C Function} void *mps_lib_memcpy (void *dest, const void *source, size_t n)

A @ref{160,,plinth} function similar to the standard @ref{1c,,C}
function @code{memcpy()}.

@code{dest} points to the destination.

@code{source} points to the source.

@code{n} is the number of bytes to copy from @code{source} to @code{dest}.

Returns @code{dest}.

This function is intended to have the same semantics as the
@code{memcpy()} function of the ANSI C Standard (@ref{118,,ISO/IEC 9899;1990} §7.11.2.1).

The MPS never passes overlapping blocks to
@ref{2da,,mps_lib_memcpy()}.

@cartouche
@quotation Note 
In the ANSI Library module, @code{mpsliban.c}, this is a simple
wrapper around @code{memcpy()}.
@end quotation
@end cartouche
@end deffn

@geindex mps_lib_memset (C function)
@anchor{topic/plinth c mps_lib_memset}@anchor{2db}
@deffn {C Function} void *mps_lib_memset (void *s, int c, size_t n)

A @ref{160,,plinth} function similar to the standard @ref{1c,,C}
function @code{memset()}.

@code{s} points to the @ref{185,,block} to fill with the byte @code{c}.

@code{c} is the byte to fill with (when converted to @code{unsigned char}).

@code{n} is the @ref{183,,size} of the block.

Returns @code{s}.

This function is intended to have the same semantics as the
@code{memset()} function of the ANSI C Standard (@ref{118,,ISO/IEC 9899;1990} §7.11.6.1).

@cartouche
@quotation Note 
In the ANSI Library module, @code{mpsliban.c}, this is a simple
wrapper around @code{memset()}.
@end quotation
@end cartouche

@cartouche
@quotation Note 
The MPS does not use this at present, but it may be required
in future.
@end quotation
@end cartouche
@end deffn

@geindex mps_lib_telemetry_control (C function)
@anchor{topic/plinth c mps_lib_telemetry_control}@anchor{2dc}
@deffn {C Function} unsigned long mps_lib_telemetry_control ()

A @ref{160,,plinth} function to supply a default value for the
@ref{295,,telemetry filter} from the environment. See
@geindex MPS_TELEMETRY_CONTROL
@geindex environment variable; MPS_TELEMETRY_CONTROL
@ref{288,,MPS_TELEMETRY_CONTROL} for more information on the
significance of the value.

Returns the default value of the telemetry filter, as derived from
the environment. It is recommended that the environment be
consulted for a symbol analogous to
@geindex MPS_TELEMETRY_CONTROL
@geindex environment variable; MPS_TELEMETRY_CONTROL
@ref{288,,MPS_TELEMETRY_CONTROL}, subject to local restrictions.

In the absence of environmental data, a default of zero is
recommended.

@cartouche
@quotation Note 
In the ANSI Library module, @code{mpsliban.c}, this reads the
environment variable 
@geindex MPS_TELEMETRY_CONTROL
@geindex environment variable; MPS_TELEMETRY_CONTROL
@ref{288,,MPS_TELEMETRY_CONTROL}.
@end quotation
@end cartouche
@end deffn

@node Platforms<2>,Porting the MPS,Plinth,Reference
@anchor{topic/platform doc}@anchor{2dd}@anchor{topic/platform platforms}@anchor{2de}@anchor{topic/platform topic-platform}@anchor{130}
@section Platforms


@geindex platform; code

@menu
* Platform codes:: 
* Platform interface:: 
* Historical platform codes:: 
* Historical platform list:: 
* Platform limitations:: 

@end menu

@node Platform codes,Platform interface,,Platforms<2>
@anchor{topic/platform platform-codes}@anchor{2df}
@subsection Platform codes


The MPS uses a six-character platform code to express a combination of
operating system, CPU architecture, and compiler toolchain. Each
six-character code breaks down into three pairs of characters:
@code{OSARCT}. The first pair of characters names the operating system:


@multitable {xxxxxxxx} {xxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxx} 
@headitem

@code{OS}

@tab

Operating system

@tab

Constant

@item

@code{fr}

@tab

FreeBSD

@tab

@ref{2e0,,MPS_OS_FR}

@item

@code{li}

@tab

Linux

@tab

@ref{2e1,,MPS_OS_LI}

@item

@code{w3}

@tab

Windows

@tab

@ref{2e2,,MPS_OS_W3}

@item

@code{xc}

@tab

macOS

@tab

@ref{2e3,,MPS_OS_XC}

@end multitable


The second pair of characters names the processor architecture:


@multitable {xxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

@code{AR}

@tab

Processor architecture

@tab

Constant

@item

@code{a6}

@tab

ARM64

@tab

@ref{2e4,,MPS_ARCH_A6}

@item

@code{i3}

@tab

Intel/AMD IA-32

@tab

@ref{2e5,,MPS_ARCH_I3}

@item

@code{i6}

@tab

Intel/AMD x86-64

@tab

@ref{2e6,,MPS_ARCH_I6}

@end multitable


The third pair of characters names the compiler toolchain:


@multitable {xxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

@code{CT}

@tab

Compiler toolchain

@tab

Constant

@item

@code{gc}

@tab

GNU Compiler collection

@tab

@ref{2e7,,MPS_BUILD_GC}

@item

@code{ll}

@tab

Clang/LLVM

@tab

@ref{2e8,,MPS_BUILD_LL}

@item

@code{mv}

@tab

Microsoft Visual C/C++

@tab

@ref{2e9,,MPS_BUILD_MV}

@end multitable


In each case the aspect of the platform can be tested by checking
whether the preprocessor constant in the third column in the table
is defined, and the full platform can be tested by checking
whether the corresponding @code{MPS_PF_} preprocessor constant is
defined. For example, “@code{xci6ll}” platform corresponds to the
@ref{2ea,,MPS_PF_XCI6LL} preprocessor constant.

Not all combinations of operating system, processor architecture,
and compiler are supported.

@geindex platform; interface

@node Platform interface,Historical platform codes,Platform codes,Platforms<2>
@anchor{topic/platform platform-interface}@anchor{2eb}@anchor{topic/platform topic-platform-interface}@anchor{2ec}
@subsection Platform interface


@example
#include "mpstd.h"
@end example

@geindex MPS_ARCH_A6 (C macro)
@anchor{topic/platform c MPS_ARCH_A6}@anchor{2e4}
@deffn {C Macro} MPS_ARCH_A6

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the target processor architecture of the compilation is a member
of the ARM64 family of 64-bit processors.
@end deffn

@geindex MPS_ARCH_I3 (C macro)
@anchor{topic/platform c MPS_ARCH_I3}@anchor{2e5}
@deffn {C Macro} MPS_ARCH_I3

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the target processor architecture of the compilation is a member
of the IA-32 Intel/AMD family of 32-bit processors.
@end deffn

@geindex MPS_ARCH_I6 (C macro)
@anchor{topic/platform c MPS_ARCH_I6}@anchor{2e6}
@deffn {C Macro} MPS_ARCH_I6

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the target processor architecture of the compilation is a member
of the x86-64 Intel/AMD family of 64-bit processors.

@cartouche
@quotation Note 
The MPS is not supported on IA-64 (Itanium).
@end quotation
@end cartouche
@end deffn

@geindex MPS_BUILD_GC (C macro)
@anchor{topic/platform c MPS_BUILD_GC}@anchor{2e7}
@deffn {C Macro} MPS_BUILD_GC

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the MPS was compiled by the C compiler from the GNU Compiler
Collection (GCC).
@end deffn

@geindex MPS_BUILD_LL (C macro)
@anchor{topic/platform c MPS_BUILD_LL}@anchor{2e8}
@deffn {C Macro} MPS_BUILD_LL

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the MPS was compiled by Clang, the C compiler from the LLVM (Low
Level Virtual Machine) system.
@end deffn

@geindex MPS_BUILD_MV (C macro)
@anchor{topic/platform c MPS_BUILD_MV}@anchor{2e9}
@deffn {C Macro} MPS_BUILD_MV

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the MPS was compiled by the C compiler from Microsoft Visual
Studio.
@end deffn

@geindex MPS_OS_FR (C macro)
@anchor{topic/platform c MPS_OS_FR}@anchor{2e0}
@deffn {C Macro} MPS_OS_FR

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the MPS was compiled on a FreeBSD operating system.
@end deffn

@geindex MPS_OS_LI (C macro)
@anchor{topic/platform c MPS_OS_LI}@anchor{2e1}
@deffn {C Macro} MPS_OS_LI

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the MPS was compiled on a Linux operating system.
@end deffn

@geindex MPS_OS_W3 (C macro)
@anchor{topic/platform c MPS_OS_W3}@anchor{2e2}
@deffn {C Macro} MPS_OS_W3

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the MPS was compiled on a Windows operating system.
@end deffn

@geindex MPS_OS_XC (C macro)
@anchor{topic/platform c MPS_OS_XC}@anchor{2e3}
@deffn {C Macro} MPS_OS_XC

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the MPS was compiled on an macOS operating system.
@end deffn

@geindex MPS_PF_ALIGN (C macro)
@anchor{topic/platform c MPS_PF_ALIGN}@anchor{6f}
@deffn {C Macro} MPS_PF_ALIGN

A @ref{1c,,C} preprocessor macro that expands to an integer giving
the @ref{70,,natural alignment} of the @ref{12f,,platform}.
@end deffn

@geindex MPS_PF_FRI3GC (C macro)
@anchor{topic/platform c MPS_PF_FRI3GC}@anchor{2ed}
@deffn {C Macro} MPS_PF_FRI3GC

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the @ref{12f,,platform} consists of the FreeBSD operating system, the
IA-32 processor architecture, and the GCC compiler.
@end deffn

@geindex MPS_PF_FRI3LL (C macro)
@anchor{topic/platform c MPS_PF_FRI3LL}@anchor{2ee}
@deffn {C Macro} MPS_PF_FRI3LL

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the @ref{12f,,platform} consists of the FreeBSD operating system, the
IA-32 processor architecture, and the Clang/LLVM compiler.
@end deffn

@geindex MPS_PF_FRI6GC (C macro)
@anchor{topic/platform c MPS_PF_FRI6GC}@anchor{2ef}
@deffn {C Macro} MPS_PF_FRI6GC

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the @ref{12f,,platform} consists of the FreeBSD operating system, the
x86-64 processor architecture, and the GCC compiler.
@end deffn

@geindex MPS_PF_FRI6LL (C macro)
@anchor{topic/platform c MPS_PF_FRI6LL}@anchor{2f0}
@deffn {C Macro} MPS_PF_FRI6LL

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the @ref{12f,,platform} consists of the FreeBSD operating system, the
x86-64 processor architecture, and the Clang/LLVM compiler.
@end deffn

@geindex MPS_PF_LIA6GC (C macro)
@anchor{topic/platform c MPS_PF_LIA6GC}@anchor{2f1}
@deffn {C Macro} MPS_PF_LIA6GC

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the @ref{12f,,platform} consists of the Linux operating system, the
ARM64 processor architecture, and the GCC compiler.
@end deffn

@geindex MPS_PF_LIA6LL (C macro)
@anchor{topic/platform c MPS_PF_LIA6LL}@anchor{2f2}
@deffn {C Macro} MPS_PF_LIA6LL

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the @ref{12f,,platform} consists of the Linux operating system, the
ARM64 processor architecture, and the Clang/LLVM compiler.
@end deffn

@geindex MPS_PF_LII3GC (C macro)
@anchor{topic/platform c MPS_PF_LII3GC}@anchor{2f3}
@deffn {C Macro} MPS_PF_LII3GC

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the @ref{12f,,platform} consists of the Linux operating system, the
IA-32 processor architecture, and the GCC compiler.
@end deffn

@geindex MPS_PF_LII6GC (C macro)
@anchor{topic/platform c MPS_PF_LII6GC}@anchor{2f4}
@deffn {C Macro} MPS_PF_LII6GC

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the @ref{12f,,platform} consists of the Linux operating system, the
x86-64 processor architecture, and the GCC compiler.
@end deffn

@geindex MPS_PF_LII6LL (C macro)
@anchor{topic/platform c MPS_PF_LII6LL}@anchor{2f5}
@deffn {C Macro} MPS_PF_LII6LL

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the @ref{12f,,platform} consists of the Linux operating system, the
x86-64 processor architecture, and the Clang/LLVM compiler.
@end deffn

@geindex MPS_PF_STRING (C macro)
@anchor{topic/platform c MPS_PF_STRING}@anchor{2f6}
@deffn {C Macro} MPS_PF_STRING

A @ref{1c,,C} preprocessor macro that names the @ref{12f,,platform} for
which the MPS was built.
@end deffn

@geindex MPS_PF_W3I3MV (C macro)
@anchor{topic/platform c MPS_PF_W3I3MV}@anchor{2f7}
@deffn {C Macro} MPS_PF_W3I3MV

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the @ref{12f,,platform} consists of the Windows operating system, the
IA-32 processor architecture, and the Microsoft Visual C/C++
compiler.
@end deffn

@geindex MPS_PF_W3I6MV (C macro)
@anchor{topic/platform c MPS_PF_W3I6MV}@anchor{2f8}
@deffn {C Macro} MPS_PF_W3I6MV

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the @ref{12f,,platform} consists of the Windows operating system, the
x86-64 processor architecture, and the Microsoft Visual C/C++
compiler.
@end deffn

@geindex MPS_PF_XCA6LL (C macro)
@anchor{topic/platform c MPS_PF_XCA6LL}@anchor{2f9}
@deffn {C Macro} MPS_PF_XCA6LL

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the @ref{12f,,platform} consists of the macOS operating system, the
ARM64 processor architecture, and the Clang/LLVM compiler.
@end deffn

@geindex MPS_PF_XCI3GC (C macro)
@anchor{topic/platform c MPS_PF_XCI3GC}@anchor{2fa}
@deffn {C Macro} MPS_PF_XCI3GC

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the @ref{12f,,platform} consists of the macOS operating system, the
IA-32 processor architecture, and the GCC compiler.
@end deffn

@geindex MPS_PF_XCI3LL (C macro)
@anchor{topic/platform c MPS_PF_XCI3LL}@anchor{2fb}
@deffn {C Macro} MPS_PF_XCI3LL

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the @ref{12f,,platform} consists of the macOS operating system, the
IA-32 processor architecture, and the Clang/LLVM compiler.
@end deffn

@geindex MPS_PF_XCI6GC (C macro)
@anchor{topic/platform c MPS_PF_XCI6GC}@anchor{2fc}
@deffn {C Macro} MPS_PF_XCI6GC

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the @ref{12f,,platform} consists of the macOS operating system, the
x86-64 processor architecture, and the GCC compiler.
@end deffn

@geindex MPS_PF_XCI6LL (C macro)
@anchor{topic/platform c MPS_PF_XCI6LL}@anchor{2ea}
@deffn {C Macro} MPS_PF_XCI6LL

A @ref{1c,,C} preprocessor macro that indicates, if defined, that
the @ref{12f,,platform} consists of the macOS operating system, the
x86-64 processor architecture, and the Clang/LLVM compiler.
@end deffn

@geindex MPS_T_ULONGEST (C macro)
@anchor{topic/platform c MPS_T_ULONGEST}@anchor{2fd}
@deffn {C Macro} MPS_T_ULONGEST

A @ref{1c,,C} preprocessor macro that expands to the name of the
largest unsigned integral type.

The exact identity of this type is
@ref{12f,,platform}-dependent. Typical identities are @code{unsigned
long} and @code{unsigned __int_64}.
@end deffn

@geindex MPS_T_WORD (C macro)
@anchor{topic/platform c MPS_T_WORD}@anchor{2fe}
@deffn {C Macro} MPS_T_WORD

A @ref{1c,,C} preprocessor macro that expands to the name of an
unsigned integral type that is the same size as an @ref{6e,,object pointer}, so that @code{sizeof(MPS_T_WORD) == sizeof(void*)}.

The exact identity of this type is
@ref{12f,,platform}-dependent. Typical identities are @code{unsigned
long} and @code{unsigned __int_64}.
@end deffn

@geindex MPS_WORD_SHIFT (C macro)
@anchor{topic/platform c MPS_WORD_SHIFT}@anchor{2ff}
@deffn {C Macro} MPS_WORD_SHIFT

A @ref{1c,,C} preprocessor macro that expands to the logarithm to
base 2 of the constant @ref{187,,MPS_WORD_WIDTH}, so that @code{1 <<
MPS_WORD_SHIFT == MPS_WORD_WIDTH}.

The value is platform-dependent. Typical values are 5 and 6.
@end deffn

@geindex MPS_WORD_WIDTH (C macro)
@anchor{topic/platform c MPS_WORD_WIDTH}@anchor{187}
@deffn {C Macro} MPS_WORD_WIDTH

A @ref{1c,,C} preprocessor macro that expands to the width in bits
of the type @ref{2fe,,MPS_T_WORD}, so that @code{MPS_WORD_WIDTH ==
sizeof(MPS_T_WORD) * CHAR_BIT}.

This value is platform-dependent. It is always a power of 2:
typical values are 32 and 64.
@end deffn

@geindex platform; historical codes

@node Historical platform codes,Historical platform list,Platform interface,Platforms<2>
@anchor{topic/platform historical-platform-codes}@anchor{300}
@subsection Historical platform codes


The platform codes in the tables below were in use in older versions
of the Memory Pool System, but are not currently supported.

Formerly supported operating systems:


@multitable {xxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxx} 
@headitem

@code{OS}

@tab

Operating system

@tab

Constant

@item

@code{i5}

@tab

Irix 5 or 6 (old ABI)

@tab

@code{MPS_OS_I5}

@item

@code{ia}

@tab

Irix 6 (new ABI)

@tab

@code{MPS_OS_IA}

@item

@code{o1}

@tab

OSF/1 aka Tru64

@tab

@code{MPS_OS_O1}

@item

@code{s7}

@tab

Macintosh System 7, 8, or 9

@tab

@code{MPS_OS_S7}

@item

@code{so}

@tab

Solaris

@tab

@code{MPS_OS_SO}

@item

@code{su}

@tab

SunOS

@tab

@code{MPS_OS_SU}

@end multitable


Formerly supported processor architectures:


@multitable {xxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxx} 
@headitem

@code{AR}

@tab

Processor architecture

@tab

Constant

@item

@code{i4}

@tab

Intel/AMD IA-32 @footnote{
Obsolete: the MPS used to make a distinction between the
80386 and 80486 processor architectures.
}

@tab

@code{MPS_ARCH_I4}

@item

@code{al}

@tab

Digital Alpha

@tab

@code{MPS_ARCH_AL}

@item

@code{m2}

@tab

MIPS R2000

@tab

@code{MPS_ARCH_M2}

@item

@code{m4}

@tab

MIPS R4000

@tab

@code{MPS_ARCH_M4}

@item

@code{m6}

@tab

Motorola 68000

@tab

@code{MPS_ARCH_M6}

@item

@code{pp}

@tab

PowerPC

@tab

@code{MPS_ARCH_PP}

@item

@code{s8}

@tab

SPARC V8

@tab

@code{MPS_ARCH_S8}

@item

@code{s9}

@tab

SPARC V9 (32-bit)

@tab

@code{MPS_ARCH_S9}

@end multitable


Formerly supported compiler toolchains:


@multitable {xxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxx} 
@headitem

@code{CT}

@tab

Compiler toolchain

@tab

Constant

@item

@code{ac}

@tab

Macintosh Programmer’s Workshop C/C++

@tab

@code{MPS_BUILD_AC}

@item

@code{cc}

@tab

The “native” C compiler @footnote{
This was the MIPSpro C compiler on IRIX; and the Digital C
Compiler on OSF/1.
}

@tab

@code{MPS_BUILD_CC}

@item

@code{cx}

@tab

SunPro C CXREF tool

@tab

@code{MPS_BUILD_CX}

@item

@code{eg}

@tab

Experimental GNU Compiler System (EGCS)

@tab

@code{MPS_BUILD_EG}

@item

@code{gp}

@tab

GCC with profiling

@tab

@code{MPS_BUILD_GP}

@item

@code{lc}

@tab

LCC

@tab

@code{MPS_BUILD_LC}

@item

@code{m9}

@tab

Microsoft Visual C/C++ 9.0 @footnote{
Obsolete: the MPS used to make a distinction between
version 9.0 of Microsoft Visual C/C++ and older versions.
}

@tab

@code{MPS_BUILD_M9}

@item

@code{mw}

@tab

Metrowerks CodeWarrior

@tab

@code{MPS_BUILD_MW}

@item

@code{pc}

@tab

Pelles C

@tab

@code{MPS_BUILD_PC}

@item

@code{sc}

@tab

SunPro C

@tab

@code{MPS_BUILD_SC}

@end multitable


@cartouche
@quotation Note 
@end quotation
@end cartouche

@geindex platform; historical list

@node Historical platform list,Platform limitations,Historical platform codes,Platforms<2>
@anchor{topic/platform historical-platform-list}@anchor{301}
@subsection Historical platform list


This is the full list of platforms that have ever been supported by
the Memory Pool System, with their current status.


@multitable {xxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Platform

@tab

Status

@item

@code{fri3gc}

@tab

Supported

@item

@code{fri3ll}

@tab

Supported

@item

@code{fri4gc}

@tab

Corrected to @code{fri3gc}

@item

@code{fri6gc}

@tab

Supported

@item

@code{fri6ll}

@tab

Supported

@item

@code{i5m2cc}

@tab

`Not supported'

@item

@code{iam4cc}

@tab

`Not supported'

@item

@code{lia6gc}

@tab

Supported

@item

@code{lia6ll}

@tab

Supported

@item

@code{lii3eg}

@tab

`Not supported'

@item

@code{lii3gc}

@tab

Supported

@item

@code{lii4gc}

@tab

Corrected to @code{lii3gc}

@item

@code{lii6gc}

@tab

Supported

@item

@code{lii6ll}

@tab

Supported

@item

@code{lippgc}

@tab

`Not supported'

@item

@code{o1alcc}

@tab

`Not supported'

@item

@code{o1algc}

@tab

`Not supported'

@item

@code{s7m6mw}

@tab

`Not supported'

@item

@code{s7ppac}

@tab

`Not supported'

@item

@code{s7ppmw}

@tab

`Not supported'

@item

@code{sos8cx}

@tab

`Not supported'

@item

@code{sos8gc}

@tab

`Not supported'

@item

@code{sos8gp}

@tab

`Not supported'

@item

@code{sos9sc}

@tab

`Not supported'

@item

@code{sus8gc}

@tab

`Not supported'

@item

@code{w3almv}

@tab

`Not supported'

@item

@code{w3i3m9}

@tab

Corrected to @code{w3i3mv}

@item

@code{w3i3mv}

@tab

Supported

@item

@code{w3i3pc}

@tab

`Not supported'

@item

@code{w3i6mv}

@tab

Supported

@item

@code{w3i6pc}

@tab

`Not supported'

@item

@code{w3ppmv}

@tab

`Not supported'

@item

@code{xca6ll}

@tab

Supported

@item

@code{xci3gc}

@tab

`Not supported'

@item

@code{xci3ll}

@tab

`Not supported'

@item

@code{xci6gc}

@tab

`Not supported'

@item

@code{xci6ll}

@tab

Supported

@item

@code{xcppgc}

@tab

`Not supported'

@end multitable


@geindex platform; limitations
@geindex Hardened Runtime

@node Platform limitations,,Historical platform list,Platforms<2>
@anchor{topic/platform platform-limitations}@anchor{302}@anchor{topic/platform topic-platform-limitations}@anchor{303}
@subsection Platform limitations


This section documents limitations that affect individual platforms.

@code{xca6ll}

@quotation

On macOS on Apple Silicon, programs may enable Hardened Runtime@footnote{https://developer.apple.com/documentation/security/hardened_runtime}.
This feature rejects attempts to map or protect memory so that it
is simultaneously writable and executable. Therefore, when Hardened
Runtime is enabled, memory managed by the MPS is not executable.

If your program needs to write executable code into memory managed
by the MPS (for example, it uses just-in-time translation or
dynamic compilation), then you must either disable Hardened
Runtime, or configure the Allow Unsigned Executable Memory Entitlement@footnote{https://developer.apple.com/documentation/bundleresources/entitlements/com_apple_security_cs_allow-unsigned-executable-memory}.

Note that the MPS has no support for Apple’s @code{MAP_JIT}
flag. If your application is using the Allow Execution of JIT-compiled Code Entitlement@footnote{https://developer.apple.com/documentation/bundleresources/entitlements/com_apple_security_cs_allow-jit} and needs support for this flag,
please @ref{d8,,contact us}.
@end quotation

@node Porting the MPS,Deprecated interfaces,Platforms<2>,Reference
@anchor{topic/porting doc}@anchor{304}@anchor{topic/porting porting-the-mps}@anchor{305}@anchor{topic/porting topic-porting}@anchor{306}
@section Porting the MPS


This chapter lists the steps involved in porting the MPS to a new
operating system, processor architecture, or compiler. It assumes that
you are familiar with @ref{14,,Building the Memory Pool System} and the @ref{130,,Platforms}
chapter.

@menu
* Platform code:: 
* Functional modules:: 
* Platform detection:: 
* Platform configuration:: 
* Module selection:: 
* Makefile:: 
* Porting strategy:: 
* Update the documentation:: 
* Contribute:: 

@end menu

@node Platform code,Functional modules,,Porting the MPS
@anchor{topic/porting platform-code}@anchor{307}
@subsection Platform code


Pick two-character codes for the new platform’s operating system,
processor architecture, and compiler toolchain, as described under
@ref{130,,Platforms}, and concatenate them to get a six-character
platform code “@code{osarct}”.

@node Functional modules,Platform detection,Platform code,Porting the MPS
@anchor{topic/porting functional-modules}@anchor{308}
@subsection Functional modules


The MPS requires platform-specific implementations of the functional
modules in the list below. You’ll probably find that it’s unnecessary
to port them all: unless the new platform is very exotic, some of the
existing implementations ought to be usable. In most cases there is a
generic (“ANSI”) implementation of the module, that uses only the
features of the Standard C Library. These generic implementations are
partially functional or non-functional, but can be used as a starting
point for a new port if none of the existing implementations is
usable.


@enumerate 

@item 
The `clock' module provides fast high-resolution clocks for use
by the @ref{15b,,telemetry system}.

See @ref{309,,Fast high-resolution clock} for the design, and @code{clock.h} for the
interface. The interface consists only of type declarations and
macro definitions, so there is no implementation.

The header falls back to the clock functions from the
@ref{160,,plinth} if there is no platform-specific interface. See
@ref{12b,,mps_clock()} and @ref{2d1,,mps_clocks_per_sec()}.

@item 
The `lock' module provides binary locks that ensure that only a
single @ref{99,,thread} may be running with a lock held, and
recursive locks, where the same thread may safely take the lock
again without deadlocking.

See @ref{30a,,Lock module} for the design, and @code{lock.h} for the
interface. There are implementations for POSIX in @code{lockix.c}, and
Windows in @code{lockw3.c}.

There is a generic implementation in @code{lockan.c}, which cannot
actually take any locks and so only works for a single thread.

@item 
The `memory protection' module applies @ref{1fd,,protection} to
areas of @ref{194,,memory (2)}, ensuring that attempts to read or
write from those areas cause @ref{1d7,,protection faults}, and
implements the means for the MPS to catch and handle these faults.

See @ref{30b,,Memory protection} for the design, and @code{prot.h} for the
interface. There are implementations for POSIX in @code{protix.c} plus
@code{protsgix.c}, Windows in @code{protw3.c}, and macOS using Mach in
@code{protix.c} plus @code{protxc.c}.

There is a generic implementation in @code{protan.c}, which can’t
provide memory protection, so it forces memory to be scanned until
there is no further need to protect it. This means it can’t support
incremental collection, and has no control over pause times.

@item 
The `mutator context' module figures out what the @ref{30c,,mutator}
was doing when it caused a @ref{1d7,,protection fault}, so that access
to a protected region of memory can be handled, or when a thread
was suspended, so that its @ref{26,,registers} and @ref{27,,control stack} can be scanned.

See @ref{30d,,Mutator context} for the design, and @code{prmc.h} for the
interface. There are implementations on FreeBSD and Windows for
IA-32 and x86-64, and on Linux and macOS for IA-32, x86-64, and
ARM64.

There is a generic implementation in @code{prmcan.c}, which can’t
provide these features, and so only supports a single thread.

@item 
The `stack probe' module checks that there is enough space on the
@ref{27,,control stack} for the MPS to complete any operation that it
might start. The purpose is to provoke a stack overflow exception,
if necessary, before taking the arena lock.

See @ref{1d8,,Stack probe} for the design, and @code{sp.h} for the
interface. There are implementations on Windows on IA-32 in
@code{spi3w3.c} and x86-64 in @code{spi6w3.c}.

There is a generic implementation in @code{span.c}, which can’t
provide this feature, and so is only suitable for use with a client
program that does not handle stack overflow faults, or does not
call into the MPS from the handler.

@item 
The `stack and register scanning' module @ref{65,,scans} the
@ref{26,,registers} and @ref{27,,control stack} of the thread that
entered the MPS.

See @ref{30e,,Stack and register scanning} for the design, @code{ss.h} for the
interface, and @code{ss.c} for a generic implementation that makes
assumptions about the platform (in particular, that the stack grows
downwards and @code{setjmp()} reliably captures the registers; see
the design for details).

@item 
The `thread manager' module suspends and resumes @ref{99,,threads},
so that the MPS can gain exclusive access to @ref{194,,memory (2)},
and so that it can scan the @ref{26,,registers} and @ref{27,,control stack} of suspended threads.

See @ref{30f,,Thread manager} for the design, and @code{th.h} for
the interface. There are implementations for POSIX in @code{thix.c}
plus @code{pthrdext.c}, macOS using Mach in @code{thxc.c}, Windows in
@code{thw3.c}.

There is a generic implementation in @code{than.c}, which necessarily
only supports a single thread.

@item 
The `virtual mapping' module reserves @ref{54,,address space} from
the operating system (and returns it), and @ref{310,,maps}
address space to @ref{311,,main memory} (and unmaps it).

See @ref{312,,Virtual mapping} for the design, and @code{vm.h} for the
interface. There are implementations for POSIX in @code{vmix.c}, and
Windows in @code{vmw3.c}. There is a generic implementation in
@code{vman.c}, which fakes virtual memory by calling @code{malloc()}.
@end enumerate

@node Platform detection,Platform configuration,Functional modules,Porting the MPS
@anchor{topic/porting platform-detection}@anchor{313}
@subsection Platform detection


The new platform must be detected in @code{mpstd.h} and preprocessor
constants like @ref{187,,MPS_WORD_WIDTH} defined. See
@ref{314,,MPS Configuration} for the design of this header, and
@ref{2ec,,Platform interface} for the list of preprocessor constants
that may need to be defined. For example:

@example
/* "Predefined Macros" from "Visual Studio 2010" on MSDN
 * <http://msdn.microsoft.com/en-us/library/b0084kay(v=vs.100).aspx>.
 * Note that Win32 includes 64-bit Windows!
 * We use the same alignment as MS malloc: 16, which is used for XMM
 * operations.
 * See MSDN -> x64 Software Conventions -> Overview of x64 Calling Conventions
 * <https://docs.microsoft.com/en-gb/cpp/build/overview-of-x64-calling-conventions>
 */

#elif defined(_MSC_VER) && defined(_WIN32) && defined(_WIN64) && defined(_M_X64) && !defined(__POCC__)
#if defined(CONFIG_PF_STRING) && ! defined(CONFIG_PF_W3I6MV)
#error "specified CONFIG_PF_... inconsistent with detected w3i6mv"
#endif
#define MPS_PF_W3I6MV
#define MPS_PF_STRING   "w3i6mv"
#define MPS_OS_W3
#define MPS_ARCH_I6
#define MPS_BUILD_MV
#define MPS_T_WORD      unsigned __int64
#define MPS_T_ULONGEST  unsigned __int64
#define MPS_WORD_WIDTH  64
#define MPS_WORD_SHIFT  6
#define MPS_PF_ALIGN    16
@end example

The comment should justify the platform test (with reference to
documentation or to the output of a command like @code{gcc -E -dM}), and
explain any unusual definitions. For example, here we need to explain
the choice of 16 bytes for @ref{6f,,MPS_PF_ALIGN}, since normally a
64-bit platform requires 8-byte @ref{68,,alignment}.

@node Platform configuration,Module selection,Platform detection,Porting the MPS
@anchor{topic/porting platform-configuration}@anchor{315}
@subsection Platform configuration


The new platform may be configured, if necessary, in @code{config.h}. See
@ref{314,,MPS Configuration} for the design of this header. Avoid
platform-specific configuration if possible, to reduce the risk of
errors being introduced on one platform and not detected when other
platforms are tested.

@node Module selection,Makefile,Platform configuration,Porting the MPS
@anchor{topic/porting module-selection}@anchor{316}
@subsection Module selection


In @code{mps.c}, add a section for the new platform. This must test the
platform constant @code{MPS_PF_OSARCT} that is now defined in
@code{mpstd.h}, and then include all the module sources for the platform.
For example:

@example
/* Linux on x86-64 with GCC or Clang */

#elif defined(MPS_PF_LII6GC) || defined(MPS_PF_LII6LL)

#include "lockix.c"     /* Posix locks */
#include "thix.c"       /* Posix threading */
#include "pthrdext.c"   /* Posix thread extensions */
#include "vmix.c"       /* Posix virtual memory */
#include "protix.c"     /* Posix protection */
#include "protsgix.c"   /* Posix signal handling */
#include "prmci6.c"     /* x86-64 mutator context */
#include "prmcix.c"     /* Posix mutator context */
#include "prmclii6.c"   /* x86-64 for Linux mutator context */
#include "span.c"       /* generic stack probe */
@end example

@node Makefile,Porting strategy,Module selection,Porting the MPS
@anchor{topic/porting makefile}@anchor{317}
@subsection Makefile


Add a makefile even if you expect to use an integrated development
environment (IDE) like Visual Studio or Xcode. Makefiles make it
easier to carry out continuous integration and delivery, and are less
likely to stop working because of incompatibilities between IDE
versions.

On Unix platforms, the makefile must be named @code{osarct.gmk}, and must
define @code{PFM} to be the platform code, @code{MPMPF} to be the list of
platform modules (the same files included by @code{mps.c}), and @code{LIBS}
to be the linker options for any libraries required by the test cases.
Then it must include the compiler-specific makefile and @code{comm.gmk}.
For example, @code{lii6ll.gmk} looks like this:

@example
PFM = lii6ll

MPMPF = \
    lockix.c \
    prmci6.c \
    prmcix.c \
    prmclii6.c \
    protix.c \
    protsgix.c \
    pthrdext.c \
    span.c \
    thix.c \
    vmix.c

LIBS = -lm -lpthread

include ll.gmk
include comm.gmk
@end example

If the platform needs specific compilation options, then define
@code{PFMDEFS} accordingly, but avoid this if at all possible. We
recommend in @ref{14,,Building the Memory Pool System} that users compile the MPS using a
simple command like @code{cc -c mps.c}, and we suggest that they can
improve performance by compiling the MPS and their object format in
the same compilation unit. These steps would be more complicated if
the MPS required particular compilation options.

On Windows, the makefile must be named @code{osarct.nmk}, and must define
@code{PFM} to be the platform code, and @code{MPMPF} to be the list of
platform modules (the same files included by @code{mps.c}) in square
brackets. Then it must include @code{commpre.nmk}, the compiler-specific
makefile and @code{commpost.nmk}. For example, @code{w3i6mv.nmk} looks like
this:

@example
PFM = w3i6mv

MPMPF = \
    [lockw3] \
    [mpsiw3] \
    [prmci6] \
    [prmcw3] \
    [prmcw3i6] \
    [protw3] \
    [spw3i6] \
    [thw3] \
    [vmw3]

!INCLUDE commpre.nmk
!INCLUDE mv.nmk
!INCLUDE commpost.nmk
@end example

@node Porting strategy,Update the documentation,Makefile,Porting the MPS
@anchor{topic/porting porting-strategy}@anchor{318}
@subsection Porting strategy


Start the port by selecting existing implementations of the functional
modules, using the generic implementations where nothing else will do.
Then check that the “smoke tests” pass, by running:

@example
make -f osarct.gmk testrun    # Unix
nmake /f osarct.nmk testrun   # Windows
@end example

Most or all of the test cases should pass at this point. If you’re
using the generic threading implementation, then the multi-threaded
test cases are expected to fail. If you’re using the generic lock
implementation, then the lock utilization test case @code{lockut} is
expected to fail. If you’re using the generic memory protection
implementation, all the tests that rely on incremental collection are
expected to fail. See @code{tool/testcases.txt} for a database of test
cases and the configurations in which they are expected to pass.

Now that there is a working system to build on, porting the necessary
modules to the new platform can be done incrementally. It’s a good
idea to measure the performance as you go along (for example, using
the @code{gcbench} benchmark) to check that the new memory protection
module is effective.

@node Update the documentation,Contribute,Porting strategy,Porting the MPS
@anchor{topic/porting update-the-documentation}@anchor{319}
@subsection Update the documentation


These sections of the manual should be updated to mention the new
platform:


@itemize -

@item 
@ref{14,,Building the Memory Pool System}

@item 
@ref{130,,Platforms}
@end itemize

In addition, if aspects of the port were especially tricky, then
consider writing a design document (see @ref{31a,,Design}) justifying the
implementation.

@node Contribute,,Update the documentation,Porting the MPS
@anchor{topic/porting contribute}@anchor{31b}
@subsection Contribute


Consider contributing the new platform to the MPS. See
@ref{31c,,Contributing to the MPS}.

@geindex deprecated interfaces

@node Deprecated interfaces,Security issues,Porting the MPS,Reference
@anchor{topic/deprecated doc}@anchor{31d}@anchor{topic/deprecated deprecated-interfaces}@anchor{31e}@anchor{topic/deprecated topic-deprecated}@anchor{116}
@section Deprecated interfaces


This chapter documents the public symbols in the MPS interface that
are currently deprecated. These symbols may be removed in any future
release (see @ref{113,,Support policy} for details). If you are
using one of these symbols, then you should update your code to use
the supported interface.

@cartouche
@quotation Note 
If you are relying on a deprecated interface, and there is no
supported alternative, please @ref{d8,,contact us}. It
makes a difference if we know that someone is using a feature.
@end quotation
@end cartouche

@geindex deprecated interfaces; in version 1.118

@menu
* Deprecated in version 1.118: Deprecated in version 1 118. 
* Deprecated in version 1.115: Deprecated in version 1 115. 
* Deprecated in version 1.113: Deprecated in version 1 113. 
* Deprecated in version 1.112: Deprecated in version 1 112. 

@end menu

@node Deprecated in version 1 118,Deprecated in version 1 115,,Deprecated interfaces
@anchor{topic/deprecated deprecated-in-version-1-118}@anchor{31f}
@subsection Deprecated in version 1.118


@geindex MPS_KEY_SPARE_COMMIT_LIMIT (C macro)
@anchor{topic/deprecated c MPS_KEY_SPARE_COMMIT_LIMIT}@anchor{147}
@deffn {C Macro} MPS_KEY_SPARE_COMMIT_LIMIT

Use @code{MPS_KEY_SPARE} instead.

When supplied as a @ref{53,,keyword argument} to
@ref{52,,mps_arena_create_k()}, specifies the initial @ref{197,,spare commit limit} in @ref{17c,,bytes (1)} relative to the arena’s
@ref{156,,commit limit}. If the value is greater than the arena’s
commit limit then the spare commit limit is set to 1.0 exactly.
@end deffn

@geindex mps_arena_spare_commit_limit (C function)
@anchor{topic/deprecated c mps_arena_spare_commit_limit}@anchor{320}
@deffn {C Function} size_t mps_arena_spare_commit_limit (mps_arena_t arena)

Use @ref{189,,mps_arena_spare()} instead.

Return the current @ref{197,,spare commit limit} for an @ref{16,,arena}
in @ref{17c,,bytes (1)}, that is, the product of the @ref{190,,committed} memory and the spare fraction.
@end deffn

@geindex mps_arena_spare_commit_limit_set (C function)
@anchor{topic/deprecated c mps_arena_spare_commit_limit_set}@anchor{321}
@deffn {C Function} void mps_arena_spare_commit_limit_set (mps_arena_t arena, size_t limit)

Use @ref{198,,mps_arena_spare_set()} instead.

Change the @ref{197,,spare commit limit} for an @ref{16,,arena} in
terms of @ref{17c,,bytes (1)} relative to the current
@ref{190,,committed} memory. If the @code{limit} argument is
greater than the current committed memory then the spare commit
limit is set to 1.0 exactly.
@end deffn

@geindex mps_arena_formatted_objects_walk (C function)
@anchor{topic/deprecated c mps_arena_formatted_objects_walk}@anchor{322}
@deffn {C Function} void mps_arena_formatted_objects_walk (mps_arena_t arena, mps_formatted_objects_stepper_t f, void *p, size_t s)

Use @ref{1a6,,mps_pool_walk()} instead.

Visit all @ref{23,,formatted objects} in an
@ref{16,,arena}.

@code{arena} is the arena whose formatted objects you want to visit.

@code{f} is a formatted objects stepper function. It will be called for
each formatted object in the arena. See
@ref{323,,mps_formatted_objects_stepper_t}.

@code{p} and @code{s} are arguments that will be passed to @code{f} each time it
is called. This is intended to make it easy to pass, for example,
an array and its size as parameters.

Each @ref{10,,pool class} determines for which objects the stepper
function is called. Typically, all validly formatted objects are
visited. @ref{67,,Padding objects} may be visited at the pool
class’s discretion: the stepper function must handle this
case.

@cartouche
@quotation Warning 
The callback function must obey the restrictions documented
under @ref{323,,mps_formatted_objects_stepper_t}.

If a garbage collection is currently in progress (that is, if
the arena is in the @ref{19f,,clamped} or
@ref{192,,unclamped state}), then only objects that are known to
be currently valid are visited.

If you need to be certain that all objects are visited, or if
the callback function needs to follow references from the
object to automatically managed memory, you must ensure that
the arena is in the @ref{b8,,parked state} by calling
@ref{b9,,mps_arena_park()} before calling this function (and
release it by calling @ref{cf,,mps_arena_release()} afterwards,
if desired).

If your application has requirements for introspection that
can’t be met under these restrictions, @ref{d8,,contact us}.
@end quotation
@end cartouche
@end deffn

@geindex mps_formatted_objects_stepper_t (C type)
@anchor{topic/deprecated c mps_formatted_objects_stepper_t}@anchor{323}
@deffn {C Type} typedef void (*mps_formatted_objects_stepper_t)(@ref{11d,,mps_addr_t} addr, @ref{141,,mps_fmt_t} fmt, @ref{1b1,,mps_pool_t} pool, void *p, size_t s)

Use @ref{1a6,,mps_pool_walk()} instead.

The type of a @ref{23,,formatted objects}
@ref{21d,,stepper function}.

A function of this type can be passed to
@ref{322,,mps_arena_formatted_objects_walk()}, in which case it will
be called for each formatted object in an @ref{16,,arena}. It
receives five arguments:

@code{addr} is the address of the object.

@code{fmt} is the @ref{39,,object format} for that object.

@code{pool} is the @ref{18,,pool} to which the object belongs.

@code{p} and @code{s} are the corresponding values that were passed to
@ref{322,,mps_arena_formatted_objects_walk()}.

The function may not call any function in the MPS. It may access:


@enumerate a

@item 
memory inside the object or block pointed to by @code{addr};

@item 
memory managed by the MPS that is in pools that do not protect
their contents;

@item 
memory not managed by the MPS.
@end enumerate

It must not:


@enumerate 4

@item 
access other memory managed by the MPS;

@item 
modify any of the references in the object.
@end enumerate
@end deffn

@geindex mps_amc_apply (C function)
@anchor{topic/deprecated c mps_amc_apply}@anchor{324}
@deffn {C Function} void mps_amc_apply (mps_pool_t pool, mps_amc_apply_stepper_t f, void *p, size_t s)

Use @ref{1a6,,mps_pool_walk()} instead.

Visit all @ref{23,,formatted objects} in an AMC pool.

@code{pool} is the pool whose formatted objects you want to visit.

@code{f} is a function that will be called for each formatted object in
the pool.

@code{p} and @code{s} are arguments that will be passed to @code{f} each time it
is called. This is intended to make it easy to pass, for example,
an array and its size as parameters.

It is an error to call this function when the @ref{16,,arena} is not
in the @ref{b8,,parked state}. You need to call
@ref{ce,,mps_arena_collect()} or @ref{b9,,mps_arena_park()} before
calling @ref{324,,mps_amc_apply()}.

The function @code{f} will be called on both @ref{325,,client} and @ref{67,,padding objects}. It is the job of @code{f} to
distinguish, if necessary, between the two. It may also be called
on @ref{49,,dead} objects that the collector has not recycled or has
been unable to recycle.

@cartouche
@quotation Note 
There is no equivalent function for other pool classes, but
there is a more general function
@ref{322,,mps_arena_formatted_objects_walk()} that visits all
formatted objects in the arena.
@end quotation
@end cartouche

@cartouche
@quotation Note 
This function is intended for heap analysis, tuning, and
debugging, not for frequent use in production.
@end quotation
@end cartouche
@end deffn

@geindex mps_amc_apply_stepper_t (C type)
@anchor{topic/deprecated c mps_amc_apply_stepper_t}@anchor{326}
@deffn {C Type} typedef void (*mps_amc_apply_stepper_t)(@ref{11d,,mps_addr_t} addr, void *p, size_t s)

Use @ref{1a6,,mps_pool_walk()} instead.

The type of a @ref{21d,,stepper function} for @ref{23,,formatted objects} in an AMC pool.

@code{addr} is the address of an object in the pool.

@code{p} and @code{s} are the corresponding arguments that were passed
to @ref{324,,mps_amc_apply()}.

The function may not call any function in the MPS. It may access:


@enumerate a

@item 
memory inside the object or block pointed to by @code{addr};

@item 
memory managed by the MPS that is in pools that do not protect
their contents;

@item 
memory not managed by the MPS;
@end enumerate

It must not:


@enumerate 4

@item 
access other memory managed by the MPS;

@item 
modify any of the references in the object.
@end enumerate
@end deffn

@geindex deprecated interfaces; in version 1.115

@node Deprecated in version 1 115,Deprecated in version 1 113,Deprecated in version 1 118,Deprecated interfaces
@anchor{topic/deprecated deprecated-in-version-1-115}@anchor{327}
@subsection Deprecated in version 1.115


@geindex mps_class_t (C type)
@anchor{topic/deprecated c mps_class_t}@anchor{328}
@deffn {C Type} typedef @ref{1b4,,mps_pool_class_t} mps_class_t

The former name for @ref{1b4,,mps_pool_class_t}, chosen when
pools were the only objects in the MPS that belonged to
classes.
@end deffn

@geindex mps_mvff_free_size (C function)
@anchor{topic/deprecated c mps_mvff_free_size}@anchor{329}
@deffn {C Function} size_t mps_mvff_free_size (mps_pool_t pool)

Use the generic function @ref{1b7,,mps_pool_free_size()} instead.

Return the total amount of free space in an MVFF pool.

@code{pool} is the MVFF pool.

Returns the total free space in the pool, in @ref{17c,,bytes (1)}.
@end deffn

@geindex mps_mvff_size (C function)
@anchor{topic/deprecated c mps_mvff_size}@anchor{32a}
@deffn {C Function} size_t mps_mvff_size (mps_pool_t pool)

Use the generic function @ref{1b6,,mps_pool_total_size()}
instead.

Return the total size of an MVFF pool.

@code{pool} is the MVFF pool.

Returns the total size of the pool, in @ref{17c,,bytes (1)}. This
is the sum of allocated space and free space.
@end deffn

@geindex mps_mvt_free_size (C function)
@anchor{topic/deprecated c mps_mvt_free_size}@anchor{32b}
@deffn {C Function} size_t mps_mvt_free_size (mps_pool_t pool)

Use the generic function @ref{1b7,,mps_pool_free_size()} instead.

Return the total amount of free space in an MVT pool.

@code{pool} is the MVT pool.

Returns the total free space in the pool, in @ref{17c,,bytes (1)}.
@end deffn

@geindex mps_mvt_size (C function)
@anchor{topic/deprecated c mps_mvt_size}@anchor{32c}
@deffn {C Function} size_t mps_mvt_size (mps_pool_t pool)

Use the generic function @ref{1b6,,mps_pool_total_size()}
instead.

Return the total size of an MVT pool.

@code{pool} is the MVT pool.

Returns the total size of the pool, in @ref{17c,,bytes (1)}. This
is the sum of allocated space and free space.
@end deffn

@geindex mps_root_create_reg (C function)
@anchor{topic/deprecated c mps_root_create_reg}@anchor{32d}
@deffn {C Function} @ref{14d,,mps_res_t} mps_root_create_reg (mps_root_t *root_o, mps_arena_t arena, mps_rank_t rank, mps_rm_t rm, mps_thr_t thr, mps_reg_scan_t reg_scan, void *p, size_t s)

Use @ref{a9,,mps_root_create_thread()} instead.

Register a @ref{97,,root} that consists of the @ref{24,,references}
fixed in a @ref{99,,thread’s} registers and stack by a
scanning function.

@code{root_o} points to a location that will hold the address of the
new root description.

@code{arena} is the arena.

@code{rank} is the @ref{9e,,rank} of references in the root.

@code{rm} is the @ref{a0,,root mode}.

@code{thr} is the thread.

@code{reg_scan} is a scanning function. See @ref{32e,,mps_reg_scan_t}.

@code{p} and @code{s} are arguments that will be passed to @code{reg_scan} each
time it is called. This is intended to make it easy to pass, for
example, an array and its size as parameters.

Returns @ref{5a,,MPS_RES_OK} if the root was registered
successfully, @ref{152,,MPS_RES_MEMORY} if the new root
description could not be allocated, or another @ref{59,,result code}
if there was another error.

The registered root description persists until it is destroyed by
calling @ref{a2,,mps_root_destroy()}.

@cartouche
@quotation Note 
It is not supported for @ref{d0,,client programs} to pass their
own scanning functions to this function. The built-in MPS
function @ref{32f,,mps_stack_scan_ambig()} must be used. In this
case the @code{p} argument must be a pointer to the @ref{aa,,cold end} of the thread’s stack (or the part of the stack
containing references to memory managed by the MPS). The @code{s}
argument is ignored.
@end quotation
@end cartouche
@end deffn

@geindex mps_root_create_table (C function)
@anchor{topic/deprecated c mps_root_create_table}@anchor{a3}
@deffn {C Function} @ref{14d,,mps_res_t} mps_root_create_table (mps_root_t *root_o, mps_arena_t arena, mps_rank_t rank, mps_rm_t rm, mps_addr_t *base, size_t count)

This function is equivalent to:

@example
mps_root_create_area(root_o, arena, rank, mode,
                     base, base + count,
                     mps_scan_area, NULL, 0)
@end example

Register a @ref{97,,root} that consists of a vector of
@ref{24,,references}.

@code{root_o} points to a location that will hold the address of the
new root description.

@code{arena} is the arena.

@code{rank} is the @ref{9e,,rank} of references in the root.

@code{rm} is the @ref{a0,,root mode}.

@code{base} points to a vector of references.

@code{count} is the number of references in the vector.

Returns @ref{5a,,MPS_RES_OK} if the root was registered
successfully, @ref{152,,MPS_RES_MEMORY} if the new root
description could not be allocated, or another @ref{59,,result code}
if there was another error.

The registered root description persists until it is destroyed by
calling @ref{a2,,mps_root_destroy()}.
@anchor{topic/deprecated topic-root-type-pun}@anchor{a6}
@cartouche
@quotation Warning 
The @code{base} argument has type @code{mps_addr_t *} (a typedef for
@code{void **}) but the table of references most likely has some
other pointer type, @code{my_object *} say. It is tempting to
write:

@example
mps_root_create_table(..., (mps_addr_t *)my_table, ...)
@end example

but this is @ref{a5,,type punning}, and its behaviour is not
defined in ANSI/ISO Standard C. (GCC and Clang have a warning
flag @code{-Wstrict-aliasing} which detects some errors of this
form.)

To ensure well-defined behaviour, the pointer must be
converted via @code{void *} (or via @ref{11d,,mps_addr_t}, which
is a typedef for @code{void *}), like this:

@example
mps_addr_t base = my_table;
mps_root_create_table(..., base, ...)
@end example
@end quotation
@end cartouche
@end deffn

@geindex mps_root_create_table_tagged (C function)
@anchor{topic/deprecated c mps_root_create_table_tagged}@anchor{330}
@deffn {C Function} @ref{14d,,mps_res_t} mps_root_create_table_tagged (mps_root_t *root_o, mps_arena_t arena, mps_rank_t rank, mps_rm_t rm, mps_addr_t *base, size_t count, mps_area_scan_t scan_area, mps_word_t mask, mps_word_t pattern)

This function is equivalent to:

@example
mps_root_create_area_tagged(root_o, arena, rank, mode,
                            base, base + size,
                            scan_area, mask, pattern)
@end example

Register a @ref{97,,root} that consists of a vector of @ref{7d,,tagged references}.

@code{root_o} points to a location that will hold the address of the
new root description.

@code{arena} is the arena.

@code{rank} is the @ref{9e,,rank} of references in the root.

@code{rm} is the @ref{a0,,root mode}.

@code{base} points to a vector of tagged references.

@code{count} is the number of tagged references in the vector.

@code{scan_area} is an tagged area scanning function that will be
used to scan the table, for example @ref{1f3,,mps_scan_area_tagged()}
or @ref{1f4,,mps_scan_area_tagged_or_zero()}.  See
@ref{1b8,,Area scanners}.

@code{mask} is a @ref{218,,bitmask} that is passed to @code{scan_area} to
be applied to the words in the vector to locate the @ref{88,,tag}.

@code{pattern} is passed to @code{scan_area} to determine whether to
consider a word as a reference.  For example,
@ref{1f3,,mps_scan_area_tagged()} will not consider any word that is
unequal to this (after masking with @code{mask}) to be a reference.

Returns @ref{5a,,MPS_RES_OK} if the root was registered
successfully, @ref{152,,MPS_RES_MEMORY} if the new root
description could not be allocated, or another @ref{59,,result code}
if there was another error.

The registered root description persists until it is destroyed by
calling @ref{a2,,mps_root_destroy()}.

@cartouche
@quotation Warning 
See the warning for @ref{a3,,mps_root_create_table()} above.
@end quotation
@end cartouche
@end deffn

@geindex mps_root_create_table_masked (C function)
@anchor{topic/deprecated c mps_root_create_table_masked}@anchor{331}
@deffn {C Function} @ref{14d,,mps_res_t} mps_root_create_table_masked (mps_root_t *root_o, mps_arena_t arena, mps_rank_t rank, mps_rm_t rm, mps_addr_t *base, size_t count, mps_word_t mask)

Use @ref{21a,,mps_root_create_area_tagged()} instead, passing
zero for the @code{pattern} argument. This function is equivalent
to:

@example
mps_root_create_area_tagged(root_o, arena, rank, rm,
                            base, base + size,
                            mps_scan_area_tagged,
                            mask, 0)
@end example

Register a @ref{97,,root} that consists of a vector of @ref{7d,,tagged references} whose pattern is zero.
@end deffn

@geindex mps_reg_scan_t (C type)
@anchor{topic/deprecated c mps_reg_scan_t}@anchor{32e}
@deffn {C Type} typedef @ref{14d,,mps_res_t} (*mps_reg_scan_t)(@ref{1dc,,mps_ss_t} ss, @ref{201,,mps_thr_t} thr, void *p, size_t s)

Use @ref{a9,,mps_root_create_thread()} instead.

The type of a root scanning function for roots created with
@ref{32d,,mps_root_create_reg()}.

@code{ss} is the @ref{79,,scan state}. It must be passed to
@ref{7a,,MPS_SCAN_BEGIN} and @ref{7b,,MPS_SCAN_END} to delimit a
sequence of fix operations, and to the functions
@ref{75,,MPS_FIX1()} and @ref{76,,MPS_FIX2()} when fixing a
@ref{24,,reference}.

@code{thr} is the @ref{99,,thread}.

@code{p} and @code{s} are the corresponding values that were passed to
@ref{32d,,mps_root_create_reg()}.

Returns a @ref{59,,result code}. If a fix function returns a value
other than @ref{5a,,MPS_RES_OK}, the scan method must return that
value, and may return without fixing any further references.
Generally, it is better if it returns as soon as possible. If the
scanning is completed successfully, the function should return
@ref{5a,,MPS_RES_OK}.

A root scan method is called whenever the MPS needs to scan the
root. It must then indicate references within the root by calling
@ref{75,,MPS_FIX1()} and @ref{76,,MPS_FIX2()}.


@subsubheading See also


@ref{25,,Scanning}.

@end deffn

@geindex mps_stack_scan_ambig (C var)
@anchor{topic/deprecated c mps_stack_scan_ambig}@anchor{32f}
@deffn {C Variable} @ref{32e,,mps_reg_scan_t} mps_stack_scan_ambig

Use @ref{1ec,,mps_root_create_thread_tagged()} instead, passing
@code{sizeof(mps_word_t) - 1} for the @code{mask} argument, and
@code{0} for the @code{pattern} argument.

A root scanning function for @ref{9f,,ambiguous} scanning of @ref{99,,threads}, suitable for
passing to @ref{32d,,mps_root_create_reg()}.

It scans all integer registers and everything on the stack of the
thread given, and can therefore only be used with @ref{1c4,,ambiguous roots}. It scans locations that are more recently added to the
stack than the location that was passed in the @code{p} argument to
@ref{32d,,mps_root_create_reg()}.

References are assumed to be represented as machine words, and are
required to be word-aligned; unaligned values are ignored.
@end deffn

@geindex deprecated interfaces; in version 1.113

@node Deprecated in version 1 113,Deprecated in version 1 112,Deprecated in version 1 115,Deprecated interfaces
@anchor{topic/deprecated deprecated-in-version-1-113}@anchor{332}
@subsection Deprecated in version 1.113


@geindex MPS_ARGS_DONE (C macro)
@anchor{topic/deprecated c MPS_ARGS_DONE}@anchor{333}
@deffn {C Macro} MPS_ARGS_DONE (args)

Formerly this was used to finalize a list of @ref{53,,keyword arguments} before passing it to a function. It is no longer
needed.
@end deffn

@geindex deprecated interfaces; in version 1.112

@node Deprecated in version 1 112,,Deprecated in version 1 113,Deprecated interfaces
@anchor{topic/deprecated deprecated-in-version-1-112}@anchor{334}
@subsection Deprecated in version 1.112


@geindex mps_arena_create (C function)
@anchor{topic/deprecated c mps_arena_create}@anchor{335}
@deffn {C Function} @ref{14d,,mps_res_t} mps_arena_create (mps_arena_t *arena_o, mps_arena_class_t arena_class, ...)

Use @ref{52,,mps_arena_create_k()} instead.

An alternative to @ref{52,,mps_arena_create_k()} that takes its
extra arguments using the standard @ref{1c,,C} variable argument
list mechanism.

When creating an arena of class @ref{4e,,mps_arena_class_cl()}, pass
the values for the keyword arguments @code{MPS_KEY_ARENA_SIZE}
and @code{MPS_KEY_ARENA_CL_BASE} like this:

@example
mps_res_t mps_arena_create(mps_arena_t *arena_o,
                           mps_arena_class_t mps_arena_class_cl(),
                           size_t arena_size,
                           mps_addr_t cl_base)
@end example

When creating an arena of class @ref{50,,mps_arena_class_vm()}, pass
the value for the keyword argument @code{MPS_KEY_ARENA_SIZE}
like this:

@example
mps_res_t mps_arena_create(mps_arena_t *arena_o,
                           mps_arena_class_t mps_arena_class_vm(),
                           size_t arena_size)
@end example
@end deffn

@geindex mps_arena_create_v (C function)
@anchor{topic/deprecated c mps_arena_create_v}@anchor{336}
@deffn {C Function} @ref{14d,,mps_res_t} mps_arena_create_v (mps_arena_t *arena_o, mps_arena_class_t arena_class, va_list args)

Use @ref{52,,mps_arena_create_k()} instead.

An alternative to @ref{52,,mps_arena_create_k()} that takes its
extra arguments using the standard @ref{1c,,C} @code{va_list}
mechanism. See @ref{335,,mps_arena_create()} for details of which
arguments to pass for the different arena classes.
@end deffn

@geindex mps_pool_create (C function)
@anchor{topic/deprecated c mps_pool_create}@anchor{337}
@deffn {C Function} @ref{14d,,mps_res_t} mps_pool_create (mps_pool_t *pool_o, mps_arena_t arena, mps_pool_class_t pool_class, ...)

Use @ref{166,,mps_pool_create_k()} instead.

An alternative to @ref{166,,mps_pool_create_k()} that takes its
extra arguments using the standard @ref{1c,,C} variable argument
list mechanism.

When creating a pool of class @ref{13b,,mps_class_amc()} or
@ref{13c,,mps_class_amcz()}, pass the values for the keyword
arguments @code{MPS_KEY_FORMAT} and @code{MPS_KEY_CHAIN}
like this:

@example
mps_res_t mps_pool_create(mps_pool_t *pool_o, mps_arena_t arena,
                          mps_pool_class_t mps_class_amc(),
                          mps_fmt_t format,
                          mps_chain_t chain)
@end example

When creating a pool of class @ref{138,,mps_class_ams()}, pass the
values for the keyword arguments @code{MPS_KEY_FORMAT},
@code{MPS_KEY_CHAIN} and ambiguous flag
@code{MPS_KEY_AMS_SUPPORT_AMBIGUOUS} like this:

@example
mps_res_t mps_pool_create(mps_pool_t *pool_o, mps_arena_t arena,
                          mps_pool_class_t mps_class_ams(),
                          mps_fmt_t format,
                          mps_chain_t chain,
                          mps_bool_t ams_support_ambiguous)
@end example

When creating a pool of class @ref{144,,mps_class_ams_debug()}, pass
the values for the keyword arguments
@code{MPS_KEY_POOL_DEBUG_OPTIONS}, @code{MPS_KEY_FORMAT},
@code{MPS_KEY_CHAIN} and
@code{MPS_KEY_AMS_SUPPORT_AMBIGUOUS} like this:

@example
mps_res_t mps_pool_create(mps_pool_t *pool_o, mps_arena_t arena,
                          mps_pool_class_t mps_class_ams_debug(),
                          mps_pool_debug_option_s *pool_debug_options,
                          mps_fmt_t format,
                          mps_chain_t chain,
                          mps_bool_t ams_support_ambiguous)
@end example

When creating a pool of class @ref{139,,mps_class_awl()}, pass the
values for the keyword arguments @code{MPS_KEY_FORMAT} and
@code{MPS_KEY_AWL_FIND_DEPENDENT} like this:

@example
mps_res_t mps_pool_create(mps_pool_t *pool_o, mps_arena_t arena,
                          mps_pool_class_t mps_class_awl(),
                          mps_fmt_t format,
                          mps_awl_find_dependent_t awl_find_dependent)
@end example

When creating a pool of class @ref{13d,,mps_class_lo()}, pass the
value for the keyword argument @code{MPS_KEY_FORMAT} like
this:

@example
mps_res_t mps_pool_create(mps_pool_t *pool_o, mps_arena_t arena,
                          mps_pool_class_t mps_class_lo(),
                          mps_fmt_t format)
@end example

When creating a pool of class @ref{13e,,mps_class_mfs()}, pass the
values for the keyword arguments @code{MPS_KEY_EXTEND_BY} and
@code{MPS_KEY_MFS_UNIT_SIZE} like this:

@example
mps_res_t mps_pool_create(mps_pool_t *pool_o, mps_arena_t arena,
                          mps_pool_class_t mps_class_mfs(),
                          size_t extend_by,
                          size_t unit_size)
@end example

When creating a pool of class @ref{136,,mps_class_mvff()}, pass the
values for the keyword arguments @code{MPS_KEY_EXTEND_BY},
@code{MPS_KEY_MEAN_SIZE}, @code{MPS_KEY_ALIGN},
@code{MPS_KEY_MVFF_SLOT_HIGH},
@code{MPS_KEY_MVFF_ARENA_HIGH} and
@code{MPS_KEY_MVFF_FIRST_FIT} like this:

@example
mps_res_t mps_pool_create(mps_pool_t *pool_o, mps_arena_t arena,
                          mps_pool_class_t mps_class_mvff(),
                          size_t extend_by,
                          size_t mean_size,
                          mps_align_t align,
                          mps_bool_t mvff_slot_high,
                          mps_bool_t mvff_arena_high,
                          mps_bool_t mvff_first_fit)
@end example

When creating a pool of class @ref{145,,mps_class_mvff_debug()}, pass
the values for the keyword arguments
@code{MPS_KEY_POOL_DEBUG_OPTIONS},
@code{MPS_KEY_EXTEND_BY}, @code{MPS_KEY_MEAN_SIZE},
@code{MPS_KEY_ALIGN}, @code{MPS_KEY_MVFF_SLOT_HIGH},
@code{MPS_KEY_MVFF_ARENA_HIGH}, and
@code{MPS_KEY_MVFF_FIRST_FIT} like this:

@example
mps_res_t mps_pool_create(mps_pool_t *pool_o, mps_arena_t arena,
                          mps_pool_class_t mps_class_mvff_debug(),
                          mps_pool_debug_option_s *pool_debug_options,
                          size_t extend_by,
                          size_t mean_size,
                          mps_align_t align,
                          mps_bool_t mvff_slot_high,
                          mps_bool_t mvff_arena_high,
                          mps_bool_t mvff_first_fit)
@end example

When creating a pool of class @ref{137,,mps_class_mvt()}, pass the
values for the keyword arguments @code{MPS_KEY_MIN_SIZE},
@code{MPS_KEY_MEAN_SIZE}, @code{MPS_KEY_MAX_SIZE},
@code{MPS_KEY_MVT_RESERVE_DEPTH} and
@code{MPS_KEY_MVT_FRAG_LIMIT} like this:

@example
mps_res_t mps_pool_create(mps_pool_t *pool_o, mps_arena_t arena,
                          mps_pool_class_t mps_class_mvt(),
                          size_t min_size,
                          size_t mean_size,
                          size_t max_size,
                          mps_word_t mvt_reserve_depth,
                          mps_word_t mvt_frag_limit)
@end example

@cartouche
@quotation Note 
The @code{mvt_frag_limit} is a percentage from 0 to 100
inclusive when passed to @ref{337,,mps_pool_create()}, not a
double from 0.0 to 1.0 as in @ref{166,,mps_pool_create_k()}.
@end quotation
@end cartouche

When creating a pool of class @ref{142,,mps_class_snc()}, pass the
value for the keyword argument @code{MPS_KEY_FORMAT} like
this:

@example
mps_res_t mps_pool_create(mps_pool_t *pool_o, mps_arena_t arena,
                          mps_pool_class_t mps_class_snc(),
                          mps_fmt_t format)
@end example
@end deffn

@geindex mps_pool_create_v (C function)
@anchor{topic/deprecated c mps_pool_create_v}@anchor{338}
@deffn {C Function} @ref{14d,,mps_res_t} mps_pool_create_v (mps_pool_t *pool_o, mps_arena_t arena, mps_pool_class_t pool_class, va_list args)

Use @ref{166,,mps_pool_create_k()} instead.

An alternative to @ref{166,,mps_pool_create_k()} that takes its extra
arguments using the standard @ref{1c,,C} @code{va_list} mechanism. See
@ref{337,,mps_pool_create()} for details of which arguments to pass
for the different pool classes.
@end deffn

@geindex mps_ap_create (C function)
@anchor{topic/deprecated c mps_ap_create}@anchor{339}
@deffn {C Function} @ref{14d,,mps_res_t} mps_ap_create (mps_ap_t *ap_o, mps_pool_t pool, ...)

Use @ref{af,,mps_ap_create_k()} instead.

An alternative to @ref{af,,mps_ap_create_k()} that takes its extra
arguments using the standard @ref{1c,,C} variable argument list
mechanism.

When creating an allocation point on a pool of class
@ref{138,,mps_class_ams()}, @ref{144,,mps_class_ams_debug()},
@ref{139,,mps_class_awl()} or @ref{142,,mps_class_snc()}, pass the
keyword argument @code{MPS_KEY_RANK} like this:

@example
mps_res_t mps_ap_create(mps_ap_t *ap_o, mps_pool_t pool,
                        mps_rank_t rank)
@end example
@end deffn

@geindex mps_ap_create_v (C function)
@anchor{topic/deprecated c mps_ap_create_v}@anchor{33a}
@deffn {C Function} @ref{14d,,mps_res_t} mps_ap_create_v (mps_ap_t *ap_o, mps_pool_t pool, va_list args)

Use @ref{af,,mps_ap_create_k()} instead.

An alternative to @ref{af,,mps_ap_create_k()} that takes its extra
arguments using the standard @ref{1c,,C} @code{va_list} mechanism. See
@ref{339,,mps_ap_create()} for details of which arguments to pass
for the different pool classes.
@end deffn

@geindex mps_fmt_A_s (C type)
@anchor{topic/deprecated c mps_fmt_A_s}@anchor{33b}
@deffn {C Type} type mps_fmt_A_s

Use @ref{13f,,mps_fmt_create_k()} instead.

The type of the structure used to create an @ref{39,,object format}
of variant A.

@example
typedef struct mps_fmt_A_s @{
    mps_align_t     align;
    mps_fmt_scan_t  scan;
    mps_fmt_skip_t  skip;
    mps_fmt_copy_t  copy;
    mps_fmt_fwd_t   fwd;
    mps_fmt_isfwd_t isfwd;
    mps_fmt_pad_t   pad;
@} mps_fmt_A_s;
@end example

The fields of this structure correspond to the keyword arguments
to @ref{13f,,mps_fmt_create_k()}, except for @code{copy}, which is not
used. In older versions of the MPS this was a `copy method'
that copied objects belonging to this format.
@end deffn

@geindex mps_fmt_create_A (C function)
@anchor{topic/deprecated c mps_fmt_create_A}@anchor{33c}
@deffn {C Function} @ref{14d,,mps_res_t} mps_fmt_create_A (mps_fmt_t *fmt_o, mps_arena_t arena, mps_fmt_A_s *fmt_A)

Use @ref{13f,,mps_fmt_create_k()} instead.

Create an @ref{39,,object format} based on a description of an
object format of variant A.
@end deffn

@geindex mps_fmt_B_s (C type)
@anchor{topic/deprecated c mps_fmt_B_s}@anchor{33d}
@deffn {C Type} type mps_fmt_B_s

Use @ref{13f,,mps_fmt_create_k()} instead.

The type of the structure used to create an @ref{39,,object format}
of variant B.

@example
typedef struct mps_fmt_B_s @{
    mps_align_t     align;
    mps_fmt_scan_t  scan;
    mps_fmt_skip_t  skip;
    mps_fmt_copy_t  copy;
    mps_fmt_fwd_t   fwd;
    mps_fmt_isfwd_t isfwd;
    mps_fmt_pad_t   pad;
    mps_fmt_class_t mps_class;
@} mps_fmt_B_s;
@end example

Variant B is the same as variant A except for the addition of the
@code{mps_class} method. See @ref{33b,,mps_fmt_A_s}.
@end deffn

@geindex mps_fmt_create_B (C function)
@anchor{topic/deprecated c mps_fmt_create_B}@anchor{33e}
@deffn {C Function} @ref{14d,,mps_res_t} mps_fmt_create_B (mps_fmt_t *fmt_o, mps_arena_t arena, mps_fmt_B_s *fmt_B)

Use @ref{13f,,mps_fmt_create_k()} instead.

Create an @ref{39,,object format} based on a description of an
object format of variant B.
@end deffn

@geindex mps_fmt_auto_header_s (C type)
@anchor{topic/deprecated c mps_fmt_auto_header_s}@anchor{33f}
@deffn {C Type} type mps_fmt_auto_header_s

Use @ref{13f,,mps_fmt_create_k()} instead.

The type of the structure used to create an @ref{39,,object format}
of variant auto-header.

@example
typedef struct mps_fmt_auto_header_s @{
    mps_align_t     align;
    mps_fmt_scan_t  scan;
    mps_fmt_skip_t  skip;
    mps_fmt_fwd_t   fwd;
    mps_fmt_isfwd_t isfwd;
    mps_fmt_pad_t   pad;
    size_t          mps_headerSize;
@} mps_fmt_auto_header_s;
@end example

Variant auto-header is the same as variant A except for the
removal of the unused @code{copy} method, and the addition of the
@code{mps_headerSize} field. See @ref{33b,,mps_fmt_A_s}.
@end deffn

@geindex mps_fmt_create_auto_header (C function)
@anchor{topic/deprecated c mps_fmt_create_auto_header}@anchor{340}
@deffn {C Function} @ref{14d,,mps_res_t} mps_fmt_create_auto_header (mps_fmt_t *fmt_o, mps_arena_t arena, mps_fmt_auto_header_s *fmt_ah)

Use @ref{13f,,mps_fmt_create_k()} instead.

Create an @ref{39,,object format} based on a description of an
object format of variant auto-header.
@end deffn

@geindex mps_fmt_fixed_s (C type)
@anchor{topic/deprecated c mps_fmt_fixed_s}@anchor{341}
@deffn {C Type} type mps_fmt_fixed_s

Use @ref{13f,,mps_fmt_create_k()} instead.

The type of the structure used to create an @ref{39,,object format}
of variant fixed.

@example
typedef struct mps_fmt_fixed_s @{
    mps_align_t     align;
    mps_fmt_scan_t  scan;
    mps_fmt_fwd_t   fwd;
    mps_fmt_isfwd_t isfwd;
    mps_fmt_pad_t   pad;
@} mps_fmt_fixed_s;
@end example

Variant fixed is the same as variant A except for the removal of
the unused @code{copy} method, and the lack of a @code{skip} method
(this is not needed because the objects are fixed in size). See
@ref{33b,,mps_fmt_A_s}.
@end deffn

@geindex mps_fmt_create_fixed (C function)
@anchor{topic/deprecated c mps_fmt_create_fixed}@anchor{342}
@deffn {C Function} @ref{14d,,mps_res_t} mps_fmt_create_fixed (mps_fmt_t *fmt_o, mps_arena_t arena, mps_fmt_fixed_s *fmt_fixed)

Use @ref{13f,,mps_fmt_create_k()} instead.

Create an @ref{39,,object format} based on a description of an
object format of variant fixed.
@end deffn

@geindex security issues

@node Security issues,,Deprecated interfaces,Reference
@anchor{topic/security doc}@anchor{343}@anchor{topic/security security-issues}@anchor{344}@anchor{topic/security topic-security}@anchor{345}
@section Security issues


This chapter describes security issues that may be present when using
the MPS.

@geindex security issues; predictable address space layout on FreeBSD
@geindex address space; predictable layout on FreeBSD

@menu
* Predictable address space layout on FreeBSD:: 
* Address disclosure:: 
* Telemetry: Telemetry<2>. 

@end menu

@node Predictable address space layout on FreeBSD,Address disclosure,,Security issues
@anchor{topic/security predictable-address-space-layout-on-freebsd}@anchor{346}
@subsection Predictable address space layout on FreeBSD


The MPS acquires @ref{54,,address space} using the operating system’s
@ref{51,,virtual memory} interface (specifically, @code{mmap()} on
FreeBSD). As of version 10, FreeBSD does not randomize the allocated
regions of address space, which means that the @ref{126,,addresses} of
@ref{185,,blocks} allocated by the MPS are predictable: a @ref{d0,,client program} that makes an identical series of calls to the MPS gets an
identical series of addresses back.

This means that if a program using the MPS has a buffer overflow, the
overflow is more easily exploitable by an attacker than if the program
had used @code{malloc()} (which has some randomization of the
allocated addresses), because it is easier for an attacker to
determine the address of allocated structures.

There is currently no workaround for this issue. If this affects you,
please @ref{d8,,contact us}.

Other supported platforms are unaffected by this issue: Linux and macOS
randomize the addresses allocated by @code{mmap()}, and Windows
randomizes the addresses allocated by @code{VirtualAlloc()}.

@geindex security issues; address disclosure

@node Address disclosure,Telemetry<2>,Predictable address space layout on FreeBSD,Security issues
@anchor{topic/security address-disclosure}@anchor{347}
@subsection Address disclosure


The MPS supports @ref{348,,semi-conservative garbage collection} in which
some memory locations are @ref{65,,scanned} as @ref{9f,,ambiguous references}. This may make it possible for a program to discover the
@ref{126,,address} of an @ref{1ab,,object}, even if the programming language
has no feature for obtaining the address of an object. Discovering the
addresses of objects makes it easier to exploit buffer overflow bugs.

The attack proceeds as follows: create a @ref{c,,weak reference (1)} to
the object of interest (for example, via a @ref{fb,,weak-key hash table}); guess a value for the address of the object; and arrange for
that value to be scanned as an ambiguous reference (for example, by
ensuring that it appears in @ref{26,,registers} or on the @ref{27,,control stack} of a @ref{99,,thread}). If the guess was correct, the MPS keeps
the object @ref{78,,alive}; if incorrect, the object may
@ref{49,,die}. The attacker can then determine which of these was
the case by examining the weak reference to see if it has been
@ref{245,,splatted}.

The attack was pointed out by Dionysus Blazakis in 2012@footnote{https://github.com/justdionysus/gcwoah} with respect to JavaScript
implementations, but it affects all @ref{349,,conservative} and @ref{348,,semi-conservative} garbage collectors.

@geindex security issues; telemetry

@node Telemetry<2>,,Address disclosure,Security issues
@anchor{topic/security telemetry}@anchor{34a}
@subsection Telemetry


In its @ref{162,,hot} and @ref{c8,,cool} varieties, the MPS contains a
@ref{15b,,telemetry system} which can be configured to record a stream of
events for later analysis and debugging. When using the default
@ref{160,,plinth}, the behaviour of the telemetry system is under the
control of the environment variable 
@geindex MPS_TELEMETRY_CONTROL
@geindex environment variable; MPS_TELEMETRY_CONTROL
@ref{288,,MPS_TELEMETRY_CONTROL},
and the @ref{ba,,telemetry stream} is written to the file named by the
environment variable 
@geindex MPS_TELEMETRY_FILENAME
@geindex environment variable; MPS_TELEMETRY_FILENAME
@ref{289,,MPS_TELEMETRY_FILENAME}.

This means that an attacker who can set arbitrary environment
variables when running a program that uses the MPS can cause that
program to write a telemetry stream to an arbitrary file. This
behaviour might be unexpected, and might enable a data overwriting
attack, or a denial-of-service attack, since telemetry streams are
typically very large.

If this is an issue for your program, then you can modify or replace
the @ref{2b8,,I/O module} in the @ref{160,,plinth} so that it meets your
requirements, or distribute the @ref{163,,rash} variety of the MPS, which
omits the @ref{15b,,telemetry system} entirely, and use the other
varieties only for development and testing.

@node Pool reference,Design,Reference,Top
@anchor{pool/index doc}@anchor{34b}@anchor{pool/index pool}@anchor{22}@anchor{pool/index pool-reference}@anchor{34c}
@chapter Pool reference


@geindex pool class; choosing

@menu
* Choosing a pool class: Choosing a pool class<2>. 
* Pool class properties:: 
* Writing a new pool class:: 
* AMC (Automatic Mostly-Copying): AMC Automatic Mostly-Copying. 
* AMCZ (Automatic Mostly-Copying Zero-rank): AMCZ Automatic Mostly-Copying Zero-rank. 
* AMS (Automatic Mark and Sweep): AMS Automatic Mark and Sweep. 
* AWL (Automatic Weak Linked): AWL Automatic Weak Linked. 
* LO (Leaf Object): LO Leaf Object. 
* MFS (Manual Fixed Small): MFS Manual Fixed Small. 
* MVFF (Manual Variable First Fit): MVFF Manual Variable First Fit. 
* MVT (Manual Variable Temporal): MVT Manual Variable Temporal. 
* SNC (Stack No Checking): SNC Stack No Checking. 

@end menu

@node Choosing a pool class<2>,Pool class properties,,Pool reference
@anchor{pool/intro doc}@anchor{34d}@anchor{pool/intro choosing-a-pool-class}@anchor{34e}@anchor{pool/intro pool-choose}@anchor{5f}
@section Choosing a pool class


This section contains a simple procedure for choosing a @ref{10,,pool class} based on the properties of the data you plan to store in
it. The MPS works well if you can segregate your data into a variety
of pools, choosing the most appropriate pool class for each.

@cartouche
@quotation Note 
Pool classes can differ in many ways not considered here: speed,
vulnerability to fragmentation, control overhead, and so on. This
procedure gives you a decent recommendation, but an expert in the
MPS might be able to make a better recommendation. And if no pool
class in the open source MPS exactly matches your needs, then it
is possible to develop new pool classes. See @ref{34f,,Writing a new pool class}.
@end quotation
@end cartouche

First, do you need the MPS to @ref{9,,automatically} @ref{4a,,reclaim} @ref{21,,unreachable} blocks? If so, you
need an automatically managed (garbage collected) pool class and you
should consult @ref{350,,Choosing an automatic pool class} below.
Otherwise, you need a manually managed pool class and you should
consult @ref{351,,Choosing a manual pool class} below.

@menu
* Choosing an automatic pool class:: 
* Choosing a manual pool class:: 

@end menu

@node Choosing an automatic pool class,Choosing a manual pool class,,Choosing a pool class<2>
@anchor{pool/intro choosing-an-automatic-pool-class}@anchor{352}@anchor{pool/intro pool-choose-automatic}@anchor{350}
@subsection Choosing an automatic pool class


Answer these questions about your data:


@enumerate 

@item 
Is it acceptable for the MPS to @ref{1ad,,move} blocks in memory and to place @ref{60,,barriers (1)} on
blocks? (For example, it might not be acceptable to move a block if
it has been passed to @ref{10b,,foreign code} that remembered its
location.)

@item 
Do your blocks contain @ref{24,,references} to blocks stored in
automatically managed pools (including references to other blocks
in the same pool, if it’s automatically managed)? And if so, are
these references @ref{61,,exact} or @ref{c,,weak}?
@end enumerate

Second, look up your answers in this table to find the recommended
pool class to use:


@multitable {xxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxx} 
@headitem

Movable & protectable?

@tab

References?

@tab

Use this pool class

@item

yes

@tab

none

@tab

@ref{89,,AMCZ (Automatic Mostly-Copying Zero-rank)}

@item

yes

@tab

exact

@tab

@ref{62,,AMC (Automatic Mostly-Copying)}

@item

yes

@tab

weak

@tab

@ref{fe,,AWL (Automatic Weak Linked)}

@item

no

@tab

none

@tab

@ref{353,,LO (Leaf Object)}

@item

no

@tab

exact

@tab

@ref{16c,,AMS (Automatic Mark and Sweep)}

@item

no

@tab

weak

@tab

nothing suitable

@end multitable


@node Choosing a manual pool class,,Choosing an automatic pool class,Choosing a pool class<2>
@anchor{pool/intro choosing-a-manual-pool-class}@anchor{354}@anchor{pool/intro pool-choose-manual}@anchor{351}
@subsection Choosing a manual pool class


Answer these questions about your data:


@enumerate 

@item 
Are the blocks fixed in size? If so, use @ref{355,,MFS (Manual Fixed Small)}.

@item 
Are the lifetimes of blocks predictable? If so, use
@ref{1bc,,MVT (Manual Variable Temporal)}, and arrange that objects that are predicted to die
at about the same time are allocated from the same
@ref{63,,allocation point}.

@item 
Otherwise, use @ref{10c,,MVFF (Manual Variable First Fit)}.
@end enumerate

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mmdoc/doc/mps/guide/pool-classes/>`_

@geindex pool class; table of properties

@node Pool class properties,Writing a new pool class,Choosing a pool class<2>,Pool reference
@anchor{pool/intro pool-class-properties}@anchor{356}@anchor{pool/intro pool-properties}@anchor{2c7}
@section Pool class properties


This table summarizes the properties of each @ref{10,,pool class}
provided by the open source MPS. For “block” properties, “yes” means
that the property holds for `all' blocks allocated from the pool. An
entry “—” indicates that a property makes no sense for a pool class:
for example, if blocks in a pool may not contain @ref{24,,references},
it makes no sense to ask whether they may contain @ref{c,,weak references (1)}.


@multitable {xxxxxxxx} {xxx} {xxx} {xxx} {xxx} {xxx} {xxx} {xxx} {xxx} {xxx} 
@headitem

Property

@tab

@ref{62,,AMC}

@tab

@ref{89,,AMCZ}

@tab

@ref{16c,,AMS}

@tab

@ref{fe,,AWL}

@tab

@ref{353,,LO}

@tab

@ref{355,,MFS}

@tab

@ref{10c,,MVFF}

@tab

@ref{1bc,,MVT}

@tab

@ref{27b,,SNC}

@item

Supports @ref{ad,,mps_alloc()}?

@tab

no

@tab

no

@tab

no

@tab

no

@tab

no

@tab

yes

@tab

yes

@tab

no

@tab

no

@item

Supports @ref{1f,,mps_free()}?

@tab

no

@tab

no

@tab

no

@tab

no

@tab

no

@tab

yes

@tab

yes

@tab

yes

@tab

no

@item

Supports allocation points?

@tab

yes

@tab

yes

@tab

yes

@tab

yes

@tab

yes

@tab

no

@tab

yes

@tab

yes

@tab

yes

@item

Manages memory using allocation frames?

@tab

no

@tab

no

@tab

no

@tab

no

@tab

no

@tab

no

@tab

no

@tab

no

@tab

yes

@item

Supports segregated allocation caches?

@tab

no

@tab

no

@tab

no

@tab

no

@tab

no

@tab

yes

@tab

yes

@tab

no

@tab

no

@item

Timing of collections? @footnote{
“Timing of collections” is “auto” if @ref{f,,garbage collection}
is under the control of the MPS, which decides when collection
should take place and performs it @ref{9,,automatically} and @ref{d,,incrementally}.
}

@tab

auto

@tab

auto

@tab

auto

@tab

auto

@tab

auto

@tab

—

@tab

—

@tab

—

@tab

—

@item

May contain references? @footnote{
The references in question are references to blocks in
@ref{9,,automatically managed}
@ref{18,,pools}.
}

@tab

yes

@tab

no

@tab

yes

@tab

yes

@tab

no

@tab

no

@tab

no

@tab

no

@tab

yes

@item

May contain exact references? @footnote{
Pools “may contain @ref{9f,,ambiguous} /
@ref{61,,exact} / @ref{c,,weak} references” if the references that the client
program fixes during scanning may include references of the
indicated @ref{9e,,rank}.
}

@tab

yes

@tab

—

@tab

yes

@tab

yes

@tab

—

@tab

—

@tab

—

@tab

—

@tab

yes

@item

May contain ambiguous references? @footnote{
Pools “may contain @ref{9f,,ambiguous} /
@ref{61,,exact} / @ref{c,,weak} references” if the references that the client
program fixes during scanning may include references of the
indicated @ref{9e,,rank}.
}

@tab

no

@tab

—

@tab

no

@tab

no

@tab

—

@tab

—

@tab

—

@tab

—

@tab

no

@item

May contain weak references? @footnote{
Pools “may contain @ref{9f,,ambiguous} /
@ref{61,,exact} / @ref{c,,weak} references” if the references that the client
program fixes during scanning may include references of the
indicated @ref{9e,,rank}.
}

@tab

no

@tab

—

@tab

no

@tab

yes

@tab

—

@tab

—

@tab

—

@tab

—

@tab

no

@item

Allocations fixed or variable in size?

@tab

var

@tab

var

@tab

var

@tab

var

@tab

var

@tab

fixed

@tab

var

@tab

var

@tab

var

@item

Alignment? @footnote{
“Alignment” is “conf” if the client program may specify
@ref{68,,alignment} for each pool.
}

@tab

conf

@tab

conf

@tab

conf

@tab

conf

@tab

conf

@tab

@footnote{
The alignment of blocks allocated from @ref{355,,MFS (Manual Fixed Small)}
pools is the platform’s @ref{70,,natural alignment},
@ref{6f,,MPS_PF_ALIGN}.
}

@tab

@footnote{
@ref{1bc,,MVT (Manual Variable Temporal)} and @ref{10c,,MVFF (Manual Variable First Fit)} pools have
configurable alignment, but it may not be smaller than
@code{sizeof(void *)}.
}

@tab

@footnote{
@ref{1bc,,MVT (Manual Variable Temporal)} and @ref{10c,,MVFF (Manual Variable First Fit)} pools have
configurable alignment, but it may not be smaller than
@code{sizeof(void *)}.
}

@tab

conf

@item

Dependent objects? @footnote{
In pools with this property, each object may specify an
@ref{ff,,dependent object} which the client program
guarantees will be accessible during the scanning of the
first object. This may be used in the implementation of
@ref{357,,weak hash tables}.
}

@tab

no

@tab

—

@tab

no

@tab

yes

@tab

—

@tab

—

@tab

—

@tab

—

@tab

no

@item

May use remote references? @footnote{
“Remote references” are references that are stored outside the
block to which they logically belong (for example, in some kind
of auxiliary table). A pool containing remote references cannot
rely on a @ref{214,,write barrier} to detect changed references.
}

@tab

no

@tab

—

@tab

no

@tab

no

@tab

—

@tab

—

@tab

—

@tab

—

@tab

no

@item

Blocks are automatically managed? @footnote{
Blocks are “automatically managed” if they may be
automatically discarded when the MPS determines that they
are unreachable; they are “manually managed” if they can be
discarded when the @ref{d0,,client program} requests it. Note
that these properties are not mutually exclusive, although
the MPS does not provide a pool class that satisfies both.
}

@tab

yes

@tab

yes

@tab

yes

@tab

yes

@tab

yes

@tab

no

@tab

no

@tab

no

@tab

no

@item

Blocks are promoted between generations

@tab

yes

@tab

yes

@tab

no

@tab

no

@tab

no

@tab

—

@tab

—

@tab

—

@tab

—

@item

Blocks are manually managed? @footnote{
Blocks are “automatically managed” if they may be
automatically discarded when the MPS determines that they
are unreachable; they are “manually managed” if they can be
discarded when the @ref{d0,,client program} requests it. Note
that these properties are not mutually exclusive, although
the MPS does not provide a pool class that satisfies both.
}

@tab

no

@tab

no

@tab

no

@tab

no

@tab

no

@tab

yes

@tab

yes

@tab

yes

@tab

yes

@item

Blocks are scanned? @footnote{
Blocks “are scanned” if the MPS @ref{65,,scans} them for
references; blocks “must be formatted” if they are
described to the MPS by an @ref{39,,object format}. At
present, the MPS only knows how to scan blocks using the
@ref{73,,scan method} from an object format, but the MPS
design does not preclude pools that scan unformatted
blocks.
}

@tab

yes

@tab

no

@tab

yes

@tab

yes

@tab

no

@tab

no

@tab

no

@tab

no

@tab

yes

@item

Blocks support base pointers only? @footnote{
A block “supports internal pointers” if a pointer to any
location within the block is considered to be a reference
to the block. It “supports base pointers only” if only a
pointer to the base of the block (or, if the block belongs
to an object format with @ref{1d1,,in-band headers}, a pointer
just past the end of the header) is considered to be a
reference to the block.

Pools that support internal pointers can be switched to
base pointers only, by setting the optional keyword
argument @code{MPS_KEY_INTERIOR} to @code{FALSE} when
calling @ref{166,,mps_pool_create_k()}.
}

@tab

no

@tab

no

@tab

yes

@tab

yes

@tab

yes

@tab

—

@tab

—

@tab

—

@tab

yes

@item

Blocks support internal pointers? @footnote{
A block “supports internal pointers” if a pointer to any
location within the block is considered to be a reference
to the block. It “supports base pointers only” if only a
pointer to the base of the block (or, if the block belongs
to an object format with @ref{1d1,,in-band headers}, a pointer
just past the end of the header) is considered to be a
reference to the block.

Pools that support internal pointers can be switched to
base pointers only, by setting the optional keyword
argument @code{MPS_KEY_INTERIOR} to @code{FALSE} when
calling @ref{166,,mps_pool_create_k()}.
}

@tab

yes

@tab

yes

@tab

no

@tab

no

@tab

no

@tab

—

@tab

—

@tab

—

@tab

no

@item

Blocks may be protected by barriers?

@tab

yes

@tab

no

@tab

yes

@tab

yes

@tab

yes

@tab

no

@tab

no

@tab

no

@tab

yes

@item

Blocks may move?

@tab

yes

@tab

yes

@tab

no

@tab

no

@tab

no

@tab

no

@tab

no

@tab

no

@tab

no

@item

Blocks may be finalized?

@tab

yes

@tab

yes

@tab

yes

@tab

yes

@tab

yes

@tab

no

@tab

no

@tab

no

@tab

no

@item

Blocks must be formatted? @footnote{
Blocks “are scanned” if the MPS @ref{65,,scans} them for
references; blocks “must be formatted” if they are
described to the MPS by an @ref{39,,object format}. At
present, the MPS only knows how to scan blocks using the
@ref{73,,scan method} from an object format, but the MPS
design does not preclude pools that scan unformatted
blocks.
}

@tab

yes

@tab

yes

@tab

yes

@tab

yes

@tab

yes

@tab

no

@tab

no

@tab

no

@tab

yes

@item

Blocks may use @ref{1d1,,in-band headers}?

@tab

yes

@tab

yes

@tab

yes

@tab

yes

@tab

yes

@tab

—

@tab

—

@tab

—

@tab

no

@end multitable


@cartouche
@quotation Note 
@end quotation
@end cartouche

@geindex pool class; writing

@node Writing a new pool class,AMC Automatic Mostly-Copying,Pool class properties,Pool reference
@anchor{pool/intro pool-writing}@anchor{34f}@anchor{pool/intro writing-a-new-pool-class}@anchor{358}
@section Writing a new pool class


If none of the pool classes supplied with the MPS are quite right for
your application, don’t despair: the MPS is designed to be extensible
with new pool classes, and designed so that the properties of pools
are as orthogonal as possible. So if you need a pool containing
objects that are scannable but unformatted, or movable objects which
are manually managed, or a pool all of whose objects are roots, there
is no technical reason why it should not be possible to write it.

If you’d be interested in our developing new pool classes for your
requirements, or if you’ve started writing a new pool class
yourself, @ref{d8,,we’d love to hear from you}.

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/master/manual/wiki/pool_classes.html>`_
@c `<https://info.ravenbrook.com/project/mps/master/design/poolamc/>`_

@geindex AMC pool class
@geindex pool class; AMC

@node AMC Automatic Mostly-Copying,AMCZ Automatic Mostly-Copying Zero-rank,Writing a new pool class,Pool reference
@anchor{pool/amc doc}@anchor{359}@anchor{pool/amc amc-automatic-mostly-copying}@anchor{35a}@anchor{pool/amc pool-amc}@anchor{62}
@section AMC (Automatic Mostly-Copying)


`AMC' is a general-purpose @ref{9,,automatically managed} @ref{10,,pool class}. This is the most mature pool
class in the MPS, intended for the majority of objects in the client
program. Use this pool class unless you need a particular feature that
it doesn’t provide.

“Mostly Copying” means that it uses @ref{e3,,copying garbage collection}
except for blocks that are @ref{1e5,,pinned} by
@ref{9f,,ambiguous references}.

It uses @ref{e,,generational garbage collection}. That is, it exploits
assumptions about object lifetimes and inter-connection variously
referred to as “the @ref{35b,,generational hypothesis}”. In particular,
the following tendencies will be efficiently exploited by an AMC pool:


@itemize -

@item 
most objects die young;

@item 
objects that don’t die young will live a long time.
@end itemize

@geindex AMC pool class; properties

@menu
* AMC properties:: 
* AMC interface:: 
* Hash arrays:: 

@end menu

@node AMC properties,AMC interface,,AMC Automatic Mostly-Copying
@anchor{pool/amc amc-properties}@anchor{35c}
@subsection AMC properties



@itemize *

@item 
Does not support allocation via @ref{ad,,mps_alloc()} or deallocation
via @ref{1f,,mps_free()}.

@item 
Supports allocation via @ref{63,,allocation points}. If an allocation
point is created in an AMC pool, the call to
@ref{af,,mps_ap_create_k()} takes no keyword arguments.

@item 
Supports @ref{27d,,allocation frames} but does not use them to improve
the efficiency of stack-like allocation.

@item 
Does not support @ref{1b2,,segregated allocation caches}.

@item 
Garbage collections are scheduled automatically. See
@ref{226,,Scheduling of collections}.

@item 
Uses @ref{e,,generational garbage collection}: blocks are promoted
from generation to generation in the pool’s chain.

@item 
Blocks may contain @ref{61,,exact references} to blocks in the same or
other pools (but may not contain @ref{9f,,ambiguous references} or
@ref{c,,weak references (1)}, and may not use @ref{35d,,remote references}).

@item 
Allocations may be variable in size.

@item 
The @ref{68,,alignment} of blocks is configurable.

@item 
Blocks do not have @ref{ff,,dependent objects}.

@item 
Blocks that are not @ref{96,,reachable} from a @ref{97,,root} are
automatically @ref{4a,,reclaimed}.

@item 
Blocks are @ref{65,,scanned}.

@item 
Blocks may be referenced by @ref{1ac,,interior pointers} (unless
@code{MPS_KEY_INTERIOR} is set to @code{FALSE}, in which case only
@ref{1aa,,base pointers}, or @ref{1d4,,client pointers} if the blocks
have @ref{1d1,,in-band headers}, are supported).

@item 
Blocks may be protected by @ref{60,,barriers (1)}.

@item 
Blocks may @ref{5d,,move}.

@item 
Blocks may be registered for @ref{b,,finalization}.

@item 
Blocks must belong to an @ref{39,,object format} which provides
@ref{73,,scan}, @ref{81,,skip},
@ref{85,,forward}, @ref{8c,,is-forwarded}, and @ref{90,,padding} methods.

@item 
Blocks may have @ref{1d1,,in-band headers}.
@end itemize

@geindex AMC pool class; interface

@node AMC interface,Hash arrays,AMC properties,AMC Automatic Mostly-Copying
@anchor{pool/amc amc-interface}@anchor{35e}
@subsection AMC interface


@example
#include "mpscamc.h"
@end example

@geindex mps_class_amc (C function)
@anchor{pool/amc c mps_class_amc}@anchor{13b}
@deffn {C Function} @ref{1b4,,mps_pool_class_t} mps_class_amc (void)

Return the @ref{10,,pool class} for an AMC (Automatic
Mostly-Copying) @ref{18,,pool}.

When creating an AMC pool, @ref{166,,mps_pool_create_k()} requires
one @ref{53,,keyword argument}:


@itemize *

@item 
@code{MPS_KEY_FORMAT} (type @ref{141,,mps_fmt_t}) specifies
the @ref{39,,object format} for the objects allocated in the pool.
The format must provide a @ref{73,,scan method}, a @ref{81,,skip method}, a @ref{85,,forward method}, an @ref{8c,,is-forwarded method} and a @ref{90,,padding method}.
@end itemize

It accepts three optional keyword arguments:


@itemize *

@item 
@code{MPS_KEY_CHAIN} (type @ref{13a,,mps_chain_t}) specifies
the @ref{e2,,generation chain} for the pool. If not specified, the
pool will use the arena’s default chain.

@item 
@code{MPS_KEY_INTERIOR} (type @ref{129,,mps_bool_t}, default
@code{TRUE}) specifies whether @ref{9f,,ambiguous} @ref{1ac,,interior pointers} to blocks in the pool keep
objects alive. If this is @code{FALSE}, then only @ref{1d4,,client pointers} keep objects alive.

@item 
@code{MPS_KEY_EXTEND_BY} (type @code{size_t},
default 4096) is the minimum @ref{183,,size} of the memory segments
that the pool requests from the @ref{16,,arena}. Larger segments
reduce the per-segment overhead, but increase
@ref{17e,,fragmentation} and @ref{17f,,retention}.
@end itemize

For example:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_FORMAT, fmt);
    res = mps_pool_create_k(&pool, arena, mps_class_amc(), args);
@} MPS_ARGS_END(args);
@end example

When creating an @ref{63,,allocation point} on an AMC pool,
@ref{af,,mps_ap_create_k()} accepts one optional keyword argument:


@itemize *

@item 
@code{MPS_KEY_AP_HASH_ARRAYS} (type @ref{129,,mps_bool_t},
defaulting to false) specifies (if true) that blocks allocated
from the allocation point do not contribute to the `new size' of
the @ref{35f,,nursery space} for the purposes of deciding whether
to start a collection of that generation. See
@ref{360,,Hash arrays}.
@end itemize
@end deffn

@geindex AMC pool class; hash arrays

@node Hash arrays,,AMC interface,AMC Automatic Mostly-Copying
@anchor{pool/amc hash-arrays}@anchor{361}@anchor{pool/amc pool-amc-hash-arrays}@anchor{360}
@subsection Hash arrays


The @ref{19a,,location dependency} feature of the MPS allows the
@ref{d0,,client program} to implement address-based hash tables in pools
like AMC that use a @ref{1ad,,moving memory manager}, re-hashing the
tables when the addresses they contain might have moved.

However, when a frequently-used hash table grows large enough, the
following sequence of events may take place:


@enumerate 

@item 
The hash table discovers that its location dependency is stale.

@item 
A new array is allocated to contain the re-hashed keys.

@item 
The new array is large enough to push the `new size' of the
@ref{35f,,nursery space} (that is, the amount of newly allocated
memory since the last collection in the first @ref{e1,,generation} in
the @ref{e2,,generation chain} for the pool containing the array)
close to its capacity.

@item 
A small amount of additional allocation causes the new size of the
nursery generation to exceed its capacity, which causes the MPS to
start a new collection of that generation. This in turn causes the
hash table to become stale again.
@end enumerate

When the hash table reaches this critical size, the client program may
find that a large fraction of its time is being spent re-hashing the
table.

In order to avoid this happening, the MPS provides a mechanism for
specifying that the newly allocated array does not contribute to the
new size of the nursery space: this cuts off the vicious cycle at step
3.

To enable this mechanism, use the optional @code{MPS_KEY_AP_HASH_ARRAYS}
keyword argument when creating an allocation point with
@ref{af,,mps_ap_create_k()}. This interface is documented in the AMC Interface
section of the @ref{62,,AMC (Automatic Mostly-Copying)} documentation above.

See @ref{226,,Scheduling of collections} for an explanation of the `new
size' of a generation, and how the MPS uses this to determine when to
start a collection of that generation.

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/master/manual/wiki/pool_classes.html>`_

@geindex AMCZ pool class
@geindex pool class; AMCZ

@node AMCZ Automatic Mostly-Copying Zero-rank,AMS Automatic Mark and Sweep,AMC Automatic Mostly-Copying,Pool reference
@anchor{pool/amcz doc}@anchor{362}@anchor{pool/amcz amcz-automatic-mostly-copying-zero-rank}@anchor{363}@anchor{pool/amcz pool-amcz}@anchor{89}
@section AMCZ (Automatic Mostly-Copying Zero-rank)


`AMCZ' is a general-purpose @ref{9,,automatically managed} @ref{10,,pool class} for @ref{107,,leaf objects}
(“zero-rank” objects that contain no references).

It is otherwise identical to @ref{62,,AMC (Automatic Mostly-Copying)}.

AMCZ is intended for “simple” objects like numbers, characters, and
strings. Segregating these objects into one or more AMCZ pools avoids
the cost of scanning them that would be incurred if they were
interleaved in a pool with objects containing references. It may also
simplify the scanning of the objects that are left behind.

See @ref{104,,Segregation of objects} for an example.

@geindex AMCZ pool class; properties

@menu
* AMCZ properties:: 
* AMCZ interface:: 

@end menu

@node AMCZ properties,AMCZ interface,,AMCZ Automatic Mostly-Copying Zero-rank
@anchor{pool/amcz amcz-properties}@anchor{364}
@subsection AMCZ properties


AMCZ is identical to @ref{62,,AMC (Automatic Mostly-Copying)}, except that:


@itemize *

@item 
Blocks may not contain @ref{24,,references} to blocks in automatically
managed pools.

@item 
Blocks are not @ref{65,,scanned}. A consequence of this is that
the pool’s @ref{39,,object format} need not provide a @ref{73,,scan method}.

@item 
Blocks are not protected by @ref{60,,barriers (1)}.
@end itemize

@geindex AMCZ pool class; interface

@node AMCZ interface,,AMCZ properties,AMCZ Automatic Mostly-Copying Zero-rank
@anchor{pool/amcz amcz-interface}@anchor{365}
@subsection AMCZ interface


@example
#include "mpscamc.h"
@end example

@geindex mps_class_amcz (C function)
@anchor{pool/amcz c mps_class_amcz}@anchor{13c}
@deffn {C Function} @ref{1b4,,mps_pool_class_t} mps_class_amcz (void)

Return the @ref{10,,pool class} for an AMCZ (Automatic
Mostly-Copying Zero-rank) @ref{18,,pool}.

When creating an AMCZ pool, @ref{166,,mps_pool_create_k()} requires
one @ref{53,,keyword argument}:


@itemize *

@item 
@code{MPS_KEY_FORMAT} (type @ref{141,,mps_fmt_t}) specifies
the @ref{39,,object format} for the objects allocated in the pool.
The format must provide a @ref{81,,skip method}, a @ref{85,,forward method}, an @ref{8c,,is-forwarded method} and a @ref{90,,padding method}.
@end itemize

It accepts two optional keyword arguments:


@itemize *

@item 
@code{MPS_KEY_CHAIN} (type @ref{13a,,mps_chain_t}) specifies
the @ref{e2,,generation chain} for the pool. If not specified, the
pool will use the arena’s default chain.

@item 
@code{MPS_KEY_INTERIOR} (type @ref{129,,mps_bool_t}, default
@code{TRUE}) specifies whether @ref{9f,,ambiguous} @ref{1ac,,interior pointers} to blocks in the pool keep
objects alive. If this is @code{FALSE}, then only @ref{1d4,,client pointers} keep objects alive.
@end itemize

For example:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_FORMAT, fmt);
    res = mps_pool_create_k(&pool, arena, mps_class_amcz(), args);
@} MPS_ARGS_END(args);
@end example
@end deffn

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/master/manual/wiki/pool_classes.html>`_
@c `<https://info.ravenbrook.com/project/mps/master/design/poolams/>`_

@geindex AMS pool class
@geindex pool class; AMS

@node AMS Automatic Mark and Sweep,AWL Automatic Weak Linked,AMCZ Automatic Mostly-Copying Zero-rank,Pool reference
@anchor{pool/ams doc}@anchor{366}@anchor{pool/ams ams-automatic-mark-and-sweep}@anchor{367}@anchor{pool/ams pool-ams}@anchor{16c}
@section AMS (Automatic Mark and Sweep)


`AMS' is an @ref{9,,automatically managed} but @ref{5e,,non-moving}
@ref{10,,pool class}. It should be used instead of @ref{62,,AMC (Automatic Mostly-Copying)} for
blocks that need to be automatically managed, but cannot be moved.

@cartouche
@quotation Note 
AMS is likely to be useful as a step in integrating a program with
the MPS. It allows you to work on scanning (and investigate errors
resulting from underscanning) without having to deal with objects
moving as well. When you are confident that scanning is correct,
you can switch to @ref{62,,AMC (Automatic Mostly-Copying)}.

AMS is not currently suitable for production use. However, it
could be developed into a solid mark-and-sweep pool. If you have a
use case that needs this, @ref{d8,,contact us}.
@end quotation
@end cartouche

@geindex AMS pool class; properties

@menu
* AMS properties:: 
* AMS interface:: 

@end menu

@node AMS properties,AMS interface,,AMS Automatic Mark and Sweep
@anchor{pool/ams ams-properties}@anchor{368}
@subsection AMS properties



@itemize *

@item 
Does not support allocation via @ref{ad,,mps_alloc()} or deallocation
via @ref{1f,,mps_free()}.

@item 
Supports allocation via @ref{63,,allocation points}. If an allocation
point is created in an AMS pool, the call to
@ref{af,,mps_ap_create_k()} takes one optional keyword argument,
@code{MPS_KEY_RANK}.

@item 
Supports @ref{27d,,allocation frames} but does not use them to improve
the efficiency of stack-like allocation.

@item 
Does not support @ref{1b2,,segregated allocation caches}.

@item 
Garbage collections are scheduled automatically. See
@ref{226,,Scheduling of collections}.

@item 
Does not use @ref{e,,generational garbage collection}, so blocks are
never promoted out of the generation in which they are allocated.

@item 
Blocks may contain @ref{61,,exact references} to blocks in the same or
other pools, or @ref{9f,,ambiguous references} (unless the
@code{MPS_KEY_AMS_SUPPORT_AMBIGUOUS} keyword argument is set to
@code{FALSE} when creating the pool). Blocks may not contain
@ref{c,,weak references (1)}, and may not use @ref{35d,,remote references}.

@item 
Allocations may be variable in size.

@item 
The @ref{68,,alignment} of blocks is configurable.

@item 
Blocks do not have @ref{ff,,dependent objects}.

@item 
Blocks that are not @ref{96,,reachable} from a @ref{97,,root} are
automatically @ref{4a,,reclaimed}.

@item 
Blocks are @ref{65,,scanned}.

@item 
Blocks may only be referenced by @ref{1aa,,base pointers} (unless they
have @ref{1d1,,in-band headers}).

@item 
Blocks are not protected by @ref{60,,barriers (1)}.

@item 
Blocks do not @ref{5d,,move}.

@item 
Blocks may be registered for @ref{b,,finalization}.

@item 
Blocks must belong to an @ref{39,,object format} which provides
@ref{73,,scan} and @ref{81,,skip} methods.

@item 
Blocks may have @ref{1d1,,in-band headers}.
@end itemize

@geindex AMS pool class; interface

@node AMS interface,,AMS properties,AMS Automatic Mark and Sweep
@anchor{pool/ams ams-interface}@anchor{369}
@subsection AMS interface


@example
#include "mpscams.h"
@end example

@geindex mps_class_ams (C function)
@anchor{pool/ams c mps_class_ams}@anchor{138}
@deffn {C Function} @ref{1b4,,mps_pool_class_t} mps_class_ams (void)

Return the @ref{10,,pool class} for an AMS (Automatic Mark & Sweep)
@ref{18,,pool}.

When creating an AMS pool, @ref{166,,mps_pool_create_k()} requires
one @ref{53,,keyword argument}:


@itemize *

@item 
@code{MPS_KEY_FORMAT} (type @ref{141,,mps_fmt_t}) specifies
the @ref{39,,object format} for the objects allocated in the pool.
The format must provide a @ref{73,,scan method} and a @ref{81,,skip method}.
@end itemize

It accepts three optional keyword arguments:


@itemize *

@item 
@code{MPS_KEY_CHAIN} (type @ref{13a,,mps_chain_t}) specifies
the @ref{e2,,generation chain} for the pool. If not specified, the
pool will use the arena’s default chain.

@item 
@code{MPS_KEY_GEN} (type @code{unsigned}) specifies the
@ref{e1,,generation} in the chain into which new objects will be
allocated. If you pass your own chain, then this defaults to
@code{0}, but if you didn’t (and so use the arena’s default chain),
then an appropriate generation is used.

Note that AWL does not use generational garbage collection, so
blocks remain in this generation and are not promoted.

@item 
@code{MPS_KEY_AMS_SUPPORT_AMBIGUOUS} (type
@ref{129,,mps_bool_t}, default @code{TRUE}) specifies whether
references to blocks in the pool may be ambiguous.
@end itemize

For example:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_FORMAT, fmt);
    res = mps_pool_create_k(&pool, arena, mps_class_ams(), args);
@} MPS_ARGS_END(args);
@end example

When creating an @ref{63,,allocation point} on an AMS pool,
@ref{af,,mps_ap_create_k()} accepts one optional keyword argument:


@itemize *

@item 
@code{MPS_KEY_RANK} (type @ref{146,,mps_rank_t}, default
@ref{9d,,mps_rank_exact()}) specifies the @ref{9e,,rank} of references
in objects allocated on this allocation point. It must be
@ref{9d,,mps_rank_exact()} (if the objects allocated on this
allocation point will contain @ref{61,,exact references}), or
@ref{20a,,mps_rank_ambig()} (if the objects may contain
@ref{9f,,ambiguous references}).
@end itemize

For example:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_RANK, mps_rank_ambig());
    res = mps_ap_create_k(&ap, ams_pool, args);
@} MPS_ARGS_END(args);
@end example
@end deffn

@geindex mps_class_ams_debug (C function)
@anchor{pool/ams c mps_class_ams_debug}@anchor{144}
@deffn {C Function} @ref{1b4,,mps_pool_class_t} mps_class_ams_debug (void)

A @ref{10d,,debugging} version of the AMS pool
class.

When creating a debugging AMS pool, @ref{166,,mps_pool_create_k()}
accepts the following keyword arguments:
@code{MPS_KEY_FORMAT}, @code{MPS_KEY_CHAIN},
@code{MPS_KEY_GEN}, and
@code{MPS_KEY_AMS_SUPPORT_AMBIGUOUS} are as described above,
and @code{MPS_KEY_POOL_DEBUG_OPTIONS} specifies the debugging
options. See @ref{143,,mps_pool_debug_option_s}.
@end deffn

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/master/manual/wiki/pool_classes.html>`_
@c `<https://info.ravenbrook.com/project/mps/master/design/poolawl/>`_
@c DRJ: `<https://info.ravenbrook.com/mail/2003/03/17/13-51-24/0.txt>`_
@c NB: `<https://info.ravenbrook.com/mail/2002/04/12/15-52-29/0.txt>`_
@c NB: `<https://info.ravenbrook.com/mail/2002/04/12/15-56-15/0.txt>`_

@geindex AWL pool class
@geindex pool class; AWL

@node AWL Automatic Weak Linked,LO Leaf Object,AMS Automatic Mark and Sweep,Pool reference
@anchor{pool/awl doc}@anchor{36a}@anchor{pool/awl awl-automatic-weak-linked}@anchor{36b}@anchor{pool/awl pool-awl}@anchor{fe}
@section AWL (Automatic Weak Linked)


`AWL' is an @ref{9,,automatically managed} @ref{5e,,non-moving}
@ref{10,,pool class} that may contain @ref{c,,weak references (1)}.

The purpose of this pool class is to allow the client to implement
@ref{fb,,weak-key}, @ref{fc,,weak-value}, and @ref{fd,,doubly weak hash tables}.

In a weak-key hash table, the keys are weakly referenced, so their
presence in the table will not prevent the key object from being
garbage collected. Once the key is no longer @ref{96,,reachable}, weak
references to it may get @ref{245,,splatted} (that is, replaced
with null pointers). Once that has happened, the client program can’t
get at the value corresponding to the key any more, so the
implementation is free to splat the value slot as well.

AWL allows the implementation to splat the value slot at the same time
that the weak key slot is splatted. (Or the other way around for
weak-value tables.) See @ref{100,,Dependent objects}.

See @ref{f9,,Weak hash tables} in the @ref{e6,,Advanced topics} section of
the user guide for a detailed example of using this pool class.

@cartouche
@quotation Note 
AWL is the only pool in the open source MPS that allows its
formatted objects to contain weak references. It was designed to
support the weak hash tables in Open Dylan@footnote{http://opendylan.org/}, and may be awkward to use for other use
cases. If you need more general handling of weak references,
@ref{d8,,contact us}.
@end quotation
@end cartouche

@geindex AWL pool class; properties

@menu
* AWL properties:: 
* Dependent objects:: 
* Protection faults:: 
* Caution:: 
* AWL interface:: 

@end menu

@node AWL properties,Dependent objects,,AWL Automatic Weak Linked
@anchor{pool/awl awl-properties}@anchor{36c}
@subsection AWL properties



@itemize *

@item 
Does not support allocation via @ref{ad,,mps_alloc()} or deallocation
via @ref{1f,,mps_free()}.

@item 
Supports allocation via @ref{63,,allocation points}. If an allocation
point is created in an AWL pool, the call to
@ref{af,,mps_ap_create_k()} accepts one optional keyword argument,
@code{MPS_KEY_RANK}.

@item 
Supports @ref{27d,,allocation frames} but does not use them to improve
the efficiency of stack-like allocation.

@item 
Does not support @ref{1b2,,segregated allocation caches}.

@item 
Garbage collections are scheduled automatically. See
@ref{226,,Scheduling of collections}.

@item 
Does not use @ref{e,,generational garbage collection}, so blocks are
never promoted out of the generation in which they are allocated.

@item 
Blocks may contain @ref{61,,exact references} or @ref{c,,weak references (1)} to blocks in the same or other pools (but may not
contain @ref{9f,,ambiguous references}, and may not use @ref{35d,,remote references}).

@item 
Allocations may be variable in size.

@item 
The @ref{68,,alignment} of blocks is configurable.

@item 
Blocks may have @ref{ff,,dependent objects}.

@item 
Blocks that are not @ref{96,,reachable} from a @ref{97,,root} are
automatically @ref{4a,,reclaimed}.

@item 
Blocks are @ref{65,,scanned}.

@item 
Blocks may only be referenced by @ref{1aa,,base pointers} (unless they
have @ref{1d1,,in-band headers}).

@item 
Blocks may be protected by @ref{60,,barriers (1)}.

@item 
Blocks do not @ref{5d,,move}.

@item 
Blocks may be registered for @ref{b,,finalization}.

@item 
Blocks must belong to an @ref{39,,object format} which provides
@ref{73,,scan} and @ref{81,,skip} methods.

@item 
Blocks may have @ref{1d1,,in-band headers}.
@end itemize

@geindex AWL pool class; dependent object

@node Dependent objects,Protection faults,AWL properties,AWL Automatic Weak Linked
@anchor{pool/awl dependent-objects}@anchor{36d}@anchor{pool/awl pool-awl-dependent}@anchor{100}
@subsection Dependent objects


In order to support prompt deletion of values in a @ref{fb,,weak-key hash table} when the key is @ref{245,,splatted} (and prompt
deletion of keys in a @ref{fc,,weak-value hash table}), an AWL pool
allows each object to have a `dependent object'. (This is where
the “Linked” in the name of the pool class comes from.)

The dependent object is specified by the
@code{MPS_KEY_AWL_FIND_DEPENDENT} keyword argument to
@ref{166,,mps_pool_create_k()} when creating an AWL pool. This is a
function of type @ref{36e,,mps_awl_find_dependent_t} that takes the
address of an object in the pool and returns the address of its
dependent object (or a null pointer if there is no corresponding
dependent object).

When @ref{65,,scanning} an object in an AWL pool, the MPS ensures
that the dependent object is not protected. This means that the
@ref{73,,scan method} in the pool’s @ref{39,,object format} can read or
write the dependent object.

If an object contains a reference to its dependent object, you should
@ref{b4,,fix} that reference, and be aware that if it is a weak
reference then it may be splatted when the dependent object dies.

The way you would normally use this feature in a weak hash table would
be to put the table’s keys in one object, and its values in another.
(This would be necessary in any case, because the MPS does not support
a mixture of @ref{61,,exact references} and @ref{c,,weak references (1)}
in the same object.) The dependent object for the keys objects is the
values object, and vice versa (if necessary). The scan method looks
out for the splatting of a reference, and when this is detected, it
splats the corresponding reference in the dependent object.

For example:

@example
obj_t obj_deleted;              /* deleted entry in hash table */

typedef struct weak_array_s @{
    struct weak_array_s *dependent;
    size_t length;              /* tagged as "length * 2 + 1" */
    obj_t slot[1];
@} weak_array_s, *weak_array_t;

typedef weak_table_s @{
    type_s type;                /* TYPE_WEAK_TABLE */
    weak_array_t keys, values;
@} weak_table_s, *weak_table_t;

mps_addr_t weak_array_find_dependent(mps_addr_t addr)
@{
    weak_array_t a = addr;
    return a->dependent;
@}

mps_res_t weak_array_scan(mps_ss_t ss, mps_addr_t base, mps_addr_t limit)
@{
    MPS_SCAN_BEGIN(ss) @{
        while (base < limit) @{
            mps_addr_t p;
            weak_array_t a = base;
            size_t i, length = a->length >> 1; /* untag */
            p = a->dependent;
            MPS_FIX12(ss, &p);
            a->dependent = p;
            for (i = 0; i < length; ++i) @{
                p = a->slot[i];
                if (MPS_FIX1(ss, p)) @{
                    mps_res_t res = MPS_FIX2(ss, &p);
                    if (res != MPS_RES_OK) return res;
                    if (p == NULL && a->dependent) @{
                        /* key/value was splatted: splat value/key too */
                        a->dependent->slot[i] = obj_deleted;
                        a->slot[i] = obj_deleted;
                    @} else @{
                        a->slot[i] = p;
                    @}
                @}
            @}
            base += offsetof(weak_array_s, slot) + a->length * sizeof a->slot[0];
        @}
    @} MPS_SCAN_END(ss);
    return MPS_RES_OK;
@}
@end example

@cartouche
@quotation Note 
The @code{length} field of the @code{weak_array_s} structure contains
the value @code{length * 2 + 1} so that it cannot be mistaken for a
pointer. See @ref{101,,Caution} below.
@end quotation
@end cartouche

@geindex AWL pool class; protection faults

@node Protection faults,Caution,Dependent objects,AWL Automatic Weak Linked
@anchor{pool/awl pool-awl-barrier}@anchor{36f}@anchor{pool/awl protection-faults}@anchor{370}
@subsection Protection faults


AWL has another special power: it enables better handing of
@ref{1d7,,protection faults} on `weak objects' (objects containing
@ref{c,,weak references (1)}).

To explain the benefit we first need to describe the problem. The MPS
uses a @ref{1d6,,read barrier} to perform @ref{d,,incremental garbage collection}. When the client program tries to read an object
containing @ref{c,,weak references (1)}, the MPS may have
@ref{1fd,,protected} it so that the MPS can process the
object before the client gets to see it.

The problem is that the client program may try to access a weak object
at a point in the @ref{1a2,,collection cycle} when the MPS cannot yet
determine the status of the objects that the weak object refers to.
What the MPS does in this situation is assume that all the referenced
objects are going to live. This assumption is correct but
conservative; it may result in objects that are weakly referenced
staying alive for longer than they need to. In the worst case this can
result in a very large amount of memory being used by objects that are
no longer needed.

In order to combat this problem the MPS sometimes does the following:
Instead of processing the entire weak object and unprotecting it, so
that the client program can access the object, the MPS may emulate the
processor instruction. When this happens, the MPS doesn’t process the
entire weak object; it only processes the exact location that was
being accessed (typically a single word). It emulates the processor
instruction, and it keeps the object protected. This happens invisibly
from the client program’s perspective: it’s exactly as if the
instruction executed as normal.

Naturally this emulation business is delicate and involves staring at
the most badly written parts of low-level processor architecture
manuals for days.

Emulation of accesses to protected objects happens when all of the
following are true:


@enumerate 

@item 
The object is a weak object allocated in an AWL pool.

@item 
The MPS is running on Linux/IA-32 or Windows/IA-32. Extending this
list to new (reasonable) operating systems should be tolerable (for
example, macOS/IA-32). Extending this to new processor architectures
requires more work.

@item 
The processor instruction that is accessing the object is of a
suitable simple form. The MPS doesn’t contain an emulator for all
possible instructions that might access memory, so currently it
only recognizes and emulates a simple @code{MOV} from memory to a
register or vice-versa.
@end enumerate

@ref{d8,,Contact us} if you need emulation of access to weak
references for new operating systems, processor architectures, or
memory access instructions.

@geindex AWL pool class; cautions

@node Caution,AWL interface,Protection faults,AWL Automatic Weak Linked
@anchor{pool/awl caution}@anchor{371}@anchor{pool/awl pool-awl-caution}@anchor{101}
@subsection Caution


Because of the instruction emulation described in
@ref{36f,,Protection faults} above, AWL places the following restriction on
the format of objects allocated in it:


@itemize *

@item 
Each slot in an object must either be a valid word-aligned
reference, or else the bottom bits of the word must be non-zero so
that it does not look like an aligned pointer.

“Aligned pointer” means a word whose numeric value (that is, its
value when treated as an unsigned integer) is a multiple of the size
of a pointer. If you’re using a 64-bit architecture, that means that
an aligned pointer is a multiple of 8 and its bottom three bits are
zero.

The bottom line is that references from an object in an AWL pool
must be untagged and aligned, and integers must be tagged with a
non-zero tag.
@end itemize

Normally one would cope with this restriction by allocating the table
metadata in a pool belonging to another pool class, and only
allocating the arrays of keys and values in an AWL pool. See @ref{100,,the example} above.

@geindex AWL pool class; interface

@node AWL interface,,Caution,AWL Automatic Weak Linked
@anchor{pool/awl awl-interface}@anchor{372}
@subsection AWL interface


@example
#include "mpscawl.h"
@end example

@geindex mps_class_awl (C function)
@anchor{pool/awl c mps_class_awl}@anchor{139}
@deffn {C Function} @ref{1b4,,mps_pool_class_t} mps_class_awl (void)

Return the @ref{10,,pool class} for an AWL (Automatic Weak Linked)
@ref{18,,pool}.

When creating an AWL pool, @ref{166,,mps_pool_create_k()} requires
one @ref{53,,keyword argument}:


@itemize *

@item 
@code{MPS_KEY_FORMAT} (type @ref{141,,mps_fmt_t}) specifies
the @ref{39,,object format} for the objects allocated in the pool.
The format must provide a @ref{73,,scan method} and a @ref{81,,skip method}.
@end itemize

It accepts three optional keyword arguments:


@itemize *

@item 
@code{MPS_KEY_AWL_FIND_DEPENDENT} (type
@ref{36e,,mps_awl_find_dependent_t}) is a function that specifies
how to find the @ref{ff,,dependent object} for an object in the
pool. This defaults to a function that always returns @code{NULL}
(meaning that there is no dependent object).

@item 
@code{MPS_KEY_CHAIN} (type @ref{13a,,mps_chain_t}) specifies
the @ref{e2,,generation chain} for the pool. If not specified, the
pool will use the arena’s default chain.

@item 
@code{MPS_KEY_GEN} (type @code{unsigned}) specifies the
@ref{e1,,generation} in the chain into which new objects will be
allocated. If you pass your own chain, then this defaults to
@code{0}, but if you didn’t (and so use the arena’s default chain),
then an appropriate generation is used.

Note that AWL does not use generational garbage collection, so
blocks remain in this generation and are not promoted.
@end itemize

For example:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_FORMAT, fmt);
    MPS_ARGS_ADD(args, MPS_KEY_AWL_FIND_DEPENDENT, find_dependent);
    res = mps_pool_create_k(&pool, arena, mps_class_awl(), args);
@} MPS_ARGS_END(args);
@end example

When creating an @ref{63,,allocation point} on an AWL pool,
@ref{af,,mps_ap_create_k()} accepts one optional keyword argument:


@itemize *

@item 
@code{MPS_KEY_RANK} (type @ref{146,,mps_rank_t}, default
@ref{9d,,mps_rank_exact()}) specifies the @ref{9e,,rank} of
references in objects allocated on this allocation point. It
must be @ref{9d,,mps_rank_exact()} (if the objects allocated on
this allocation point will contain @ref{61,,exact references}), or
@ref{20c,,mps_rank_weak()} (if the objects will contain @ref{c,,weak references (1)}).
@end itemize

For example:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_RANK, mps_rank_weak());
    res = mps_ap_create_k(&ap, awl_pool, args);
@} MPS_ARGS_END(args);
@end example
@end deffn

@geindex mps_awl_find_dependent_t (C type)
@anchor{pool/awl c mps_awl_find_dependent_t}@anchor{36e}
@deffn {C Type} typedef @ref{11d,,mps_addr_t} (*mps_awl_find_dependent_t)(@ref{11d,,mps_addr_t} addr)

The type of functions that find the @ref{ff,,dependent object} for
an object in an AWL pool.

@code{addr} is the address of an object in an AWL pool.

Returns the address of the corresponding dependent object, or a
null pointer if there is none.

The dependent object need not be in memory managed by the MPS, but
if it is, then it must be in a @ref{5e,,non-moving} pool in the same arena as @code{addr}.
@end deffn

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/master/manual/wiki/pool_classes.html>`_
@c `<https://info.ravenbrook.com/project/mps/master/design/poollo/>`_

@geindex LO pool class
@geindex pool class; LO

@node LO Leaf Object,MFS Manual Fixed Small,AWL Automatic Weak Linked,Pool reference
@anchor{pool/lo doc}@anchor{373}@anchor{pool/lo lo-leaf-object}@anchor{374}@anchor{pool/lo pool-lo}@anchor{353}
@section LO (Leaf Object)


`LO' is an @ref{9,,automatically managed} @ref{10,,pool class} for @ref{107,,leaf objects} (objects that
contain no references). It does not move or protect its objects.

This pool class is intended for unstructured data that needs to be
accessed by @ref{10b,,foreign code}. It’s ideal for allocating a buffer
that needs to be passed to an operating system I/O function.

@cartouche
@quotation Note 
A thread that reads or writes from blocks allocated in this pool
need not be @ref{1f9,,registered with the arena} so long as the @ref{78,,liveness} of
the block is independent of that thread.

This means that you can launch a thread to read or write a buffer
allocated in this pool, without having to register the thread, so
long as you ensure that the buffer remains alive until the thread
has finished (for example, by keeping a reference to the buffer in
a @ref{97,,root} or a @ref{65,,scanned} object).
@end quotation
@end cartouche

If LO is used to allocate large numbers of small objects, the garbage
collection performance will degrade. For leaf objects that can move
and be protected, it is better to use @ref{89,,AMCZ (Automatic Mostly-Copying Zero-rank)} instead.

@geindex LO pool class; properties

@menu
* LO properties:: 
* LO interface:: 

@end menu

@node LO properties,LO interface,,LO Leaf Object
@anchor{pool/lo lo-properties}@anchor{375}
@subsection LO properties



@itemize *

@item 
Does not support allocation via @ref{ad,,mps_alloc()} or deallocation
via @ref{1f,,mps_free()}.

@item 
Supports allocation via @ref{63,,allocation points}. If an allocation
point is created in a LO pool, the call to
@ref{af,,mps_ap_create_k()} takes no keyword arguments.

@item 
Supports @ref{27d,,allocation frames} but does not use them to improve
the efficiency of stack-like allocation.

@item 
Does not support @ref{1b2,,segregated allocation caches}.

@item 
Garbage collections are scheduled automatically. See
@ref{226,,Scheduling of collections}.

@item 
Does not use @ref{e,,generational garbage collection}, so blocks are
never promoted out of the generation in which they are allocated.

@item 
Blocks may not contain @ref{24,,references} to blocks in automatically
managed pools.

@item 
Allocations may be variable in size.

@item 
The @ref{68,,alignment} of blocks is configurable.

@item 
Blocks do not have @ref{ff,,dependent objects}.

@item 
Blocks that are not @ref{96,,reachable} from a @ref{97,,root} are
automatically @ref{4a,,reclaimed}.

@item 
Blocks are not @ref{65,,scanned}. A consequence of this is that
the pool’s @ref{39,,object format} need not provide a @ref{73,,scan method}.

@item 
Blocks may only be referenced by @ref{1aa,,base pointers} (unless they
have @ref{1d1,,in-band headers}).

@item 
Blocks are not protected by @ref{60,,barriers (1)}.

@item 
Blocks do not @ref{5d,,move}.

@item 
Blocks may be registered for @ref{b,,finalization}.

@item 
Blocks must belong to an @ref{39,,object format} which provides
@ref{73,,scan} and @ref{81,,skip} methods.

@item 
Blocks may have @ref{1d1,,in-band headers}.
@end itemize

@geindex LO pool class; interface

@node LO interface,,LO properties,LO Leaf Object
@anchor{pool/lo lo-interface}@anchor{376}
@subsection LO interface


@example
#include "mpsclo.h"
@end example

@geindex mps_class_lo (C function)
@anchor{pool/lo c mps_class_lo}@anchor{13d}
@deffn {C Function} @ref{1b4,,mps_pool_class_t} mps_class_lo (void)

Return the @ref{10,,pool class} for an LO (Leaf Object)
@ref{18,,pool}.

When creating an LO pool, @ref{166,,mps_pool_create_k()} requires one
@ref{53,,keyword argument}:


@itemize *

@item 
@code{MPS_KEY_FORMAT} (type @ref{141,,mps_fmt_t}) specifies
the @ref{39,,object format} for the objects allocated in the pool.
The format must provide a @ref{81,,skip method}.
@end itemize

It accepts two optional keyword arguments:


@itemize *

@item 
@code{MPS_KEY_CHAIN} (type @ref{13a,,mps_chain_t}) specifies
the @ref{e2,,generation chain} for the pool. If not specified, the
pool will use the arena’s default chain.

@item 
@code{MPS_KEY_GEN} (type @code{unsigned}) specifies the
@ref{e1,,generation} in the chain into which new objects will be
allocated. If you pass your own chain, then this defaults to
@code{0}, but if you didn’t (and so use the arena’s default chain),
then an appropriate generation is used.

Note that LO does not use generational garbage collection, so
blocks remain in this generation and are not promoted.
@end itemize

For example:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_FORMAT, fmt);
    res = mps_pool_create_k(&pool, arena, mps_class_lo(), args);
@} MPS_ARGS_END(args);
@end example
@end deffn

@geindex MFS pool class
@geindex pool class; MFS

@node MFS Manual Fixed Small,MVFF Manual Variable First Fit,LO Leaf Object,Pool reference
@anchor{pool/mfs doc}@anchor{377}@anchor{pool/mfs mfs-manual-fixed-small}@anchor{378}@anchor{pool/mfs pool-mfs}@anchor{355}
@section MFS (Manual Fixed Small)


`MFS' is an @ref{8,,manually managed}
@ref{10,,pool class} for small objects of fixed size.

Unlike other manual pool classes, it is not subject to @ref{379,,internal fragmentation}: if the population remains bounded, the memory usage
remains bounded too. On the other hand, unlike @ref{1bc,,MVT (Manual Variable Temporal)} and
@ref{10c,,MVFF (Manual Variable First Fit)} it does not return unused memory to the arena for
reuse by other pools.

The implementation is very simple: unlike most other @ref{10,,pool classes} which store their control structures separately from the
allocated blocks, MFS maintains a stack of free blocks using a pointer
in the free block. @ref{ad,,mps_alloc()} pops this stack and
@ref{1f,,mps_free()} pushes it.

@geindex MFS pool class; properties

@menu
* MFS properties:: 
* MFS interface:: 

@end menu

@node MFS properties,MFS interface,,MFS Manual Fixed Small
@anchor{pool/mfs mfs-properties}@anchor{37a}
@subsection MFS properties



@itemize *

@item 
Supports allocation via @ref{ad,,mps_alloc()} and deallocation via
@ref{1f,,mps_free()}.

@item 
Does not support allocation via @ref{63,,allocation points}.

@item 
Does not support @ref{27d,,allocation frames}.

@item 
Supports @ref{1b2,,segregated allocation caches} (but using one would
be pointless, since all blocks are the same size).

@item 
There are no garbage collections in this pool.

@item 
Blocks may not contain @ref{24,,references} to blocks in automatically
managed pools (unless these are registered as @ref{97,,roots}).

@item 
Allocations are fixed in size.

@item 
The @ref{68,,alignment} of blocks is not configurable: it is the
@ref{70,,natural alignment} of the platform (see
@ref{6f,,MPS_PF_ALIGN}).

@item 
Blocks do not have @ref{ff,,dependent objects}.

@item 
Blocks are not automatically @ref{4a,,reclaimed}.

@item 
Blocks are not @ref{65,,scanned}.

@item 
Blocks are not protected by @ref{60,,barriers (1)}.

@item 
Blocks do not @ref{5d,,move}.

@item 
Blocks may not be registered for @ref{b,,finalization}.

@item 
Blocks must not belong to an @ref{39,,object format}.
@end itemize

@geindex MFS pool class; interface

@node MFS interface,,MFS properties,MFS Manual Fixed Small
@anchor{pool/mfs mfs-interface}@anchor{37b}
@subsection MFS interface


@example
#include "mpscmfs.h"
@end example

@geindex mps_class_mfs (C function)
@anchor{pool/mfs c mps_class_mfs}@anchor{13e}
@deffn {C Function} @ref{1b4,,mps_pool_class_t} mps_class_mfs (void)

Return the @ref{10,,pool class} for an MFS (Manual Fixed Small)
@ref{18,,pool}.

When creating an MFS pool, @ref{166,,mps_pool_create_k()} requires
one @ref{53,,keyword argument}:


@itemize *

@item 
@code{MPS_KEY_MFS_UNIT_SIZE} (type @code{size_t}) is the
@ref{183,,size} of blocks that will be allocated from this pool, in
@ref{17c,,bytes (1)}. It must be at least one @ref{37c,,word}.
@end itemize

In addition, @ref{166,,mps_pool_create_k()} accepts one optional
keyword argument:


@itemize *

@item 
@code{MPS_KEY_EXTEND_BY} (type @code{size_t},
default 65536) is the @ref{183,,size} of extent that the pool will
request from the @ref{16,,arena}. For efficiency, this should be
much larger than @code{MPS_KEY_MFS_UNIT_SIZE}, so that many
blocks fit into each extent.
@end itemize

For example:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_MFS_UNIT_SIZE, 1024);
    MPS_ARGS_ADD(args, MPS_KEY_EXTEND_BY, 1024 * 1024);
    res = mps_pool_create_k(&pool, arena, mps_class_mfs(), args);
@} MPS_ARGS_END(args);
@end example
@end deffn

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/master/design/poolmvff/>`_

@geindex MVFF pool class
@geindex pool class; MVFF

@node MVFF Manual Variable First Fit,MVT Manual Variable Temporal,MFS Manual Fixed Small,Pool reference
@anchor{pool/mvff doc}@anchor{37d}@anchor{pool/mvff mvff-manual-variable-first-fit}@anchor{37e}@anchor{pool/mvff pool-mvff}@anchor{10c}
@section MVFF (Manual Variable First Fit)


`MVFF' @ref{8,,manually manages}
variable-sized, unformatted objects. It uses the @ref{37f,,first fit}
@ref{380,,allocation policy} for blocks allocated via
@ref{ad,,mps_alloc()}.

@ref{381,,Johnstone (1997)} found that in his test cases:

@quotation

No version of @ref{382,,best fit} had more than 5% actual
@ref{383,,fragmentation}. This is also true
for all versions of first fit that used an @ref{384,,address-ordered free list}, and the two versions of
first fit that used a @ref{385,,FIFO free list}. This strongly suggests that the basic best-fit algorithm
and the first-fit algorithm with an address-ordered free list are
very robust algorithms.
@end quotation

The MVFF pool class also supports buffered allocation (that is,
allocation via @ref{63,,allocation points}), and in this case, the
allocation policy is different: the buffers are filled according to
the @ref{386,,worst fit} policy, and allocation always proceeds upwards
from the base.

Buffered and unbuffered allocation can be used at the same time, but
the first allocation point must be created before any call to
@ref{ad,,mps_alloc()}.

It is usually not advisable to use buffered and unbuffered allocation
on the same pool, because the worst-fit policy of buffer filling will
grab all the large blocks, leading to severe fragmentation. If you
need both forms of allocation, use two separate pools.

@geindex MVFF pool class; properties

@menu
* MVFF properties:: 
* MVFF interface:: 

@end menu

@node MVFF properties,MVFF interface,,MVFF Manual Variable First Fit
@anchor{pool/mvff mvff-properties}@anchor{387}
@subsection MVFF properties



@itemize *

@item 
Supports allocation via @ref{ad,,mps_alloc()}.

@item 
Supports allocation via @ref{63,,allocation points}. If an allocation
point is created in an MVFF pool, the call to
@ref{af,,mps_ap_create_k()} takes no keyword arguments.

@item 
Supports deallocation via @ref{1f,,mps_free()}.

@item 
Supports @ref{27d,,allocation frames} but does not use them to improve
the efficiency of stack-like allocation.

@item 
Supports @ref{1b2,,segregated allocation caches}.

@item 
There are no garbage collections in this pool.

@item 
Blocks may not contain @ref{24,,references} to blocks in automatically
managed pools (unless these are registered as @ref{97,,roots}).

@item 
Allocations may be variable in size.

@item 
The @ref{68,,alignment} of blocks is configurable, but may not be
smaller than @code{sizeof(void *)}.

@item 
Blocks do not have @ref{ff,,dependent objects}.

@item 
Blocks are not automatically @ref{4a,,reclaimed}.

@item 
Blocks are not @ref{65,,scanned}.

@item 
Blocks are not protected by @ref{60,,barriers (1)}.

@item 
Blocks do not @ref{5d,,move}.

@item 
Blocks may not be registered for @ref{b,,finalization}.

@item 
Blocks must not belong to an @ref{39,,object format}.
@end itemize

@geindex MVFF pool class; interface

@node MVFF interface,,MVFF properties,MVFF Manual Variable First Fit
@anchor{pool/mvff mvff-interface}@anchor{388}
@subsection MVFF interface


@example
#include "mpscmvff.h"
@end example

@geindex mps_class_mvff (C function)
@anchor{pool/mvff c mps_class_mvff}@anchor{136}
@deffn {C Function} @ref{1b4,,mps_pool_class_t} mps_class_mvff (void)

Return the @ref{10,,pool class} for an MVFF (Manual Variable First
Fit) @ref{18,,pool}.

When creating an MVFF pool, @ref{166,,mps_pool_create_k()} accepts
seven optional @ref{53,,keyword arguments}:


@itemize *

@item 
@code{MPS_KEY_EXTEND_BY} (type @code{size_t}, default
65536) is the @ref{183,,size} of block that the pool will request
from the @ref{16,,arena}.

@item 
@code{MPS_KEY_MEAN_SIZE} (type @code{size_t}, default 32)
is the predicted mean size of blocks that will be allocated from
the pool. This is a `hint' to the MPS: the pool will be less
efficient if this is wrong, but nothing will break.

@item 
@code{MPS_KEY_ALIGN} (type @ref{128,,mps_align_t}, default is
@ref{6f,,MPS_PF_ALIGN}) is the @ref{68,,alignment} of the
addresses allocated (and freed) in the pool. The minimum
alignment supported by pools of this class is @code{sizeof(void *)}
and the maximum is the arena grain size
(see @code{MPS_KEY_ARENA_GRAIN_SIZE}).

@item 
@code{MPS_KEY_SPARE} (type @code{double}, default 0.75)
is the maximum proportion of memory that the pool will keep
spare for future allocations. If the proportion of memory that’s
free exceeds this, then the pool will return some of it to the
arena for use by other pools.

@item 
@code{MPS_KEY_MVFF_ARENA_HIGH} (type @ref{129,,mps_bool_t},
default false) determines whether new blocks are acquired at high
addresses (if true), or at low addresses (if false).

@item 
@code{MPS_KEY_MVFF_SLOT_HIGH} @footnote{
Allocation points are not affected by
@code{MPS_KEY_MVFF_SLOT_HIGH} or
@code{MPS_KEY_MVFF_FIRST_FIT}.
They use a worst-fit policy in order to maximise the number of
in-line allocations.
} (type
@ref{129,,mps_bool_t}, default false) determines whether to
search for the highest addressed free area (if true) or lowest
(if false) when allocating using @ref{ad,,mps_alloc()}.

@item 
@code{MPS_KEY_MVFF_FIRST_FIT} @footnote{
Allocation points are not affected by
@code{MPS_KEY_MVFF_SLOT_HIGH} or
@code{MPS_KEY_MVFF_FIRST_FIT}.
They use a worst-fit policy in order to maximise the number of
in-line allocations.
} (type
@ref{129,,mps_bool_t}, default true) determines whether to
allocate from the highest address in a found free area (if true)
or lowest (if false) when allocating using @ref{ad,,mps_alloc()}.
@end itemize

The defaults yield a simple first-fit allocator. Specify
@code{MPS_KEY_MVFF_ARENA_HIGH} and
@code{MPS_KEY_MVFF_SLOT_HIGH} true, and
@code{MPS_KEY_MVFF_FIRST_FIT} false to get a first-fit
allocator that works from the top of memory downwards. Other
combinations may be useful in special circumstances.

For example:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_EXTEND_BY, 1024 * 1024);
    MPS_ARGS_ADD(args, MPS_KEY_MEAN_SIZE, 32);
    MPS_ARGS_ADD(args, MPS_KEY_ALIGN, 8);
    MPS_ARGS_ADD(args, MPS_KEY_MVFF_ARENA_HIGH, 1);
    MPS_ARGS_ADD(args, MPS_KEY_MVFF_SLOT_HIGH, 1);
    MPS_ARGS_ADD(args, MPS_KEY_MVFF_FIRST_FIT, 0);
    res = mps_pool_create_k(&pool, arena, mps_class_mvff(), args);
@} MPS_ARGS_END(args);
@end example
@end deffn

@geindex mps_class_mvff_debug (C function)
@anchor{pool/mvff c mps_class_mvff_debug}@anchor{145}
@deffn {C Function} @ref{1b4,,mps_pool_class_t} mps_class_mvff_debug (void)

A @ref{10d,,debugging} version of the MVFF pool
class.

When creating a debugging MVFF pool, @ref{166,,mps_pool_create_k()}
accepts eight optional @ref{53,,keyword arguments}:
@code{MPS_KEY_EXTEND_BY}, @code{MPS_KEY_MEAN_SIZE},
@code{MPS_KEY_ALIGN}, @code{MPS_KEY_SPARE},
@code{MPS_KEY_MVFF_ARENA_HIGH},
@code{MPS_KEY_MVFF_SLOT_HIGH}, and
@code{MPS_KEY_MVFF_FIRST_FIT} are as described above, and
@code{MPS_KEY_POOL_DEBUG_OPTIONS} specifies the debugging
options. See @ref{143,,mps_pool_debug_option_s}.
@end deffn

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/master/design/poolmvt/>`_

@geindex MVT pool class
@geindex pool class; MVT

@node MVT Manual Variable Temporal,SNC Stack No Checking,MVFF Manual Variable First Fit,Pool reference
@anchor{pool/mvt doc}@anchor{389}@anchor{pool/mvt mvt-manual-variable-temporal}@anchor{38a}@anchor{pool/mvt pool-mvt}@anchor{1bc}
@section MVT (Manual Variable Temporal)


`MVT' @ref{8,,manually manages}
variable-sized, unformatted objects. It uses the `temporal fit'
@ref{380,,allocation policy}.

@geindex MVT pool class; temporal fit
@geindex allocation policy; temporal fit

@menu
* Temporal fit:: 
* MVT properties:: 
* MVT interface:: 

@end menu

@node Temporal fit,MVT properties,,MVT Manual Variable Temporal
@anchor{pool/mvt temporal-fit}@anchor{38b}
@subsection Temporal fit


Temporal fit attempts to place consecutive allocations next to each
other. It relies on delaying re-use as long as possible to permit freed
blocks to @ref{38c,,coalesce}, thus maximizing the number of consecutive
allocations that can be co-located. Temporal fit permits a very fast
allocator and a deallocator competitive in speed with all other known
policies.

Temporal fit is intended to take advantage of knowledge of object
@ref{b5,,lifetimes}: either `a priori' knowledge, or knowledge acquired
by profiling. The best performance will be achieved by allocating
objects with similar expected death times together.

A simple policy can be implemented to take advantage of MVT. Object
size is typically well-correlated with object life-expectancy, and
birth time plus lifetime gives death time, so allocating objects of
similar size sequentially from the same pool instance should result in
objects allocated close to each other dying at about the same time.

An application that has several classes of objects of widely differing
life expectancy will best be served by creating a different MVT pool
instance for each life-expectancy class. A more sophisticated policy
can use either the programmer’s knowledge of the expected lifetime of
an object, or any characteristic of objects that correlates with
lifetime, to choose an appropriate pool to allocate in.

Allocating objects with unknown or very different death times together
will pessimize the space performance of MVT.

@geindex MVT pool class; properties

@node MVT properties,MVT interface,Temporal fit,MVT Manual Variable Temporal
@anchor{pool/mvt mvt-properties}@anchor{38d}
@subsection MVT properties



@itemize *

@item 
Does not support allocation via @ref{ad,,mps_alloc()}.

@item 
Supports allocation via @ref{63,,allocation points} only. If an
allocation point is created in an MVT pool, the call to
@ref{af,,mps_ap_create_k()} takes no keyword arguments.

@item 
Supports deallocation via @ref{1f,,mps_free()}.

@item 
Supports @ref{27d,,allocation frames} but does not use them to improve
the efficiency of stack-like allocation.

@item 
Does not support @ref{1b2,,segregated allocation caches}.

@item 
There are no garbage collections in this pool.

@item 
Blocks may not contain @ref{24,,references} to blocks in automatically
managed pools (unless these are registered as @ref{97,,roots}).

@item 
Allocations may be variable in size.

@item 
The @ref{68,,alignment} of blocks is configurable, but may not be
smaller than @code{sizeof(void *)}.

@item 
Blocks do not have @ref{ff,,dependent objects}.

@item 
Blocks are not automatically @ref{4a,,reclaimed}.

@item 
Blocks are not @ref{65,,scanned}.

@item 
Blocks are not protected by @ref{60,,barriers (1)}.

@item 
Blocks do not @ref{5d,,move}.

@item 
Blocks may not be registered for @ref{b,,finalization}.

@item 
Blocks must not belong to an @ref{39,,object format}.
@end itemize

@geindex MVT pool class; interface

@node MVT interface,,MVT properties,MVT Manual Variable Temporal
@anchor{pool/mvt mvt-interface}@anchor{38e}
@subsection MVT interface


@example
#include "mpscmvt.h"
@end example

@geindex mps_class_mvt (C function)
@anchor{pool/mvt c mps_class_mvt}@anchor{137}
@deffn {C Function} @ref{1b4,,mps_pool_class_t} mps_class_mvt (void)

Return the @ref{10,,pool class} for an MVT (Manual Variable
Temporal) @ref{18,,pool}.

When creating an MVT pool, @ref{166,,mps_pool_create_k()} accepts six
optional @ref{53,,keyword arguments}:


@itemize *

@item 
@code{MPS_KEY_ALIGN} (type @ref{128,,mps_align_t}, default is
@ref{6f,,MPS_PF_ALIGN}) is the @ref{68,,alignment} of the
addresses allocated (and freed) in the pool. The minimum
alignment supported by pools of this class is @code{sizeof(void *)}
and the maximum is the arena grain size
(see @code{MPS_KEY_ARENA_GRAIN_SIZE}).

@item 
@code{MPS_KEY_MIN_SIZE} (type @code{size_t}, default is
@ref{6f,,MPS_PF_ALIGN}) is the
predicted minimum size of blocks that will be allocated from the
pool.

@item 
@code{MPS_KEY_MEAN_SIZE} (type @code{size_t}, default 32) is the
predicted mean size of blocks that will be allocated from the
pool.

@item 
@code{MPS_KEY_MAX_SIZE} (type @code{size_t}, default 8192) is the
predicted maximum size of blocks that will be allocated from the
pool. Partial freeing is not supported for blocks larger than
this; doing so will result in the storage of the block never
being reused.
@end itemize

The three @code{SIZE} arguments above are `hints' to the MPS: the
pool will be less efficient if they are wrong, but the only thing
that will break is the partial freeing of large blocks.


@itemize *

@item 
@code{MPS_KEY_MVT_RESERVE_DEPTH} (type
@ref{6d,,mps_word_t}, default 1024) is the expected hysteresis
of the population of the pool. When blocks are freed, the pool
will retain sufficient storage to allocate this many blocks of the
mean size for near term allocations (rather than immediately
making that storage available to other pools).

If a pool has a stable population, or one which only grows over
the lifetime of the pool, or one which grows steadily and then
shrinks steadily, use a reserve depth of 0.

It is always safe to use a reserve depth of 0, but if the
population typically fluctuates in a range (for example, the
client program repeatedly creates and destroys a subset of
blocks in a loop), it is more efficient for the pool to retain
enough storage to satisfy that fluctuation. For example, if a
pool has an object population that typically fluctuates between
8,000 and 10,000, use a reserve depth of 2,000.

The reserve will not normally be available to other pools for
allocation, even when it is not used by the pool. If this is
undesirable, a reserve depth of 0 may be used for a pool whose
object population does vary, at a slight cost in efficiency. The
reserve does not guarantee any particular amount of allocation.

@item 
@code{MPS_KEY_MVT_FRAG_LIMIT} (type @code{double}, default 0.3)
may range from 0.0 to 1.0 (inclusive). It sets an upper limit on
the space overhead of an MVT pool, in case block death times and
allocations do not correlate well. If the free space managed by
the pool as a ratio of all the space managed by the pool exceeds
the fragmentation limit, the pool falls back to a first fit
allocation policy, exploiting space more efficiently at a cost
in time efficiency. A fragmentation limit of 0.0 would cause the
pool to operate as a first-fit pool, at a significant cost in
time efficiency: therefore this is not permitted.

A fragmentation limit of 1.0 causes the pool to always use
temporal fit (unless resources are exhausted). If the objects
allocated in the pool have similar lifetime expectancies, this
mode will have the best time- and space-efficiency. If the
objects have widely varying lifetime expectancies, this mode
will be time-efficient, but may be space-inefficient. An
intermediate setting can be used to limit the space-inefficiency
of temporal fit due to varying object life expectancies.
@end itemize

For example:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_MIN_SIZE, 4);
    MPS_ARGS_ADD(args, MPS_KEY_MEAN_SIZE, 32);
    MPS_ARGS_ADD(args, MPS_KEY_MAX_SIZE, 1024);
    MPS_ARGS_ADD(args, MPS_KEY_MVT_RESERVE_DEPTH, 256);
    MPS_ARGS_ADD(args, MPS_KEY_MVT_FRAG_LIMIT, 0.5);
    res = mps_pool_create_k(&pool, arena, mps_class_mvt(), args);
@} MPS_ARGS_END(args);
@end example
@end deffn

@c Sources:
@c 
@c `<https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mmdoc/doc/mps/guide/stack-alloc/>`_

@geindex SNC pool class
@geindex pool class; SNC

@node SNC Stack No Checking,,MVT Manual Variable Temporal,Pool reference
@anchor{pool/snc doc}@anchor{38f}@anchor{pool/snc pool-snc}@anchor{27b}@anchor{pool/snc snc-stack-no-checking}@anchor{390}
@section SNC (Stack No Checking)


`SNC' is a @ref{8,,manually managed}
@ref{10,,pool class} that supports a stack-like protocol for allocation
and deallocation using @ref{27d,,allocation frames} on @ref{63,,allocation points}. See @ref{27a,,Allocation frames}.

If @ref{16d,,mps_ap_frame_pop()} is used on an allocation point in an SNC
pool (after a corresponding call to @ref{16e,,mps_ap_frame_push()}), then
the objects affected by the pop are assumed to be dead, and are
reclaimed by the collector without checking whether there are any
references to them.

This pool class is intended to be used to implement stack languages
like Forth and PostScript, where some objects are allocated in stack
frames and are known to be dead when the stack is popped, because the
language can ensure that objects that are kept alive when the stack is
popped are copied to the heap.

@geindex SNC pool class; properties

@menu
* SNC properties:: 
* SNC interface:: 

@end menu

@node SNC properties,SNC interface,,SNC Stack No Checking
@anchor{pool/snc snc-properties}@anchor{391}
@subsection SNC properties



@itemize *

@item 
Does not support allocation via @ref{ad,,mps_alloc()}.

@item 
Supports allocation via @ref{63,,allocation points} only. If an
allocation point is created in an SNC pool, the call to
@ref{af,,mps_ap_create_k()} accepts one optional keyword argument,
@code{MPS_KEY_RANK}.

@item 
Does not support deallocation via @ref{1f,,mps_free()}.

@item 
Supports @ref{27d,,allocation frames}.

@item 
Does not support @ref{1b2,,segregated allocation caches}.

@item 
Blocks may contain @ref{61,,exact references} to blocks in the same or
other pools (but may not contain @ref{9f,,ambiguous references} or
@ref{c,,weak references (1)}, and may not use @ref{35d,,remote references}).

@item 
There are no garbage collections in this pool.

@item 
Allocations may be variable in size.

@item 
The @ref{68,,alignment} of blocks is configurable.

@item 
Blocks do not have @ref{ff,,dependent objects}.

@item 
Blocks are not automatically @ref{4a,,reclaimed}.

@item 
Blocks are @ref{65,,scanned}.

@item 
Blocks may only be referenced by @ref{1aa,,base pointers}.

@item 
Blocks are not protected by @ref{60,,barriers (1)}.

@item 
Blocks do not @ref{5d,,move}.

@item 
Blocks may not be registered for @ref{b,,finalization}.

@item 
Blocks must belong to an @ref{39,,object format} which provides
@ref{73,,scan}, @ref{81,,skip}, and
@ref{90,,padding} methods.

@item 
Blocks must not have @ref{1d1,,in-band headers}.
@end itemize

@geindex SNC pool class; interface

@node SNC interface,,SNC properties,SNC Stack No Checking
@anchor{pool/snc snc-interface}@anchor{392}
@subsection SNC interface


@example
#include "mpscsnc.h"
@end example

@geindex mps_class_snc (C function)
@anchor{pool/snc c mps_class_snc}@anchor{142}
@deffn {C Function} @ref{1b4,,mps_pool_class_t} mps_class_snc (void)

Return the @ref{10,,pool class} for an SNC (Stack No Check)
@ref{18,,pool}.

When creating an SNC pool, @ref{166,,mps_pool_create_k()} requires one
@ref{53,,keyword argument}:


@itemize *

@item 
@code{MPS_KEY_FORMAT} (type @ref{141,,mps_fmt_t}) specifies
the @ref{39,,object format} for the objects allocated in the pool.
The format must provide a @ref{73,,scan method}, a @ref{81,,skip method}, and a @ref{90,,padding method}.
@end itemize

For example:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_FORMAT, fmt);
    res = mps_pool_create_k(&pool, arena, mps_class_snc(), args);
@} MPS_ARGS_END(args);
@end example

When creating an @ref{63,,allocation point} on an SNC pool,
@ref{af,,mps_ap_create_k()} accepts one optional keyword argument:


@itemize *

@item 
@code{MPS_KEY_RANK} (type @ref{146,,mps_rank_t}, default
@ref{9d,,mps_rank_exact()}) specifies the @ref{9e,,rank} of references
in objects allocated on this allocation point.
@end itemize

For example:

@example
MPS_ARGS_BEGIN(args) @{
    MPS_ARGS_ADD(args, MPS_KEY_RANK, mps_rank_exact());
    res = mps_ap_create_k(&ap, awl_pool, args);
@} MPS_ARGS_END(args);
@end example
@end deffn

@c manual/source/design/index.rst -- index of designs in MPS manual

@c See design.mps.doc.impl.manual.design.

@c NOTE: If there is a discrepancy between the design directory and
@c this list then Sphinx will produce a warning.

@c TODO: Generate this list from the design directory rather than rely
@c in keeping it updated.

@node Design,Old design,Pool reference,Top
@anchor{design/index doc}@anchor{393}@anchor{design/index design}@anchor{31a}@anchor{design/index id1}@anchor{394}
@chapter Design


@cartouche
@quotation Warning 
The documents in this section are included from the working
designs in the MPS source tree.  They are intended for developers
of the MPS.  They vary a great deal in detail depending on the
risks associated with the things they describe.
@end quotation
@end cartouche

@geindex fixed-length queues; design

@menu
* Fixed-length queues:: 
* Generic modules:: 
* Bootstrapping:: 
* Coalescing block structures:: 
* Fast high-resolution clock:: 
* MPS Configuration:: 
* The critical path through the MPS:: 
* Documentation:: 
* Execution environment:: 
* Fail-over allocator:: 
* Finalization: Finalization<3>. 
* Free list allocator:: 
* New developer guide:: 
* Transliterating the alphabet into hexadecimal:: 
* C Style – formatting:: 
* C Style – naming:: 
* Review checklist:: 
* C interface design:: 
* Keyword arguments in the MPS:: 
* Lands:: 
* Lock module:: 
* Client message protocol:: 
* Monitor:: 
* Nailboards for ambiguously referenced segments:: 
* Pool classes: Pool classes<2>. 
* Mutator context:: 
* Memory protection:: 
* POSIX implementation of protection module:: 
* Ranges of addresses:: 
* Ring data structure:: 
* Shield:: 
* Signatures in the MPS:: 
* Stack probe:: 
* Splay trees:: 
* Stack and register scanning:: 
* Tests:: 
* Multi-threaded testing:: 
* Thread manager:: 
* Thread safety in the MPS:: 
* Transforms: Transforms<2>. 
* General MPS types:: 
* Library version mechanism:: 
* Virtual mapping:: 
* Walking formatted objects:: 
* Write barrier:: 
* The WriteF function:: 

@end menu

@node Fixed-length queues,Generic modules,,Design
@anchor{design/abq doc}@anchor{395}@anchor{design/abq design-abq}@anchor{396}@anchor{design/abq fixed-length-queues}@anchor{397}
@section Fixed-length queues


@menu
* Introduction: Introduction<2>. 
* Requirements:: 
* Interface: Interface<3>. 

@end menu

@node Introduction<2>,Requirements,,Fixed-length queues
@anchor{design/abq design mps abq}@anchor{398}@anchor{design/abq introduction}@anchor{399}
@subsection Introduction


@anchor{design/abq design mps abq intro}@anchor{39a}@ref{39a,,.intro;} This is the design of the ABQ module, which implements a
fixed-length queue of small objects.

@anchor{design/abq design mps abq readership}@anchor{39b}@ref{39b,,.readership;} This document is intended for any MM developer.

@anchor{design/abq design mps abq name}@anchor{39c}@ref{39c,,.name;} The name ABQ originally stood for “Available Block Queue” as
the module is used by the MVT pool.

@node Requirements,Interface<3>,Introduction<2>,Fixed-length queues
@anchor{design/abq requirements}@anchor{39d}
@subsection Requirements


@anchor{design/abq design mps abq req push}@anchor{39e}@ref{39e,,.req.push;} Clients can efficiently push new elements onto the queue.

@anchor{design/abq design mps abq req pop}@anchor{39f}@ref{39f,,.req.pop;} Clients can efficiently pop elements from the queue.

@anchor{design/abq design mps abq req empty}@anchor{3a0}@ref{3a0,,.req.empty;} Clients can efficiently test whether the queue is empty.

@anchor{design/abq design mps abq req abstract}@anchor{3a1}@ref{3a1,,.req.abstract;} The ABQ module does not know anything about the
elements in the queue other than their size.

@anchor{design/abq design mps abq req delete}@anchor{3a2}@ref{3a2,,.req.delete;} Clients can delete elements from the queue. (Note: not necessarily efficiently.)

@anchor{design/abq design mps abq req iterate}@anchor{3a3}@ref{3a3,,.req.iterate;} Clients can iterate over elements in the queue.

@node Interface<3>,,Requirements,Fixed-length queues
@anchor{design/abq interface}@anchor{3a4}
@subsection Interface


@geindex ABQ (C type)
@anchor{design/abq c ABQ}@anchor{3a5}
@deffn {C Type} typedef ABQStruct *ABQ
@end deffn

@ref{3a5,,ABQ} is the type of a queue. It is an alias for @code{ABQStruct *}.
@code{ABQStruct} is defined in the header so that it can be inlined in
client structures: clients must not depend on its implementation
details.

@geindex ABQInit (C function)
@anchor{design/abq c ABQInit}@anchor{3a6}
@deffn {C Function} void ABQInit (Arena arena, ABQ abq, void *owner, Count elements, Size elementSize)
@end deffn

Initialize the queue @code{abq}. The parameter @code{arena} is the arena
whose control pool should be used to allocate the memory for the
queue; @code{owner} is passed to @code{MeterInit()} for the statistics;
@code{elements} is the maximum number of elements that can be stored in
the queue; and @code{elementSize} is the size of each element.

@geindex ABQFinish (C function)
@anchor{design/abq c ABQFinish}@anchor{3a7}
@deffn {C Function} void ABQFinish (Arena arena, ABQ abq)
@end deffn

Finish @code{abq} and free all resources associated with it.

@geindex ABQPush (C function)
@anchor{design/abq c ABQPush}@anchor{3a8}
@deffn {C Function} @ref{3a9,,Bool} ABQPush (ABQ abq, void *element)
@end deffn

If the queue is full, leave it unchanged and return @code{FALSE}.
Otherwise, push @code{element} on to the queue and return @code{TRUE}.

@geindex ABQPop (C function)
@anchor{design/abq c ABQPop}@anchor{3aa}
@deffn {C Function} @ref{3a9,,Bool} ABQPop (ABQ abq, void *elementReturn)
@end deffn

If the queue is empty, return @code{FALSE}. Otherwise, copy the first
element on the queue into the memory pointed to by @code{elementReturn},
remove the element from the queue, and return @code{TRUE}.

@geindex ABQPeek (C function)
@anchor{design/abq c ABQPeek}@anchor{3ab}
@deffn {C Function} @ref{3a9,,Bool} ABQPeek (ABQ abq, void *elementReturn)
@end deffn

If the queue is empty, return @code{FALSE}. Otherwise, copy the first
element on the queue into the memory pointed to by @code{elementReturn}
and return @code{TRUE}. (This is the same as @ref{3aa,,ABQPop()} except that
the queue is unchanged.)

@geindex ABQIsEmpty (C function)
@anchor{design/abq c ABQIsEmpty}@anchor{3ac}
@deffn {C Function} @ref{3a9,,Bool} ABQIsEmpty (ABQ abq)
@end deffn

If the queue is empty, return @code{TRUE}, otherwise return @code{FALSE}.

@geindex ABQIsFull (C function)
@anchor{design/abq c ABQIsFull}@anchor{3ad}
@deffn {C Function} @ref{3a9,,Bool} ABQIsFull (ABQ abq)
@end deffn

If the queue is full, return @code{TRUE}, otherwise return @code{FALSE}.

@geindex ABQDepth (C function)
@anchor{design/abq c ABQDepth}@anchor{3ae}
@deffn {C Function} @ref{3af,,Count} ABQDepth (ABQ abq)
@end deffn

Return the number of elements in the queue.

@geindex ABQVisitor (C type)
@anchor{design/abq c ABQVisitor}@anchor{3b0}
@deffn {C Type} typedef @ref{3a9,,Bool} (*ABQVisitor)(@ref{3a9,,Bool} *deleteReturn, void *element, void *closure)
@end deffn

A callback function for @ref{3b1,,ABQIterate()}. The parameter @code{element} is
an element in the queue, and @code{closure} is the value originally
passed to @ref{3b1,,ABQIterate()}. This function must set @code{*deleteReturn}
to @code{FALSE} if @code{element} must be kept in the queue, or @code{TRUE} if
@code{element} must be deleted from the queue.  It must return @code{TRUE}
if the iteration must continue, or @code{FALSE} if the iteration must
stop after processing @code{element}.

@geindex ABQIterate (C function)
@anchor{design/abq c ABQIterate}@anchor{3b1}
@deffn {C Function} void ABQIterate (ABQ abq, ABQVisitor visitor, void *closure)
@end deffn

Call @code{visitor} for each element in the queue, passing the element
and @code{closure}. See @code{ABQVisitor} for details.

@geindex generic modules; design

@node Generic modules,Bootstrapping,Fixed-length queues,Design
@anchor{design/an doc}@anchor{3b2}@anchor{design/an design-an}@anchor{3b3}@anchor{design/an generic-modules}@anchor{3b4}
@section Generic modules


@menu
* Introduction: Introduction<3>. 
* Requirements: Requirements<2>. 
* Design: Design<2>. 
* Modules:: 
* Limitations of generic implementations:: 

@end menu

@node Introduction<3>,Requirements<2>,,Generic modules
@anchor{design/an design mps an}@anchor{3b5}@anchor{design/an introduction}@anchor{3b6}
@subsection Introduction


@anchor{design/an design mps an intro}@anchor{3b7}@ref{3b7,,.intro;} This is the design of generic modules in the MPS.

@anchor{design/an design mps an readership}@anchor{3b8}@ref{3b8,,.readership;} Any MPS developer; anyone porting the MPS to a new
platform.

@anchor{design/an design mps an overview}@anchor{3b9}@ref{3b9,,.overview;} Generic modules provide implementations of functional
modules using only the features of the Standard C Library. These
implementations are partially functional or non-functional, but
provide a basis for ports of the MPS to new platforms.

@anchor{design/an design mps an name}@anchor{3ba}@ref{3ba,,.name;} The name “ANSI” for the generic modules is historical: the C
language was originally standardized by the American National
Standards Institute, and so Standard C used to be known as “ANSI C”.

@node Requirements<2>,Design<2>,Introduction<3>,Generic modules
@anchor{design/an requirements}@anchor{3bb}
@subsection Requirements


@anchor{design/an design mps an req port}@anchor{3bc}@ref{3bc,,.req.port;} The MPS must be portable to new platforms. (Otherwise we
can’t meet the needs of customers using new platforms.)

@anchor{design/an design mps an req port rapid}@anchor{3bd}@ref{3bd,,.req.port.rapid;} The MPS should be portable to new platforms
rapidly.

@anchor{design/an design mps an req port rapid expert}@anchor{3be}@ref{3be,,.req.port.rapid.expert;} An expert MPS developer (who may be a
novice on the new platform) should be able to get a minimally useful
implementation of the MPS running on a new platform within a few
hours.

@anchor{design/an design mps an req port rapid novice}@anchor{3bf}@ref{3bf,,.req.port.rapid.novice;} A novice MPS developer (who is an expert on
the new platform) should be able to get the MPS running on a new
platform within a few days.

@node Design<2>,Modules,Requirements<2>,Generic modules
@anchor{design/an design}@anchor{3c0}
@subsection Design


@anchor{design/an design mps an sol modules}@anchor{3c1}@ref{3c1,,.sol.modules;} Features of the MPS which can benefit from
platform-specific implementations are divided into `functional
modules', with clean interfaces to the MPS and to each other. See
@ref{3c2,,.mod} for a list of these modules. (This helps meet @ref{3bc,,.req.port} by
isolating the platform dependencies, and it helps meet
@ref{3bd,,.req.port.rapid} because a porter can mix and match implementations,
using existing implementations where possible.)

@anchor{design/an design mps an sol generic}@anchor{3c3}@ref{3c3,,.sol.generic;} Each functional module has a generic implementation
using only features of the Standard C Library. (This helps meet
@ref{3bd,,.req.port.rapid} because the MPS can be ported in stages, starting
with the generic modules and porting the modules needed to meet the
most urgent requirements. The generic implementations help meet
@ref{3bf,,.req.port.rapid.novice} by providing clear and illustrative
examples.)

@anchor{design/an design mps an sol fallback}@anchor{3c4}@ref{3c4,,.sol.fallback;} The interfaces to the modules are designed to make
it possible to implement @ref{3c3,,.sol.generic}. When a platform-specific
feature is needed to meet performance (or other attribute)
requirements, the interface also makes it possible to meet the
functional requirements while missing the attribute requirements. See
@ref{3c5,,.sol.fallback.example} for an example. (This helps meet
@ref{3bd,,.req.port.rapid} by allowing the generic implementations to meet
many or most of the functional requirements.)

@anchor{design/an design mps an sol fallback example}@anchor{3c5}@ref{3c5,,.sol.fallback.example;} The MPS normally uses incremental collection
to meet requirements on pause times, but this requires barriers. The
interface to the protection module is designed to make it possible to
write an implementation without barriers, via the function
@ref{3c6,,ProtSync()} that synchronizes the mutator with the collector.

@anchor{design/an design mps an sol test}@anchor{3c7}@ref{3c7,,.sol.test;} There are makefiles for the pseudo-platforms @code{anangc},
@code{ananll} and @code{ananmv} that compile and test the generic
implementations. See design.mps.config.opt@footnote{config.html#design.mps.config.opt} for the configuration
options used to implement these platforms. (This supports
@ref{3bd,,.req.port.rapid} by making sure that the generic implementations are
working when it is time to use them.)

@node Modules,Limitations of generic implementations,Design<2>,Generic modules
@anchor{design/an design-mps-config-opt}@anchor{3c8}@anchor{design/an modules}@anchor{3c9}
@subsection Modules


@anchor{design/an design mps an mod}@anchor{3c2}@ref{3c2,,.mod;} This section lists the functional modules in the MPS.

@anchor{design/an design mps an mod lock}@anchor{3ca}@ref{3ca,,.mod.lock;} Locks. See design.mps.lock@footnote{lock.html}.

@anchor{design/an design mps an mod prmc}@anchor{3cb}@ref{3cb,,.mod.prmc;} Mutator context. See design.mps.prmc@footnote{prmc.html}.

@anchor{design/an design mps an mod prot}@anchor{3cc}@ref{3cc,,.mod.prot;} Memory protection. See design.mps.prot@footnote{prot.html}.

@anchor{design/an design mps an mod sp}@anchor{3cd}@ref{3cd,,.mod.sp;} Stack probe. See design.mps.sp@footnote{sp.html}.

@anchor{design/an design mps an mod ss}@anchor{3ce}@ref{3ce,,.mod.ss;} Stack scanning. See design.mps.stack-scan@footnote{stack-scan.html}.

@anchor{design/an design mps an mod th}@anchor{3cf}@ref{3cf,,.mod.th;} Thread manager. See design.mps.thread-manager@footnote{thread-manager.html}.

@anchor{design/an design mps an mod vm}@anchor{3d0}@ref{3d0,,.mod.vm;} Virtual mapping. See design.mps.vm@footnote{vm.html}.

@node Limitations of generic implementations,,Modules,Generic modules
@anchor{design/an design-mps-vm}@anchor{3d1}@anchor{design/an limitations-of-generic-implementations}@anchor{3d2}
@subsection Limitations of generic implementations


@anchor{design/an design mps an lim}@anchor{3d3}@ref{3d3,,.lim;} This section summarizes the limitations of the generic
implementations of the function modules.

@anchor{design/an design mps an lim lock}@anchor{3d4}@ref{3d4,,.lim.lock;} Requires a single-threaded mutator (see
design.mps.lock.impl.an@footnote{lock.html#design.mps.lock.impl.an}).

@anchor{design/an design mps an lim prmc}@anchor{3d5}@ref{3d5,,.lim.prmc;} Does not support single-stepping of accesses (see
design.mps.prmc.impl.an.fault@footnote{prmc.html#design.mps.prmc.impl.an.fault}) and requires a single-threaded mutator
(see design.mps.prmc.impl.an.suspend@footnote{prmc.html#design.mps.prmc.impl.an.suspend}).

@anchor{design/an design mps an lim prot}@anchor{3d6}@ref{3d6,,.lim.prot;} Does not support incremental collection (see
design.mps.prot.impl.an.sync@footnote{prot.html#design.mps.prot.impl.an.sync}) and is not compatible with
implementations of the mutator context module that support
single-stepping of accesses (see design.mps.prot.impl.an.sync.issue@footnote{prot.html#design.mps.prot.impl.an.sync.issue}).

@anchor{design/an design mps an lim sp}@anchor{3d7}@ref{3d7,,.lim.sp;} Only suitable for use with programs that do not handle
stack overflow faults, or do not call into the MPS from the handler
(see design.mps.sp.issue.an@footnote{sp.html#design.mps.sp.issue.an}).

@anchor{design/an design mps an lim stack-scan}@anchor{3d8}@ref{3d8,,.lim.stack-scan;} Assumes that the stack grows downwards and that
@code{setjmp()} reliably captures the registers (see design.mps.stack-scan.sol.stack.platform@footnote{stack-scan.html#design.mps.stack-scan.sol.stack.platform}).

@anchor{design/an design mps an lim th}@anchor{3d9}@ref{3d9,,.lim.th;} Requires a single-threaded mutator (see
design.mps.thread-manager.impl.an.single@footnote{thread-manager.html#design.mps.thread-manager.impl.an.single}).

@anchor{design/an design mps an lim vm}@anchor{3da}@ref{3da,,.lim.vm;} Maps all reserved addresses into main memory (see
design.mps.vm.impl.an.reserve@footnote{vm.html#design.mps.vm.impl.an.reserve}), thus using more main memory than a
platform-specific implementation.

@geindex bootstrap; design

@node Bootstrapping,Coalescing block structures,Generic modules,Design
@anchor{design/bootstrap doc}@anchor{3db}@anchor{design/bootstrap bootstrapping}@anchor{3dc}@anchor{design/bootstrap design-bootstrap}@anchor{3dd}@anchor{design/bootstrap design-mps-vm-impl-an-reserve}@anchor{3de}
@section Bootstrapping


@menu
* Introduction: Introduction<4>. 
* Bootstrapping problems:: 

@end menu

@node Introduction<4>,Bootstrapping problems,,Bootstrapping
@anchor{design/bootstrap design mps bootstrap}@anchor{3df}@anchor{design/bootstrap introduction}@anchor{3e0}
@subsection Introduction


@anchor{design/bootstrap design mps bootstrap intro}@anchor{3e1}@ref{3e1,,.intro;} This explains how the MPS gets started.

@anchor{design/bootstrap design mps bootstrap readership}@anchor{3e2}@ref{3e2,,.readership;} Any MPS developer.

@anchor{design/bootstrap design mps bootstrap overview}@anchor{3e3}@ref{3e3,,.overview;} The job of the MPS is to allocate memory to a program.
Before it can allocate memory, the MPS needs to create data structures
to represent its internal state. But before it can create those data
structures, it needs to allocate memory to store them in. This
bootstrapping problem affects the MPS at several points, which are
listed here, together with their solutions.

@node Bootstrapping problems,,Introduction<4>,Bootstrapping
@anchor{design/bootstrap bootstrapping-problems}@anchor{3e4}
@subsection Bootstrapping problems


@menu
* Virtual memory descriptor:: 
* Arena descriptor:: 
* Arena’s free land:: 

@end menu

@node Virtual memory descriptor,Arena descriptor,,Bootstrapping problems
@anchor{design/bootstrap virtual-memory-descriptor}@anchor{3e5}
@subsubsection Virtual memory descriptor


@anchor{design/bootstrap design mps bootstrap vm}@anchor{3e6}@ref{3e6,,.vm;} Before address space can be mapped into main memory, the
virtual memory descriptor must be initialized. But before the virtual
memory descriptor can be initialized, some address space must be
mapped into main memory in order to store it. See
design.vm.req.bootstrap@footnote{vm#req.bootstrap}.

@anchor{design/bootstrap design mps bootstrap vm sol}@anchor{3e7}@ref{3e7,,.vm.sol;} The virtual memory descriptor is allocated initially on
the stack, and then copied into its place in the chunk after the
memory for it has been mapped. See design.vm.sol.bootstrap@footnote{vm#sol.bootstrap}.

@node Arena descriptor,Arena’s free land,Virtual memory descriptor,Bootstrapping problems
@anchor{design/bootstrap arena-descriptor}@anchor{3e8}@anchor{design/bootstrap design-vm-sol-bootstrap}@anchor{3e9}
@subsubsection Arena descriptor


@anchor{design/bootstrap design mps bootstrap arena}@anchor{3ea}@ref{3ea,,.arena;} Before chunks of address space can be reserved and mapped,
the virtual memory arena descriptor must be initialized (so that the
chunks can be added to the arena’s chunk tree). But before a virtual
memory arena descriptor can be initialized, address space must be
reserved and mapped in order to store it.

@anchor{design/bootstrap design mps bootstrap arena sol}@anchor{3eb}@ref{3eb,,.arena.sol;} A small amount of address space is reserved and mapped
directly via @ref{3ec,,VMInit()} and @ref{3ed,,VMMap()} (not via the chunk system)
in order to provide enough memory for the arena descriptor.

@node Arena’s free land,,Arena descriptor,Bootstrapping problems
@anchor{design/bootstrap arena-s-free-land}@anchor{3ee}
@subsubsection Arena’s free land


@anchor{design/bootstrap design mps bootstrap land}@anchor{3ef}@ref{3ef,,.land;} Before the arena can allocate memory, a range of addresses
must be inserted into the arena’s free land (so that the free land can
hand out memory from this range). But before addresses can be inserted
into the arena’s free land, the free land’s block pool must have
memory from the arena to store the nodes in the tree representing
those addresses.

@anchor{design/bootstrap design mps bootstrap land sol}@anchor{3f0}@ref{3f0,,.land.sol;} The arena has two “back door” mechanisms and uses them
in combination.

@anchor{design/bootstrap design mps bootstrap land sol alloc}@anchor{3f1}@ref{3f1,,.land.sol.alloc;} First, there is a mechanism for allocating a
page of memory directly from a chunk, bypassing the free land.

@anchor{design/bootstrap design mps bootstrap land sol pool}@anchor{3f2}@ref{3f2,,.land.sol.pool;} Second, the free land’s block pool has an option to
prevent it extending itself by allocating memory from the arena.
Instead, it fails allocations with @code{ResLIMIT}.  The free land’s
block pool also has a mechanism, @code{MFSExtend} to extend it with a
block of memory.  When the free land fails with @code{ResLIMIT} the arena
uses @ref{3f1,,.land.sol.alloc} to provide it with memory.

@geindex coalescing block structures; design

@node Coalescing block structures,Fast high-resolution clock,Bootstrapping,Design
@anchor{design/cbs doc}@anchor{3f3}@anchor{design/cbs coalescing-block-structures}@anchor{3f4}@anchor{design/cbs design-cbs}@anchor{3f5}
@section Coalescing block structures


@menu
* Introduction: Introduction<5>. 
* Requirements: Requirements<3>. 
* Interface: Interface<4>. 
* Implementation:: 
* Testing:: 
* Notes for future development:: 
* Risks:: 

@end menu

@node Introduction<5>,Requirements<3>,,Coalescing block structures
@anchor{design/cbs design mps cbs}@anchor{3f6}@anchor{design/cbs introduction}@anchor{3f7}
@subsection Introduction


@anchor{design/cbs design mps cbs intro}@anchor{3f8}@ref{3f8,,.intro;} This is the design for impl.c.cbs, which implements a data
structure for the management of non-intersecting memory ranges, with
eager coalescence.

@anchor{design/cbs design mps cbs readership}@anchor{3f9}@ref{3f9,,.readership;} This document is intended for any MM developer.

@anchor{design/cbs design mps cbs source}@anchor{3fa}@ref{3fa,,.source;} design.mps.poolmvt@footnote{poolmvt.html}, design.mps.poolmvff@footnote{poolmvff.html}.

@anchor{design/cbs design mps cbs overview}@anchor{3fb}@ref{3fb,,.overview;} The “coalescing block structure” is a set of addresses
(or a subset of address space), with provision for efficient
management of contiguous ranges, including insertion and deletion,
high level communication with the client about the size of contiguous
ranges, and detection of protocol violations.

@node Requirements<3>,Interface<4>,Introduction<5>,Coalescing block structures
@anchor{design/cbs requirements}@anchor{3fc}
@subsection Requirements


In addition to the generic land requirements (see
design.mps.land@footnote{land.html}), the CBS must satisfy:

@anchor{design/cbs design mps cbs req fast}@anchor{3fd}@ref{3fd,,.req.fast;} Common operations must have a low amortized cost.

@anchor{design/cbs design mps cbs req small}@anchor{3fe}@ref{3fe,,.req.small;} Must have a small space overhead for the storage of
typical subsets of address space and not have abysmal overhead for the
storage of any subset of address space.

@node Interface<4>,Implementation,Requirements<3>,Coalescing block structures
@anchor{design/cbs interface}@anchor{3ff}
@subsection Interface


@anchor{design/cbs design mps cbs land}@anchor{400}@ref{400,,.land;} CBS is an implementation of the `land' abstract data type,
so the interface consists of the generic functions for lands. See
design.mps.land@footnote{land.html}.

@menu
* External types:: 
* External classes:: 
* Keyword arguments: Keyword arguments<2>. 
* Limitations:: 

@end menu

@node External types,External classes,,Interface<4>
@anchor{design/cbs external-types}@anchor{401}
@subsubsection External types


@geindex CBS (C type)
@anchor{design/cbs c CBS}@anchor{402}
@deffn {C Type} typedef struct CBSStruct *CBS
@end deffn

@anchor{design/cbs design mps cbs type cbs}@anchor{403}@ref{403,,.type.cbs;} The type of coalescing block structures. A @code{CBSStruct}
is typically embedded in another structure.

@node External classes,Keyword arguments<2>,External types,Interface<4>
@anchor{design/cbs external-classes}@anchor{404}
@subsubsection External classes


@anchor{design/cbs design mps cbs class cbs}@anchor{405}@ref{405,,.class.cbs;} @code{CLASS(CBS)} is the CBS class, a subclass of
@code{CLASS(Land)} suitable for passing to @ref{406,,LandInit()}.

@anchor{design/cbs design mps cbs class fast}@anchor{407}@ref{407,,.class.fast;} @code{CLASS(CBSFast)} is subclass of @code{CLASS(CBS)} that
maintains, for each subtree, the size of the largest block in that
subtree. This enables the @ref{408,,LandFindFirst()}, @ref{409,,LandFindLast()}, and
@ref{40a,,LandFindLargest()} generic functions.

@anchor{design/cbs design mps cbs class zoned}@anchor{40b}@ref{40b,,.class.zoned;} @code{CLASS(CBSZoned)} is a subclass of
@code{CLASS(CBSFast)} that maintains, for each subtree, the union of the
zone sets of all ranges in that subtree. This enables the
@ref{40c,,LandFindInZones()} generic function.

@node Keyword arguments<2>,Limitations,External classes,Interface<4>
@anchor{design/cbs keyword-arguments}@anchor{40d}
@subsubsection Keyword arguments


When initializing a CBS, @ref{406,,LandInit()} takes the following optional
keyword arguments:


@itemize *

@item 
@code{CBSBlockPool} (type @code{Pool}) is the pool from which the CBS
block descriptors will be allocated. If omitted, a new MFS pool is
created for this purpose.

@item 
@code{MPS_KEY_CBS_EXTEND_BY} (type @ref{40e,,Size}; default 4096) is passed as
the @code{MPS_KEY_EXTEND_BY} keyword argument to @code{PoolCreate()} if a
block descriptor pool is created. It specifies the size of segment
that the block descriptor pool will request from the arena.

@item 
@code{MFSExtendSelf} (type @ref{3a9,,Bool}; default @code{TRUE}) is passed to
@code{PoolCreate()} if a block descriptor pool is created. If @code{TRUE},
the block descriptor pool automatically extends itself when out of
space; if @code{FALSE}, the pool returns @code{ResLIMIT} in this case.
(This feature is used by the arena to bootstrap its own CBS of free
memory. See design.mps.bootstrap.land.sol.pool@footnote{bootstrap.html#design.mps.bootstrap.land.sol.pool}.)
@end itemize

@node Limitations,,Keyword arguments<2>,Interface<4>
@anchor{design/cbs limitations}@anchor{40f}
@subsubsection Limitations


@anchor{design/cbs design mps cbs limit find}@anchor{410}@ref{410,,.limit.find;} @code{CBSLandClass} does not support the
@ref{408,,LandFindFirst()}, @ref{409,,LandFindLast()}, and @ref{40a,,LandFindLargest()}
generic functions (the subclasses do support these operations).

@anchor{design/cbs design mps cbs limit zones}@anchor{411}@ref{411,,.limit.zones;} @code{CBSLandClass} and @code{CBSFastLandClass} do not
support the @ref{40c,,LandFindInZones()} generic function (the subclass
@code{CBSZonedLandClass} does support this operation).

@anchor{design/cbs design mps cbs limit iterate}@anchor{412}@ref{412,,.limit.iterate;} CBS does not provide an implementation for the
@ref{413,,LandIterateAndDelete()} generic function. This is because
@code{TreeTraverse()} does not permit modification, for speed and to
avoid perturbing the splay tree balance.

@anchor{design/cbs design mps cbs limit flush}@anchor{414}@ref{414,,.limit.flush;} CBS cannot be used as the source in a call to
@ref{415,,LandFlush()}. (Because of @ref{412,,.limit.iterate}.)

@node Implementation,Testing,Interface<4>,Coalescing block structures
@anchor{design/cbs implementation}@anchor{416}
@subsection Implementation


@menu
* Splay tree:: 
* Low memory behaviour:: 
* The CBS block:: 

@end menu

@node Splay tree,Low memory behaviour,,Implementation
@anchor{design/cbs splay-tree}@anchor{417}
@subsubsection Splay tree


@anchor{design/cbs design mps cbs impl splay}@anchor{418}@ref{418,,.impl.splay;} The CBS is implemented using a splay tree (see
design.mps.splay@footnote{splay.html}). Each splay tree node is embedded in a block
structure with a semi-open address range (design.mps.range@footnote{range.html}). The
splay tree is ordered by the range base address.

@anchor{design/cbs design mps cbs impl splay fast-find}@anchor{419}@ref{419,,.impl.splay.fast-find;} In the @code{CBSFastLandClass} class,
@code{cbsFindFirst()} and @code{cbsFindLast()} use the update/refresh
facility of splay trees to store, in each block, an accurate summary
of the maximum block size in the tree rooted at the corresponding
splay node. This allows rapid location of the first or last suitable
block, and very rapid failure if there is no suitable block.  For
example, this is used in the implementation of allocation in the MVFF
pool class (design.mps.poolmvff@footnote{poolmvff.html}).

@anchor{design/cbs design mps cbs impl find-largest}@anchor{41a}@ref{41a,,.impl.find-largest;} @code{cbsFindLargest()} simply finds out the size
of the largest block in the CBS from the root of the tree, using
@code{SplayRoot()}, and does @ref{41b,,SplayFindFirst()} for a block of that
size. This takes time proportional to the logarithm of the size of the
free list, so it’s about the best you can do without maintaining a
separate priority queue, just to do @code{cbsFindLargest()}.  For
example, this is used in the implementation of allocation buffers in
the MVFF pool class (design.mps.poolmvff@footnote{poolmvff.html}).

@anchor{design/cbs design mps cbs impl splay zones}@anchor{41c}@ref{41c,,.impl.splay.zones;} In the @code{CBSZonedLandClass} class,
@code{cbsFindInZones()} uses the update/refresh facility of splay trees
to store, in each block, the union of the zones of the ranges in the
tree rooted at the corresponding splay node. This allows rapid
location of a block in a set of zones.  For example, this is used to
allocate segments in particular zones in the arena to optimised
garbage collection (see design.mps.critical-path@footnote{critical-path.html}).

@node Low memory behaviour,The CBS block,Splay tree,Implementation
@anchor{design/cbs design-mps-critical-path}@anchor{41d}@anchor{design/cbs low-memory-behaviour}@anchor{41e}
@subsubsection Low memory behaviour


@anchor{design/cbs design mps cbs impl low-mem}@anchor{41f}@ref{41f,,.impl.low-mem;} When the CBS tries to allocate a new @code{CBSBlock}
structure for a new isolated range as a result of either
@ref{420,,LandInsert()} or @ref{421,,LandDelete()}, and there is insufficient memory
to allocate the block structure, then the range is not added to the
CBS or deleted from it, and the call to @ref{420,,LandInsert()} or
@ref{421,,LandDelete()} returns @code{ResMEMORY}.

@node The CBS block,,Low memory behaviour,Implementation
@anchor{design/cbs the-cbs-block}@anchor{422}
@subsubsection The CBS block


@anchor{design/cbs design mps cbs impl cbs block}@anchor{423}@ref{423,,.impl.cbs.block;} The block contains a non-empty range and a splay
tree node.

@anchor{design/cbs design mps cbs impl cbs block special}@anchor{424}@ref{424,,.impl.cbs.block.special;} The range may be empty if the block is
halfway through being deleted.

@anchor{design/cbs design mps cbs impl cbs block special just}@anchor{425}@ref{425,,.impl.cbs.block.special.just;} This conflates values and status, but
is justified because block size is very important.

@node Testing,Notes for future development,Implementation,Coalescing block structures
@anchor{design/cbs testing}@anchor{426}
@subsection Testing


@anchor{design/cbs design mps cbs test}@anchor{427}@ref{427,,.test;} The following testing will be performed on this module:

@anchor{design/cbs design mps cbs test land}@anchor{428}@ref{428,,.test.land;} A generic test for land implementations. See
design.mps.land.test@footnote{land.html#design.mps.land.test}.

@anchor{design/cbs design mps cbs test pool}@anchor{429}@ref{429,,.test.pool;} The arena and two pools (MVT@footnote{poolmvt} and MVFF@footnote{poolmvff}) are
implemented on top of a CBS. These are subject to testing in
development, QA, and are heavily exercised by customers.

@node Notes for future development,Risks,Testing,Coalescing block structures
@anchor{design/cbs mvff}@anchor{42a}@anchor{design/cbs notes-for-future-development}@anchor{42b}
@subsection Notes for future development


@anchor{design/cbs design mps cbs future not-splay}@anchor{42c}@ref{42c,,.future.not-splay;} The implementation of CBSs is based on splay
trees. It could be revised to use other data structures that meet the
requirements (especially @ref{3fd,,.req.fast}).

@anchor{design/cbs design mps cbs future hybrid}@anchor{42d}@ref{42d,,.future.hybrid;} It would be possible to attenuate the problem of
@ref{42e,,.risk.overhead} (below) by using a single word bit set to represent
the membership in a (possibly aligned) word-width of grains. This
might be used for block sizes less than a word-width of grains,
converting them when they reach all free in the bit set. Note that
this would make coalescence slightly less eager, by up to
@code{(word-width - 1)}.

@anchor{design/cbs design mps cbs future iterate and delete}@anchor{42f}@ref{42f,,.future.iterate.and.delete;} It would be possible to provide an
implementation for the @ref{413,,LandIterateAndDelete()} generic function
using @code{TreeTraverseAndDelete()}, which calls @code{TreeToVine()} first,
iterates over the vine (where deletion is straightforward), and then
rebalances the tree. Note that this is little better than using
@code{SplayFirst()} and @code{SplayNext()}.

@anchor{design/cbs design mps cbs future lazy-coalesce}@anchor{430}@ref{430,,.future.lazy-coalesce;} It’s long been observed that small blocks
are often freed and then reallocated, so that coalescing them is a
waste of time.  It might be worth considering how a splay tree could
implement a lazy coalescing scheme, where blocks are coalesced with
their adjacent neighbours during the search only if they aren’t big
enough.  This would break @ref{41a,,.impl.find-largest} and so might be best
done as a different kind of land.  On the other hand, since the MPS
does not use client memory to store the tree, eager coalescing avoids
allocation.

@node Risks,,Notes for future development,Coalescing block structures
@anchor{design/cbs risks}@anchor{431}
@subsection Risks


@anchor{design/cbs design mps cbs risk overhead}@anchor{42e}@ref{42e,,.risk.overhead;} Clients should note that the current implementation
of CBSs has a space overhead proportional to the number of isolated
contiguous ranges. [Four words per range.] If the CBS contains every
other grain in an area, then the overhead will be large compared to
the size of that area. [Four words per two grains.] The CBS structure
is thus suitable only for managing large enough ranges.

@geindex clock; design

@node Fast high-resolution clock,MPS Configuration,Coalescing block structures,Design
@anchor{design/clock doc}@anchor{432}@anchor{design/clock design-clock}@anchor{309}@anchor{design/clock fast-high-resolution-clock}@anchor{433}
@section Fast high-resolution clock


@menu
* Introduction: Introduction<6>. 
* Requirements: Requirements<4>. 
* Interface: Interface<5>. 
* Implementation: Implementation<2>. 

@end menu

@node Introduction<6>,Requirements<4>,,Fast high-resolution clock
@anchor{design/clock design mps clock}@anchor{434}@anchor{design/clock introduction}@anchor{435}
@subsection Introduction


@anchor{design/clock design mps clock intro}@anchor{436}@ref{436,,.intro;} This is the design of the clock module, which implements a
fast high-resolution clock for use by the telemetry system.

@anchor{design/clock design mps clock readership}@anchor{437}@ref{437,,.readership;} This document is intended for any MPS developer.

@node Requirements<4>,Interface<5>,Introduction<6>,Fast high-resolution clock
@anchor{design/clock requirements}@anchor{438}
@subsection Requirements


@anchor{design/clock design mps clock req monotonic}@anchor{439}@ref{439,,.req.monotonic;} Successive calls to @ref{43a,,EVENT_CLOCK()} must yield
values that are monotonically increasing. (So that comparing the
timestamp on two events never gives false positives.)

@anchor{design/clock design mps clock req fast}@anchor{43b}@ref{43b,,.req.fast;} @ref{43a,,EVENT_CLOCK()} should take very little time; it
should not require a system call. (So that programs that use the MPS
remain usable when telemetry is turned on.)

@anchor{design/clock design mps clock req high-resolution}@anchor{43c}@ref{43c,,.req.high-resolution;} Successive calls to @ref{43a,,EVENT_CLOCK()} should
yield values that are strictly monotonically increasing (so that
sorting the telemetry stream puts the events in the order they
happened).

@node Interface<5>,Implementation<2>,Requirements<4>,Fast high-resolution clock
@anchor{design/clock interface}@anchor{43d}
@subsection Interface


@code{EventClock}

@anchor{design/clock design mps clock if type}@anchor{43e}@ref{43e,,.if.type;} The type of timestamps. It must be an unsigned 64-bit
integral type, for example a @code{typedef} for @code{uint64_t} or
@code{unsigned __int64}.

@geindex EVENT_CLOCK_MAKE (C macro)
@anchor{design/clock c EVENT_CLOCK_MAKE}@anchor{43f}
@deffn {C Macro} EVENT_CLOCK_MAKE (lvalue, low, high)
@end deffn

@anchor{design/clock design mps clock if make}@anchor{440}@ref{440,,.if.make;} Construct an @code{EventClock} timestamp from its two
halves. The first parameter is an lvalue with type @code{EventClock}, and
the second and third parameters are 32-bit unsigned integers. The
macro must assign a timestamp to @code{lvalue} with the value @code{(high
<< 32) + low}.

@geindex EVENT_CLOCK (C macro)
@anchor{design/clock c EVENT_CLOCK}@anchor{43a}
@deffn {C Macro} EVENT_CLOCK (lvalue)
@end deffn

@anchor{design/clock design mps clock if get}@anchor{441}@ref{441,,.if.get;} Assign an @code{EventClock} timestamp for the current time to
@code{lvalue}, which is an lvalue with type @code{EventClock}.

@geindex EVENT_CLOCK_PRINT (C macro)
@anchor{design/clock c EVENT_CLOCK_PRINT}@anchor{442}
@deffn {C Macro} EVENT_CLOCK_PRINT (stream, clock)
@end deffn

@anchor{design/clock design mps clock if print}@anchor{443}@ref{443,,.if.print;} Write the value of @code{clock} to the standard C output
file handle @code{stream} as 16 hexadecimal digits (with leading zeros,
and capital letters A to F).

@geindex EVENT_CLOCK_WRITE (C macro)
@anchor{design/clock c EVENT_CLOCK_WRITE}@anchor{444}
@deffn {C Macro} EVENT_CLOCK_WRITE (stream, clock)
@end deffn

@anchor{design/clock design mps clock if write}@anchor{445}@ref{445,,.if.write;} Write the value of @code{clock} to the output stream
@code{stream} as 16 hexadecimal digits (with leading zeros, and capital
letters A to F). The macro should be implemented using @ref{446,,WriteF()}.

@node Implementation<2>,,Interface<5>,Fast high-resolution clock
@anchor{design/clock implementation}@anchor{447}
@subsection Implementation


@anchor{design/clock design mps clock impl tsc}@anchor{448}@ref{448,,.impl.tsc;} On IA-32 and x86-64, the Time Stamp Counter@footnote{https://en.wikipedia.org/wiki/Time_Stamp_Counter} returned by the
RDTSC instruction is a suitable clock for single-core CPUs, but on
multiple-core CPUs, different cores may have different values or tick at different speeds, and so it may fail to meet @ref{439,,.req.monotonic}.

@geindex configuration; design

@node MPS Configuration,The critical path through the MPS,Fast high-resolution clock,Design
@anchor{design/config doc}@anchor{449}@anchor{design/config design-config}@anchor{314}@anchor{design/config mps-configuration}@anchor{44a}
@section MPS Configuration


@menu
* Introduction: Introduction<7>. 
* Requirements: Requirements<5>. 
* Definitions:: 
* Overview:: 
* The build system:: 
* Implementation: Implementation<3>. 
* Source code configuration:: 
* Configuration options:: 
* To document:: 
* References:: 

@end menu

@node Introduction<7>,Requirements<5>,,MPS Configuration
@anchor{design/config design mps config}@anchor{44b}@anchor{design/config introduction}@anchor{44c}
@subsection Introduction


@anchor{design/config design mps config intro}@anchor{44d}@ref{44d,,.intro;} This document describes how the Memory Pool System@footnote{https://www.ravenbrook.com/project/mps/} source code is configured so
that it can target different architectures, operating systems, build
environments, varieties, and products.

@anchor{design/config design mps config readership}@anchor{44e}@ref{44e,,.readership;} Any MPS developer; anyone porting the MPS to a new
platform.

@node Requirements<5>,Definitions,Introduction<7>,MPS Configuration
@anchor{design/config requirements}@anchor{44f}
@subsection Requirements


@anchor{design/config design mps config req import}@anchor{450}@ref{450,,.req.import;} The MPS must be simple to include in third-party projects.

@anchor{design/config design mps config req arch}@anchor{451}@ref{451,,.req.arch;} Allow architecture specific configurations of the MPS, so
that we can vary the MPS according to the target architecture.

@anchor{design/config design mps config req os}@anchor{452}@ref{452,,.req.os;} Allow operating system specific configurations of the MPS,
so that we can vary the MPS according to the target OS.

@anchor{design/config design mps config req builder}@anchor{453}@ref{453,,.req.builder;} Allow build environment specific configurations of the
MPS, so that we can vary the MPS according to the compiler, etc.

@anchor{design/config design mps config req var}@anchor{454}@ref{454,,.req.var;} Allow configurations with different amounts of
instrumentation (assertions, metering, etc.).

@anchor{design/config design mps config req impact}@anchor{455}@ref{455,,.req.impact;} The configuration system should have a minimal effect on
maintainability of the implementation.

@anchor{design/config design mps config req port}@anchor{456}@ref{456,,.req.port;} The system should be easy to port across platforms.

@anchor{design/config design mps config req maint}@anchor{457}@ref{457,,.req.maint;} Maintenance of the configuration and build system should
not consume much developer time.

@menu
* Retired requirements:: 

@end menu

@node Retired requirements,,,Requirements<5>
@anchor{design/config retired-requirements}@anchor{458}
@subsubsection Retired requirements


@anchor{design/config design mps config req prod}@anchor{459}@ref{459,,.req.prod;} Allow product specific configurations of the MPS, so that
we can build variants of the MPS for use in different products.  This
requirement has been retired on 2012-09-03 as part of work on the
variety-reform@footnote{/project/mps/branch/2012-08-15/variety-reform} branch.  Client-specific customisation of the MPS will
be handled in source control, while the MPS source remains generic, to
reduce costs and increase reliability.  See @ref{45a,,[RB_2012-09-13]}.

@node Definitions,Overview,Requirements<5>,MPS Configuration
@anchor{design/config definitions}@anchor{45b}@anchor{design/config variety-reform}@anchor{45c}
@subsection Definitions


@anchor{design/config design mps config def platform}@anchor{45d}@ref{45d,,.def.platform;} A `platform' is a combination of an architecture
(@ref{45e,,.def.arch}), an operating system (@ref{45f,,.def.os}), and a builder
(@ref{460,,.def.builder}). The set of supported platforms is maintained in the
Platforms section of "Building the Memory Pool System"@footnote{../../../manual/html/guide/build.html#platforms}.

@anchor{design/config design mps config def arch}@anchor{45e}@ref{45e,,.def.arch;} An `architecture' is processor type with associated calling
conventions and other binary interface stuff these days often called the
ABI@footnote{https://en.wikipedia.org/wiki/Application_binary_interface}.
Most importantly for the MPS it determines the layout of the register
file, thread context, and thread stack.

@anchor{design/config design mps config def os}@anchor{45f}@ref{45f,,.def.os;} An `operating system' is the interface to external resources.
Most importantly for the MPS it determines the low level interface to
virtual memory (if any) and threading.

@anchor{design/config design mps config def builder}@anchor{460}@ref{460,,.def.builder;} A `builder' is the tools (C compiler, etc.) used to make
the target (@ref{461,,.def.target}).  The MPS minimises use of compiler-specific
extensions, but this is handy for suppressing warnings, inlining hints,
etc.

@anchor{design/config design mps config def var}@anchor{462}@ref{462,,.def.var;} A `variety' determines things like the amount of debugging,
internal consistency checking, annotation, etc.  In modern IDEs this
called a “build configuration” and the usual default is to have two:
“debug” and “release”. The MPS predates this convention, but the concept
is the same.

@anchor{design/config design mps config def prod}@anchor{463}@ref{463,,.def.prod;} A `product' is the intended product into which the MPS will
fit, e.g. ScriptWorks, Dylan, etc.  We no longer maintain this concept
as a dimension of configuration since @ref{459,,.req.prod} has been retired.

@anchor{design/config design mps config def target}@anchor{461}@ref{461,,.def.target;} The `target' is the result of the build.

@anchor{design/config design mps config def option}@anchor{464}@ref{464,,.def.option;} An `option' is a feature of the MPS that is not
selected via the `platform' and `variety'. See @ref{465,,.opt}.

@node Overview,The build system,Definitions,MPS Configuration
@anchor{design/config overview}@anchor{466}
@subsection Overview


@anchor{design/config design mps config import source}@anchor{467}@ref{467,,.import.source;} The MPS can be simply included in client products as
source code.  Since version 1.110@footnote{https://www.ravenbrook.com/project/mps/version/1.110/} we made it possible to simply
include the file @code{mps.c} in a client’s build process, without
requiring a separate build of the MPS or linking a library.  This is
described section 2.3.1@comma{} "Compiling for production" of the MPS manual@footnote{../../../manual/html/guide/build.html#compiling-for-production}.

@anchor{design/config design mps config no-gen}@anchor{468}@ref{468,,.no-gen;} No generated code or external tools are required.  On most
platforms the only tool is the C compiler.  On 64-bit Windows we require
the assembler since Microsoft withdrew in-line assembler from their C
compiler.

@anchor{design/config design mps config no-spaghetti}@anchor{469}@ref{469,,.no-spaghetti;} Several of the MPS team have worked on some extremely
messy code bases which used a great number of @code{#ifdef} statements.
These quickly became very expensive to maintain and develop.  The
general rule in the MPS is “no @code{#ifdefs}”.  Instead, platform-specific
code is kept in separate source files and selected by carefully controlled
@code{#ifdefs}, such as in mps.c@footnote{../../../code/mps.c}.

@anchor{design/config design mps config min-dep}@anchor{46a}@ref{46a,,.min-dep;} Dependency on a particular configuration should be
minimized and localized when developing code.  This is enshrined in the
general rules for implementation [ref?] that are enforced by MPS
development procedures including code review and inspection.

@node The build system,Implementation<3>,Overview,MPS Configuration
@anchor{design/config the-build-system}@anchor{46b}
@subsection The build system


@menu
* Abstract build function:: 
* File Structure:: 
* Modules and naming:: 
* Build system rationale:: 
* Warnings and errors:: 

@end menu

@node Abstract build function,File Structure,,The build system
@anchor{design/config abstract-build-function}@anchor{46c}
@subsubsection Abstract build function


@anchor{design/config design mps config build fun}@anchor{46d}@ref{46d,,.build.fun;} The MPS implementation assumes only a simple “build
function” that takes a set of sources, possibly in several languages,
compiles them with a set of predefined preprocessor symbols, and links
the result with a set of libraries to form the target:

@example
target := build(<defs>, <srcs>, <libs>)
@end example

@anchor{design/config design mps config build sep}@anchor{46e}@ref{46e,,.build.sep;} Separate compilation and linkage can be seen as a
memoization of this function, and is not strictly necessary for the
build. Indeed, since @cite{version 1.110} we found that modern compilers
are quite happy to compile the whole MPS in one go @ref{467,,.import.source}.

@anchor{design/config design mps config build cc}@anchor{46f}@ref{46f,,.build.cc;} A consequence of this approach is that it should always
be possible to build a complete target with a single UNIX command line
calling the compiler driver (usually “cc” or “gcc”), for example:

@example
cc -o main -DCONFIG_VAR_COOL foo.c bar.c baz.s -lz
@end example

@anchor{design/config design mps config build defs}@anchor{470}@ref{470,,.build.defs;} The “defs” are the set of preprocessor macros which are to be
predefined when compiling the module sources:

@example
CONFIG_VAR_<variety-code>
@end example

@anchor{design/config design mps config var codes}@anchor{471}@ref{471,,.var.codes;} The variety codes are as follows:

@anchor{design/config design mps config var hot}@anchor{472}@ref{472,,.var.hot;} @code{HOT}

@quotation

Intended for release in products.  Optimised, reduced internal
checking, especially on the critical path @ref{473,,[RB_2012-09-07]}.
@end quotation

@anchor{design/config design mps config var cool}@anchor{474}@ref{474,,.var.cool;} @code{COOL}

@quotation

Intended for use during development.  Moderately thorough internal
consistency checking.  Reduced optimisation to allow for
single-stepping.
@end quotation

@anchor{design/config design mps config var rash}@anchor{475}@ref{475,,.var.rash;} @code{RASH}

@quotation

No internal checking at all.  Slight performance improvement over
@ref{472,,.var.hot} at the cost of early detection of memory management
bugs.  We do not advise use of this variety, as memory management
bugs tend to be extremely expensive to deal with.
@end quotation

@anchor{design/config design mps config default hot}@anchor{476}@ref{476,,.default.hot;} If no @code{CONFIG_VAR} is present, @code{HOT} is assumed in
config.h@footnote{../../../code/config.h}.

@anchor{design/config design mps config build srcs}@anchor{477}@ref{477,,.build.srcs;} The “srcs” are the set of sources that must be
compiled in order to build the target. The set of sources may vary
depending on the configuration. For example, different sets of sources
may be required to build different architectures.

@cartouche
@quotation Note 
This is a dependency between the makefile (or whatever) and the
module configuration in config.h@footnote{../../../code/config.h}.
@end quotation
@end cartouche

@anchor{design/config design mps config build libs}@anchor{478}@ref{478,,.build.libs;} The “libs” are the set of libraries to which the
compiled sources must be linked in order to build the target. For
example, when building a test program, it might include the ANSI C
library and an operating system interface library.

@node File Structure,Modules and naming,Abstract build function,The build system
@anchor{design/config file-structure}@anchor{479}
@subsubsection File Structure


@anchor{design/config design mps config file dir}@anchor{47a}@ref{47a,,.file.dir;} The MPS source code is arranged in a single directory
called “code” containing all the sources for the whole family of
targets.

@anchor{design/config design mps config file base}@anchor{47b}@ref{47b,,.file.base;} The names of sources must be unique in the first eight
characters in order to conform to FAT filesystem naming restrictions.
(Do not scoff – this has been an important requirement as recently as
2012!)

@anchor{design/config design mps config file ext}@anchor{47c}@ref{47c,,.file.ext;} The extension may be up to three characters and directly
indicates the source language.

@anchor{design/config design mps config file platform}@anchor{47d}@ref{47d,,.file.platform;} Platform-specific files include the platform code
in their name.  See @ref{47e,,.mod.impls}.

@node Modules and naming,Build system rationale,File Structure,The build system
@anchor{design/config modules-and-naming}@anchor{47f}
@subsubsection Modules and naming


@anchor{design/config design mps config mod unique}@anchor{480}@ref{480,,.mod.unique;} Each module has an identifier which is unique within the MPS.

@anchor{design/config design mps config mod impls}@anchor{47e}@ref{47e,,.mod.impls;} Each module has one or more implementations which may be
in any language supported by the relevant build environment.

@anchor{design/config design mps config mod primary}@anchor{481}@ref{481,,.mod.primary;} The primary implementation of a module is written in
target-independent ANSI C in a source file with the same name as the
module.

@anchor{design/config design mps config mod an}@anchor{482}@ref{482,,.mod.an;} Where there are platform-specific implementations and an
inferior portable ANSI C fallback implementation, “an” is used in
place of the platform code.

@anchor{design/config design mps config mod secondary}@anchor{483}@ref{483,,.mod.secondary;} The names of other implementations should begin
with the same prefix (the module id or a shortened version of it) and
be suffixed with on or more target parameter codes (defined below). In
particular, the names of assembly language sources must include the
target parameter code for the relevant architecture.

@anchor{design/config design mps config mod example}@anchor{484}@ref{484,,.mod.example;} For example, the stack scanner is defined in ss.h@footnote{../../../code/ss.h}
(which is platform-independent). It has some platform-independent C in
ss.c@footnote{../../../code/ss.c} and, for example, ssw3i6mv.c@footnote{../../../code/ssw3i6mv.c} is specific to Windows on the x64
architecture built with Microsoft Visual C.

@node Build system rationale,Warnings and errors,Modules and naming,The build system
@anchor{design/config build-system-rationale}@anchor{485}@anchor{design/config ssw3i6mv-c}@anchor{486}
@subsubsection Build system rationale


@anchor{design/config design mps config build rat}@anchor{487}@ref{487,,.build.rat;} This simple design makes it possible to build the MPS
using many different tools.  Microsoft Visual C and other graphical
development tools do not support much in the way of generated sources,
staged building, or other such stuff.  The Visual C and Xcode “project”
files correspond closely to a closure of the build function
(@ref{46d,,.build.fun}).  The simplicity of the build function has also made it
easy to set up builds using NMAKE (DOS), MPW (Macintosh), and to get the
MPS up and running on other platforms such as FreeBSD and Linux in very
little time.  The cost of maintaining the build systems on these various
platforms is also reduced to a minimum, allowing the MPS developers to
concentrate on primary development.  The source code is kept simple and
straightforward.  When looking at MPS sources you can tell exactly what
is going to be generated with very little context.  The sources are not
munged beyond the standard ANSI C preprocessor.

@anchor{design/config design mps config build port}@anchor{488}@ref{488,,.build.port;} The portability requirement (@ref{456,,.req.port}) implies that
the build system must use only standard tools that will be available on
all conceivable target platforms.  Experience of development
environments on the Macintosh (Metrowerks Codewarrior) and Windows NT
(Visual C++) indicates that we cannot assume much sophistication in the
use of file structure by development environments.  The best that we can
hope for is the ability to combine a fixed list of source files,
libraries, and predefined preprocessor symbols into a single target.

@anchor{design/config design mps config build maint}@anchor{489}@ref{489,,.build.maint;} The maintainability requirement (@ref{457,,.req.maint}) implies
that we don’t spend time trying to develop a set of tools to support
anything more complicated than the simple build function described
above.  The effort in constructing and maintaining a portable system of
this kind is considerable. Such efforts failed in the Electronic
Publishing division of Harlequin.

@node Warnings and errors,,Build system rationale,The build system
@anchor{design/config warnings-and-errors}@anchor{48a}
@subsubsection Warnings and errors


@anchor{design/config design mps config warning free}@anchor{48b}@ref{48b,,.warning.free;} A consequence of @ref{467,,.import.source} is that the MPS
needs to compile in the context of the client’s build system, with
`whatever compilation and warning options' the client has enabled in
that system, and this might include options causing warnings to be
treated as errors. Accordingly, the MPS should compile without
warnings when enabling the compiler options most likely to be employed
by clients.

@anchor{design/config design mps config warning impl}@anchor{48c}@ref{48c,,.warning.impl;} In order to ensure that the MPS meets the
requirement in @ref{48b,,.warning.free}, during development and testing of the
MPS we compile with a large selection of warning options for each
supported compiler, and with warnings treated as errors so that
developers do not get into the habit of ignoring warning messages.
These are enabled in the compiler makefile fragments for each
compiler, for example ll.gmk@footnote{../../../code/ll.gmk} for Clang/LLVM.

@anchor{design/config design mps config warning benefit}@anchor{48d}@ref{48d,,.warning.benefit;} The implementation in @ref{48c,,.warning.impl} also helps
us keep the code free of subtle compiler issues that break memory
managers, and free of constructs which might be accidentally
mis-interpreted by other developers.

@anchor{design/config design mps config warning silence}@anchor{48e}@ref{48e,,.warning.silence;} When code needs to be modified, for example by
adding a cast, to silence a warning that has been analyzed and turned
out to be harmless, it is best practice to introduce a macro that
expresses the intention, and cross-reference this paragraph from the
macro’s comment. If the macro is general-purpose then misc.h@footnote{../../../code/misc.h} is a
good place to put it.

@node Implementation<3>,Source code configuration,The build system,MPS Configuration
@anchor{design/config implementation}@anchor{48f}@anchor{design/config misc-h}@anchor{490}
@subsection Implementation


@anchor{design/config design mps config impl}@anchor{491}@ref{491,,.impl;} The two implementation files config.h@footnote{../../../code/config.h} and mpstd.h@footnote{../../../code/mpstd.h} can be
seen as preprocessor programs which “accept” build parameters and “emit”
configuration parameters (@ref{492,,.fig.impl}).  The build parameters are
defined either by the builder (in the case of target detection) or by
the build function (in the case of selecting the variety).

@anchor{design/config design mps config fig impl}@anchor{492}@ref{492,,.fig.impl;}


@multitable {xxxxxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Build parameters

@tab

Source file

@tab

Configuration parameters

@item

@ref{172,,CONFIG_VAR_HOT}

@tab

⟶ @code{config.h}

@tab

⟶ @code{MPS_ASSERT_STRING}, etc.

@item

@code{_WIN32}

@tab

⟶ @code{mpstd.h}

@tab

⟶ @ref{2e2,,MPS_OS_W3}, etc.

@end multitable


@anchor{design/config design mps config impl dep}@anchor{493}@ref{493,,.impl.dep;} No source code, other than the directives in config.h@footnote{../../../code/config.h}
and mpstd.h@footnote{../../../code/mpstd.h}, should depend on any build parameters.  That is,
identifiers beginning “CONFIG_” should only appear in impl.h.config.
Code may depend on configuration parameters in certain, limited ways, as
defined below (@ref{494,,.conf}).

@menu
* Target platform detection:: 
* Target varieties:: 

@end menu

@node Target platform detection,Target varieties,,Implementation<3>
@anchor{design/config mpstd-h}@anchor{495}@anchor{design/config target-platform-detection}@anchor{496}
@subsubsection Target platform detection


@anchor{design/config design mps config pf}@anchor{497}@ref{497,,.pf;} The target platform is “detected” by the preprocessor directives in
mpstd.h@footnote{../../../code/mpstd.h}.

@anchor{design/config design mps config pf form}@anchor{498}@ref{498,,.pf.form;} This file consists of sets of directives of the form:

@example
#elif <conjunction of builder predefinitions>
#define MPS_PF_<platform code>
#define MPS_PF_STRING "<platform code>"
#define MPS_OS_<operating system code>
#define MPS_ARCH_<architecture code>
#define MPS_BUILD_<builder code>
#define MPS_T_WORD     <word type>
#define MPS_T_ULONGEST <longest unsigned integer type>
#define MPS_WORD_WIDTH <word width in bits>
#define MPS_WORD_SHIFT <log to the base 2 of word width>
#define MPS_PF_ALIGN   <minimum alignment>
@end example

@anchor{design/config design mps config pf detect}@anchor{499}@ref{499,,.pf.detect;} The conjunction of builder predefinitions is a constant
expression which detects the target platform.  It is a logical AND of
expressions which look for preprocessor symbols defined by the build
environment to indicate the target.  These must be accompanied by a
reference to the build tool documentation from which the symbols came.
For example:

@example
/* "Predefined Macros" from "Visual Studio 2010" on MSDN
 * <http://msdn.microsoft.com/en-us/library/b0084kay(v=vs.100).aspx>. */

#elif defined(_MSC_VER) && defined(_WIN32) && defined(_M_IX86)
@end example

@anchor{design/config design mps config pf codes}@anchor{49a}@ref{49a,,.pf.codes;} The declarations of the platform, operating system,
architecture, and builder codes define preprocessor macros corresponding
to the target detected (@ref{499,,.pf.detect}).  For example:

@example
#define MPS_PF_W3I3MV
#define MPS_OS_W3
#define MPS_ARCH_I3
#define MPS_BUILD_MV
@end example

@anchor{design/config design mps config pf word}@anchor{49b}@ref{49b,,.pf.word;} The declaration of @ref{2fe,,MPS_T_WORD} defines the unsigned
integral type which corresponds, on the detected target, to the
machine word. It is used to defined the MPS Word type
(design.mps.type.word@footnote{type.html#design.mps.type.word}). For example:

@example
#define MPS_T_WORD      unsigned long
@end example

We avoid using @code{typedef} here because mpstd.h@footnote{../../../code/mpstd.h} could potentially
be included in assembly language source code.

@anchor{design/config design mps config pf word-width}@anchor{49c}@ref{49c,,.pf.word-width;} The declaration of @ref{187,,MPS_WORD_WIDTH} defines the
number of bits in the type defined by @ref{2fe,,MPS_T_WORD} (@ref{49b,,.pf.word}) on the
target. For example:

@example
#define MPS_WORD_WIDTH  32
@end example

@anchor{design/config design mps config pf word-shift}@anchor{49d}@ref{49d,,.pf.word-shift;} The declaration of @ref{2ff,,MPS_WORD_SHIFT} defines the log
to the base 2 of @ref{187,,MPS_WORD_WIDTH}.  For example:

@example
#define MPS_WORD_SHIFT  5
@end example

@anchor{design/config design mps config pf pf-align}@anchor{49e}@ref{49e,,.pf.pf-align;} The declaration of @ref{6f,,MPS_PF_ALIGN} defines the minimum
alignment which must be used for a memory block to permit any normal
processor memory access.  In other words, it is the maximum alignment
required by the processor for normal memory access.  For example:

@example
#define MPS_PF_ALIGN    4
@end example

@anchor{design/config design mps config pf ulongest}@anchor{49f}@ref{49f,,.pf.ulongest;} The declaration of @ref{2fd,,MPS_T_ULONGEST} defines the
longest available unsigned integer type on the platform.  This is
usually just @code{unsigned long} but under Microsoft C on 64-bit Windows
@code{unsigned long} is just 32-bits (curse them!)  For example:

@example
#define MPS_T_ULONGEST      unsigned __int64
@end example

@anchor{design/config design mps config pf pf-string}@anchor{4a0}@ref{4a0,,.pf.pf-string;} The declaration of @ref{2f6,,MPS_PF_STRING} defines a
string that is used to identify the target platform in version.c@footnote{../../../code/version.c}. For
example:

@example
#define MPS_PF_STRING   "w3i6mv"
@end example

@node Target varieties,,Target platform detection,Implementation<3>
@anchor{design/config target-varieties}@anchor{4a1}@anchor{design/config version-c}@anchor{4a2}
@subsubsection Target varieties


@anchor{design/config design mps config var}@anchor{4a3}@ref{4a3,,.var;} The target variety is handled by preprocessor directives in
impl.h.config.

@anchor{design/config design mps config var form}@anchor{4a4}@ref{4a4,,.var.form;} The file contains sets of directives of the form:

@example
#if defined(CONFIG_VAR_COOL)
#define CONFIG_ASSERT
#define CONFIG_ASSERT_ALL
#define CONFIG_STATS
@end example

@anchor{design/config design mps config var detect}@anchor{4a5}@ref{4a5,,.var.detect;} The configured variety is one of the variety
preprocessor definitions passed to the build function
(@ref{470,,.build.defs}), for example, @ref{ca,,CONFIG_VAR_COOL}. These are
decoupled in order to keep the number of supported varieties small,
controlling each feature (for example, assertions) by a single
preprocessor definition, and maintaining flexibility about which
features are enabled in each variety.

@anchor{design/config design mps config var symbols}@anchor{4a6}@ref{4a6,,.var.symbols;} The directives should define whatever symbols are
necessary to control features. These symbols parameterize other parts
of the code, such as the declaration of assertions, etc. The symbols
should all begin with the prefix @code{CONFIG_}.

@node Source code configuration,Configuration options,Implementation<3>,MPS Configuration
@anchor{design/config source-code-configuration}@anchor{4a7}
@subsection Source code configuration


@anchor{design/config design mps config conf}@anchor{494}@ref{494,,.conf;} This section describes how the configuration may affect the
source code of the MPS.

@anchor{design/config design mps config conf limit}@anchor{4a8}@ref{4a8,,.conf.limit;} The form of dependency allowed is carefully limited to
ensure that code remains maintainable and portable (@ref{455,,.req.impact}).

@anchor{design/config design mps config conf min}@anchor{4a9}@ref{4a9,,.conf.min;} The dependency of code on configuration parameters should
be kept to a minimum in order to keep the system maintainable
(@ref{455,,.req.impact}).

@menu
* Configuration Parameters:: 
* Abstract and Concrete Module Interfaces:: 

@end menu

@node Configuration Parameters,Abstract and Concrete Module Interfaces,,Source code configuration
@anchor{design/config configuration-parameters}@anchor{4aa}
@subsubsection Configuration Parameters


@anchor{design/config design mps config conf params}@anchor{4ab}@ref{4ab,,.conf.params;} The compilation of a module is parameterized by:

@example
MPS_ARCH_<arch-code>
MPS_OS_<os-code>
MPS_BUILD_<builder-code>
MPS_PF_<platform-code>
@end example

@node Abstract and Concrete Module Interfaces,,Configuration Parameters,Source code configuration
@anchor{design/config abstract-and-concrete-module-interfaces}@anchor{4ac}
@subsubsection Abstract and Concrete Module Interfaces


@anchor{design/config design mps config abs caller}@anchor{4ad}@ref{4ad,,.abs.caller;} Basic principle: the caller musn’t be affected by
configuration of a module. This reduces complexity and dependency of
configuration.  All callers use the same abstract interface.  Caller
code does not change.

@anchor{design/config design mps config abs interface}@anchor{4ae}@ref{4ae,,.abs.interface;} Abstract interface includes:


@itemize -

@item 
method definitions (logical function prototypes which may be macro methods)

@item 
names of types

@item 
names of constants

@item 
names of structures and fields which form part of the interface, and
possibly their types, depending on the protocol defined

@item 
the protocols
@end itemize

@anchor{design/config design mps config abs rule}@anchor{4af}@ref{4af,,.abs.rule;} The abstract interface to a module may not be altered by a
configuration parameter.  However, the concrete interface may vary.

For example, this isn’t allowed, because there is a change in the interface:

@example
#if defined(PROT_FOO)
void ProtSpong(Foo foo, Bar bar);
#else
int ProtSpong(Bar bar, Foo foo);
#endif
@end example

This example shows how:

@example
#ifdef PROTECTION
void ProtSync(Space space);
/* more decls. */
#else /* PROTECTION not */
#define ProtSync(space) NOOP
/* more decls. */
#endif /* PROTECTION */
@end example

or:

@example
#if defined(PROT_FOO)
typedef struct ProtStruct @{
  int foo;
@} ProtStruct;
#define ProtSpong(prot)  X((prot)->foo)
#elif defined(PROT_BAR)
typedef struct ProtStruct @{
  float bar;
@} ProtStruct;
#define ProtSpong(prot)  Y((prot)->bar)
#else
#error "No PROT_* configured."
#endif
@end example

Configuration parameters may not be used to vary implementations in C files.
For example, this sort of thing:

@example
int map(void *base, size_t size)
@{
#if defined(MPS_OS_W3)
  VirtualAlloc(foo, bar, base, size);
#elif defined(MPS_OS_SU)
  mmap(base, size, frob);
#else
#error "No implementation of map."
#endif
@}
@end example

This violates @ref{469,,.no-spaghetti}.

@node Configuration options,To document,Source code configuration,MPS Configuration
@anchor{design/config configuration-options}@anchor{4b0}
@subsection Configuration options


@anchor{design/config design mps config opt}@anchor{465}@ref{465,,.opt;} Options select features of the MPS that are not selected by the `platform' and the `variety'.

@anchor{design/config design mps config opt support}@anchor{4b1}@ref{4b1,,.opt.support;} The features selected by options are not supported or
documented in the public interface. This is to keep the complexity of
the MPS manageable: at present the number of supported configuration
is `platforms' × `varieties' (at time of writing, 9 × 3 = 27). Each
supported option would double (or worse) the number of supported
configurations.

@anchor{design/config design mps config opt ansi}@anchor{4b2}@ref{4b2,,.opt.ansi;} @code{CONFIG_PF_ANSI} tells @code{mps.c} to exclude the
sources for the auto-detected platform, and use the generic (“ANSI”)
platform instead.

@anchor{design/config design mps config opt thread}@anchor{4b3}@ref{4b3,,.opt.thread;} @code{CONFIG_THREAD_SINGLE} causes the MPS to be built
for single-threaded execution only, where locks are not needed and so
the generic (“ANSI”) lock module @code{lockan.c} can be used instead of
the platform-specific lock module.

@anchor{design/config design mps config opt poll}@anchor{4b4}@ref{4b4,,.opt.poll;} @code{CONFIG_POLL_NONE} causes the MPS to be built without
support for polling. This means that garbage collections will only
happen if requested explicitly via @ref{ce,,mps_arena_collect()} or
@ref{19c,,mps_arena_step()}, but it also means that protection is not needed,
and so shield operations can be replaced with no-ops in @code{mpm.h}.

@anchor{design/config design mps config opt signal suspend}@anchor{4b5}@ref{4b5,,.opt.signal.suspend;} @ref{1fb,,CONFIG_PTHREADEXT_SIGSUSPEND} names the
signal used to suspend a thread, on platforms using the POSIX thread
extensions module. See design.pthreadext.impl.signals@footnote{pthreadext#impl.signals}.

@anchor{design/config design mps config opt signal resume}@anchor{4b6}@ref{4b6,,.opt.signal.resume;} @ref{1fc,,CONFIG_PTHREADEXT_SIGRESUME} names the
signal used to resume a thread, on platforms using the POSIX thread
extensions module. See design.pthreadext.impl.signals@footnote{pthreadext#impl.signals}.

@node To document,References,Configuration options,MPS Configuration
@anchor{design/config to-document}@anchor{4b7}
@subsection To document



@itemize -

@item 
What about constants in config.h?

@item 
Update files to refer to this design document.

@item 
Explain the role of @code{mps.c}

@item 
Reference to @code{build.txt}

@item 
Procedures for adding an architecture, etc.

@item 
Reduce duplication in this document (especially after
@ref{4aa,,Configuration Parameters} which looks like it’s been pasted in from
elsewhere.)
@end itemize

@node References,,To document,MPS Configuration
@anchor{design/config references}@anchor{4b8}
@subsection References


@anchor{design/config rb-2012-09-07}@anchor{473}@w{(RB_2012-09-07)} 
Richard Brooksby. Ravenbrook Limited. 2012-09-07. “The critical path through the MPS@footnote{https://www.ravenbrook.com/project/mps/master/design/critical-path}”.

@anchor{design/config rb-2012-09-13}@anchor{45a}@w{(RB_2012-09-13)} 
Richard Brooksby. Ravenbrook Limited. 2013-09-13. “The Configura CET custom mainline@footnote{https://info.ravenbrook.com/mail/2012/09/13/16-43-35/0/}”.

@geindex critical path
@geindex path; critical
@geindex Memory Pool System; critical path

@node The critical path through the MPS,Documentation,MPS Configuration,Design
@anchor{design/critical-path doc}@anchor{4b9}@anchor{design/critical-path design-critical-path}@anchor{1e3}@anchor{design/critical-path the-critical-path-through-the-mps}@anchor{4ba}
@section The critical path through the MPS


@quotation

single: critical path
single: path; critical
single: Memory Pool System; critical path
@end quotation

@menu
* Introduction: Introduction<8>. 
* What makes the critical path critical:: 
* How the MPS avoids scanning and fixing:: 
* Where to find the critical path:: 
* The format scanner:: 
* The second stage fix in the MPM:: 
* The third stage fix in the segment class:: 
* Other considerations:: 
* References: References<2>. 

@end menu

@node Introduction<8>,What makes the critical path critical,,The critical path through the MPS
@anchor{design/critical-path introduction}@anchor{4bb}
@subsection Introduction


The critical path is a key concept in the design of the Memory Pool System@footnote{https://www.ravenbrook.com/project/mps/}.  Code on the critical
path is usually executed more than any other code in the process.  A
change of just one instruction on the critical path can make as much as
a 1% difference in overall run-time.  A lot of the design of the MPS is
arranged around making the critical path as short and fast as possible.
This document describes the critical path and explains some of that
design, with reference to more detailed documents.

@node What makes the critical path critical,How the MPS avoids scanning and fixing,Introduction<8>,The critical path through the MPS
@anchor{design/critical-path what-makes-the-critical-path-critical}@anchor{4bc}
@subsection What makes the critical path critical


In order to determine which objects can be recycled, the garbage
collector has to frequently examine a very large number of pointers in
the program’s objects.  It does this by scanning@footnote{https://www.memorymanagement.org/glossary/s.html#scan} memory, both
allocated objects and roots (such as the thread stacks).

This means that the scanning functions must loop over pretty much `every
word in memory' sooner or later.  The MPS takes great pains to avoid
scanning memory which does not need scanning, but to get good
performance, scanning must be highly optimised.

What’s more, the scanning functions apply an operation called “fix” to
every pointer (or potential pointer) that they find in the objects in
memory.  Fixing also attempts to eliminate uninteresting pointers as
fast as possible, but it has to do some work on every object that is
being considered for recycling, and that can be a large proportion of
the objects in existence.  The path through fixing must also be highly
optimised, especially in the early stages.

@node How the MPS avoids scanning and fixing,Where to find the critical path,What makes the critical path critical,The critical path through the MPS
@anchor{design/critical-path how-the-mps-avoids-scanning-and-fixing}@anchor{4bd}
@subsection How the MPS avoids scanning and fixing


This is just a brief overview of how the MPS is designed to reduce
unnecessary scanning and fixing.

Firstly, the MPS must occasionally decide which objects to try to
recycle.  It does this using various facts it knows about the objects,
primarily their age and whether they’ve survived previous attempts at
recycling them.  It then “condemns@footnote{https://www.memorymanagement.org/glossary/c.html#condemned.set}” a large number of objects
at once, and each of these objects must be “preserved” by fixing
references to them.

When the MPS condemns objects it chooses sets of objects in a small set
of “zones” in memory (preferably a single zone).  The zone of an object
can be determined extremely quickly from its address, without looking at
the object or any other data structure.

The MPS arranges that objects which will probably die at the same time
are in the same zones.

The MPS allocates in “segments”. Each segment is of the order of one
“tract” of memory (generally the same as the operating system page
size, usually 4 KiB or 8 KiB) but may be larger if there are large
objects inside. The MPS maintains a “summary” of the zones pointed to
by all the pointers in a segment from previous scans.

So, once the MPS has decided what to condemn, it can quickly eliminate
all segments which definitely do not point to anything in those zones.
This avoids a large amount of scanning. It is an implementation of a
remembered set@footnote{https://www.memorymanagement.org/glossary/r.html#remembered.set}, though it is unlike that in most other garbage
collectors.

In addition, the fix operation can quickly ignore pointers to the wrong
zones.  This is called the “zone check” and is a BIBOP@footnote{https://www.memorymanagement.org/glossary/b.html#bibop} technique.

Even if a pointer passes the zone check, it may still not point to a
segment containing condemned objects.  The next stage of the fix
operation is to look up the segment pointed to by the pointer and see if
it was condemned.  This is a fast lookup.

After that, each pool class must decide whether the pointer is to a
condemned object and do something to preserve it. This code is still
critical. The MPS will have tried to condemn objects that are dead,
but those objects are still likely to be in segments with other
objects that must be preserved. The segment class fix method must
quickly distinguish between them.

Furthermore, many objects will be preserved at least once in their
lifetime, so even the code that preserves an object needs to be highly
efficient.  (Programs in languages like ML might not preserve 95% of
their objects even once, but many other programs will preserve nearly
all of theirs many times.)

@node Where to find the critical path,The format scanner,How the MPS avoids scanning and fixing,The critical path through the MPS
@anchor{design/critical-path where-to-find-the-critical-path}@anchor{4be}
@subsection Where to find the critical path


Very briefly, the critical path consists of five stages:


@enumerate 

@item 
The scanner, which iterates over pointers in objects. The MPS has
several internal scanners, but the most important ones will be
format scanners in client code registered through
@ref{13f,,mps_fmt_create_k()}.

@cartouche
@quotation Note 
There needs to be a chapter in the manual explaining how to
write a good scanner. Then that could be linked from here.
@end quotation
@end cartouche

@item 
The first-stage fix, which filters out pointers inline in the
scanner.  This is implemented in the @ref{75,,MPS_FIX1()} macro in
mps.h@footnote{../../../code/mps.h}.

@item 
The second-stage fix, which filters out pointers using general
information about segments. This is @code{_mps_fix2()} in trace.c@footnote{../../../code/trace.c}.

@item 
The third-stage fix, which filters out pointers using
segment-specific information. Implemented in segment class
functions called @ref{4bf,,amcSegFix()}, @ref{4c0,,loSegFix()}, etc. in pool*.c.

@item 
Preserving the object, which might entail:


@itemize -

@item 
marking@footnote{https://www.memorymanagement.org/glossary/m.html#marking} it to prevent it being recycled; and/or

@item 
copying@footnote{https://www.memorymanagement.org/glossary/c.html#copying.garbage.collection} it and updating the original pointer (or just
updating the pointer, if the object has previously been
copied); and/or

@item 
adding it to a queue of objects to be scanned later, if it
contains pointers.
@end itemize
@end enumerate

@node The format scanner,The second stage fix in the MPM,Where to find the critical path,The critical path through the MPS
@anchor{design/critical-path the-format-scanner}@anchor{4c1}
@subsection The format scanner


The critical path starts when a format scan method is called. That is
a call from the MPS to a client function of type @ref{74,,mps_fmt_scan_t}
registered with @ref{13f,,mps_fmt_create_k()}.

Here is an example of part of a format scanner for scanning contiguous
runs of pointers, from fmtdy.c@footnote{../../../code/fmtdy.c}, the scanner for the Open Dylan@footnote{https://opendylan.org/}
runtime:

@example
static mps_res_t dylan_scan_contig(mps_ss_t mps_ss,
                                   mps_addr_t *base, mps_addr_t *limit)
@{
  mps_res_t res;
  mps_addr_t *p;        /* reference cursor */
  mps_addr_t r;         /* reference to be fixed */

  MPS_SCAN_BEGIN(mps_ss) @{
          p = base;
    loop: if(p >= limit) goto out;
          r = *p++;
          if(((mps_word_t)r&3) != 0) /* pointers tagged with 0 */
            goto loop;             /* not a pointer */
          if(!MPS_FIX1(mps_ss, r)) goto loop;
          res = MPS_FIX2(mps_ss, p-1);
          if(res == MPS_RES_OK) goto loop;
          return res;
    out:  assert(p == limit);
  @} MPS_SCAN_END(mps_ss);

  return MPS_RES_OK;
@}
@end example

(To help with understanding optimisation of this code, it’s written in
a pseudo-assembler style, with one line roughly corresponding to each
instruction of an idealized intermediate code.)

The MPS C interface provides macros to try to help optimise this code.
The @code{mps_ss} object is a “scan state” and contains data that is used
to eliminate uninteresting pointers now, and record information which
will be used to reduce scanning in future by maintaining the
remembered set.

The macros @ref{7a,,MPS_SCAN_BEGIN()} and @ref{7b,,MPS_SCAN_END()} load key data
from the scan state into local variables, and hopefully into processor
registers. This avoids aliasing values that we know won’t change when
calls are made to @code{_mps_fix2()} later, and so allows the compiler to
keep the scan loop small and avoid unnecessary memory references.

This scanner knows that words not ending in 0b00 aren’t pointers to
objects, so it eliminates them straight away. This is a kind of
reference tag@footnote{https://www.memorymanagement.org/glossary/t.html#tag} chosen by the client for its object representation.

Next, the pointer is tested using @ref{75,,MPS_FIX1()}. This performs fast
tests on the pointer without using any other memory. In particular, it
does the “zone check” described in section 3. If a pointer fails these
tests, it isn’t interesting and can be skipped. It is very important
to proceed to the next pointer as fast as possible in this case.

Having passed these tests, we need to fix the pointer using other data
in memory, and possibly call the MPS to preserve the object. This is
what @ref{76,,MPS_FIX2()} does. The important distinction here is that
@ref{76,,MPS_FIX2()} can fail and return an error code, which must be
propagated without ado by returning from the scanner. Separating
@ref{75,,MPS_FIX1()} from @ref{76,,MPS_FIX2()} helps keep the error handling code
away from the tight loop with the zone check.

@code{MPS_FIX*}, the macro/inline part of the fix operation, are referred
to as “fix stage 1” or “the first stage fix” in other documents and
comments.

If these inline checks pass, @code{_mps_fix2()} is called. If the MPS has
been built as a separate object file or library, this is where the
function call out of the scan loop happens. Since version 1.110 of the
MPS, we encourage clients to compile the MPS in the same translation
unit as their format code, so that the compiler can be intelligent
about inlining parts of @code{_mps_fix2()} in the format scanner. The
instructions for doing this are in Building the Memory Pool System@footnote{../../../manual/build.txt}, part of the manual.

@node The second stage fix in the MPM,The third stage fix in the segment class,The format scanner,The critical path through the MPS
@anchor{design/critical-path build-txt}@anchor{4c2}@anchor{design/critical-path the-second-stage-fix-in-the-mpm}@anchor{4c3}
@subsection The second stage fix in the MPM


If a pointer gets past the first-stage fix filters, it is passed to
@code{_mps_fix2()}, the “second stage fix”. The second stage can filter
out yet more pointers using information about segments before it has
to consult the pool class.

The first test is to determine if the address points to a `chunk' (a
contiguous region of address space managed by the arena). Addresses
that do not point to any chunk (for example, ambiguous references that
are not in fact pointers) are rejected immediately. See
@code{ChunkOfAddr()}.

When there are many chunks (that is, when the arena has been extended
many times), this test can consume the majority of the garbage
collection time. This is the reason that it’s important to give a good
estimate of the amount of address space you will ever occupy with
objects when you initialize the arena.

The second test applied is the “tract test”. The MPS looks up the
tract containing the address in the tract table, which is a simple
linear table indexed by the address shifted—a kind of flat page
table. See @ref{4c4,,TractOfAddr()}.

If the pointer is in a tract allocated with garbage collected objects,
then the table also contains a pointer to a “segment”, which contains
a bitfield representing the “white set”—the set of garbage
collection traces for which the tract is “interesting”. If a segment
isn’t interesting, then we know that it contains no condemned objects,
and we can filter out the pointer.

The MPM can’t know anything about the internal layout of the segment,
so at this point we dispatch to the third stage fix.

This dispatch is slightly subtle. We have a cache of the function to
dispatch to in the scan state, which has recently been looked at and
is with luck still in the processor cache. The reason there is a
dispatch at all is to allow for a fast changeover to emergency garbage
collection, or overriding of garbage collection with extra operations.
Those are beyond the scope of this document. Normally, @code{ss->fix}
points at @code{SegFix()}.

@code{SegFix()} is passed the segment, which is fetched from the tract
table entry, and that should be in the cache. @code{SegFix()} itself
dispatches to the segment class.

@node The third stage fix in the segment class,Other considerations,The second stage fix in the MPM,The critical path through the MPS
@anchor{design/critical-path the-third-stage-fix-in-the-segment-class}@anchor{4c5}
@subsection The third stage fix in the segment class


The final stage of fixing is entirely dependent on the segment class.
The MPM can’t, in general, know how the objects within a segment are
arranged, so this is segment class specific code.

Furthermore, the segment class must make decisions based on the
“reference rank” of the pointer. If a pointer is ambiguous
(@code{RankAMBIG}) then it can’t be changed, so even a copying segment
class can’t move an object. On the other hand, if the pointer is weak
(@code{RankWEAK}) then the segment fix method shouldn’t preserve the
object at all, even if it’s condemned.

The exact details of the logic that the segment fix must implement in
order to co-operate with the MPM and other pools are beyond the scope
of this document, which is about the critical path.  Since it is on
the critical path, it’s important that whatever the segment fix does is
simple and fast and returns to scanning as soon as possible.

The first step, though, is to further filter out pointers which aren’t
to objects, if that’s its policy.  Then, it may preserve the object,
according to its policy, and possibly ensure that the object gets
scanned at some point in the future, if it contains more pointers.

If the object is moved to preserve it (for instance, if the pool class
implements a copying collector), or was already moved when fixing a
previous reference to it, the reference being fixed must be updated
(this is the origin of the term “fix”).

As a simple example, @ref{4c0,,loSegFix()} is the segment fix method for
segments belonging to the LO (Leaf Object) pool class. It implements a
marking garbage collector, and does not have to worry about scanning
preserved objects because it is used to store objects that don’t
contain pointers. (It is used in compiler run-time systems to store
binary data such as character strings, thus avoiding any scanning,
decoding, or remembered set overhead for them.)

@ref{4c0,,loSegFix()} filters any ambiguous pointers that aren’t aligned,
since they can’t point to objects it allocated. Otherwise it subtracts
the segment base address and shifts the result to get an index into a
mark bit table. If the object wasn’t marked and the pointer is weak,
then it sets the pointer to zero, since the object is about to be
recycled. Otherwise, the mark bit is set, which preserves the object
from recycling when @ref{4c6,,loSegReclaim()} is called later on.
@ref{4c0,,loSegFix()} illustrates about the minimum and most efficient thing
a segment fix method can do.

@node Other considerations,References<2>,The third stage fix in the segment class,The critical path through the MPS
@anchor{design/critical-path other-considerations}@anchor{4c7}
@subsection Other considerations


So far this document has described the ways in which the garbage
collector is designed around optimising the critical path.  There are a
few other things that the MPS does that are important.

Firstly, inlining is very important. The first stage fix is inlined
into the format scanner by being implemented in macros in mps.h@footnote{../../../code/mps.h}. And
to get even better inlining, we recommend@footnote{../../../manual/build.txt} that the
whole MPS is compiled in a single translation unit with the client
format and that strong global optimisation is applied.

Secondly, we are very careful with code annotations on the critical
path.  Assertions, statistics, and telemetry are all disabled on the
critical path in “hot” (production) builds.  (In fact, it’s because the
critical path is critical that we can afford to leave annotations
switched on elsewhere.)

Last, but by no means least, we pay a lot of brainpower and measurement
to the critical path, and are very very careful about changing it.  Code
review around the critical path is especially vigilant.

And we write long documents about it.

@node References<2>,,Other considerations,The critical path through the MPS
@anchor{design/critical-path references}@anchor{4c8}
@subsection References


@geindex documentation; design

@node Documentation,Execution environment,The critical path through the MPS,Design
@anchor{design/doc doc}@anchor{4c9}@anchor{design/doc design-doc}@anchor{4ca}@anchor{design/doc documentation}@anchor{4cb}@anchor{design/doc open-dylan}@anchor{4cc}
@section Documentation


@menu
* Introduction: Introduction<9>. 
* Types: Types<2>. 
* Requirements: Requirements<6>. 
* Implementation: Implementation<4>. 
* Manual extensions:: 
* Design formatting conventions:: 
* References: References<3>. 

@end menu

@node Introduction<9>,Types<2>,,Documentation
@anchor{design/doc design mps doc}@anchor{4cd}@anchor{design/doc introduction}@anchor{4ce}
@subsection Introduction


@anchor{design/doc design mps doc intro}@anchor{4cf}@ref{4cf,,.intro;} This is the design of the documentation system for the
Memory Pool System.

@anchor{design/doc design mps doc readership}@anchor{4d0}@ref{4d0,,.readership;} This document is intended for any MPS developer.

@node Types<2>,Requirements<6>,Introduction<9>,Documentation
@anchor{design/doc types}@anchor{4d1}
@subsection Types


@anchor{design/doc design mps doc type}@anchor{4d2}@ref{4d2,,.type;} The MPS has multiple types of documentation, suitable for
different audiences.

@anchor{design/doc design mps doc type comment}@anchor{4d3}@ref{4d3,,.type.comment;} Comments in the code provide information that is
required in order for developers to make correct edits to nearby code.
(Audience: MPS developers editing nearby code.)

@anchor{design/doc design mps doc type design}@anchor{4d4}@ref{4d4,,.type.design;} Design documentation lists requirements and explains
how the code meets the requirements. (Audience: MPS developers working
on a subsystem.)

@anchor{design/doc design mps doc type devguide}@anchor{4d5}@ref{4d5,,.type.devguide;} Developer guides provide general guidance for
developers, not specific to any particular subsystem. (Audience: MPS
developers generally.)

@anchor{design/doc design mps doc type procedure}@anchor{4d6}@ref{4d6,,.type.procedure;} Procedures list the steps for carrying out
development tasks. (Audience: MPS developers who need to carry out
particular tasks reliably.)

@anchor{design/doc design mps doc type tutorial}@anchor{4d7}@ref{4d7,,.type.tutorial;} Tutorials describe how to use the MPS to meet
client program requirements. (Audience: beginner client program
developers.)

@anchor{design/doc design mps doc type reference}@anchor{4d8}@ref{4d8,,.type.reference;} Reference documentation specifies the public
features of the MPS. (Audience: expert client program developers.)

@anchor{design/doc design mps doc type mmref}@anchor{4d9}@ref{4d9,,.type.mmref;} The Memory Management Reference describes general
principles of memory management, with cross-references to the MPS
documentation. (Audience: the world.)

@node Requirements<6>,Implementation<4>,Types<2>,Documentation
@anchor{design/doc requirements}@anchor{4da}
@subsection Requirements


@anchor{design/doc design mps doc req source}@anchor{4db}@ref{4db,,.req.source;} Derived from @ref{4dc,,[RB_2013-05-09]}.

@anchor{design/doc design mps doc req easy}@anchor{4dd}@ref{4dd,,.req.easy;} It must be easy to read and write documentation using
standard text editors. Barriers to documentation must be low.

@anchor{design/doc design mps doc req presentation}@anchor{4de}@ref{4de,,.req.presentation;} It must be possible to process documentation
into presentation formats, for example web pages.

@anchor{design/doc design mps doc req single-source}@anchor{4df}@ref{4df,,.req.single-source;} Documents must have a single source. Processing
into other formats must be automatic and not depend on hand editing or
maintaining parallel versions.

@anchor{design/doc design mps doc req durable}@anchor{4e0}@ref{4e0,,.req.durable;} The format of documents should be supported for the
foreseeable future. It must not require continual updating to keep up
with changes to processing software.

@anchor{design/doc design mps doc req design ref}@anchor{4e1}@ref{4e1,,.req.design.ref;} It must be easy to reference points made in design
documents from the code.

@anchor{design/doc design mps doc req design standalone}@anchor{4e2}@ref{4e2,,.req.design.standalone;} Design documents must stand alone: they
must not require particular software to make them readable or
complete.

@node Implementation<4>,Manual extensions,Requirements<6>,Documentation
@anchor{design/doc implementation}@anchor{4e3}
@subsection Implementation


@anchor{design/doc design mps doc impl rst}@anchor{4e4}@ref{4e4,,.impl.rst;} Documents are written in reStructuredText@footnote{http://docutils.sourceforge.net/rst.html} (RST).

@anchor{design/doc design mps doc impl design}@anchor{4e5}@ref{4e5,,.impl.design;} Design documents are written in plain RST (with no
custom directives) to meet @ref{4e2,,.req.design.standalone}.

@anchor{design/doc design mps doc impl design pelican}@anchor{4e6}@ref{4e6,,.impl.design.pelican;} Design documents are converted to HTML using
pelican.readers.RstReader@footnote{https://fossies.org/dox/pelican-3.7.1/classpelican_1_1readers_1_1RstReader.html} as part of Charlotte@footnote{https://info.ravenbrook.com/project/charlotte}.

@anchor{design/doc design mps doc impl design github}@anchor{4e7}@ref{4e7,,.impl.design.github;} Design documents are also rendered as HTML by GitHub@footnote{https://docs.github.com/en/repositories/working-with-files/using-files/working-with-non-code-files#rendering-differences-in-prose-documents}.

@anchor{design/doc design mps doc impl manual}@anchor{4e8}@ref{4e8,,.impl.manual;} The manual is written in RST using Sphinx@footnote{https://www.sphinx-doc.org/en/master/} extensions
and custom manual extensions (see @ref{4e9,,.ext}).

@anchor{design/doc design mps doc impl manual sphinx}@anchor{4ea}@ref{4ea,,.impl.manual.sphinx;} The manual is converted to HTML using the
Sphinx@footnote{https://www.sphinx-doc.org/en/master/} documentation generator.

@anchor{design/doc design mps doc impl manual design}@anchor{4eb}@ref{4eb,,.impl.manual.design;} Design documents are automatically processed
for inclusion in the manual using a set of formatting conventions (see
@ref{4ec,,.fmt}).

@node Manual extensions,Design formatting conventions,Implementation<4>,Documentation
@anchor{design/doc manual-extensions}@anchor{4ed}
@subsection Manual extensions


@anchor{design/doc design mps doc ext}@anchor{4e9}@ref{4e9,,.ext;} These are reStructuredText directives and roles used by the
MPS manual. See manual/source/extensions/mps/__init__.py.

@anchor{design/doc design mps doc ext aka}@anchor{4ee}@ref{4ee,,.ext.aka;} The @code{aka} directive generates an “Also known as”
section. This should be used in a glossary entry, and should contain a
comma-separated, alphabetically ordered, list of glossary entries (in
italics) that are synonyms for this glossary entry.

@anchor{design/doc design mps doc ext bibref}@anchor{4ef}@ref{4ef,,.ext.bibref;} The @code{bibref} directive generates a “Related
publication” or “Related publications” section. This should be used in
a glossary entry, and should contain a comma-separated, alphabetically
ordered, list of @code{:ref:} roles referring to entries in the
bibliography.

@anchor{design/doc design mps doc ext deprecated}@anchor{4f0}@ref{4f0,,.ext.deprecated;} The @code{deprecated} directive generates a
“Deprecated” section. It should be used in a description of a public
interface in the MPS Reference, and describe the first version in
which the interface was deprecated, and the interface that should be
used instead. There may be an initial “starting with version 1.115”
paragraph, but this is unnecessary if the directive is used in the
“Deprecated interfaces” chapter.

@anchor{design/doc design mps doc ext historical}@anchor{4f1}@ref{4f1,,.ext.historical;} The @code{historical} directive generates a
“Historical note” section. This should be used in a glossary entry,
and should contain material of historical interest, for example the
origin of the term, or ways in which it was formerly used.

@anchor{design/doc design mps doc ext link}@anchor{4f2}@ref{4f2,,.ext.link;} The @code{link} directive generates a “Related link” or
“Related links” section. This should be used in a glossary entry, and
should contain a comma-separated list of references to URLs.

@anchor{design/doc design mps doc ext note}@anchor{4f3}@ref{4f3,,.ext.note;} The @code{note} directive generates a “Note” or “Notes”
section. This should consist of a paragraph or a numbered list
containing especially important information about an interface that a
user should be aware of when using it.

@anchor{design/doc design mps doc ext opposite}@anchor{4f4}@ref{4f4,,.ext.opposite;} The @code{opposite} directive generates an “Opposite
term” or “Opposite terms” section. This should be used in a glossary
entry, and should contain a comma-separated, alphabetically ordered,
list of @code{:term:} roles referring to glossary entries with opposite
meaning.

@anchor{design/doc design mps doc ext relevance}@anchor{4f5}@ref{4f5,,.ext.relevance;} The @code{relevance} directive generates a “Relevance
to memory management” section. This should be used in a glossary
entry, and should contain an explanation of how the term relates to
memory management, if this is not obvious.

@anchor{design/doc design mps doc ext see}@anchor{4f6}@ref{4f6,,.ext.see;} The @code{see} directive generates a “See” section. This
should be used in a glossary entry, and should contain a single
@code{:term:} role referring to the entry for which the currente entry is
a synonym.

@anchor{design/doc design mps doc ext seealso}@anchor{4f7}@ref{4f7,,.ext.seealso;} The @code{seealso} directive generates a “See also”
section. This should be used in a glossary entry, and should contain a
comma-separated, alphabetically ordered, list of @code{:term:} roles
referring to glossary entries that relate to the entry but are neither
synonyms for it (@ref{4ee,,.ext.aka}), nor opposites (@ref{4f4,,.ext.opposite}), nor
similar (@ref{4f8,,.ext.similar}).

@anchor{design/doc design mps doc ext similar}@anchor{4f8}@ref{4f8,,.ext.similar;} The @code{similar} directive generates a “Similar term”
or “Similar terms” section. This should be used in a glossary entry,
and should contain a comma-separated, alphabetically ordered, list of
@code{:term:} roles referring to glossary entries with similar meaning to
the entry but which are not synonyms for it (@ref{4ee,,.ext.aka}).

@anchor{design/doc design mps doc ext specific}@anchor{4f9}@ref{4f9,,.ext.specific;} The @code{mps:specific} directive generates an “In the
MPS” section. This should be used in a glossary entry, and should
contain an explanation of how the glossary entry pertains to the MPS.
If the term is idiosyncratic to the MPS, for example “spare committed
memory” then the entire glossary entry should consist of a single
@code{mps:specific} directive to make it clear that the term is not in
general use.

@node Design formatting conventions,References<3>,Manual extensions,Documentation
@anchor{design/doc design-formatting-conventions}@anchor{4fa}
@subsection Design formatting conventions


@anchor{design/doc design mps doc fmt}@anchor{4ec}@ref{4ec,,.fmt;} This section lists formatting conventions used in the design
documentation that are used to generate extended markup when the
design document is converted for use in the MPS manual. See
manual/source/extensions/mps/designs.py.

@anchor{design/doc design mps doc fmt function-decl}@anchor{4fb}@ref{4fb,,.fmt.function-decl;} A paragraph consisting of a function
declaration on a single line formatted as code, for example:

@example
`@w{`}void LandFinish(Land land)`@w{`}
@end example

is translated into a @code{c:function} directive:

@example
.. c:function:: void LandFinish(Land land)
@end example

@anchor{design/doc design mps doc fmt macro-decl}@anchor{4fc}@ref{4fc,,.fmt.macro-decl;} A paragraph consisting of a macro declaration on a
single line formatted as code, for example:

@example
`@w{`}RING_FOR(node, ring, next)`@w{`}
@end example

is translated into a @code{c:macro} directive:

@example
.. c:macro:: RING_FOR(node, ring, next)
@end example

@anchor{design/doc design mps doc fmt macro}@anchor{4fd}@ref{4fd,,.fmt.macro;} Macros are identified by having names consisting of
capital letters, numbers, and underscore, or appearing in the list of
exceptions given by the @code{MACROS} global in designs.py.

@anchor{design/doc design mps doc fmt type-def}@anchor{4fe}@ref{4fe,,.fmt.type-def;} A paragraph consisting of a type definition on a
single line formatted as code, for example:

@example
`@w{`}typedef LandStruct *Land`@w{`}
@end example

is translated into a @code{c:type} directive:

@example
.. c:type:: LandStruct *Land
@end example

@anchor{design/doc design mps doc fmt function-ref}@anchor{4ff}@ref{4ff,,.fmt.function-ref;} A word formatted as code and suffixed by @code{()},
for example:

@example
This saves a separate call to :c:func:`LandDelete()`, and uses the
knowledge of exactly where we found the range.
@end example

is translated into a @code{:c:func:} role:

@example
This saves a separate call to :c:func:`LandDelete`, and uses the
knowledge of exactly where we found the range.
@end example

@anchor{design/doc design mps doc fmt type-ref}@anchor{500}@ref{500,,.fmt.type-ref;} The name of an MPS type formatted as code, for
example:

@example
The function must return a :c:type:`Bool` indicating whether to continue
with the iteration.
@end example

is translated into a @code{:c:type:} role:

@example
The function must return a :c:type:`Bool` indicating whether to
continue with the iteration.
@end example

The list of MPS types thus converted is given by the @code{TYPES} global
in designs.py, plus any word matching @code{mps_[a-z_]+_[stu]}, plus any
word ending @code{Class}, @code{Function}, @code{Method}, @code{Struct}, or
@code{Union}.

@anchor{design/doc design mps doc fmt tag}@anchor{501}@ref{501,,.fmt.tag;} A paragraph starting with an MPS tag, for example:

@example
:mps:tag:`type.land` The type of a generic land instance.
@end example

is translated into an @code{:mps:tag:} role:

@example
:mps:tag:`type.land` The type of a generic land instance.
@end example

@anchor{design/doc design mps doc fmt ref}@anchor{502}@ref{502,,.fmt.ref;} Cross-references to tags, for example:

@example
A *node* is used in the typical data structure sense to mean an
element of a tree (see also :mps:ref:`.type.tree`).
@end example

is translated into an @code{:mps:ref:} role:

@example
A *node* is used in the typical data structure sense to mean an
element of a tree (see also :mps:ref:`.type.tree`).
@end example

@anchor{design/doc design mps doc fmt history}@anchor{503}@ref{503,,.fmt.history;} The section “Document History” is removed.

@anchor{design/doc design mps doc fmt copyright}@anchor{504}@ref{504,,.fmt.copyright;} The section “Copyright and License” is removed.

@anchor{design/doc design mps doc fmt sections}@anchor{505}@ref{505,,.fmt.sections;} Section numbers are removed.

@anchor{design/doc design mps doc fmt metadata}@anchor{506}@ref{506,,.fmt.metadata;} Metadata roles are removed, except for:

@anchor{design/doc design mps doc fmt metadata tag}@anchor{507}@ref{507,,.fmt.metadata.tag;} @code{:Tag:}, which is translated into an
@code{mps:prefix} directive; and

@anchor{design/doc design mps doc fmt metadata index}@anchor{508}@ref{508,,.fmt.metadata.index;} @code{:Index Terms:}, which is is translated into
an @code{index} directive.

@anchor{design/doc design mps doc fmt citation}@anchor{509}@ref{509,,.fmt.citation;} Citations are translated from design style:

@example
[Citation] "Title"; Author; Date; <URL>.
@end example

into manual style:

@example
[Citation] Author. Date. "`Title <URL>`__".
@end example

@anchor{design/doc design mps doc fmt link relative}@anchor{50a}@ref{50a,,.fmt.link.relative;} Project-relative links must be specified using
named hyperlink targets@footnote{https://docutils.sourceforge.io/docs/ref/rst/restructuredtext.html#hyperlink-targets} whose targets start with @code{../}, for
example:

@example
`@w{`}#ifdefs`@w{`}, such as in mps.c_.

.. _mps.c: ../../../code/mps.c
@end example

The target is adjusted to reflect the different location of the manual
sources relative to the design sources.

@node References<3>,,Design formatting conventions,Documentation
@anchor{design/doc named-hyperlink-targets}@anchor{50b}@anchor{design/doc references}@anchor{50c}
@subsection References


@anchor{design/doc rb-2013-05-09}@anchor{4dc}@w{(RB_2013-05-09)} 
Richard Brooksby. Ravenbrook Limited. 2013-05-09. “MPS design document format and process@footnote{https://info.ravenbrook.com/mail/2013/05/09/14-54-55/0/}”.

@geindex execution; environment

@node Execution environment,Fail-over allocator,Documentation,Design
@anchor{design/exec-env doc}@anchor{50d}@anchor{design/exec-env design-exec-env}@anchor{50e}@anchor{design/exec-env execution-environment}@anchor{50f}
@section Execution environment


@menu
* Introduction: Introduction<10>. 
* Discussion:: 
* Interpretation:: 
* Requirements: Requirements<7>. 
* Architecture:: 

@end menu

@node Introduction<10>,Discussion,,Execution environment
@anchor{design/exec-env design mps exec-env}@anchor{510}@anchor{design/exec-env introduction}@anchor{511}
@subsection Introduction


@anchor{design/exec-env design mps exec-env intro}@anchor{512}@ref{512,,.intro;} This document describes how the MPS is designed to work in
different execution environments (see standard.ansic section 5.1.2).

@node Discussion,Interpretation,Introduction<10>,Execution environment
@anchor{design/exec-env discussion}@anchor{513}
@subsection Discussion


@anchor{design/exec-env design mps exec-env std}@anchor{514}@ref{514,,.std;} These are the relevant statements from the International
Standard ISO/IEC 9899:1990 “Programming languages — C”, with tags
added:

@quotation


@enumerate 4

@item 
Compliance
@end enumerate

[…]

@anchor{design/exec-env design mps exec-env std com hosted}@anchor{515}@ref{515,,.std.com.hosted;} A “conforming hosted implementation” shall
accept any strictly conforming program. @anchor{design/exec-env design mps exec-env std com free}@anchor{516}@ref{516,,.std.com.free;} A
“conforming freestanding implementation” shall accept any strictly
conforming program in which the use of the features specified in
the library clause (clause 7) is confined to the contents of the
standard headers @code{<float.h>}, @code{<limits.h>}, @code{<stdarg.h>},
and @code{<stddef.h>}. A conforming implementation may have
extensions (including additional library functions), provided they
do not alter the behaviour of any strictly conforming program.

[…]

5.1.2 Execution environments

@anchor{design/exec-env design mps exec-env std def}@anchor{517}@ref{517,,.std.def;} Two execution environments are defined:
“freestanding” and “hosted”. […]

@anchor{design/exec-env design mps exec-env std init}@anchor{518}@ref{518,,.std.init;} All objects in static storage shall be “initialized”
(set to their initial values) before program startup. The manner
and timing of such initialization are otherwise unspecified. […]

@anchor{design/exec-env design mps exec-env std term}@anchor{519}@ref{519,,.std.term;} “Program termination” returns control to the execution
environment. […]

5.1.2.1 Freestanding environment

@anchor{design/exec-env design mps exec-env std free lib}@anchor{51a}@ref{51a,,.std.free.lib;} Any library facilities available to a
freestanding environment are implementation-defined.

@anchor{design/exec-env design mps exec-env std free term}@anchor{51b}@ref{51b,,.std.free.term;} The effect of program termination in a
free-standing environment is implementation-defined.
@end quotation

@node Interpretation,Requirements<7>,Discussion,Execution environment
@anchor{design/exec-env interpretation}@anchor{51c}
@subsection Interpretation


@anchor{design/exec-env design mps exec-env int free}@anchor{51d}@ref{51d,,.int.free;} We interpret the “freestanding environment” as being the
sort of environment you’d expect in an embedded system. The classic
example is a washing machine. There are no library facilities
available, only language facilities.

@anchor{design/exec-env design mps exec-env int free lib}@anchor{51e}@ref{51e,,.int.free.lib;} We assume that the headers @code{<float.h>},
@code{<limits.h>}, @code{<stdarg.h>} and @code{<stddef.h>} are available in the
freestanding environment, because they define only language features
and not library calls. We assume that we may not make use of
definitions in any other headers in freestanding parts of the system.

@anchor{design/exec-env design mps exec-env int free term}@anchor{51f}@ref{51f,,.int.free.term;} We may not terminate the program in a freestanding
environment, and therefore we may not call @code{abort()}. We can’t call
@code{abort()} anyway, because it’s not defined in the headers listed
above (@ref{51e,,.int.free.lib}).

@anchor{design/exec-env design mps exec-env int free term own}@anchor{520}@ref{520,,.int.free.term.own;} We can add an interface for asserting, that is,
reporting an error and not returning, for use in debugging builds
only. This is because the environment can implement this in a way that
does not return to the MPS, but doesn’t terminate, either. We need
this if debugging builds are to run in a (possibly simulated or
emulated) freestanding environment at all.

@node Requirements<7>,Architecture,Interpretation,Execution environment
@anchor{design/exec-env requirements}@anchor{521}
@subsection Requirements


@anchor{design/exec-env design mps exec-env req}@anchor{522}@ref{522,,.req;} It should be possible to make use of the MPS in a
freestanding environment such as an embedded controller.

@anchor{design/exec-env design mps exec-env req conf}@anchor{523}@ref{523,,.req.conf;} There can be configurations of the MPS that are not
freestanding (such as using a VM arena).

@node Architecture,,Requirements<7>,Execution environment
@anchor{design/exec-env architecture}@anchor{524}
@subsection Architecture


@anchor{design/exec-env design mps exec-env arch}@anchor{525}@ref{525,,.arch;} Like Gaul, the MPS is divided into three parts: the `core',
the `platform', and the `plinth'.

@anchor{design/exec-env design mps exec-env arch core}@anchor{526}@ref{526,,.arch.core;} The `core' consists of the Memory Pool Manager (the
core data structures and algorithms) and the built-in Pool Classes.
The core must be freestanding.

@anchor{design/exec-env design mps exec-env arch platform}@anchor{527}@ref{527,,.arch.platform;} The `platform' provides the core with interfaces to
features of the operating system and processor (locks, memory
protection, mutator context, stack probing, stack and register
scanning, thread management, and virtual memory). The platform is
specialized to a particular environment and so can safely use whatever
features are available in that environment.

@anchor{design/exec-env design mps exec-env arch plinth}@anchor{528}@ref{528,,.arch.plinth;} The `plinth' provides the core with interfaces to
features of the user environment (time, assertions, and logging). See
design.mps.io@footnote{io.html} and design.mps.lib@footnote{lib.html}.

@anchor{design/exec-env design mps exec-env arch distinction}@anchor{529}@ref{529,,.arch.distinction;} The distinction between `plinth' and `platform'
is that end users will need to customize the features provided by the
plinth for most programs that use the MPS (and so the interface needs
to be simple, documented and supported), whereas implementing the
platform interface is a specialized task that will typically be done
once for each platform and then maintained alongside the core.

@geindex fail-over allocator; design

@node Fail-over allocator,Finalization<3>,Execution environment,Design
@anchor{design/failover doc}@anchor{52a}@anchor{design/failover design-failover}@anchor{52b}@anchor{design/failover fail-over-allocator}@anchor{52c}
@section Fail-over allocator


@menu
* Introduction: Introduction<11>. 
* Interface: Interface<6>. 
* Implementation: Implementation<5>. 

@end menu

@node Introduction<11>,Interface<6>,,Fail-over allocator
@anchor{design/failover design mps failover}@anchor{52d}@anchor{design/failover introduction}@anchor{52e}
@subsection Introduction


@anchor{design/failover design mps failover intro}@anchor{52f}@ref{52f,,.intro;} This is the design of the fail-over allocator, a data
structure for the management of address ranges.

@anchor{design/failover design mps failover readership}@anchor{530}@ref{530,,.readership;} This document is intended for any MPS developer.

@anchor{design/failover design mps failover source}@anchor{531}@ref{531,,.source;} design.mps.land@footnote{land.html}, design.mps.poolmvt@footnote{poolmvt.html}, design.mps.poolmvff@footnote{poolmvff.html}.

@anchor{design/failover design mps failover overview}@anchor{532}@ref{532,,.overview;} The fail-over allocator combines two `land' instances.
It stores address ranges in one of the lands (the `primary') unless
insertion fails, in which case it falls back to the other (the
`secondary'). The purpose is to be able to combine two lands with
different properties: with a CBS@footnote{cbs} for the primary and a
Freelist@footnote{freelist} for the secondary, operations are fast so long as there
is memory to allocate new nodes in the CBS@footnote{cbs}, but operations can
continue using the Freelist@footnote{freelist} when memory is low.

@node Interface<6>,Implementation<5>,Introduction<11>,Fail-over allocator
@anchor{design/failover design-mps-poolmvff}@anchor{533}@anchor{design/failover interface}@anchor{534}
@subsection Interface


@anchor{design/failover design mps failover land}@anchor{535}@ref{535,,.land;} The fail-over allocator is an implementation of the `land'
abstract data type, so the interface consists of the generic functions
for lands. See design.mps.land@footnote{land.html}.

@menu
* Types: Types<3>. 
* Classes:: 
* Keyword arguments: Keyword arguments<3>. 

@end menu

@node Types<3>,Classes,,Interface<6>
@anchor{design/failover types}@anchor{536}
@subsubsection Types


@geindex Failover (C type)
@anchor{design/failover c Failover}@anchor{537}
@deffn {C Type} typedef struct FailoverStruct *Failover
@end deffn

@anchor{design/failover design mps failover type failover}@anchor{538}@ref{538,,.type.failover;} The type of fail-over allocator structures. A
@code{FailoverStruct} is typically embedded in another structure.

@node Classes,Keyword arguments<3>,Types<3>,Interface<6>
@anchor{design/failover classes}@anchor{539}
@subsubsection Classes


@anchor{design/failover design mps failover class}@anchor{53a}@ref{53a,,.class;} @code{CLASS(Failover)} is the fail-over allocator class, a
subclass of @code{CLASS(Land)} suitable for passing to @ref{406,,LandInit()}.

@node Keyword arguments<3>,,Classes,Interface<6>
@anchor{design/failover keyword-arguments}@anchor{53b}
@subsubsection Keyword arguments


When initializing a fail-over allocator, @ref{406,,LandInit()} requires these
two keyword arguments:


@itemize *

@item 
@code{FailoverPrimary} (type @ref{53c,,Land}) is the primary land.

@item 
@code{FailoverSecondary} (type @ref{53c,,Land}) is the secondary land.
@end itemize

@node Implementation<5>,,Interface<6>,Fail-over allocator
@anchor{design/failover implementation}@anchor{53d}
@subsection Implementation


@anchor{design/failover design mps failover impl assume}@anchor{53e}@ref{53e,,.impl.assume;} The implementation assumes that the primary is fast
but space-hungry (a CBS@footnote{cbs}) and the secondary is slow but space-frugal
(a Freelist@footnote{freelist}). This assumption is used in the following places:

@anchor{design/failover design mps failover impl assume flush}@anchor{53f}@ref{53f,,.impl.assume.flush;} The fail-over allocator attempts to flush the
secondary to the primary before any operation, in order to benefit
from the speed of the primary wherever possible. In the normal case
where the secondary is empty this is cheap.

@anchor{design/failover design mps failover impl assume delete}@anchor{540}@ref{540,,.impl.assume.delete;} When deletion of a range on the primary fails
due to lack of memory, we assume that this can only happen when there
are splinters on both sides of the deleted range, one of which needs
to be allocated a new node (this is the case for CBS@footnote{cbs}), and that
therefore the following procedure will be effective: first, delete the
enclosing range from the primary (leaving no splinters and thus
requiring no allocation), and re-insert the splinters (failing over to
the secondary if necessary).

@geindex finalization; design

@node Finalization<3>,Free list allocator,Fail-over allocator,Design
@anchor{design/finalize doc}@anchor{541}@anchor{design/finalize design-finalize}@anchor{542}@anchor{design/finalize finalization}@anchor{543}
@section Finalization


@menu
* Overview: Overview<2>. 
* Requirements: Requirements<8>. 
* Implementation: Implementation<6>. 
* External interface:: 
* Internal interface:: 

@end menu

@node Overview<2>,Requirements<8>,,Finalization<3>
@anchor{design/finalize design mps finalize}@anchor{544}@anchor{design/finalize overview}@anchor{545}
@subsection Overview


@anchor{design/finalize design mps finalize overview}@anchor{546}@ref{546,,.overview;} Finalization is implemented internally using the MRG
pool class (design.mps.poolmrg@footnote{poolmrg.html}). Objects can be registered for
finalization by calling @ref{e8,,mps_finalize()}. Notification of
finalization is given to the client via the messaging interface
(design.mps.message@footnote{message.html}). The MRG pool class implements a @ref{547,,Message}
subclass which implements the finalization messages.

@node Requirements<8>,Implementation<6>,Overview<2>,Finalization<3>
@anchor{design/finalize design-mps-message}@anchor{548}@anchor{design/finalize requirements}@anchor{549}
@subsection Requirements


@anchor{design/finalize design mps finalize req}@anchor{54a}@ref{54a,,.req;} Historically only Dylan had requirements for finalization,
see req.dylan.fun.final@footnote{https://info.ravenbrook.com/project/mps/import/2001-09-27/mminfo/doc/req/dylan}. Now (2003-02-19) Configura have requirements
for finalization. Happily they are very similar.

@node Implementation<6>,External interface,Requirements<8>,Finalization<3>
@anchor{design/finalize implementation}@anchor{54b}@anchor{design/finalize req-dylan-fun-final}@anchor{54c}
@subsection Implementation


@anchor{design/finalize design mps finalize impl over}@anchor{54d}@ref{54d,,.impl.over;} Registering an object for finalization corresponds to
allocating a reference of rank FINAL to that object. This reference is
allocated in a guardian object in a pool belonging to the MRG pool
class (see design.mps.poolmrg@footnote{poolmrg.html}).

@anchor{design/finalize design mps finalize impl arena struct}@anchor{54e}@ref{54e,,.impl.arena.struct;} A single pool belonging to the MRG pool class
and used for managing final references is kept in the arena and
referred to as the “final pool”.

@anchor{design/finalize design mps finalize impl arena lazy}@anchor{54f}@ref{54f,,.impl.arena.lazy;} The final pool is lazily created. It is not
created until the first object is registered for finalization.

@anchor{design/finalize design mps finalize impl arena flag}@anchor{550}@ref{550,,.impl.arena.flag;} There is a flag in the Arena that indicates
whether the final pool has been created yet or not.

@anchor{design/finalize design mps finalize impl scan}@anchor{551}@ref{551,,.impl.scan;} An object is determined to be finalizable if it is
fixed at rank FINAL for a trace, and was not fixed at any lower rank
for that trace. See design.mps.poolmrg.scan.wasold@footnote{poolmrg.html#design.mps.poolmrg.scan.wasold}.

@anchor{design/finalize design mps finalize impl message}@anchor{552}@ref{552,,.impl.message;} When an object is determined to be finalizable, a
message for that object is posted to the arena’s message queue.

@anchor{design/finalize design mps finalize impl arena-destroy empty}@anchor{553}@ref{553,,.impl.arena-destroy.empty;} @code{ArenaDestroy()} empties the message
queue by calling @ref{554,,MessageEmpty()}.

@anchor{design/finalize design mps finalize impl arena-destroy final-pool}@anchor{555}@ref{555,,.impl.arena-destroy.final-pool;} If the final pool has been created
then @code{ArenaDestroy()} destroys the final pool.

@anchor{design/finalize design mps finalize impl access}@anchor{556}@ref{556,,.impl.access;} @ref{ed,,mps_message_finalization_ref()} needs to access
the finalization message to retrieve the reference and then write it
to where the client asks. This must be done carefully, in order to
avoid invalidating collection invariants such as the segment summary.

@anchor{design/finalize design mps finalize impl invariants}@anchor{557}@ref{557,,.impl.invariants;} We protect the invariants by using
@code{ArenaRead()} and @code{ArenaWrite()} to read and write the reference
via the software barrier.

@node External interface,Internal interface,Implementation<6>,Finalization<3>
@anchor{design/finalize external-interface}@anchor{558}
@subsection External interface


@anchor{design/finalize design mps finalize if register}@anchor{559}@ref{559,,.if.register;} @ref{e8,,mps_finalize()} registers an object for
finalization.

@anchor{design/finalize design mps finalize if deregister}@anchor{55a}@ref{55a,,.if.deregister;} @ref{24c,,mps_definalize()} deregisters an object for
finalization. It is an error to definalize an object that has not been
registered for finalization.

@anchor{design/finalize design mps finalize if get-ref}@anchor{55b}@ref{55b,,.if.get-ref;} @ref{ed,,mps_message_finalization_ref()} returns the reference
to the finalized object stored in the finalization message.

@anchor{design/finalize design mps finalize if multiple}@anchor{55c}@ref{55c,,.if.multiple;} The external interface allows an object to be
registered multiple times, but does not specify the number of
finalization messages that will be posted for that object.

@node Internal interface,,External interface,Finalization<3>
@anchor{design/finalize internal-interface}@anchor{55d}
@subsection Internal interface


@geindex ArenaFinalize (C function)
@anchor{design/finalize c ArenaFinalize}@anchor{55e}
@deffn {C Function} @ref{55f,,Res} ArenaFinalize (Arena arena, Ref addr)
@end deffn

@anchor{design/finalize design mps finalize int finalize create}@anchor{560}@ref{560,,.int.finalize.create;} Creates the final pool if it has not been
created yet.

@anchor{design/finalize design mps finalize int finalize alloc}@anchor{561}@ref{561,,.int.finalize.alloc;} Allocates a guardian in the final pool.

@anchor{design/finalize design mps finalize int finalize alloc multiple}@anchor{562}@ref{562,,.int.finalize.alloc.multiple;} A consequence of this implementation
is that if an object is finalized multiple times, then multiple
guardians are created in the final pool, and so multiple messages will
be posted to the message queue when the object is determined to be
finalizable. But this behaviour is not guaranteed by the
documentation, leaving us free to change the implementation.

@anchor{design/finalize design mps finalize int finalize write}@anchor{563}@ref{563,,.int.finalize.write;} Writes a reference to the object into the
guardian object.

@anchor{design/finalize design mps finalize int finalize all}@anchor{564}@ref{564,,.int.finalize.all;} That’s all.

@anchor{design/finalize design mps finalize int finalize error}@anchor{565}@ref{565,,.int.finalize.error;} If either the creation of the pool or the
allocation of the object fails then the error is returned to the
caller.

@anchor{design/finalize design mps finalize int finalize error no-unwind}@anchor{566}@ref{566,,.int.finalize.error.no-unwind;} This function does not need to do
any unwinding in the error cases because the creation of the pool is
not something that needs to be undone.

@geindex ArenaDefinalize (C function)
@anchor{design/finalize c ArenaDefinalize}@anchor{567}
@deffn {C Function} @ref{55f,,Res} ArenaDefinalize (Arena arena, Ref obj)
@end deffn

@anchor{design/finalize design mps finalize int definalize fail}@anchor{568}@ref{568,,.int.definalize.fail;} If the final pool has not been created,
return @code{ResFAIL} immediately.

@anchor{design/finalize design mps finalize int definalize search}@anchor{569}@ref{569,,.int.definalize.search;} Otherwise, search for a guardian in the
final pool that refers to the object and which has not yet been
finalized. If one is found, delete it and return @code{ResOK}. Otherwise
no guardians in the final pool refer to the object, so return
@code{ResFAIL}.

@geindex free list allocator; design

@node Free list allocator,New developer guide,Finalization<3>,Design
@anchor{design/freelist doc}@anchor{56a}@anchor{design/freelist design-freelist}@anchor{56b}@anchor{design/freelist free-list-allocator}@anchor{56c}
@section Free list allocator


@menu
* Introduction: Introduction<12>. 
* Overview: Overview<3>. 
* Requirements: Requirements<9>. 
* Interface: Interface<7>. 
* Implementation: Implementation<7>. 
* Testing: Testing<2>. 
* Opportunities for improvement:: 

@end menu

@node Introduction<12>,Overview<3>,,Free list allocator
@anchor{design/freelist design mps freelist}@anchor{56d}@anchor{design/freelist introduction}@anchor{56e}
@subsection Introduction


@anchor{design/freelist design mps freelist intro}@anchor{56f}@ref{56f,,.intro;} This is the design of the free list allocator.

@anchor{design/freelist design mps freelist readership}@anchor{570}@ref{570,,.readership;} Any MPS developer.

@node Overview<3>,Requirements<9>,Introduction<12>,Free list allocator
@anchor{design/freelist overview}@anchor{571}
@subsection Overview


@anchor{design/freelist design mps freelist overview}@anchor{572}@ref{572,,.overview;} The free list allocator is an “emergency” allocator. It
is intended for use as a fallback allocation strategy in low memory
situations, when memory is not available for the control structures
needed by other allocators. In these situations the free list allocator
ensures that memory is not lost, but with several disadvantages:


@enumerate 

@item 
operations on the free list take time proportional to the number of
free blocks;

@item 
the data structures are stored in client memory and so are
vulnerable to corruption;

@item 
the data structures have poor locality (and thus potentially poor
cache performance).
@end enumerate

When memory becomes available again to allocate control structures,
the free lists can be “flushed” back into the more efficient data
structures.

@node Requirements<9>,Interface<7>,Overview<3>,Free list allocator
@anchor{design/freelist requirements}@anchor{573}
@subsection Requirements


In addition to the generic land requirements (see design.mps.land@footnote{land.html}),
free lists must satisfy:

@anchor{design/freelist design mps freelist req zero-overhead}@anchor{574}@ref{574,,.req.zero-overhead;} Must have zero space overhead for the storage
of any set of free blocks, so that it can be used to manage memory
when no memory can be allocated for control structures.

@node Interface<7>,Implementation<7>,Requirements<9>,Free list allocator
@anchor{design/freelist interface}@anchor{575}
@subsection Interface


@anchor{design/freelist design mps freelist land}@anchor{576}@ref{576,,.land;} Free lists are an implementation of the `land' abstract data
type, so the interface consists of the generic functions for lands.
See design.mps.land@footnote{land.html}.

@menu
* Types: Types<4>. 
* Classes: Classes<2>. 
* Keyword arguments: Keyword arguments<4>. 

@end menu

@node Types<4>,Classes<2>,,Interface<7>
@anchor{design/freelist types}@anchor{577}
@subsubsection Types


@geindex Freelist (C type)
@anchor{design/freelist c Freelist}@anchor{578}
@deffn {C Type} typedef struct FreelistStruct *Freelist
@end deffn

@anchor{design/freelist design mps freelist type freelist}@anchor{579}@ref{579,,.type.freelist;} The type of free lists. A @code{FreelistStruct} is
typically embedded in another structure.

@node Classes<2>,Keyword arguments<4>,Types<4>,Interface<7>
@anchor{design/freelist classes}@anchor{57a}
@subsubsection Classes


@anchor{design/freelist design mps freelist class}@anchor{57b}@ref{57b,,.class;} @code{CLASS(Freelist)} is the free list class, a subclass of
@code{CLASS(Land)} suitable for passing to @ref{406,,LandInit()}.

@node Keyword arguments<4>,,Classes<2>,Interface<7>
@anchor{design/freelist keyword-arguments}@anchor{57c}
@subsubsection Keyword arguments


When initializing a free list, @ref{406,,LandInit()} takes no keyword
arguments. Pass @code{mps_args_none}.

@node Implementation<7>,Testing<2>,Interface<7>,Free list allocator
@anchor{design/freelist implementation}@anchor{57d}
@subsection Implementation


@anchor{design/freelist design mps freelist impl list}@anchor{57e}@ref{57e,,.impl.list;} The isolated contiguous free address ranges are kept on
an address-ordered singly linked free list. (As in traditional
@code{malloc()} implementations.)

@anchor{design/freelist design mps freelist impl block}@anchor{57f}@ref{57f,,.impl.block;} If the free address range is large enough to contain
an inline block descriptor consisting of two pointers, then the two
pointers stored are to the next free range in address order (or
@code{freelistEND} if there are no more ranges), and to the limit of the
current free address range, in that order.

@anchor{design/freelist design mps freelist impl grain}@anchor{580}@ref{580,,.impl.grain;} Otherwise, the free address range must be large enough
to contain a single pointer. The pointer stored is to the next free
range in address order, or @code{freelistEND} if there are no more
ranges.

@anchor{design/freelist design mps freelist impl tag}@anchor{581}@ref{581,,.impl.tag;} Grains and blocks are distinguished by a one-bit tag in
the low bit of the first word (the one containing the pointer to the
next range). Grains have this bit set; blocks have this bit reset.

@anchor{design/freelist design mps freelist impl invariant}@anchor{582}@ref{582,,.impl.invariant;} The ranges stored in the free list are `isolated':
no two ranges are adjacent or overlapping.

@anchor{design/freelist design mps freelist impl merge}@anchor{583}@ref{583,,.impl.merge;} When a free address range is added to the free list,
it is merged with adjacent ranges so as to maintain
@ref{582,,.impl.invariant}.

@anchor{design/freelist design mps freelist impl rule break}@anchor{584}@ref{584,,.impl.rule.break;} The use of @code{freelistEND} to mark the end of the
list violates the rule that exceptional values should not be used to
distinguish exceptional situations. This infraction allows the
implementation to meet @ref{574,,.req.zero-overhead}. (There are other ways to
do this, such as using another tag to indicate the last block in the
list, but these would be more complicated.)

@node Testing<2>,Opportunities for improvement,Implementation<7>,Free list allocator
@anchor{design/freelist testing}@anchor{585}
@subsection Testing


@anchor{design/freelist design mps freelist test}@anchor{586}@ref{586,,.test;} The following testing will be performed on this module:

@anchor{design/freelist design mps freelist test land}@anchor{587}@ref{587,,.test.land;} A generic test for land implementations. See
design.mps.land.test@footnote{land.html#design.mps.land.test}.

@anchor{design/freelist design mps freelist test pool}@anchor{588}@ref{588,,.test.pool;} Two pools (MVT@footnote{poolmvt} and MVFF@footnote{poolmvff}) use free lists as a fallback
when low on memory. These are subject to testing in development, QA,
and are heavily exercised by customers.

@node Opportunities for improvement,,Testing<2>,Free list allocator
@anchor{design/freelist mvff}@anchor{589}@anchor{design/freelist opportunities-for-improvement}@anchor{58a}
@subsection Opportunities for improvement


@anchor{design/freelist design mps freelist improve length}@anchor{58b}@ref{58b,,.improve.length;} When iterating over the list, we could check that
the number of elements visited in the course of the iteration does not
exceed the recorded size of the list.

@anchor{design/freelist design mps freelist improve maxsize}@anchor{58c}@ref{58c,,.improve.maxsize;} We could maintain the maximum size of any range
on the list, and use that to make an early exit from
@code{freelistFindLargest()}. It’s not clear that this would actually be
an improvement.

@geindex developer; guide

@node New developer guide,Transliterating the alphabet into hexadecimal,Free list allocator,Design
@anchor{design/guide developer doc}@anchor{58d}@anchor{design/guide developer design-guide-developer}@anchor{58e}@anchor{design/guide developer new-developer-guide}@anchor{58f}
@section New developer guide


@menu
* Introduction: Introduction<13>. 
* What to read first:: 
* References: References<4>. 

@end menu

@node Introduction<13>,What to read first,,New developer guide
@anchor{design/guide developer guide developer}@anchor{590}@anchor{design/guide developer introduction}@anchor{591}
@subsection Introduction


@anchor{design/guide developer guide developer intro}@anchor{592}@ref{592,,.intro;} This is an introduction to the Memory Pool System (MPS) for
new developers.

@anchor{design/guide developer guide developer source}@anchor{593}@ref{593,,.source;} This is based on @ref{594,,[APT_2018-09-17]}.

@node What to read first,References<4>,Introduction<13>,New developer guide
@anchor{design/guide developer what-to-read-first}@anchor{595}
@subsection What to read first



@itemize *

@item 
manual/build.txt@footnote{https://www.ravenbrook.com/project/mps/master/manual/build.txt} – how to build the MPS.

@item 
manual/guide@footnote{https://www.ravenbrook.com/project/mps/master/manual/html/guide/index.html} – tutorial for the public interface.

@item 
manual/topic@footnote{https://www.ravenbrook.com/project/mps/master/manual/html/topic/index.html} – reference manual for the public interface.

@item 
manual/code-index@footnote{https://www.ravenbrook.com/project/mps/master/manual/html/code-index.html} – description and purpose of each file of source code.

@item 
design.mps.config@footnote{config.html} – build configuration.

@item 
design.mps.tests@footnote{tests.html} – how to run test cases.

@item 
design.mps.doc@footnote{doc.html} – how to write and edit documentation.
@end itemize

@node References<4>,,What to read first,New developer guide
@anchor{design/guide developer design-mps-doc}@anchor{596}@anchor{design/guide developer references}@anchor{597}
@subsection References


@anchor{design/guide developer apt-2018-09-17}@anchor{594}@w{(APT_2018-09-17)} 
“Procedure for new developers”; Alistair Turnbull; Ravenbrook Limited; 2018-09-17; <@indicateurl{https://info.ravenbrook.com/mail/2018/09/17/11-16-41/0/}>

@geindex hexadecimal; transliterating

@node Transliterating the alphabet into hexadecimal,C Style – formatting,New developer guide,Design
@anchor{design/guide hex trans doc}@anchor{598}@anchor{design/guide hex trans design-guide-hex-trans}@anchor{599}@anchor{design/guide hex trans transliterating-the-alphabet-into-hexadecimal}@anchor{59a}
@section Transliterating the alphabet into hexadecimal


@menu
* Introduction: Introduction<14>. 
* Transliteration:: 
* Justification:: 
* Notes:: 
* References: References<5>. 

@end menu

@node Introduction<14>,Transliteration,,Transliterating the alphabet into hexadecimal
@anchor{design/guide hex trans guide hex trans}@anchor{59b}@anchor{design/guide hex trans introduction}@anchor{59c}
@subsection Introduction


@anchor{design/guide hex trans guide hex trans scope}@anchor{59d}@ref{59d,,.scope;} This document explains how to represent the alphabet as
hexadecimal digits.

@anchor{design/guide hex trans guide hex trans readership}@anchor{59e}@ref{59e,,.readership;} This document is intended for anyone devising
arbitrary constants which may appear in hex-dumps.

@anchor{design/guide hex trans guide hex trans sources}@anchor{59f}@ref{59f,,.sources;} This transliteration was supplied by Richard Kistruck
@ref{5a0,,[RHSK-1997-04-07]} based on magic number encodings for object signatures
used by Richard Brooksby @ref{5a1,,[RB-1996-02-12]}, the existence of which was
inspired by the structure marking used in the Multics operating system
@ref{5a2,,[THVV-1995]}.

@node Transliteration,Justification,Introduction<14>,Transliterating the alphabet into hexadecimal
@anchor{design/guide hex trans transliteration}@anchor{5a3}
@subsection Transliteration


@anchor{design/guide hex trans guide hex trans forward}@anchor{5a4}@ref{5a4,,.forward;} The chosen transliteration is as follows:

@example
ABCDEFGHIJKLMNOPQRSTUVWXYZ
ABCDEF9811C7340BC6520F3812
@end example

@anchor{design/guide hex trans guide hex trans backward}@anchor{5a5}@ref{5a5,,.backward;} The backwards transliteration is as follows:

@example
0 OU
1 IJY
2 TZ
3 MW
4 N
5 S
6 R
7 L
8 HX
9 G
A A
B BP
C CKQ
D D
E E
F FV
@end example

@anchor{design/guide hex trans guide hex trans pad}@anchor{5a6}@ref{5a6,,.pad;} If padding is required (to fill a hex constant length), you
should use 9’s, because G is rare and can usually be inferred from
context.

@anchor{design/guide hex trans guide hex trans punc}@anchor{5a7}@ref{5a7,,.punc;} There is no formal scheme for spaces, or punctuation. It is
suggested that you use 9 (as @ref{5a6,,.pad}).

@node Justification,Notes,Transliteration,Transliterating the alphabet into hexadecimal
@anchor{design/guide hex trans justification}@anchor{5a8}
@subsection Justification


@anchor{design/guide hex trans guide hex trans letters}@anchor{5a9}@ref{5a9,,.letters;} The hexadecimal letters (A-F) are all formed by
similarity of sound. B and P sound similar, as do F and V, and C, K, &
Q can all sound similar.

@anchor{design/guide hex trans guide hex trans numbers}@anchor{5aa}@ref{5aa,,.numbers;} The numbers (0-9) are all formed by similarity of shape
(but see @ref{5ab,,.trans.t}). Nevertheless, 1=IJY retains some similarity of
sound.

@anchor{design/guide hex trans guide hex trans trans t}@anchor{5ab}@ref{5ab,,.trans.t;} T is an exception to @ref{5aa,,.numbers}, but is such a common
letter that it deserves it.

@node Notes,References<5>,Justification,Transliterating the alphabet into hexadecimal
@anchor{design/guide hex trans notes}@anchor{5ac}
@subsection Notes


@anchor{design/guide hex trans guide hex trans change}@anchor{5ad}@ref{5ad,,.change;} This transliteration differs from the old transliteration
used for signatures (see design.mps.sig@footnote{sig.html}), as follows: J:6->1;
L:1->7; N:9->4; R:4->6; W:8->3; X:5->8; Y:E->I.

@anchor{design/guide hex trans guide hex trans problem mw}@anchor{5ae}@ref{5ae,,.problem.mw;} There is a known problem that M and W are both common,
map to the same digit (3), and are hard to distinguish in context.

@anchor{design/guide hex trans guide hex trans find c}@anchor{5af}@ref{5af,,.find.c;} It is possible to find all 8-digit hexadecimal constants
and how many times they’re used in C files, using the following Perl
script:

@example
perl5 -n -e 'BEGIN @{ %C=(); @} if(/0x([0-9A-Fa-f]@{8@})/) @{ $C@{$1@} = +[] if(
!defined($C@{$1@})); push(@@@{$C@{$1@}@}, $ARGV); @} END @{ foreach $H (sort(keys(%C)))
@{ printf "%3d %s %s\n", scalar(@@@{$C@{$H@}@}), $H, join(", ", @@@{@@C@{$H@}@}); @} @}' *.c
*.h
@end example

@anchor{design/guide hex trans guide hex trans comment}@anchor{5b0}@ref{5b0,,.comment;} It is a good idea to add a comment to any constant
declaration indicating the English version and which letters were
selected (by capitalisation), e.g.:

@example
#define SpaceSig        ((Sig)0x5195BACE) /* SIGnature SPACE */
@end example

@node References<5>,,Notes,Transliterating the alphabet into hexadecimal
@anchor{design/guide hex trans references}@anchor{5b1}
@subsection References


@anchor{design/guide hex trans rb-1996-02-12}@anchor{5a1}@w{(RB-1996-02-12)} 
“Signature magic numbers” (e-mail message); @email{rb@@ravenbrook.com,Richard Brooksby}; Harlequin; 1996-12-02 12:05:30Z.

@anchor{design/guide hex trans rhsk-1997-04-07}@anchor{5a0}@w{(RHSK-1997-04-07)} 
“Alpha-to-Hex v1.0 beta”; Richard Kistruck; Ravenbrook; 1997-04-07 14:42:02+0100; <@indicateurl{https://info.ravenbrook.com/project/mps/mail/1997/04/07/13-44/0.txt}>.

@anchor{design/guide hex trans thvv-1995}@anchor{5a2}@w{(THVV-1995)} 
“Structure Marking”; Tom Van Vleck; multicians.org@footnote{http://www.multicians.org/}; <@indicateurl{http://www.multicians.org/thvv/marking.html}>.

@geindex C language; formatting guide
@geindex C language formatting; guide

@node C Style – formatting,C Style – naming,Transliterating the alphabet into hexadecimal,Design
@anchor{design/guide impl c format doc}@anchor{5b2}@anchor{design/guide impl c format c-style-formatting}@anchor{5b3}@anchor{design/guide impl c format design-guide-impl-c-format}@anchor{5b4}@anchor{design/guide impl c format multicians-org}@anchor{5b5}
@section C Style – formatting


@menu
* Introduction: Introduction<15>. 
* General formatting conventions:: 

@end menu

@node Introduction<15>,General formatting conventions,,C Style – formatting
@anchor{design/guide impl c format guide impl c format}@anchor{5b6}@anchor{design/guide impl c format introduction}@anchor{5b7}
@subsection Introduction


@anchor{design/guide impl c format guide impl c format scope}@anchor{5b8}@ref{5b8,,.scope;} This document describes the Ravenbrook conventions for the
general format of C source code in the MPS.

@anchor{design/guide impl c format guide impl c format readership}@anchor{5b9}@ref{5b9,,.readership;} This document is intended for anyone working on or with the
C source code.

@node General formatting conventions,,Introduction<15>,C Style – formatting
@anchor{design/guide impl c format general-formatting-conventions}@anchor{5ba}
@subsection General formatting conventions


@menu
* Line width:: 
* White space:: 
* Sections and paragraphs:: 
* Statements:: 
* Indentation:: 
* Positioning of braces:: 
* Switch statements:: 
* Comments:: 
* Macros: Macros<2>. 

@end menu

@node Line width,White space,,General formatting conventions
@anchor{design/guide impl c format line-width}@anchor{5bb}
@subsubsection Line width


@anchor{design/guide impl c format guide impl c format width}@anchor{5bc}@ref{5bc,,.width;} Lines should be no wider than 72 characters. @anchor{design/guide impl c format guide impl c format width why}@anchor{5bd}@ref{5bd,,.width.why;} Many
people use 80 column terminal windows so that multiple windows can be
placed side by side. Restricting lines to 72 characters allows line
numbering to be used (in vi for example) and also allows diffs to be
displayed without overflowing the terminal.

@node White space,Sections and paragraphs,Line width,General formatting conventions
@anchor{design/guide impl c format white-space}@anchor{5be}
@subsubsection White space


@anchor{design/guide impl c format guide impl c format space notab}@anchor{5bf}@ref{5bf,,.space.notab;} No tab characters should appear in the source files.
Ordinary spaces should be used to indent and format the sources.

@anchor{design/guide impl c format guide impl c format space notab why}@anchor{5c0}@ref{5c0,,.space.notab.why;} Tab characters are displayed differently on different
platforms, and sometimes translated back and forth, destroying layout
information.

@anchor{design/guide impl c format guide impl c format space punct}@anchor{5c1}@ref{5c1,,.space.punct;} There should always be whitespace after commas and
semicolons and similar punctuation.

@anchor{design/guide impl c format guide impl c format space op}@anchor{5c2}@ref{5c2,,.space.op;} Put white space around operators in expressions, except when
removing it would make the expression clearer by binding certain
sub-expressions more tightly. For example:

@example
foo = x + y*z;
@end example

@anchor{design/guide impl c format guide impl c format space control}@anchor{5c3}@ref{5c3,,.space.control;} One space between a control-flow keyword
(@code{switch}, @code{while}, @code{for}, @code{if}) and the following opening
parenthesis.

@anchor{design/guide impl c format guide impl c format space control why}@anchor{5c4}@ref{5c4,,.space.control.why;} This distinguishes control statements lexically
from function calls, making it easier to distinguish them visually and
when searching with tools like @code{grep}.

@anchor{design/guide impl c format guide impl c format space function not}@anchor{5c5}@ref{5c5,,.space.function.not;} No space between a function name and the opening
parenthesis beginning its argument list.

@node Sections and paragraphs,Statements,White space,General formatting conventions
@anchor{design/guide impl c format sections-and-paragraphs}@anchor{5c6}
@subsubsection Sections and paragraphs


@anchor{design/guide impl c format guide impl c format section}@anchor{5c7}@ref{5c7,,.section;} Source files can be thought of as breaking down into
“sections” and “paragraphs”. A section might be the leader comment of a
file, the imports, or a set of declarations which are related.

@anchor{design/guide impl c format guide impl c format section space}@anchor{5c8}@ref{5c8,,.section.space;} Precede sections by two blank lines (except the first
one in the file, which should be the leader comment in any case).

@anchor{design/guide impl c format guide impl c format section comment}@anchor{5c9}@ref{5c9,,.section.comment;} Each section should start with a banner comment (see
@ref{5ca,,.comment.banner}) describing what the section contains.

@anchor{design/guide impl c format guide impl c format para}@anchor{5cb}@ref{5cb,,.para;} Within sections, code often breaks down into natural units called
“paragraphs”. A paragraph might be a set of strongly related
declarations (Init and Finish, for example), or a few lines of code
which it makes sense to consider together (the assignment of fields into
a structure, for example).

@anchor{design/guide impl c format guide impl c format para space}@anchor{5cc}@ref{5cc,,.para.space;} Precede paragraphs by a single blank line.

@node Statements,Indentation,Sections and paragraphs,General formatting conventions
@anchor{design/guide impl c format statements}@anchor{5cd}
@subsubsection Statements


@anchor{design/guide impl c format guide impl c format statement one}@anchor{5ce}@ref{5ce,,.statement.one;} Generally only have at most one statement per line. In
particular the following are deprecated:

@example
if (thing) return;

a=0; b=0;

case 0: f = inRampMode ? AMCGen0RampmodeFrequency : AMCGen0Frequency;
@end example

@anchor{design/guide impl c format guide impl c format statement one why}@anchor{5cf}@ref{5cf,,.statement.one.why;} Debuggers can often only place breakpoints on lines,
not expressions or statements within a line. The @code{if (thing) return;} is
a particularly important case, if thing is a reasonably rare return
condition then you might want to breakpoint it in a debugger session.
Annoying because @code{if (thing) return;} is quite compact and pleasing
otherwise.

@node Indentation,Positioning of braces,Statements,General formatting conventions
@anchor{design/guide impl c format indentation}@anchor{5d0}
@subsubsection Indentation


@anchor{design/guide impl c format guide impl c format indent}@anchor{5d1}@ref{5d1,,.indent;} Indent the body of a block by two spaces. For formatting
purposes, the “body of a block” means:


@itemize -

@item 
statements between braces,

@item 
a single statement following a lone @code{if};

@item 
statements in a switch body; see .switch.
@end itemize

(@anchor{design/guide impl c format guide impl c format indent logical}@anchor{5d2}@ref{5d2,,.indent.logical;} The aim is to group what we think of as logical
blocks, even though they may not exactly match how “block” is used in
the definition of C syntax).

Some examples:

@example
if (res != ResOK) @{
  SegFinish(&span->segStruct);
  PoolFreeP(MV->spanPool, span, sizeof(SpanStruct));
  return res;
@}

if (res != ResOK)
  goto error;

if (j == block->base) @{
  if (j+step == block->limit) @{
    if (block->thing)
      putc('@@', stream);
  @}
@} else if (j+step == block->limit) @{
  putc(']', stream);
  pop_bracket();
@} else @{
  putc('.', stream);
@}

switch (c) @{
case 'A':
  c = 'A';
  p += 1;
  break;
@}
@end example

@anchor{design/guide impl c format guide impl c format indent goto-label}@anchor{5d3}@ref{5d3,,.indent.goto-label;} Place each goto-label on a line of its own,
outdented to the same level as the surrounding block. Then indent the
non-label part of the statement normally.

@example
result foo(void)
@{
  statement();
  if (error)
    goto foo;
  statement();
  return OK;

foo:
  unwind();
  return ERROR;
@}
@end example

@anchor{design/guide impl c format guide impl c format indent case-label}@anchor{5d4}@ref{5d4,,.indent.case-label;} Outdent case- and default-labels in a switch
statement in the same way as @ref{5d3,,.indent.goto-label}.  See @ref{5d5,,.switch}.

@anchor{design/guide impl c format guide impl c format indent cont}@anchor{5d6}@ref{5d6,,.indent.cont;} If an expression or statement won’t fit on a single line,
indent the continuation lines by two spaces, apart from the following
exception:

@anchor{design/guide impl c format guide impl c format indent cont parens}@anchor{5d7}@ref{5d7,,.indent.cont.parens;} if you break a statement inside a parameter list or
other parenthesized expression, indent so that the continuation lines up
just after the open parenthesis. For example:

@example
res = ChunkInit(chunk, arena, alignedBase,
                AddrAlignDown(limit, ArenaGrainSize(arena)),
                AddrOffset(base, limit), boot);
@end example

@anchor{design/guide impl c format guide impl c format indent cont expr}@anchor{5d8}@ref{5d8,,.indent.cont.expr;} Note that when breaking an expression it is clearer
to place the operator at the start of the continuation line:

@example
CHECKL(AddrAdd((Addr)chunk->allocTable, BTSize(chunk->pages))
       <= PageIndexBase(chunk, chunk->allocBase));
@end example

This is particularly useful in long conditional expressions that use &&
and ||. For example:

@example
if (BufferRankSet(buffer) != RankSetEMPTY
    && (buffer->mode & BufferModeFLIPPED) == 0
    && !BufferIsReset(buffer))
@end example

@anchor{design/guide impl c format guide impl c format indent hint}@anchor{5d9}@ref{5d9,,.indent.hint;} Usually, it is possible to determine the correct
indentation for a line by looking to see if the previous line ends with
a semicolon. If it does, indent to the same amount, otherwise indent by
two more spaces. The main exceptions are lines starting with a close
brace, goto-labels, and line-breaks between parentheses.

@node Positioning of braces,Switch statements,Indentation,General formatting conventions
@anchor{design/guide impl c format positioning-of-braces}@anchor{5da}
@subsubsection Positioning of braces


@anchor{design/guide impl c format guide impl c format brace otb}@anchor{5db}@ref{5db,,.brace.otb;} Use the “One True Brace” (or OTB) style. This places the
open brace after the control word or expression, separated by a space,
and when there is an else, places that after the close brace. For
example:

@example
if (buffer->mode & BufferModeFLIPPED) @{
  return buffer->initAtFlip;
@} else @{
  return buffer->ap_s.init;
@}
@end example

The same applies to @code{struct}, @code{enum}, and @code{union}.

@anchor{design/guide impl c format guide impl c format brace otb function not}@anchor{5dc}@ref{5dc,,.brace.otb.function.not;} OTB is never used for function definitions.

@anchor{design/guide impl c format guide impl c format brace always}@anchor{5dd}@ref{5dd,,.brace.always;} Braces are always required after @code{if}, @code{else}, @code{switch},
@code{while}, @code{do}, and @code{for}.

@anchor{design/guide impl c format guide impl c format brace always except}@anchor{5de}@ref{5de,,.brace.always.except;} Except that a lone @code{if} with no @code{else} is allowed
to drop its braces when its body is a single simple statement. Typically
this will be a @code{goto} or an assignment. For example:

@example
if (res != ResOK)
  goto failStart;
@end example

Note in particular that an @code{if} with an @code{else} must have braces on both
paths.

@node Switch statements,Comments,Positioning of braces,General formatting conventions
@anchor{design/guide impl c format switch-statements}@anchor{5df}
@subsubsection Switch statements


@anchor{design/guide impl c format guide impl c format switch}@anchor{5d5}@ref{5d5,,.switch;} format switch statements like this:

@example
switch (SplaySplay(splay, oldKey, splay->compare)) @{
default:
  NOTREACHED;
  /* fall through */
case CompareLESS:
  return SplayTreeRoot(splay);

case CompareGREATER:
case CompareEQUAL:
  return SplayTreeSuccessor(splay);
@}
@end example

The component rules that result in this style are:

@anchor{design/guide impl c format guide impl c format switch break}@anchor{5e0}@ref{5e0,,.switch.break;} The last line of every case-clause body must be an
unconditional jump statement (usually @code{break}, but may be @code{goto},
@code{continue}, or @code{return}), or if a fall-through is intended, the
comment @code{/* fall through */}. (Note: if the unconditional jump
should never be taken, because of previous conditional jumps, use
@code{NOTREACHED} on the line before it.) This rule is to prevent
accidental fall-throughs, even if someone makes a editing mistake that
causes a conditional jump to be missed. This rule is automatically
checked by GCC and Clang with the @code{-Wimplicit-fallthrough} option.

@anchor{design/guide impl c format guide impl c format switch default}@anchor{5e1}@ref{5e1,,.switch.default;} It is usually a good idea to have a
default-clause, even if all it contains is @code{NOTREACHED} and
@code{break} or @code{/* fall through */}. Remember that @code{NOTREACHED}
doesn’t stop the process in all build varieties.

@node Comments,Macros<2>,Switch statements,General formatting conventions
@anchor{design/guide impl c format comments}@anchor{5e2}
@subsubsection Comments


@anchor{design/guide impl c format guide impl c format comment}@anchor{5e3}@ref{5e3,,.comment;} There are three types of comments: banners, paragraph
comments, and column comments.

@anchor{design/guide impl c format guide impl c format comment banner}@anchor{5ca}@ref{5ca,,.comment.banner;} Banner comments come at the start of sections. A banner
comment consists of a heading usually composed of a symbol, an em-dash
(–) and a short explanation, followed by English text which is
formatted using conventional text documentation guidelines (see
guide.text). The open and close comment tokens (@code{/*} and @code{*/}) are
placed at the top and bottom of a column of asterisks. The text is
separated from the asterisks by one space. Place a blank line between
the banner comment and the section it comments. For example:

@example
/* BlockStruct --  Block descriptor
 *
 * The pool maintains a descriptor structure for each
 * contiguous allocated block of memory it manages.
 * The descriptor is on a simple linked-list of such
 * descriptors, which is in ascending order of address.
 */

typedef struct BlockStruct @{
@end example

@anchor{design/guide impl c format guide impl c format comment para}@anchor{5e4}@ref{5e4,,.comment.para;} Paragraph comments come at the start of paragraphs
in the code. A paragraph comment consists of formatted English text.
For example:

@example
/* If the freed area is in the base sentinel then insert
   the new descriptor after it, otherwise insert before. */
if (isBase) @{
@end example

@anchor{design/guide impl c format guide impl c format comment para precede}@anchor{5e5}@ref{5e5,,.comment.para.precede;} Paragraph comments, even one-liners, precede the
code to which they apply.

@anchor{design/guide impl c format guide impl c format comment column}@anchor{5e6}@ref{5e6,,.comment.column;} Column comments appear in a column to the right of
the code. They should be used sparingly, since they clutter the code and
make it hard to edit. Use them on variable declarations and structure,
union, or enum declarations. They should start at least at column 32
(counting from 0, that is, on a tab-stop), and should be terse
descriptive text. Abandon English sentence structure if this makes the
comment clearer. Don’t write more than one line. Here’s an example:

@example
typedef struct MVFFStruct @{     /* MVFF pool outer structure */
  PoolStruct poolStruct;        /* generic structure */
  LocusPrefStruct locusPrefStruct; /* the preferences for allocation */
  Size extendBy;                /* size to extend pool by */
  Size avgSize;                 /* client estimate of allocation size */
  double spare;                 /* spare space fraction, see MVFFReduce */
  MFSStruct cbsBlockPoolStruct; /* stores blocks for CBSs */
  CBSStruct totalCBSStruct;     /* all memory allocated from the arena */
  CBSStruct freeCBSStruct;      /* free memory (primary) */
  FreelistStruct flStruct;      /* free memory (secondary, for emergencies) */
  FailoverStruct foStruct;      /* free memory (fail-over mechanism) */
  Bool firstFit;                /* as opposed to last fit */
  Bool slotHigh;                /* prefers high part of large block */
  Sig sig;                      /* <design/sig/> */
@} MVFFStruct;
@end example

@node Macros<2>,,Comments,General formatting conventions
@anchor{design/guide impl c format macros}@anchor{5e7}
@subsubsection Macros


@anchor{design/guide impl c format guide impl c format macro careful}@anchor{5e8}@ref{5e8,,.macro.careful;} Macros in C are a real horror bag, be extra careful.
There’s lots that could go here, but proper coverage probably deserves a
separate document. Which isn’t written yet.

@anchor{design/guide impl c format guide impl c format macro general}@anchor{5e9}@ref{5e9,,.macro.general;} Do try and follow the other formatting conventions for
code in macro definitions.

@anchor{design/guide impl c format guide impl c format macro backslash}@anchor{5ea}@ref{5ea,,.macro.backslash;} Backslashes used for continuation lines in macro
definitions should be put on the right somewhere where they will be less
in the way. Example:

@example
#define RAMP_RELATION(X)                       \
  X(RampOUTSIDE,        "outside ramp")        \
  X(RampBEGIN,          "begin ramp")          \
  X(RampRAMPING,        "ramping")             \
  X(RampFINISH,         "finish ramp")         \
  X(RampCOLLECTING,     "collecting ramp")
@end example

@geindex C language; naming guide
@geindex C language naming; guide

@node C Style – naming,Review checklist,C Style – formatting,Design
@anchor{design/guide impl c naming doc}@anchor{5eb}@anchor{design/guide impl c naming c-style-naming}@anchor{5ec}@anchor{design/guide impl c naming design-guide-impl-c-naming}@anchor{5ed}
@section C Style – naming


@menu
* Introduction: Introduction<16>. 
* Capitalization:: 
* Prefixes:: 
* Suffixes:: 

@end menu

@node Introduction<16>,Capitalization,,C Style – naming
@anchor{design/guide impl c naming guide impl c naming}@anchor{5ee}@anchor{design/guide impl c naming introduction}@anchor{5ef}
@subsection Introduction


@anchor{design/guide impl c naming guide impl c naming scope}@anchor{5f0}@ref{5f0,,.scope;} This document describes the conventions for naming in C
source code that’s internal in the MPS. See design.mps.interface-c@footnote{interface-c.html}
for the corresponding conventions for the public interface.

@anchor{design/guide impl c naming guide impl c naming readership}@anchor{5f1}@ref{5f1,,.readership;} This document is intended for anyone working on or
with the C source code.

@node Capitalization,Prefixes,Introduction<16>,C Style – naming
@anchor{design/guide impl c naming capitalization}@anchor{5f2}
@subsection Capitalization


@anchor{design/guide impl c naming guide impl c naming capital macro}@anchor{5f3}@ref{5f3,,.capital.macro;} Statement-like macros have names consisting of
uppercase words separated by underscores, for example
@code{ARG_DEFINE_KEY}.

@anchor{design/guide impl c naming guide impl c naming capital constant}@anchor{5f4}@ref{5f4,,.capital.constant;} Constants have names consisting of a type (named
according to @ref{5f5,,.capital.program} or @ref{5f6,,.capital.other}), concatenated
with an identifier in uppercase with underscores, for example
@code{BufferFramePOP_PENDING}.

@anchor{design/guide impl c naming guide impl c naming capital program}@anchor{5f5}@ref{5f5,,.capital.program;} Other names with program scope consist of
concatenated title-case words, for example @code{BufferFramePush}.

@anchor{design/guide impl c naming guide impl c naming capital other}@anchor{5f6}@ref{5f6,,.capital.other;} Other names (including function parameters, names
with block scope, and names with file scope) consist of concatenated
words, the first of which is lowercase and the remainder are
uppercase. For example, @code{poolReturn}.

@node Prefixes,Suffixes,Capitalization,C Style – naming
@anchor{design/guide impl c naming prefixes}@anchor{5f7}
@subsection Prefixes


@anchor{design/guide impl c naming guide impl c naming prefix program}@anchor{5f8}@ref{5f8,,.prefix.program;} Any name with program scope must start with the
name of the module to which it belongs. For example, names belonging
to the buffer module must start with @code{buffer} or @code{Buffer} or
@code{BUFFER}. Justification: the C language lacks a namespace facility
so the only way to avoid name clashes is for each name to be globally
unique.

@anchor{design/guide impl c naming guide impl c naming prefix file}@anchor{5f9}@ref{5f9,,.prefix.file;} Any name with file scope should start with the name
of the module to which it belongs. Justification: makes it easy to
tell which module a function belongs to; makes it easy to set
breakpoints in the debugger.

@node Suffixes,,Prefixes,C Style – naming
@anchor{design/guide impl c naming suffixes}@anchor{5fa}
@subsection Suffixes


@anchor{design/guide impl c naming guide impl c naming suffix struct}@anchor{5fb}@ref{5fb,,.suffix.struct;} The type of a structure must be the same as the
structure tag, and must consist of the type of the pointer to the
structure concatenated with @code{Struct}. For example, @code{ArenaStruct}.

@anchor{design/guide impl c naming guide impl c naming suffix union}@anchor{5fc}@ref{5fc,,.suffix.union;} The type of a union must be the same as the union
tag, and must consist of the type of the pointer to the union
concatenated with @code{Union}. For example, @code{PageUnion}.

@anchor{design/guide impl c naming guide impl c naming suffix class}@anchor{5fd}@ref{5fd,,.suffix.class;} The type of a class (see design.mps.protocol@footnote{protocol.html})
must end with @code{Class}. For example, @code{ArenaClass}.

@anchor{design/guide impl c naming guide impl c naming suffix method}@anchor{5fe}@ref{5fe,,.suffix.method;} The type of a method in a class must end with
@code{Method}. For example, @code{PoolFixMethod}.

@anchor{design/guide impl c naming guide impl c naming suffix visitor}@anchor{5ff}@ref{5ff,,.suffix.visitor;} The type of a visitor function must end with
@code{Visitor}. For example, @code{TreeVisitor}.

@anchor{design/guide impl c naming guide impl c naming suffix function}@anchor{600}@ref{600,,.suffix.function;} The type of other functions must end with
@code{Function}. For example, @ref{601,,TreeKeyFunction}.

@geindex review; checklist

@node Review checklist,C interface design,C Style – naming,Design
@anchor{design/guide review doc}@anchor{602}@anchor{design/guide review design-guide-review}@anchor{603}@anchor{design/guide review review-checklist}@anchor{604}
@section Review checklist


@menu
* Introduction: Introduction<17>. 
* Checklist:: 

@end menu

@node Introduction<17>,Checklist,,Review checklist
@anchor{design/guide review guide review}@anchor{605}@anchor{design/guide review introduction}@anchor{606}
@subsection Introduction


@anchor{design/guide review guide review scope}@anchor{607}@ref{607,,.scope;} This document contains a list of checks to apply when
reviewing code or other documents in the Memory Pool System.

@anchor{design/guide review guide review readership}@anchor{608}@ref{608,,.readership;} This document is intended for reviewers.

@anchor{design/guide review guide review example}@anchor{609}@ref{609,,.example;} The “example” links are issues caused by a failure to
apply the checklist item.

@anchor{design/guide review guide review diff}@anchor{60a}@ref{60a,,.diff;} Some items in the checklist are particularly susceptible to
being ignored if one reviews only via the version control diff. These
items refer to this tag.

@node Checklist,,Introduction<17>,Review checklist
@anchor{design/guide review checklist}@anchor{60b}
@subsection Checklist


@anchor{design/guide review guide review test}@anchor{60c}@ref{60c,,.test;} If a new feature has been added to the code, is there a test
case? Example: job003923@footnote{https://www.ravenbrook.com/project/mps/issue/job003923/}.

@anchor{design/guide review guide review unwind}@anchor{60d}@ref{60d,,.unwind;} If code has been updated in a function that unwinds its
state in failure cases, have the failure cases been updated to
correspond? Example: job003922@footnote{https://www.ravenbrook.com/project/mps/issue/job003922/}. See @ref{60a,,.diff}.

@geindex C interface; design

@node C interface design,Keyword arguments in the MPS,Review checklist,Design
@anchor{design/interface-c doc}@anchor{60e}@anchor{design/interface-c c-interface-design}@anchor{60f}@anchor{design/interface-c design-interface-c}@anchor{610}@anchor{design/interface-c job003922}@anchor{611}
@section C interface design


@menu
* Introduction: Introduction<18>. 
* Analysis:: 
* Architecture: Architecture<2>. 
* Naming conventions:: 
* Type conventions:: 
* Checking:: 
* Binary compatibility issues:: 
* Constraints:: 
* Implementation: Implementation<8>. 
* Notes: Notes<2>. 

@end menu

@node Introduction<18>,Analysis,,C interface design
@anchor{design/interface-c design mps interface c}@anchor{612}@anchor{design/interface-c introduction}@anchor{613}
@subsection Introduction


@anchor{design/interface-c design mps interface c scope}@anchor{614}@ref{614,,.scope;} This document is the design for the Memory Pool System
(MPS) interface to the C Language, impl.h.mps.

@anchor{design/interface-c design mps interface c bg}@anchor{615}@ref{615,,.bg;} See mail.richard.1996-07-24.10-57@footnote{https://info.ravenbrook.com/project/mps/mail/1996/07/24/10-57/0.txt}.

@node Analysis,Architecture<2>,Introduction<18>,C interface design
@anchor{design/interface-c analysis}@anchor{616}@anchor{design/interface-c mail-richard-1996-07-24-10-57}@anchor{617}
@subsection Analysis


@menu
* Goals:: 
* Requirements: Requirements<10>. 

@end menu

@node Goals,Requirements<10>,,Analysis
@anchor{design/interface-c goals}@anchor{618}
@subsubsection Goals


@anchor{design/interface-c design mps interface c goal c}@anchor{619}@ref{619,,.goal.c;} The file impl.h.mps is the C external interface to the
MPS. It is the default interface between client code written in C and
the MPS.

@anchor{design/interface-c design mps interface c goal cpp}@anchor{61a}@ref{61a,,.goal.cpp;} impl.h.mps is not specifically designed to be
an interface to C++, but should be usable from C++.

@node Requirements<10>,,Goals,Analysis
@anchor{design/interface-c requirements}@anchor{61b}
@subsubsection Requirements


@anchor{design/interface-c design mps interface c req}@anchor{61c}@ref{61c,,.req;} The interface must provide an interface from client code
written in C to the functionality of the MPS required by the product
(see req.product), and Open Dylan (req.dylan).

@anchor{design/interface-c design mps interface c req separation}@anchor{61d}@ref{61d,,.req.separation;} The external interface may not include internal
MPS header files (such as @code{pool.h}).

@anchor{design/interface-c design mps interface c req flexibility}@anchor{61e}@ref{61e,,.req.flexibility;} It is essential that the interface cope well with
change, in order to avoid restricting possible future MPS
developments. This means that the interface must be “open ended” in
its definitions. This accounts for some of the apparently tortuous
methods of doing things (such as the keyword argument mechanism; see
design.mps.keyword-arguments@footnote{keyword-arguments.html}). The requirement is that the MPS should
be able to add new functionality, or alter the implementation of
existing functionality, without affecting existing client code. A
stronger requirement is that the MPS should be able to change without
`recompiling' client code. This is not always possible.

@anchor{design/interface-c design mps interface c req name iso}@anchor{61f}@ref{61f,,.req.name.iso;} The interface shall not conflict in terms of
naming with any interfaces specified by ISO C and all reasonable
future versions.

@anchor{design/interface-c design mps interface c req name general}@anchor{620}@ref{620,,.req.name.general;} The interface shall use a documented and
reasonably small portion of the namespace so that clients can use the
MPS C interface in combination with other interfaces without name
conflicts.

@node Architecture<2>,Naming conventions,Analysis,C interface design
@anchor{design/interface-c architecture}@anchor{621}
@subsection Architecture


@anchor{design/interface-c design mps interface c fig arch}@anchor{622}@ref{622,,.fig.arch;} The architecture of the MPS Interface

[missing figure]

Just behind @code{mps.h} is the file @code{mpsi.c}, the “MPS interface
layer” which does the job of converting types and checking parameters
before calling through to the MPS proper, using internal MPS methods.

@node Naming conventions,Type conventions,Architecture<2>,C interface design
@anchor{design/interface-c naming-conventions}@anchor{623}
@subsection Naming conventions


@anchor{design/interface-c design mps interface c naming}@anchor{624}@ref{624,,.naming;} The external interface names should adhere to the
documented interface conventions; these are found in the “Interface conventions@footnote{../../../topic/interface.html}” chapter of the Reference Manual. They are
paraphrased/recreated here.

@anchor{design/interface-c design mps interface c naming file}@anchor{625}@ref{625,,.naming.file;} All files in the external interface have names
starting with @code{mps}.

@anchor{design/interface-c design mps interface c naming unixy}@anchor{626}@ref{626,,.naming.unixy;} The external interface does not follow the same
naming conventions as the internal code. The interface is designed to
resemble a more conventional C, Unix, or Posix naming convention.

@anchor{design/interface-c design mps interface c naming case}@anchor{627}@ref{627,,.naming.case;} Identifiers are in lower case, except
non-function-like macros, which are in upper case.

@anchor{design/interface-c design mps interface c naming global}@anchor{628}@ref{628,,.naming.global;} All documented identifiers begin @code{mps_} or
@code{MPS_}.

@anchor{design/interface-c design mps interface c naming all}@anchor{629}@ref{629,,.naming.all;} All identifiers defined by the MPS begin @code{mps_} or
@code{MPS_} or @code{_mps_}.

@anchor{design/interface-c design mps interface c naming type}@anchor{62a}@ref{62a,,.naming.type;} Types are suffixed @code{_t}, except for structure and union types.

@anchor{design/interface-c design mps interface c naming struct}@anchor{62b}@ref{62b,,.naming.struct;} Structure types and tags are suffixed @code{_s}.

@anchor{design/interface-c design mps interface c naming union}@anchor{62c}@ref{62c,,.naming.union;} Unions types and tags are suffixed @code{_u}.

@anchor{design/interface-c design mps interface c naming scope}@anchor{62d}@ref{62d,,.naming.scope;} The naming conventions apply to all identifiers (see
ISO C §6.1.2); this includes names of functions, variables, types
(through typedef), structure and union tags, enumeration members,
structure and union members, macros, macro parameters, labels.

@anchor{design/interface-c design mps interface c naming scope labels}@anchor{62e}@ref{62e,,.naming.scope.labels;} labels (for @code{goto} statements) should be
rare, only in special block macros and probably not even then.

@anchor{design/interface-c design mps interface c naming scope other}@anchor{62f}@ref{62f,,.naming.scope.other;} The naming convention would also extend to
enumeration types and parameters in functions prototypes but both of
those are prohibited from having names in an interface file.

@node Type conventions,Checking,Naming conventions,C interface design
@anchor{design/interface-c type-conventions}@anchor{630}
@subsection Type conventions


@anchor{design/interface-c design mps interface c type gen}@anchor{631}@ref{631,,.type.gen;} The interface defines memory addresses as @code{void *} and
sizes as @code{size_t} for compatibility with standard C (in particular,
with @code{malloc()}). These types must be binary compatible with the
internal types @ref{632,,Addr} and @ref{40e,,Size} respectively. Note that this
restricts the definitions of the internal types @ref{632,,Addr} and @ref{40e,,Size}
when the MPS is interfaced with C, but does not restrict the MPS in
general.

@anchor{design/interface-c design mps interface c type opaque}@anchor{633}@ref{633,,.type.opaque;} Opaque types are defined as pointers to structures
which are never defined. These types are cast to the corresponding
internal types in @code{mpsi.c}.

@anchor{design/interface-c design mps interface c type trans}@anchor{634}@ref{634,,.type.trans;} Some transparent structures are defined. The client is
expected to read these, or poke about in them, under documented
restrictions. The most important is the allocation point structure
(@ref{1c1,,mps_ap_s}) which is part of allocation buffers. The transparent
structures must be binary compatible with corresponding internal
structures. For example, the fields of @ref{1c1,,mps_ap_s} must correspond
with @code{APStruct} internally. This is checked by @code{mpsi.c} in
@code{mps_check()}.

@anchor{design/interface-c design mps interface c type pseudo}@anchor{635}@ref{635,,.type.pseudo;} Some pseudo-opaque structures are defined. These only
exist so that code can be inlined using macros. The client code
shouldn’t mess with them. The most important case of this is the scan
state (@code{mps_ss_s}) which is accessed by the in-line scanning macros,
@code{MPS_SCAN_*} and @code{MPS_FIX*}.

@anchor{design/interface-c design mps interface c type enum}@anchor{636}@ref{636,,.type.enum;} There are no enumeration types in the interface. Note
that enum specifiers (to declare integer constants) are fine as long
as no type is declared. See guide.impl.c.misc.enum.type.

@anchor{design/interface-c design mps interface c type fun}@anchor{637}@ref{637,,.type.fun;} Whenever function types or derived function types (such
as pointer to function) are declared a prototype should be used and
the parameters to the function should not be named. This includes the
case where you are declaring the prototype for an interface function.

@anchor{design/interface-c design mps interface c type fun example}@anchor{638}@ref{638,,.type.fun.example;} So use:

@example
extern mps_res_t mps_alloc(mps_addr_t *, mps_pool_t, size_t, ...);
@end example

rather than:

@example
extern mps_res_t mps_alloc(mps_addr_t *addr_return, mps_pool_t pool , size_t size, ...);
@end example

and:

@example
typedef mps_addr_t (*mps_fmt_class_t)(mps_addr_t);
@end example

rather than:

@example
typedef mps_addr_t (*mps_fmt_class_t)(mps_addr_t object);
@end example

See guide.impl.c.misc.prototype.parameters.

@node Checking,Binary compatibility issues,Type conventions,C interface design
@anchor{design/interface-c checking}@anchor{639}
@subsection Checking


@anchor{design/interface-c design mps interface c check testt}@anchor{63a}@ref{63a,,.check.testt;} Before any use of a parameter @code{foo} belonging to a
pointer type @code{Foo}, it is checked using @code{TESTT(Foo, foo)}. The
macro @code{TESTT()} in impl.h.check performs simple thread-safe checking
of @code{foo}, so it can be called outside of @code{ArenaEnter()} and
@code{ArenaLeave()}.

@anchor{design/interface-c design mps interface c check avert}@anchor{63b}@ref{63b,,.check.avert;} With the arena lock held, @code{foo} is checked using
@code{AVERT(Foo, foo)}. This macro has different definitions depending on
how the MPS is compiled (see design.mps.config.def.var@footnote{config.html#design.mps.config.def.var}). It may
expand to @code{TESTT()}, or it may call the full checking function for
the type.

@anchor{design/interface-c design mps interface c check types}@anchor{63c}@ref{63c,,.check.types;} We use definitions of types in both our external
interface and our internal code, and we want to make sure that they
are compatible. (The external interface changes less often and hides
more information.) This checking uses the following macros, originally
from mail.richard.1996-08-07.09-49@footnote{https://info.ravenbrook.com/project/mps/mail/1996/08/07/09-49/0.txt}.

@geindex COMPATLVALUE (C macro)
@anchor{design/interface-c c COMPATLVALUE}@anchor{63d}
@deffn {C Macro} COMPATLVALUE (lvalue1, lvalue2)
@end deffn

@anchor{design/interface-c design mps interface c check types compat lvalue}@anchor{63e}@ref{63e,,.check.types.compat.lvalue;} This macro checks the assignment
compatibility of two lvalues. It uses @code{sizeof} to ensure that the
assignments have no effect.

@example
#define COMPATLVALUE(lv1, lv2) \
  ((void)sizeof((lv1) = (lv2)), (void)sizeof((lv2) = (lv1)), TRUE)
@end example

@geindex COMPATTYPE (C macro)
@anchor{design/interface-c c COMPATTYPE}@anchor{63f}
@deffn {C Macro} COMPATTYPE (type1, type2)
@end deffn

@anchor{design/interface-c design mps interface c check types compat type}@anchor{640}@ref{640,,.check.types.compat.type;} This macro checks that two types are
assignment-compatible and equal in size. The hack here is that it
generates an lvalue for each type by casting zero to a pointer to the
type. The use of @code{sizeof} avoids the undefined behaviour that
would otherwise result from dereferencing a null pointer.

@example
#define COMPATTYPE(t1, t2) \
  (sizeof(t1) == sizeof(t2) && \
   COMPATLVALUE(*((t1 *)0), *((t2 *)0)))
@end example

@geindex COMPATFIELDAPPROX (C macro)
@anchor{design/interface-c c COMPATFIELDAPPROX}@anchor{641}
@deffn {C Macro} COMPATFIELDAPPROX (structure1, field1, structure2, field2)
@end deffn

@anchor{design/interface-c design mps interface c check types compat field approx}@anchor{642}@ref{642,,.check.types.compat.field.approx;} This macro checks that the offset
and size of two fields in two structure types are the same.

@example
#define COMPATFIELDAPPROX(s1, f1, s2, f2) \
  (sizeof(((s1 *)0)->f1) == sizeof(((s2 *)0)->f2) && \
   offsetof(s1, f1) == offsetof(s2, f2))
@end example

@geindex COMPATFIELD (C macro)
@anchor{design/interface-c c COMPATFIELD}@anchor{643}
@deffn {C Macro} COMPATFIELD (structure1, field1, structure2, field2)
@end deffn

@anchor{design/interface-c design mps interface c check types compat field}@anchor{644}@ref{644,,.check.types.compat.field;} This macro checks the offset, size, and
assignment-compatibility of two fields in two structure types.

@example
#define COMPATFIELD(s1, f1, s2, f2) \
  (COMPATFIELDAPPROX(s1, f1, s2, f2) && \
   COMPATLVALUE(((s1 *)0)->f1, ((s2 *)0)->f2))
@end example

@node Binary compatibility issues,Constraints,Checking,C interface design
@anchor{design/interface-c binary-compatibility-issues}@anchor{645}
@subsection Binary compatibility issues


As in, “Enumeration types are not allowed” (see
mail.richard.1995-09-08.09-28@footnote{https://info.ravenbrook.com/project/mps/mail/1995/09/08/09-28/0.txt}).

@anchor{design/interface-c design mps interface c compat}@anchor{646}@ref{646,,.compat;} There are two main aspects to run-time compatibility:
binary interface and protocol.

@anchor{design/interface-c design mps interface c compat binary}@anchor{647}@ref{647,,.compat.binary;} The binary interface is all the information needed
to correctly use the library, and includes external symbol linkage,
calling conventions, type representation compatibility, structure
layouts, etc.

@anchor{design/interface-c design mps interface c compat binary unneeded}@anchor{648}@ref{648,,.compat.binary.unneeded;} Binary compatibility is not required by
the open source MPS: we expect (and indeed, recommend) that a client
program is compiled against the MPS sources. Nonetheless we try to
maintain binary compatibility in case the capability is required in
future.

@anchor{design/interface-c design mps interface c compat binary dependencies}@anchor{649}@ref{649,,.compat.binary.dependencies;} The binary interface is determined
completely by the header file and the target. The header file
specifies the external names and the types, and the target platform
specifies calling conventions and type representation. There is
therefore a many-to-one mapping between the header file version and
the binary interface.

@anchor{design/interface-c design mps interface c compat protocol}@anchor{64a}@ref{64a,,.compat.protocol;} The protocol is how the library is actually used
by the client code – whether this is called before that – and
determines the semantic correctness of the client with respect to the
library.

@anchor{design/interface-c design mps interface c compat protocol dependencies}@anchor{64b}@ref{64b,,.compat.protocol.dependencies;} The protocol is determined by the
implementation of the library.

@node Constraints,Implementation<8>,Binary compatibility issues,C interface design
@anchor{design/interface-c constraints}@anchor{64c}
@subsection Constraints


@anchor{design/interface-c design mps interface c cons}@anchor{64d}@ref{64d,,.cons;} The MPS C Interface constrains the MPS in order to provide
useful memory management services to a C or C++ program.

@anchor{design/interface-c design mps interface c cons addr}@anchor{64e}@ref{64e,,.cons.addr;} The interface constrains the MPS address type, Addr
(design.mps.type.addr@footnote{type.html#design.mps.type.addr}), to being the same as C’s generic pointer type,
@code{void *}, so that the MPS can manage C objects in the natural way.

@anchor{design/interface-c design mps interface c pun addr}@anchor{64f}@ref{64f,,.pun.addr;} We pun the type of @ref{11d,,mps_addr_t} (which is @code{void *})
into @ref{632,,Addr} (an incomplete type, see design.mps.type.addr@footnote{type.html#design.mps.type.addr}). This
happens in the call to the scan state’s fix function, for example.

@anchor{design/interface-c design mps interface c cons size}@anchor{650}@ref{650,,.cons.size;} The interface constrains the MPS size type, @ref{40e,,Size}
(design.mps.type.size@footnote{type.html#design.mps.type.size}), to being the same as C’s size type,
@code{size_t}, so that the MPS can manage C objects in the natural way.

@anchor{design/interface-c design mps interface c pun size}@anchor{651}@ref{651,,.pun.size;} We pun the type of @code{size_t} in mps.h into @ref{40e,,Size} in
the MPM, as an argument to the format methods. We assume this works.

@anchor{design/interface-c design mps interface c cons word}@anchor{652}@ref{652,,.cons.word;} The MPS assumes that @ref{653,,Word} (design.mps.type.word@footnote{type.html#design.mps.type.word})
and @ref{632,,Addr} (design.mps.type.addr@footnote{type.html#design.mps.type.addr}) are the same size, and the
interface constrains @ref{653,,Word} to being the same size as C’s generic
pointer type, @code{void *}.

@node Implementation<8>,Notes<2>,Constraints,C interface design
@anchor{design/interface-c design-mps-type-word}@anchor{654}@anchor{design/interface-c implementation}@anchor{655}
@subsection Implementation


@anchor{design/interface-c design mps interface c impl}@anchor{656}@ref{656,,.impl;} The external interface consists of the following header
files:

@anchor{design/interface-c design mps interface c impl mps}@anchor{657}@ref{657,,.impl.mps;} @code{mps.h} is the main external interface, containing of
type and function declarations needed by all clients of the MPS.

@anchor{design/interface-c design mps interface c impl mpstd}@anchor{658}@ref{658,,.impl.mpstd;} @code{mpstd.h} is the MPS target detection header. It
decodes preprocessor symbols which are predefined by build
environments in order to determine the target platform (see
design.mps.config@footnote{config.html}), and then defines uniform symbols, such as
@ref{2e5,,MPS_ARCH_I3}, for use externally and internally by the MPS.
@code{mpstd.h} is not included by any of the other external headers, as
it relies on exact set of preprocessor constants defined by compilers.

@anchor{design/interface-c design mps interface c impl mpsio}@anchor{659}@ref{659,,.impl.mpsio;} @code{mpsio.h} is the interface to the MPS I/O subsystem,
part of the plinth. See design.mps.io@footnote{io.html}.

@anchor{design/interface-c design mps interface c impl mpslib}@anchor{65a}@ref{65a,,.impl.mpslib;} @code{mpslib.h} is the interface to the MPS Library
Interface, part of the plinth. See design.mps.lib@footnote{lib.html}.

@anchor{design/interface-c design mps interface c impl mpsa}@anchor{65b}@ref{65b,,.impl.mpsa;} Interfaces to arena classes are in files with names
starting @code{mpsa}: for example, the interface to the Virtual Memory
arena class is in @code{mpsavm.h}.

@anchor{design/interface-c design mps interface c impl mpsc}@anchor{65c}@ref{65c,,.impl.mpsc;} Interfaces to pool classes are in files with names
starting @code{mpsc}: for example, the interface to the MVFF pool class
is in @code{mpscmvff.h}.

@node Notes<2>,,Implementation<8>,C interface design
@anchor{design/interface-c notes}@anchor{65d}
@subsection Notes


@anchor{design/interface-c design mps interface c fmt extend}@anchor{65e}@ref{65e,,.fmt.extend;} @code{mps_fmt_A_t} is so called because new pool classes
might require new format methods, but these methods cannot be added to
the format structure without breaking binary compatibility. Therefore
these new pool classes would use new format structures named
@code{mps_fmt_B_t} and so on.

@anchor{design/interface-c design mps interface c thread-safety}@anchor{65f}@ref{65f,,.thread-safety;} Most calls through this interface lock the arena
and therefore make the MPM single-threaded. In order to do this they
must recover the arena from their parameters. Methods such as
@code{FormatArena()} and @ref{660,,ThreadArena()} must therefore be callable
when the arena is `not' locked. These methods are tagged with the tag
of this note.

@anchor{design/interface-c design mps interface c lock-free}@anchor{661}@ref{661,,.lock-free;} Certain functions inside the MPM are thread-safe and do
not need to be serialized by using locks. They are marked with the tag
of this note.

@anchor{design/interface-c design mps interface c form}@anchor{662}@ref{662,,.form;} Almost all functions in this implementation simply cast
their arguments to the equivalent internal types, and cast results
back to the external type, where necessary. Only exceptions are noted
in comments.

@geindex keyword arguments; design

@node Keyword arguments in the MPS,Lands,C interface design,Design
@anchor{design/keyword-arguments doc}@anchor{663}@anchor{design/keyword-arguments design-keyword-arguments}@anchor{664}@anchor{design/keyword-arguments keyword-arguments-in-the-mps}@anchor{665}
@section Keyword arguments in the MPS


@menu
* Introduction: Introduction<19>. 
* Overview: Overview<4>. 
* Internals:: 
* The varargs legacy:: 
* References: References<6>. 

@end menu

@node Introduction<19>,Overview<4>,,Keyword arguments in the MPS
@anchor{design/keyword-arguments introduction}@anchor{666}
@subsection Introduction


Up to version 1.111, the Memory Pool System@footnote{https://www.ravenbrook.com/project/mps/} used varags to pass arguments
to arena and pool classes, because the general MPS interface can’t
specify what arguments those classes might need in C prototypes. This
mechanism was error-prone and did not allow for any optional arguments,
meaning that the client had to specify or predict esoteric tuning
parameters.

Starting with version 1.112, the MPS uses an idiom for keyword arguments.

The keyword argument design was originally proposed in @ref{667,,[RB_2012-05-24]}.

@node Overview<4>,Internals,Introduction<19>,Keyword arguments in the MPS
@anchor{design/keyword-arguments overview}@anchor{668}
@subsection Overview


The basic design is not specific to the MPS.  The keyword argument list is
passed as an array of argument structures which look like this:

@example
typedef struct mps_key_s *mps_key_t;
typedef struct mps_arg_s @{
  mps_key_t key;
  union @{
    int i;
    char c;
    void *p;
    size_t size;
    /* etc. */
  @} val;
@} mps_arg_s;
@end example

The argument list is assembled and passed like this:

@example
mps_arg_s args[3];
args[0].key = MPS_KEY_MIN_SIZE;
args[0].val.size = 32;
args[1].key = MPS_KEY_MAX_SIZE;
args[1].val.size = 1024;
args[2].key = MPS_KEY_ARGS_END;
mps_pool_create_k(&pool, some_pool_class(), args);
@end example

This can be written quite concisely in C99:

@example
mps_pool_create_k(&pool, some_pool_class(),
        (mps_arg_s [])@{@{MPS_KEY_MIN_SIZE, @{.size = 32@}@},
                       @{MPS_KEY_MAX_SIZE, @{.size = 1024@}@},
                       @{MPS_KEY_ARGS_END@}@});
@end example

The arguments that are recognised and used by the function are removed
from the array (and the subsequent arguments moved up) so that if they
are all consumed the array has @code{MPS_KEY_ARGS_END} in slot zero on
return. This can be checked by the caller.


@itemize -

@item 
It’s not a static error to pass excess arguments.  This makes it easy to
substitute one pool or arena class for another (which might ignore some
arguments).  The caller can check that @code{args[0].key} is
@code{MPS_KEY_ARGS_END} if desired.

@item 
NULL is not a valid argument list.  This is in line with general MPS
design principles to avoid accidental omissions.  For convenience, we
provide @code{mps_args_none} as a static empty argument list.

@item 
NULL is not a valid argument key.  This is in line with general MPS
design principles to avoid accidental omissions.  Every key points to
a structure with a signature that can be checked.  This makes it virtually
impossible to get an argument list with bad keys or that is unterminated
past MPS checking.
@end itemize

@node Internals,The varargs legacy,Overview<4>,Keyword arguments in the MPS
@anchor{design/keyword-arguments internals}@anchor{669}
@subsection Internals


Internally, keys are static constant structures which are signed and contain
a checking method for the argument, like this:

@example
typedef struct mps_arg_s *Arg;
typedef struct mps_key_s @{
  Sig sig;              /* Always KeySig */
  const char *name;
  Bool check(Arg arg);
@} KeyStruct;
@end example

They are mostly declared in the modules that consume them, except for a few
common keys.  Declarations look like:

@example
const KeyStruct _mps_key_extend_by = @{KeySig, "extend_by", ArgCheckSize@};
@end example

but @code{arg.h} provides a macro for this:

@example
ARG_DEFINE_KEY(extend_by, Size);
@end example

We define keys as static structures (rather than, say, an enum) because:


@itemize -

@item 
The set of keys can be extended indefinitely.

@item 
The set of keys can be extended by independently linked modules.

@item 
The structure contents allow strong checking of argument lists.
@end itemize

In the MPS C Interface, we declare keys like this:

@example
extern const struct mps_key_s _mps_key_extend_by;
#define MPS_KEY_EXTEND_BY (&_mps_key_extend_by)
@end example

The underscore on the symbol requests that client code doesn’t reference
it, but instead uses the macro.  This gives us adaptability to change the
design and replace keys with, say, magic numbers.

@node The varargs legacy,References<6>,Internals,Keyword arguments in the MPS
@anchor{design/keyword-arguments the-varargs-legacy}@anchor{66a}
@subsection The varargs legacy


For backward compatibility, varargs to arena and pool creation are
converted into keyword arguments by position, using a method in the
arena or pool class. For example:

@example
static void MVVarargs(ArgStruct args[], va_list varargs)
@{
  args[0].key = MPS_KEY_EXTEND_BY;
  args[0].val.size = va_arg(varargs, Size);
  args[1].key = MPS_KEY_MEAN_SIZE;
  args[1].val.size = va_arg(varargs, Size);
  args[2].key = MPS_KEY_MAX_SIZE;
  args[2].val.size = va_arg(varargs, Size);
  args[3].key = MPS_KEY_ARGS_END;
  AVER(ArgListCheck(args));
@}
@end example

This leaves the main body of code, and any future code, free to just
handle keyword arguments only.

Varargs methods must be thread-safe as they are called without taking
the arena lock.

The use of varargs is deprecated in the manual and the interface and these
methods can be deleted at some point in the future.

@node References<6>,,The varargs legacy,Keyword arguments in the MPS
@anchor{design/keyword-arguments references}@anchor{66b}
@subsection References


@anchor{design/keyword-arguments rb-2012-05-24}@anchor{667}@w{(RB_2012-05-24)} 
Richard Brooksby. Ravenbrook Limited. 2012-05-24. “Keyword and optional arguments@footnote{https://info.ravenbrook.com/mail/2012/05/24/21-19-15/0/}”.

@geindex lands; design

@node Lands,Lock module,Keyword arguments in the MPS,Design
@anchor{design/land doc}@anchor{66c}@anchor{design/land design-land}@anchor{66d}@anchor{design/land lands}@anchor{66e}
@section Lands


@menu
* Introduction: Introduction<20>. 
* Definitions: Definitions<2>. 
* Requirements: Requirements<11>. 
* Interface: Interface<8>. 
* Implementations:: 
* Testing: Testing<3>. 

@end menu

@node Introduction<20>,Definitions<2>,,Lands
@anchor{design/land design mps land}@anchor{66f}@anchor{design/land introduction}@anchor{670}
@subsection Introduction


@anchor{design/land design mps land intro}@anchor{671}@ref{671,,.intro;} This is the design of the `land' abstract data type, which
represents a collection of contiguous address ranges.

@anchor{design/land design mps land readership}@anchor{672}@ref{672,,.readership;} This document is intended for any MPS developer.

@anchor{design/land design mps land source}@anchor{673}@ref{673,,.source;} design.mps.cbs@footnote{cbs.html}, design.mps.freelist@footnote{freelist.html}.

@anchor{design/land design mps land overview}@anchor{674}@ref{674,,.overview;} Collections of address ranges are used in several places
in the MPS: the arena stores a set of mapped address ranges; pools
store sets of address ranges which have been acquired from the arena
and sets of address ranges that are available for allocation. The
`land' abstract data type makes it easy to try out different
implementations with different performance characteristics and other
attributes.

@anchor{design/land design mps land name}@anchor{675}@ref{675,,.name;} The name is inspired by `rangeland' meaning `group of
ranges' (where `ranges' is used in the sense `grazing areas').

@node Definitions<2>,Requirements<11>,Introduction<20>,Lands
@anchor{design/land definitions}@anchor{676}
@subsection Definitions


@anchor{design/land design mps land def range}@anchor{677}@ref{677,,.def.range;} A (contiguous) `range' of addresses is a semi-open
interval on address space.

@anchor{design/land design mps land def isolated}@anchor{678}@ref{678,,.def.isolated;} A contiguous range is `isolated' with respect to
some property it has, if adjacent elements do not have that property.

@node Requirements<11>,Interface<8>,Definitions<2>,Lands
@anchor{design/land requirements}@anchor{679}
@subsection Requirements


@anchor{design/land design mps land req set}@anchor{67a}@ref{67a,,.req.set;} Must maintain a set of addresses.

@anchor{design/land design mps land req add}@anchor{67b}@ref{67b,,.req.add;} Must be able to add address ranges to the set.

@anchor{design/land design mps land req remove}@anchor{67c}@ref{67c,,.req.remove;} Must be able to remove address ranges from the set.

@anchor{design/land design mps land req size}@anchor{67d}@ref{67d,,.req.size;} Must report concisely to the client when isolated
contiguous ranges of at least a certain size appear and disappear.

@anchor{design/land design mps land req iterate}@anchor{67e}@ref{67e,,.req.iterate;} Must support the iteration of all isolated
contiguous ranges.

@anchor{design/land design mps land req protocol}@anchor{67f}@ref{67f,,.req.protocol;} Must detect protocol violations.

@anchor{design/land design mps land req debug}@anchor{680}@ref{680,,.req.debug;} Must support debugging of client code.

@anchor{design/land design mps land req align}@anchor{681}@ref{681,,.req.align;} Must support an alignment (the alignment of all
addresses specifying ranges) of down to @code{sizeof(void *)} without
losing memory.

@node Interface<8>,Implementations,Requirements<11>,Lands
@anchor{design/land interface}@anchor{682}
@subsection Interface


@menu
* Types: Types<5>. 
* Generic functions:: 

@end menu

@node Types<5>,Generic functions,,Interface<8>
@anchor{design/land types}@anchor{683}
@subsubsection Types


@geindex Land (C type)
@anchor{design/land c Land}@anchor{53c}
@deffn {C Type} typedef LandStruct *Land
@end deffn

@anchor{design/land design mps land type land}@anchor{684}@ref{684,,.type.land;} The type of a generic land instance.

@geindex LandVisitor (C type)
@anchor{design/land c LandVisitor}@anchor{685}
@deffn {C Type} typedef @ref{3a9,,Bool} (*LandVisitor)(@ref{53c,,Land} land, @ref{686,,Range} range, void *closure)
@end deffn

@anchor{design/land design mps land type visitor}@anchor{687}@ref{687,,.type.visitor;} Type @code{LandVisitor} is a callback function that may
be passed to @ref{688,,LandIterate()}. It is called for every isolated
contiguous range in address order. The function must return a @ref{3a9,,Bool}
indicating whether to continue with the iteration.

@geindex LandDeleteVisitor (C type)
@anchor{design/land c LandDeleteVisitor}@anchor{689}
@deffn {C Type} typedef @ref{3a9,,Bool} (*LandDeleteVisitor)(@ref{3a9,,Bool} *deleteReturn, @ref{53c,,Land} land, @ref{686,,Range} range, void *closure)
@end deffn

@anchor{design/land design mps land type deletevisitor}@anchor{68a}@ref{68a,,.type.deletevisitor;} Type @code{LandDeleteVisitor} is a callback function that may
be passed to @ref{413,,LandIterateAndDelete()}. It is called for every isolated
contiguous range in address order. The function must return a @ref{3a9,,Bool}
indicating whether to continue with the iteration. It may additionally
update @code{*deleteReturn} to @code{TRUE} if the range must be deleted from
the land, or @code{FALSE} if the range must be kept. (The default is to
keep the range.)

@node Generic functions,,Types<5>,Interface<8>
@anchor{design/land generic-functions}@anchor{68b}
@subsubsection Generic functions


@geindex LandInit (C function)
@anchor{design/land c LandInit}@anchor{406}
@deffn {C Function} @ref{55f,,Res} LandInit (Land land, LandClass class, Arena arena, Align alignment, void *owner, ArgList args)
@end deffn

@anchor{design/land design mps land function init}@anchor{68c}@ref{68c,,.function.init;} @ref{406,,LandInit()} initializes the land structure for
the given class. The land will perform allocation (if necessary – not
all land classes need to allocate) in the supplied arena. The
@code{alignment} parameter is the alignment of the address ranges that
will be stored and retrieved from the land. The parameter @code{owner} is
output as a parameter to the @code{LandInit} event. The newly initialized
land contains no ranges.

@geindex LandCreate (C function)
@anchor{design/land c LandCreate}@anchor{68d}
@deffn {C Function} @ref{55f,,Res} LandCreate (Land *landReturn, Arena arena, LandClass class, Align alignment, void *owner, ArgList args)
@end deffn

@anchor{design/land design mps land function create}@anchor{68e}@ref{68e,,.function.create;} @ref{68d,,LandCreate()} allocates memory for a land
structure of the given class in @code{arena}, and then passes all
parameters to @ref{406,,LandInit()}.

@geindex LandFinish (C function)
@anchor{design/land c LandFinish}@anchor{68f}
@deffn {C Function} void LandFinish (Land land)
@end deffn

@anchor{design/land design mps land function finish}@anchor{690}@ref{690,,.function.finish;} @ref{68f,,LandFinish()} finishes the land structure and
discards any other resources associated with the land.

@geindex LandSize (C function)
@anchor{design/land c LandSize}@anchor{691}
@deffn {C Function} void LandSize (Land land)
@end deffn

@anchor{design/land design mps land function size}@anchor{692}@ref{692,,.function.size;} @ref{691,,LandSize()} returns the total size of the ranges
stored in the land.

@geindex LandInsert (C function)
@anchor{design/land c LandInsert}@anchor{420}
@deffn {C Function} @ref{55f,,Res} LandInsert (Range rangeReturn, Land land, Range range)
@end deffn

@anchor{design/land design mps land function insert}@anchor{693}@ref{693,,.function.insert;} If any part of @code{range} is already in the land,
then leave the land unchanged and return @code{ResFAIL}. Otherwise,
attempt to insert @code{range} into the land. If the insertion succeeds,
then update @code{rangeReturn} to describe the contiguous isolated range
containing the inserted range (this may differ from @code{range} if there
was coalescence on either side) and return @code{ResOK}. If the insertion
fails, return a result code indicating allocation failure.

@anchor{design/land design mps land function insert fail}@anchor{694}@ref{694,,.function.insert.fail;} Insertion of a valid range (that is, one
that does not overlap with any range in the land) can only fail if the
new range is isolated and the allocation of the necessary data
structure to represent it failed.

@anchor{design/land design mps land function insert alias}@anchor{695}@ref{695,,.function.insert.alias;} It is acceptable for @code{rangeReturn} and
@code{range} to share storage.

@geindex LandInsertSteal (C function)
@anchor{design/land c LandInsertSteal}@anchor{696}
@deffn {C Function} @ref{55f,,Res} LandInsertSteal (Range rangeReturn, Land land, Range rangeIO)
@end deffn

@anchor{design/land design mps land function insert-steal}@anchor{697}@ref{697,,.function.insert-steal;} If any part of @code{rangeIO} is already in
the land, then leave the land unchanged and return @code{ResFAIL}.
Otherwise, insert @code{rangeIO} into the land, update @code{rangeReturn} to
describe the contiguous isolated range containing the inserted range
(this may differ from @code{range} if there was coalescence on either
side), and return @code{ResOK}.

@anchor{design/land design mps land function insert-steal steal}@anchor{698}@ref{698,,.function.insert-steal.steal;} If insertion requires allocation for
the land’s internal data structures, steal some of the memory in
@code{rangeIO}, use it to satisfy the allocation, update @code{rangeIO} so
that it describes the remaining part of of the range, and insert the
remainder into the land as described above.

@anchor{design/land design mps land function insert-steal allocated}@anchor{699}@ref{699,,.function.insert-steal.allocated;} In order for stealing to work,
the inserted range must be allocated from the arena to some pool or
pools.

@anchor{design/land design mps land function insert-steal empty}@anchor{69a}@ref{69a,,.function.insert-steal.empty;} After stealing memory, @code{rangeIO}
might be empty, in which case @code{rangeReturn} will be a copy of
@code{rangeIO}.

@anchor{design/land design mps land function insert-steal alias not}@anchor{69b}@ref{69b,,.function.insert-steal.alias.not;} It is not acceptable for
@code{rangeReturn} and @code{rangeIO} to share storage.

@geindex LandDelete (C function)
@anchor{design/land c LandDelete}@anchor{421}
@deffn {C Function} @ref{55f,,Res} LandDelete (Range rangeReturn, Land land, Range range)
@end deffn

@anchor{design/land design mps land function delete}@anchor{69c}@ref{69c,,.function.delete;} If any part of the range is not in the land,
then leave the land unchanged and return @code{ResFAIL}. Otherwise, update
@code{rangeReturn} to describe the contiguous isolated range that
contains @code{range} (this may differ from @code{range} if there are
fragments on either side) and attempt to delete the range from the
land. If the deletion succeeds, return @code{ResOK}. If the deletion
fails, return a result code indicating allocation failure.

@anchor{design/land design mps land function delete fail}@anchor{69d}@ref{69d,,.function.delete.fail;} Deletion of a valid range (that is, one
that is wholly contained in the land) can only fail if there are
fragments on both sides and the allocation of the necessary data
structures to represent them fails.

@anchor{design/land design mps land function delete return}@anchor{69e}@ref{69e,,.function.delete.return;} @ref{421,,LandDelete()} returns the contiguous
isolated range that contains @code{range} even if the deletion fails.
This is so that the caller can try deleting the whole block (which is
guaranteed to succeed) and managing the fragments using a fallback
strategy.

@anchor{design/land design mps land function delete alias}@anchor{69f}@ref{69f,,.function.delete.alias;} It is acceptable for @code{rangeReturn} and
@code{range} to share storage.

@geindex LandDeleteSteal (C function)
@anchor{design/land c LandDeleteSteal}@anchor{6a0}
@deffn {C Function} @ref{55f,,Res} LandDeleteSteal (Range rangeReturn, Land land, Range range)
@end deffn

@anchor{design/land design mps land function delete-steal}@anchor{6a1}@ref{6a1,,.function.delete-steal;} If any part of the range is not in the
land, then leave the land unchanged and return @code{ResFAIL}. Otherwise,
update @code{rangeReturn} to describe the contiguous isolated range that
contains @code{range} (this may differ from @code{range} if there are
fragments on either side), delete the range from the land, and return
@code{ResOK}.

@anchor{design/land design mps land function delete-steal steal}@anchor{6a2}@ref{6a2,,.function.delete-steal.steal;} If deletion requires allocation for
the land’s internal data structures, steal some of the memory in the
contiguous isolated range that contains @code{range}, and use it to
satisfy the allocation.

@anchor{design/land design mps land function delete-steal allocated}@anchor{6a3}@ref{6a3,,.function.delete-steal.allocated;} In order for stealing to work,
the addresses stored in the land must be allocated from the arena to
some pool or pools.

@anchor{design/land design mps land function delete-steal alias}@anchor{6a4}@ref{6a4,,.function.delete-steal.alias;} It is acceptable for @code{rangeReturn}
and @code{range} to share storage.

@geindex LandIterate (C function)
@anchor{design/land c LandIterate}@anchor{688}
@deffn {C Function} @ref{3a9,,Bool} LandIterate (Land land, LandVisitor visitor, void *closure)
@end deffn

@anchor{design/land design mps land function iterate}@anchor{6a5}@ref{6a5,,.function.iterate;} @ref{688,,LandIterate()} is the function used to
iterate all isolated contiguous ranges in a land. It receives a
visitor function to invoke on every range, and a closure pointer
to pass on to the visitor function. If the visitor
function returns @code{FALSE}, then iteration is terminated and
@ref{688,,LandIterate()} returns @code{FALSE}. If all iterator method calls
return @code{TRUE}, then @ref{688,,LandIterate()} returns @code{TRUE}

@geindex LandIterateAndDelete (C function)
@anchor{design/land c LandIterateAndDelete}@anchor{413}
@deffn {C Function} @ref{3a9,,Bool} LandIterateAndDelete (Land land, LandDeleteVisitor visitor, void *closure)
@end deffn

@anchor{design/land design mps land function iterate and delete}@anchor{6a6}@ref{6a6,,.function.iterate.and.delete;} As @ref{688,,LandIterate()}, but the visitor
function additionally returns a Boolean indicating whether the range
should be deleted from the land.

@anchor{design/land design mps land function iterate and delete justify}@anchor{6a7}@ref{6a7,,.function.iterate.and.delete.justify;} The reason for having both
@ref{688,,LandIterate()} and @ref{413,,LandIterateAndDelete()} is that it may be
possible to use a more efficient algorithm, or to preserve more
properties of the data structure, when it is known that the land will
not be modified during the iteration. For example, in the CBS
implementation, @ref{688,,LandIterate()} uses @code{TreeTraverse()} which
preserves the tree structure, whereas @ref{413,,LandIterateAndDelete()} uses
@code{TreeTraverseAndDelete()} which flattens the tree structure, losing
information about recently accessed nodes.

@geindex LandFindFirst (C function)
@anchor{design/land c LandFindFirst}@anchor{408}
@deffn {C Function} @ref{3a9,,Bool} LandFindFirst (Range rangeReturn, Range oldRangeReturn, Land land, Size size, FindDelete findDelete)
@end deffn

@anchor{design/land design mps land function find first}@anchor{6a8}@ref{6a8,,.function.find.first;} Locate the first block (in address order)
within the land of at least the specified size, update @code{rangeReturn}
to describe that range, and return @code{TRUE}. If there is no such
block, it returns @code{FALSE}.

In addition, optionally delete the top, bottom, or all of the found
range, depending on the @code{findDelete} argument. This saves a separate
call to @ref{421,,LandDelete()}, and uses the knowledge of exactly where we
found the range. The value of @code{findDelete} must come from this
enumeration:

@example
enum @{
    FindDeleteNONE,    /* don't delete after finding */
    FindDeleteLOW,     /* delete size bytes from low end of block */
    FindDeleteHIGH,    /* delete size bytes from high end of block */
    FindDeleteENTIRE   /* delete entire range */
@};
@end example

The original contiguous isolated range in which the range was found is
returned via the @code{oldRangeReturn} argument. (If @code{findDelete} is
@code{FindDeleteNONE} or @code{FindDeleteENTIRE}, then this will be
identical to the range returned via the @code{rangeReturn} argument.)

@geindex LandFindLast (C function)
@anchor{design/land c LandFindLast}@anchor{409}
@deffn {C Function} @ref{3a9,,Bool} LandFindLast (Range rangeReturn, Range oldRangeReturn, Land land, Size size, FindDelete findDelete)
@end deffn

@anchor{design/land design mps land function find last}@anchor{6a9}@ref{6a9,,.function.find.last;} Like @ref{408,,LandFindFirst()}, except that it
finds the last block in address order.

@geindex LandFindLargest (C function)
@anchor{design/land c LandFindLargest}@anchor{40a}
@deffn {C Function} @ref{3a9,,Bool} LandFindLargest (Range rangeReturn, Range oldRangeReturn, Land land, Size size, FindDelete findDelete)
@end deffn

@anchor{design/land design mps land function find largest}@anchor{6aa}@ref{6aa,,.function.find.largest;} Locate the largest block within the
land, and if that block is at least as big as @code{size}, return its
range via the @code{rangeReturn} argument, and return @code{TRUE}. If there
are no blocks in the land at least as large as @code{size}, return
@code{FALSE}. Pass 0 for @code{size} if you want the largest block
unconditionally.

Like @ref{408,,LandFindFirst()}, optionally delete the range (specifying
@code{FindDeleteLOW} or @code{FindDeleteHIGH} has the same effect as
@code{FindDeleteENTIRE}), and return the original contiguous isolated
range in which the range was found via the @code{oldRangeReturn}
argument.

@geindex LandFindInZones (C function)
@anchor{design/land c LandFindInZones}@anchor{40c}
@deffn {C Function} @ref{55f,,Res} LandFindInZones (Bool *foundReturn, Range rangeReturn, Range oldRangeReturn, Land land, Size size, ZoneSet zoneSet, Bool high)
@end deffn

@anchor{design/land design mps land function find zones}@anchor{6ab}@ref{6ab,,.function.find.zones;} Locate a block at least as big as @code{size}
that lies entirely within the @code{zoneSet}, return its range via the
@code{rangeReturn} argument, set @code{*foundReturn} to @code{TRUE}, and return
@code{ResOK}. (The first such block, if @code{high} is @code{FALSE}, or the
last, if @code{high} is @code{TRUE}.) If there is no such block, set
@code{*foundReturn} to @code{FALSE}, and return @code{ResOK}.

Delete the range as for @ref{408,,LandFindFirst()} and @code{LastFindLast()}
(with the effect of @code{FindDeleteLOW} if @code{high} is @code{FALSE} and the
effect of @code{FindDeleteHIGH} if @code{high} is @code{TRUE}), and return the
original contiguous isolated range in which the range was found via
the @code{oldRangeReturn} argument.

@anchor{design/land design mps land function find zones fail}@anchor{6ac}@ref{6ac,,.function.find.zones.fail;} It’s possible that the range can’t be
deleted from the land because that would require allocation, in which
case the result code indicates the cause of the failure.

@geindex LandDescribe (C function)
@anchor{design/land c LandDescribe}@anchor{6ad}
@deffn {C Function} @ref{55f,,Res} LandDescribe (Land land, mps_lib_FILE *stream)
@end deffn

@anchor{design/land design mps land function describe}@anchor{6ae}@ref{6ae,,.function.describe;} @ref{6ad,,LandDescribe()} prints a textual
representation of the land to the given stream. It is provided for
debugging purposes only.

@geindex LandFlush (C function)
@anchor{design/land c LandFlush}@anchor{415}
@deffn {C Function} void LandFlush (Land dest, Land src)
@end deffn

@anchor{design/land design mps land function flush}@anchor{6af}@ref{6af,,.function.flush;} Delete ranges of addresses from @code{src} and insert
them into @code{dest}, so long as @ref{420,,LandInsert()} remains successful.

@node Implementations,Testing<3>,Interface<8>,Lands
@anchor{design/land implementations}@anchor{6b0}
@subsection Implementations


There are three land implementations:


@enumerate 

@item 
CBS (Coalescing Block Structure) stores ranges in a splay tree. It
has fast (logarithmic in the number of ranges) insertion, deletion
and searching, but has substantial space overhead. See
design.mps.cbs@footnote{cbs.html}.

@item 
Freelist stores ranges in an address-ordered free list, as in
traditional @code{malloc()} implementations. Insertion, deletion, and
searching are slow (proportional to the number of ranges) but it
does not need to allocate. See design.mps.freelist@footnote{freelist.html}.

@item 
Failover combines two lands, using one (the `primary') until it
fails, and then falls back to the other (the `secondary'). See
design.mps.failover@footnote{failover.html}.
@end enumerate

@node Testing<3>,,Implementations,Lands
@anchor{design/land design-mps-failover}@anchor{6b1}@anchor{design/land testing}@anchor{6b2}
@subsection Testing


@anchor{design/land design mps land test}@anchor{6b3}@ref{6b3,,.test;} There is a stress test for implementations of this interface
in impl.c.landtest. This allocates a large block of memory and then
simulates the allocation and deallocation of ranges within this block
using both a @ref{53c,,Land} and a @ref{6b4,,BT}. It makes both valid and invalid
requests, and compares the @ref{53c,,Land} response to the correct behaviour
as determined by the @ref{6b4,,BT}. It iterates the ranges in the @ref{53c,,Land},
comparing them to the @ref{6b4,,BT}. It invokes the @ref{6ad,,LandDescribe()}
generic function, but makes no automatic test of the resulting output.

@geindex locking; design

@node Lock module,Client message protocol,Lands,Design
@anchor{design/lock doc}@anchor{6b5}@anchor{design/lock design-lock}@anchor{30a}@anchor{design/lock lock-module}@anchor{6b6}
@section Lock module


@menu
* Introduction: Introduction<21>. 
* Background:: 
* Requirements: Requirements<12>. 
* Interface: Interface<9>. 
* Implementation: Implementation<9>. 
* Example: Example<2>. 
* References: References<7>. 

@end menu

@node Introduction<21>,Background,,Lock module
@anchor{design/lock design mps lock}@anchor{6b7}@anchor{design/lock introduction}@anchor{6b8}
@subsection Introduction


@anchor{design/lock design mps lock intro}@anchor{6b9}@ref{6b9,,.intro;} This is the design of the lock module.

@anchor{design/lock design mps lock readership}@anchor{6ba}@ref{6ba,,.readership;} Any MPS developer; anyone porting the MPS to a new
platform.

@node Background,Requirements<12>,Introduction<21>,Lock module
@anchor{design/lock background}@anchor{6bb}
@subsection Background


@anchor{design/lock design mps lock need}@anchor{6bc}@ref{6bc,,.need;} In an environment where multiple threads are accessing
shared data, threads need to cooperate to maintain consistency. Locks
provide a simple mechanism for doing this.

@anchor{design/lock design mps lock ownership}@anchor{6bd}@ref{6bd,,.ownership;} A lock is an object which may be “owned” by a single
thread at a time. By claiming ownership of a lock before executing
some piece of code, a thread can guarantee that no other thread owns
the lock during execution of that code. If some other thread holds a
claim on a lock, the thread trying to claim the lock will suspend
until the lock is released by the owning thread.

@anchor{design/lock design mps lock data}@anchor{6be}@ref{6be,,.data;} A simple way of using this behaviour is to associate a lock
with a shared data structure. By claiming that lock around accesses to
the data, a consistent view of the structure can be seen by the
accessing thread. More generally any set of operations which are
required to be mutually exclusive may be performed so by using locks.

@node Requirements<12>,Interface<9>,Background,Lock module
@anchor{design/lock requirements}@anchor{6bf}
@subsection Requirements


@anchor{design/lock design mps lock req thread-safety}@anchor{6c0}@ref{6c0,,.req.thread-safety;} Support the locking needs of
design.mps.thread-safety@footnote{thread-safety.html}.

@anchor{design/lock design mps lock req binary}@anchor{6c1}@ref{6c1,,.req.binary;} Provide `binary' locks: that is, locks that can be
claimed, and until released, other attempts to claim them block. (This
is needed to implement the arena lock.)

@anchor{design/lock design mps lock req recursive}@anchor{6c2}@ref{6c2,,.req.recursive;} Provide `recursive' locks: that is, locks that can
be claimed again by the thread currently holding them, without
blocking or deadlocking. (This is needed to implement the global
recursive lock.)

@anchor{design/lock design mps lock req held}@anchor{6c3}@ref{6c3,,.req.held;} Provide a means to test if a lock is held. (This is
needed for debugging a dynamic function table callback on Windows on
x86-64. See @ref{1a7,,mps_arena_busy()} for a detailed description of this
use case. Note that in this use case the program is running
single-threaded and so there is no need for this feature to be
thread-safe.)

@anchor{design/lock design mps lock req global}@anchor{6c4}@ref{6c4,,.req.global;} Provide `global' locks: that is locks that need not be
allocated or initialized by the user.

@anchor{design/lock design mps lock req global binary}@anchor{6c5}@ref{6c5,,.req.global.binary;} Provide a global binary lock. (This is required
to protect the data structure allowing multiple arenas to coordinate
handling of protection faults: see
design.mps.thread-safety.sol.global.mutable@footnote{thread-safety.html#design.mps.thread-safety.sol.global.mutable}.)

@anchor{design/lock design mps lock req global recursive}@anchor{6c6}@ref{6c6,,.req.global.recursive;} Provide a global recursive lock. (This is
required to protect protocol class initialization: see
design.mps.thread-safety.sol.global.once@footnote{thread-safety.html#design.mps.thread-safety.sol.global.once}.)

@anchor{design/lock design mps lock req deadlock not}@anchor{6c7}@ref{6c7,,.req.deadlock.not;} There is no requirement to provide protection
against deadlock. (Clients are able to avoid deadlock using
traditional strategies such as ordering of locks; see
design.mps.thread-safety.sol.deadlock@footnote{thread-safety.html#design.mps.thread-safety.sol.deadlock}.)

@node Interface<9>,Implementation<9>,Requirements<12>,Lock module
@anchor{design/lock design-mps-thread-safety-sol-deadlock}@anchor{6c8}@anchor{design/lock interface}@anchor{6c9}
@subsection Interface


@geindex Lock (C type)
@anchor{design/lock c Lock}@anchor{6ca}
@deffn {C Type} typedef LockStruct *Lock
@end deffn

An opaque type representing a lock. Clients that needs to allocate
space for a lock should dynamically allocate space for the structure,
calling @ref{6cb,,LockSize()} to determine the size.

@geindex LockSize (C function)
@anchor{design/lock c LockSize}@anchor{6cb}
@deffn {C Function} size_t LockSize (void)
@end deffn

Return the size of a @code{LockStruct} for allocation purposes.

@geindex LockInit (C function)
@anchor{design/lock c LockInit}@anchor{6cc}
@deffn {C Function} void LockInit (Lock lock)
@end deffn

Initialize the lock. This must be called before any use of the lock.
After initialization, the lock is not owned by any thread.

@geindex LockFinish (C function)
@anchor{design/lock c LockFinish}@anchor{6cd}
@deffn {C Function} void LockFinish (Lock lock)
@end deffn

Finish the lock. The lock must not be owned by any thread.

@geindex LockClaim (C function)
@anchor{design/lock c LockClaim}@anchor{6ce}
@deffn {C Function} void LockClaim (Lock lock)
@end deffn

Wait, if necessary, until the lock is not owned by any thread. Then
claim ownership of the lock by the current thread.

@geindex LockRelease (C function)
@anchor{design/lock c LockRelease}@anchor{6cf}
@deffn {C Function} void LockRelease (Lock lock)
@end deffn

Releases ownership of a lock that is currently owned.

@geindex LockClaimRecursive (C function)
@anchor{design/lock c LockClaimRecursive}@anchor{6d0}
@deffn {C Function} void LockClaimRecursive (Lock lock)
@end deffn

Remembers the previous state of the lock with respect to the current
thread and claims the lock (if not already held).

@geindex LockReleaseRecursive (C function)
@anchor{design/lock c LockReleaseRecursive}@anchor{6d1}
@deffn {C Function} void LockReleaseRecursive (Lock lock)
@end deffn

Restores the previous state of the lock remembered by the
corresponding @ref{6d0,,LockClaimRecursive()} call.

@geindex LockIsHeld (C function)
@anchor{design/lock c LockIsHeld}@anchor{6d2}
@deffn {C Function} @ref{3a9,,Bool} LockIsHeld (Lock lock)
@end deffn

Return true if the lock is held by any thread, false otherwise. Note
that this function need not be thread-safe (see @ref{6c3,,.req.held}).

@geindex LockInitGlobal (C function)
@anchor{design/lock c LockInitGlobal}@anchor{6d3}
@deffn {C Function} void LockInitGlobal (void)
@end deffn

Initialize (or re-initialize) the global locks. This should only be
called in the following circumstances: the first time either of the
global locks is claimed; and in the child process after a @code{fork()}.
See design.mps.thread-safety.sol.fork.lock@footnote{thread-safety.html#design.mps.thread-safety.sol.fork.lock}.

@geindex LockClaimGlobal (C function)
@anchor{design/lock c LockClaimGlobal}@anchor{6d4}
@deffn {C Function} void LockClaimGlobal (void)
@end deffn

Claims ownership of the binary global lock which was previously not
held by current thread.

@geindex LockReleaseGlobal (C function)
@anchor{design/lock c LockReleaseGlobal}@anchor{6d5}
@deffn {C Function} void LockReleaseGlobal (void)
@end deffn

Releases ownership of the binary global lock that is currently owned.

@geindex LockClaimGlobalRecursive (C function)
@anchor{design/lock c LockClaimGlobalRecursive}@anchor{6d6}
@deffn {C Function} void LockClaimGlobalRecursive (void)
@end deffn

Remembers the previous state of the recursive global lock with respect
to the current thread and claims the lock (if not already held).

@geindex LockReleaseGlobalRecursive (C function)
@anchor{design/lock c LockReleaseGlobalRecursive}@anchor{6d7}
@deffn {C Function} void LockReleaseGlobalRecursive (void)
@end deffn

Restores the previous state of the recursive global lock remembered by
the corresponding @ref{6d6,,LockClaimGlobalRecursive()} call.

@geindex LockSetup (C function)
@anchor{design/lock c LockSetup}@anchor{6d8}
@deffn {C Function} void LockSetup (void)
@end deffn

One-time initialization function, intended for calling
@code{pthread_atfork()} on the appropriate platforms: see design.mps.thread-safety.sol.fork.lock@footnote{thread-safety.html#design.mps.thread-safety.sol.fork.lock}.

@node Implementation<9>,Example<2>,Interface<9>,Lock module
@anchor{design/lock implementation}@anchor{6d9}
@subsection Implementation


@anchor{design/lock design mps lock impl recursive}@anchor{6da}@ref{6da,,.impl.recursive;} For recursive claims, the list of previous states
can be implemented by keeping a count of the number of claims made by
the current thread so far. In the multi-threaded implementations this
is handled by the operating system interface, but a count is still
kept and used to check correctness.

@anchor{design/lock design mps lock impl recursive limit}@anchor{6db}@ref{6db,,.impl.recursive.limit;} The implementation imposes a limit on the
number of recursive claims (see issue.lock-claim-limit@footnote{https://info.ravenbrook.com/project/mps/import/2001-09-27/mminfo/issue/lock-claim-limit}). On Windows,
the critical section object contains the field @code{LONG
RecursionCount}. In typical POSIX Threads implementations,
@code{pthread_mutex_t} uses an @code{int} for the count of recursive claims.

@anchor{design/lock design mps lock impl global}@anchor{6dc}@ref{6dc,,.impl.global;} The binary and recursive global locks are typically
implemented using the same mechanism as normal locks. (But an
operating system-specific mechanism is used, if possible, to ensure
that the global locks are initialized just once.)

@anchor{design/lock design mps lock impl an}@anchor{6dd}@ref{6dd,,.impl.an;} Single-threaded generic implementation @code{lockan.c}:


@itemize -

@item 
single-threaded;

@item 
no need for locking;

@item 
locking structure contains count;

@item 
provides checking in debug version;

@item 
otherwise does nothing except keep count of claims.
@end itemize

@anchor{design/lock design mps lock impl w3}@anchor{6de}@ref{6de,,.impl.w3;} Windows implementation @code{lockw3.c}:


@itemize -

@item 
supports Windows threads;

@item 
uses critical section objects @ref{6df,,[cso]};

@item 
locking structure contains a critical section object;

@item 
recursive and non-recursive calls use the same Windows function;

@item 
also performs checking.
@end itemize

@anchor{design/lock design mps lock impl ix}@anchor{6e0}@ref{6e0,,.impl.ix;} POSIX implementation @code{lockix.c}:


@itemize -

@item 
supports @ref{6e1,,[POSIXThreads]};

@item 
locking structure contains a mutex, initialized to check for
recursive locking;

@item 
locking structure contains a count of the number of active claims;

@item 
non-recursive locking calls @code{pthread_mutex_lock()} and expects
success;

@item 
recursive locking calls @code{pthread_mutex_lock()} and expects either
success or @code{EDEADLK} (indicating a recursive claim);

@item 
also performs checking.
@end itemize

@node Example<2>,References<7>,Implementation<9>,Lock module
@anchor{design/lock example}@anchor{6e2}
@subsection Example


@anchor{design/lock design mps lock example init}@anchor{6e3}@ref{6e3,,.example.init;} An example of allocating and initializing a lock:

@example
#include "lock.h"

static Lock lock;

void init()
@{
    mps_addr_t p;
    if (mps_alloc(&p, pool, LockSize()) != MPS_RES_OK)
        exit(1);
    lock = p;
    LockInit(lock);
@}
@end example

@anchor{design/lock design mps lock example binary}@anchor{6e4}@ref{6e4,,.example.binary;} An example of using a binary lock:

@example
void binaryUse()
@{
    /* lock must not be owned by this thread, or else this deadlocks. */
    LockClaim(lock);
    /* lock is now owned by this thread. */
    /* cannot call binaryUse() at this point. */
    /* only one thread at a time may be at this point. */
    LockRelease(lock);
    /* lock not owned by this thread. */
@}
@end example

@anchor{design/lock design mps lock example recursive}@anchor{6e5}@ref{6e5,,.example.recursive;} An example of using a recursive lock:

@example
void recursiveUse()
@{
    /* lock may or may not already be owned by this thread. */
    LockClaimRecursive(lock);
    /* lock is now owned by this thread. */
    /* cannot call binaryUse() at this point. */
    /* can call recursiveUse() at this point. */
    /* only one thread at a time may be at this point. */
    LockReleaseRecursive(lock);
    /* lock is still owned by this thread if it was before. */
@}
@end example

@node References<7>,,Example<2>,Lock module
@anchor{design/lock references}@anchor{6e6}
@subsection References


@anchor{design/lock cso}@anchor{6df}@w{(cso)} 
Microsoft Developer Network; “Critical Section Objects”; <@indicateurl{https://docs.microsoft.com/en-gb/windows/desktop/Sync/critical-section-objects}>

@anchor{design/lock posixthreads}@anchor{6e1}@w{(POSIXThreads)} 
The Open Group; “The Single UNIX Specification, Version 2—Threads”; <@indicateurl{https://pubs.opengroup.org/onlinepubs/7990989775/xsh/threads.html}>

@geindex messages; design
@geindex client message protocol

@node Client message protocol,Monitor,Lock module,Design
@anchor{design/message doc}@anchor{6e7}@anchor{design/message client-message-protocol}@anchor{6e8}@anchor{design/message design-message}@anchor{6e9}
@section Client message protocol


@menu
* Introduction: Introduction<22>. 
* Requirements: Requirements<13>. 
* Design: Design<3>. 
* External interface: External interface<2>. 
* Internal interface: Internal interface<2>. 
* Message life cycle:: 
* References: References<8>. 

@end menu

@node Introduction<22>,Requirements<13>,,Client message protocol
@anchor{design/message design mps message}@anchor{6ea}@anchor{design/message introduction}@anchor{6eb}
@subsection Introduction


@anchor{design/message design mps message intro}@anchor{6ec}@ref{6ec,,.intro;} The client message protocol provides a means by which
clients can receive messages from the MPS. The motivating use case is
finalization notification (see design.mps.finalize@footnote{finalize.html}), but the
mechanism is also used for feedback about collections.

@anchor{design/message design mps message contents}@anchor{6ed}@ref{6ed,,.contents;} This document describes the design of the external and
internal interfaces and concludes with a sketch of an example design
of an internal client. The example is that of implementing
finalization using the MRG pool.

@anchor{design/message design mps message readership}@anchor{6ee}@ref{6ee,,.readership;} Any MPS developer.

@node Requirements<13>,Design<3>,Introduction<22>,Client message protocol
@anchor{design/message requirements}@anchor{6ef}
@subsection Requirements


@anchor{design/message design mps message req synchronous}@anchor{6f0}@ref{6f0,,.req.synchronous;} The message protocol must be synchronous with the
client program: that is, the client program must be able to choose
when to collect and act on messages. Justification: @ref{6f1,,[Boehm_2002]}
shows that asynchronous finalization is impossible to implement
correctly.

@anchor{design/message design mps message req reliable}@anchor{6f2}@ref{6f2,,.req.reliable;} Posting a message must be reliable: that is, it must
not fail for a dynamic reason such as running out memory to store the
message. Justification: messages can’t be used to implement
finalization unless the messages can be delivered reliably.

@anchor{design/message design mps message req extensible types}@anchor{6f3}@ref{6f3,,.req.extensible.types;} The message mechanism must be extensible
with new types of message in future versions of the MPS, without
breaking client programs that do not receive those types of message.

@anchor{design/message design mps message req resources}@anchor{6f4}@ref{6f4,,.req.resources;} It follows from @ref{6f3,,.req.extensible.types} that
messages must not use resources unless the client program has
requested them (otherwise resources would leak in client programs that
have not been updated to handle new types of message).

@anchor{design/message design mps message req extensible fields}@anchor{6f5}@ref{6f5,,.req.extensible.fields;} It must be possible to add new fields to
existing types of message in future versions of the MPS, without
breaking client programs that do not receive those types of message.

@node Design<3>,External interface<2>,Requirements<13>,Client message protocol
@anchor{design/message design}@anchor{6f6}
@subsection Design


@anchor{design/message design mps message sol synchronous}@anchor{6f7}@ref{6f7,,.sol.synchronous;} Messages are stored on a ring belonging to the
arena. An interface is provided that allows the client program to
collect messages from the ring at a time of its choosing.

@anchor{design/message design mps message sol reliable}@anchor{6f8}@ref{6f8,,.sol.reliable;} The memory needed for the message is allocated at an
earlier point in time, when it possible to communicate an allocation
failure via a result code. In particular, space for a finalization
message is allocated when the client program calls @ref{e8,,mps_finalize()},
and space for trace messages is allocated in the arena (there can be
at most one instance of each message per trace, and the maximum number
of traces is known statically).

@anchor{design/message design mps message sol resources}@anchor{6f9}@ref{6f9,,.sol.resources;} Messages are not posted unless they belong to a
type that has been enabled by the client program calling
@code{mps_message_enable()}. This means that message types that are not
understood by the client program are not posted and use no resources.

@anchor{design/message design mps message sol extensible fields}@anchor{6fa}@ref{6fa,,.sol.extensible.fields;} Message fields are retrieved by calling
accessor functions.

@node External interface<2>,Internal interface<2>,Design<3>,Client message protocol
@anchor{design/message external-interface}@anchor{6fb}
@subsection External interface


@menu
* Functions: Functions<2>. 
* Types of messages:: 

@end menu

@node Functions<2>,Types of messages,,External interface<2>
@anchor{design/message functions}@anchor{6fc}
@subsubsection Functions


@anchor{design/message design mps message if fun}@anchor{6fd}@ref{6fd,,.if.fun;} The following functions are provided:

@anchor{design/message design mps message if fun poll}@anchor{6fe}@ref{6fe,,.if.fun.poll;} @ref{240,,mps_message_poll()} sees whether there are any
messages pending. Returns 1 only if there is a message on the queue of
arena. Returns 0 otherwise.

@anchor{design/message design mps message if fun enable}@anchor{6ff}@ref{6ff,,.if.fun.enable;} @ref{eb,,mps_message_type_enable()} enables the flow of
messages of a certain type. The queue of messages of a arena will
contain only messages whose types have been enabled. Initially all
message types are disabled. Effectively this function allows the
client to declare to the MPS what message types the client
understands.

@anchor{design/message design mps message if fun disable}@anchor{700}@ref{700,,.if.fun.disable;} @ref{239,,mps_message_type_disable()} disables the flow
of messages of a certain type. The antidote to
@ref{eb,,mps_message_type_enable()}. Disables the specified message type.
Flushes any existing messages of that type on the queue, and stops any
further generation of messages of that type. This permits clients to
dynamically decline interest in a message type, which may help to
avoid a memory leak or bloated queue when the messages are only
required temporarily.

@anchor{design/message design mps message if fun get}@anchor{701}@ref{701,,.if.fun.get;} @ref{ec,,mps_message_get()} begins a message “transaction”.
If there is a message of the specified type on the queue then the
first such message will be removed from the queue and a handle to it
will be returned to the client via the @code{messageReturn} argument; in
this case the function will return @code{TRUE}. Otherwise it will return
@code{FALSE}. Having obtained a handle on a message in this way, the
client can use the type-specific accessors to find out about the
message. When the client is done with the message the client should
call @ref{ee,,mps_message_discard()}; failure to do so will result in a
resource leak.

@anchor{design/message design mps message if fun discard}@anchor{702}@ref{702,,.if.fun.discard;} @ref{ee,,mps_message_discard()} ends a message
“transaction”. It indicates to the MPS that the client is done with
this message and its resources may be reclaimed.

@anchor{design/message design mps message if fun type any}@anchor{703}@ref{703,,.if.fun.type.any;} @ref{241,,mps_message_queue_type()} determines the type
of a message in the queue. Returns @code{TRUE} only if there is a message
on the queue of arena, and in this case updates the @code{typeReturn}
argument to be the type of a message in the queue. Otherwise returns
@code{FALSE}.

@anchor{design/message design mps message if fun type}@anchor{704}@ref{704,,.if.fun.type;} @ref{23e,,mps_message_type()} determines the type of a
message (that has already been got). Only legal when inside a message
transaction (that is, after @ref{ec,,mps_message_get()} and before
@ref{ee,,mps_message_discard()}). Note that the type will be the same as the
type that the client passed in the call to @ref{ec,,mps_message_get()}.

@node Types of messages,,Functions<2>,External interface<2>
@anchor{design/message types-of-messages}@anchor{705}
@subsubsection Types of messages


@anchor{design/message design mps message type}@anchor{706}@ref{706,,.type;} The type governs the “shape” and meaning of the message.

@anchor{design/message design mps message type int}@anchor{707}@ref{707,,.type.int;} A message type is an integer belonging to the
@ref{708,,MessageType} enumeration.

@anchor{design/message design mps message type semantics}@anchor{709}@ref{709,,.type.semantics;} A type indicates the semantics of the message.

@anchor{design/message design mps message type semantics interpret}@anchor{70a}@ref{70a,,.type.semantics.interpret;} The semantics of a message are
interpreted by the client by calling various accessor methods on the
message.

@anchor{design/message design mps message type accessor}@anchor{70b}@ref{70b,,.type.accessor;} The type of a message governs which accessor
methods are legal to apply to the message.

@anchor{design/message design mps message type finalization}@anchor{70c}@ref{70c,,.type.finalization;} There is a finalization type,
@code{MessageTypeFINALIZATION}.

@anchor{design/message design mps message type finalization semantics}@anchor{70d}@ref{70d,,.type.finalization.semantics;} A finalization message indicates that
an object has been discovered to be finalizable (see
design.mps.poolmrg.def.final.object@footnote{poolmrg.html#design.mps.poolmrg.def.final.object} for a definition of finalizable).

@anchor{design/message design mps message type finalization ref}@anchor{70e}@ref{70e,,.type.finalization.ref;} The accessor function
@ref{ed,,mps_message_finalization_ref()} retrieves the reference to the
object which is finalizable.

@anchor{design/message design mps message type finalization ref scan}@anchor{70f}@ref{70f,,.type.finalization.ref.scan;} Note that the reference returned
must be stored in scanned memory.

@node Internal interface<2>,Message life cycle,External interface<2>,Client message protocol
@anchor{design/message internal-interface}@anchor{710}
@subsection Internal interface


@menu
* Types: Types<6>. 
* Functions: Functions<3>. 

@end menu

@node Types<6>,Functions<3>,,Internal interface<2>
@anchor{design/message types}@anchor{711}
@subsubsection Types


@geindex Message (C type)
@anchor{design/message c Message}@anchor{547}
@deffn {C Type} typedef struct MessageStruct *Message
@end deffn

@anchor{design/message design mps message message type}@anchor{712}@ref{712,,.message.type;} @ref{547,,Message} is the type of messages.

@anchor{design/message design mps message message instance}@anchor{713}@ref{713,,.message.instance;} Messages are instances of Message Classes.

@anchor{design/message design mps message message concrete}@anchor{714}@ref{714,,.message.concrete;} Concretely a message is represented by a
@code{MessageStruct}. A @code{MessageStruct} has the usual signature field
(see design.mps.sig@footnote{sig.html}). A @code{MessageStruct} has a type field which
defines its type, a ring node, which is used to attach the message to
the queue of pending messages, a class field, which identifies a
@ref{715,,MessageClass} object.

@anchor{design/message design mps message message intent}@anchor{716}@ref{716,,.message.intent;} The intention is that a @code{MessageStruct} will be
embedded in some richer object which contains information relevant to
that specific type of message.

@anchor{design/message design mps message message struct}@anchor{717}@ref{717,,.message.struct;} The structure is declared as follows:

@example
typedef struct mps_message_s @{
  Sig sig;                      /* <design/sig/> */
  Arena arena;                  /* owning arena */
  MessageClass klass;           /* Message Class Structure */
  Clock postedClock;            /* mps_clock() at post time, or 0 */
  RingStruct queueRing;         /* Message queue ring */
@} MessageStruct;
@end example

@geindex MessageClass (C type)
@anchor{design/message c MessageClass}@anchor{715}
@deffn {C Type} typedef struct MessageClassStruct *MessageClass
@end deffn

@anchor{design/message design mps message class}@anchor{718}@ref{718,,.class;} A message class is an encapsulation of methods. It
encapsulates methods that are applicable to all types of messages
(generic) and methods that are applicable to messages only of a
certain type (type-specific).

@anchor{design/message design mps message class concrete}@anchor{719}@ref{719,,.class.concrete;} Concretely a message class is represented by a
@code{MessageClassStruct} (a struct). Clients of the Message module are
expected to allocate storage for and initialise the
@code{MessageClassStruct}. It is expected that such storage will be
allocated and initialised statically.

@anchor{design/message design mps message class one-type}@anchor{71a}@ref{71a,,.class.one-type;} A message class implements exactly one message
type. The identifier for this type is stored in the @code{type} field of
the @code{MessageClassStruct}. Note that the converse is not true: a
single message type may be implemented by two (or more) different
message classes (for example: for two pool classes that require
different implementations for that message type).

@anchor{design/message design mps message class methods generic}@anchor{71b}@ref{71b,,.class.methods.generic;} The generic methods are as follows:


@itemize *

@item 
@code{delete} – used when the message is destroyed (by the client
calling @ref{ee,,mps_message_discard()}). The class implementation should
finish the message (by calling @ref{71c,,MessageFinish()}) and storage for
the message should be reclaimed (if applicable).
@end itemize

@anchor{design/message design mps message class methods specific}@anchor{71d}@ref{71d,,.class.methods.specific;} The type specific methods are:

@anchor{design/message design mps message class methods specific finalization}@anchor{71e}@ref{71e,,.class.methods.specific.finalization;} Specific to
@code{MessageTypeFINALIZATION}:


@itemize *

@item 
@code{finalizationRef} – returns a reference to the finalizable object
represented by this message.
@end itemize

@anchor{design/message design mps message class methods specific gc}@anchor{71f}@ref{71f,,.class.methods.specific.gc;} Specific to @code{MessageTypeGC}:


@itemize *

@item 
@code{gcLiveSize} – returns the number of bytes (of objects) that were
condemned by the trace but survived.

@item 
@code{gcCondemnedSize} – returns the number of bytes condemned by the
trace.

@item 
@code{gcNotCondemnedSize} – returns the number of bytes (of
objects) that are collectable but were not condemned by the trace.
@end itemize

@anchor{design/message design mps message class methods specific gcstart}@anchor{720}@ref{720,,.class.methods.specific.gcstart;} Specific to @code{MessageTypeGCSTART}:


@itemize *

@item 
@code{gcStartWhy} – returns an English-language description of the
reason why the trace was started.
@end itemize

@anchor{design/message design mps message class sig double}@anchor{721}@ref{721,,.class.sig.double;} The @code{MessageClassStruct} has a signature field
at both ends. This is so that if the @code{MessageClassStruct} changes
size (by adding extra methods for example) then any static
initializers will generate errors from the compiler (there will be a
type error causes by initialising a non-signature type field with a
signature) unless the static initializers are changed as well.

@anchor{design/message design mps message class struct}@anchor{722}@ref{722,,.class.struct;} The structure is declared as follows:

@example
typedef struct MessageClassStruct @{
  Sig sig;                      /* <design/sig/> */
  const char *name;             /* Human readable Class name */

  MessageType type;             /* Message Type */

  /* generic methods */
  MessageDeleteMethod delete;   /* terminates a message */

  /* methods specific to MessageTypeFINALIZATION */
  MessageFinalizationRefMethod finalizationRef;

  /* methods specific to MessageTypeGC */
  MessageGCLiveSizeMethod gcLiveSize;
  MessageGCCondemnedSizeMethod gcCondemnedSize;
  MessageGCNotCondemnedSizeMethod gcNotCondemnedSize;

  /* methods specific to MessageTypeGCSTART */
  MessageGCStartWhyMethod gcStartWhy;

  Sig endSig;                   /* <design/message/#class.sig.double> */
@} MessageClassStruct;
@end example

@anchor{design/message design mps message space queue}@anchor{723}@ref{723,,.space.queue;} The arena structure is augmented with a structure for
managing for queue of pending messages. This is a ring in the
@code{ArenaStruct}:

@example
struct ArenaStruct
@{
  ...
  RingStruct messageRing;
  ...
@}
@end example

@node Functions<3>,,Types<6>,Internal interface<2>
@anchor{design/message id2}@anchor{724}
@subsubsection Functions


@geindex MessageInit (C function)
@anchor{design/message c MessageInit}@anchor{725}
@deffn {C Function} void MessageInit (Arena arena, Message message, MessageClass klass, MessageType type)
@end deffn

@anchor{design/message design mps message fun init}@anchor{726}@ref{726,,.fun.init;} Initializes the @code{MessageStruct} pointed to by
@code{message}. The caller of this function is expected to manage the
store for the @code{MessageStruct}.

@geindex MessageFinish (C function)
@anchor{design/message c MessageFinish}@anchor{71c}
@deffn {C Function} void MessageFinish (Message message)
@end deffn

@anchor{design/message design mps message fun finish}@anchor{727}@ref{727,,.fun.finish;} Finishes the @code{MessageStruct} pointed to by
@code{message}. The caller of this function is expected to manage the
store for the @code{MessageStruct}.

@geindex MessagePost (C function)
@anchor{design/message c MessagePost}@anchor{728}
@deffn {C Function} void MessagePost (Arena arena, Message message)
@end deffn

@anchor{design/message design mps message fun post}@anchor{729}@ref{729,,.fun.post;} Places a message on the queue of an arena.

@anchor{design/message design mps message fun post precondition}@anchor{72a}@ref{72a,,.fun.post.precondition;} Prior to calling the function, the
@code{queueRing} field of the message must be a singleton
(design.mps.ring.def.singleton@footnote{ring.html#design.mps.ring.def.singleton}). After the call to the function the
message will be available for MPS client to access. After the call to
the function the message fields must not be manipulated except from
the message’s class’s method functions (that is, you mustn’t poke
about with the @code{queueRing} field in particular).

@geindex MessageEmpty (C function)
@anchor{design/message c MessageEmpty}@anchor{554}
@deffn {C Function} void MessageEmpty (Arena arena)
@end deffn

@anchor{design/message design mps message fun empty}@anchor{72b}@ref{72b,,.fun.empty;} Empties the message queue. This function has the same
effect as discarding all the messages on the queue. After calling this
function there will be no messages on the queue.

@anchor{design/message design mps message fun empty internal-only}@anchor{72c}@ref{72c,,.fun.empty.internal-only;} This functionality is not exposed to
clients. We might want to expose this functionality to our clients in
the future.

@node Message life cycle,References<8>,Internal interface<2>,Client message protocol
@anchor{design/message message-life-cycle}@anchor{72d}
@subsection Message life cycle


@anchor{design/message design mps message life alloc}@anchor{72e}@ref{72e,,.life.alloc;} Space for the message structure is allocated at the
earliest point in time when the MPS knows that the message might be
needed.

@anchor{design/message design mps message life init}@anchor{72f}@ref{72f,,.life.init;} The message structure is initialized by calling
@ref{725,,MessageInit()}.

@anchor{design/message design mps message life post}@anchor{730}@ref{730,,.life.post;} The message is posted on the arena’s message queue by
calling @ref{728,,MessagePost()}.

@anchor{design/message design mps message life get}@anchor{731}@ref{731,,.life.get;} The client program retrieves the message by calling @ref{ec,,mps_message_get()}.

@anchor{design/message design mps message life discard}@anchor{732}@ref{732,,.life.discard;} The client program indicates that it is finished
with the message by calling @ref{ee,,mps_message_discard()}.

@anchor{design/message design mps message life reuse}@anchor{733}@ref{733,,.life.reuse;} The MPS may reuse the message structure, in which case
the lifecycle continues from @ref{730,,.life.post}.

@anchor{design/message design mps message life delete}@anchor{734}@ref{734,,.life.delete;} When the MPS no longer needs the message structure,
its @code{delete} method is called.

@node References<8>,,Message life cycle,Client message protocol
@anchor{design/message references}@anchor{735}
@subsection References


@anchor{design/message boehm-2002}@anchor{6f1}@w{(Boehm_2002)} 
Hans-J. Boehm. 2002. “Destructors@comma{} Finalizers@comma{} and Synchronization@footnote{http://www.hpl.hp.com/techreports/2002/HPL-2002-335.html}”. HP Labs technical report HPL-2002-335.

@geindex monitor; design

@node Monitor,Nailboards for ambiguously referenced segments,Client message protocol,Design
@anchor{design/monitor doc}@anchor{736}@anchor{design/monitor design-monitor}@anchor{737}@anchor{design/monitor monitor}@anchor{738}
@section Monitor


@menu
* Introduction: Introduction<23>. 
* Requirements: Requirements<14>. 
* Installation and usage:: 
* References: References<9>. 

@end menu

@node Introduction<23>,Requirements<14>,,Monitor
@anchor{design/monitor design mps monitor}@anchor{739}@anchor{design/monitor introduction}@anchor{73a}
@subsection Introduction


@anchor{design/monitor design mps monitor intro}@anchor{73b}@ref{73b,,.intro;} This is the design of the MPS monitor, a graphical user
interface for inspecting the behaviour of the MPS in a client program
by collating the program’s telemetry output.

@anchor{design/monitor design mps monitor readership}@anchor{73c}@ref{73c,,.readership;} This document is intended for any MPS user.

@anchor{design/monitor design mps monitor source}@anchor{73d}@ref{73d,,.source;} This is based on @ref{73e,,[GDR_2018-06-27]}.

@node Requirements<14>,Installation and usage,Introduction<23>,Monitor
@anchor{design/monitor requirements}@anchor{73f}
@subsection Requirements


It should be possible to analyze the behaviour of the
MPS in a client program:

@anchor{design/monitor design mps monitor req state running}@anchor{740}@ref{740,,.req.state.running;} that is currently running (job003960@footnote{https://www.ravenbrook.com/project/mps/issue/job003960/}); or

@anchor{design/monitor design mps monitor req state stopped}@anchor{741}@ref{741,,.req.state.stopped;} that has finished running.

It should be possible to see:

@anchor{design/monitor design mps monitor req memory total}@anchor{742}@ref{742,,.req.memory.total;} the total memory in use by the client program
@ref{743,,[GR_2004-12-02]};

@anchor{design/monitor design mps monitor req memory pool}@anchor{744}@ref{744,,.req.memory.pool;} the memory in use by each pool (job003960@footnote{https://www.ravenbrook.com/project/mps/issue/job003960/});

@anchor{design/monitor design mps monitor req trace}@anchor{745}@ref{745,,.req.trace;} when traces take place (job003960@footnote{https://www.ravenbrook.com/project/mps/issue/job003960/});

@anchor{design/monitor design mps monitor req trace generation}@anchor{746}@ref{746,,.req.trace.generation;} which generations get collected by each
trace (job003960@footnote{https://www.ravenbrook.com/project/mps/issue/job003960/});

@anchor{design/monitor design mps monitor req time-fraction}@anchor{747}@ref{747,,.req.time-fraction;} the fraction of runtime spent in collections;

@anchor{design/monitor design mps monitor req barriers}@anchor{748}@ref{748,,.req.barriers;} the rate of barrier hits, to indicate how the barriers
are working (job003921@footnote{https://www.ravenbrook.com/project/mps/issue/job003921/}).

@node Installation and usage,References<9>,Requirements<14>,Monitor
@anchor{design/monitor installation-and-usage}@anchor{749}@anchor{design/monitor job003921}@anchor{74a}
@subsection Installation and usage


These are placeholder instructions, to be revised when we figure out
the best way to automate them.


@enumerate 

@item 
Build the @code{mpseventpy} program:

@example
cd code
nmake /f w3i6mv.nmk VARIETY=cool mpseventpy.exe # Windows
make -f xci6ll.gmk VARIETY=cool mpseventpy # macOS
make -f lii6ll.gmk VARIETY=cool mpseventpy # Linux
@end example

@item 
Run @code{mpseventpy} program and redirect the output to @code{tool/mpsevent.py}:

@example
w3i6mv/cool/mpseventpy.exe > ../tool/mpsevent.py # Windows
xci6ll/cool/mpseventpy > ../tool/mpsevent.py # macOS
lii6ll/cool/mpseventpy > ../tool/mpsevent.py # Linux
@end example

@item 
Install Python 3.6 (or later). On Windows, there are installers@footnote{https://www.python.org/ftp/python/3.6.5/python-3.6.5-amd64.exe}
named like @code{python-3.6.6-amd64.exe}. On other platforms, you
probably want to use your package manager, for example:

@example
sudo port install python36 # macPorts
sudo apt install python3.6 # Linux
@end example

@item 
On Windows, you’ll want to edit the system environment variables to
put Python 3.6 on the path.

@item 
Install Matplotlib and PyQt5. On Windows, the easiest way to do
this is to launch a command prompt (possibly as administrator, if
you installed Python somewhere like @code{C:/Program Files}) and
then:

@example
python -m ensurepip
python -m pip install matplotlib pyqt5
@end example

On other platforms, you’ll want to use the package manager, for example:

@example
sudo port install py36-matplotlib py36-pyqt5 # macPorts
sudo apt install python3-matplotlib python3-pyqt5 # Linux
@end example

@item 
Now, from the @code{tool} subdirectory, you should be able to run the
monitor:

@example
cd tool
./monitor [FILENAME]
@end example

where FILENAME defaults to mpsio.log. So for example, you could
compile the @code{amcss} smoke test:

@example
cd code
nmake /f w3i6mv.nmk VARIETY=cool amcss.exe # Windows
make -f xci6ll.gmk VARIETY=cool amcss # macOS
make -f lli6ll.gmk VARIETY=cool amcss # Linux
@end example

and then run @code{amcss} generating telemetry output:

@example
cd tool
MPS_TELEMETRY_FILENAME=mpsio.log MPS_TELEMETRY_CONTROL="arena pool user” ../code/w3i6mv/cool/amcss.exe > /dev/null # Windows
MPS_TELEMETRY_FILENAME=mpsio.log MPS_TELEMETRY_CONTROL="arena pool user" ../code/xci6ll/cool/amcss > /dev/null # macOS
MPS_TELEMETRY_FILENAME=mpsio.log MPS_TELEMETRY_CONTROL="arena pool user" ../code/lli6ll/cool/amcss > /dev/null # Linux
@end example

and then launch the monitor on the file you just created:

@example
cd tool
./monitor
@end example

which should show you something like this (the exact graphs will
depend on the random choices made by @code{amcss}):


@float Figure

@image{MemoryPoolSystem-figures/monitor,,,Screenshot of the MPS monitor showing a run of the amcss smoke test.,png}

@end float


@item 
The monitor is capable of monitoring an application in real-time.
The pause button on the toolbar pauses the updating of the display
(but not the application). The zoom and pan tools automatically
pause the updating too, so after zooming you’ll need to unpause in
order to resume updating the display.
@end enumerate

@node References<9>,,Installation and usage,Monitor
@anchor{design/monitor references}@anchor{74b}
@subsection References


@anchor{design/monitor gdr-2018-06-27}@anchor{73e}@w{(GDR_2018-06-27)} 
Gareth Rees. Ravenbrook Limited. 2018-06-27. “Setting up and running the monitor@footnote{https://info.ravenbrook.com/mail/2018/06/27/10-51-04/0/}”.

@anchor{design/monitor gr-2004-12-02}@anchor{743}@w{(GR_2004-12-02)} 
Göran Rydqvist. Configura Sverige AB. 2004-12-02. “RE: MPS@comma{} working set@comma{} and address space@footnote{https://info.ravenbrook.com/mail/2004/12/02/07-53-32/0/}”.

@geindex nailboard; design

@node Nailboards for ambiguously referenced segments,Pool classes<2>,Monitor,Design
@anchor{design/nailboard doc}@anchor{74c}@anchor{design/nailboard design-nailboard}@anchor{74d}@anchor{design/nailboard nailboards-for-ambiguously-referenced-segments}@anchor{74e}
@section Nailboards for ambiguously referenced segments


@menu
* Introduction: Introduction<24>. 
* Requirements: Requirements<15>. 
* Implementation: Implementation<10>. 
* Future:: 
* References: References<10>. 

@end menu

@node Introduction<24>,Requirements<15>,,Nailboards for ambiguously referenced segments
@anchor{design/nailboard design mps nailboard}@anchor{74f}@anchor{design/nailboard introduction}@anchor{750}
@subsection Introduction


@anchor{design/nailboard design mps nailboard intro}@anchor{751}@ref{751,,.intro;} This is the design of the nailboard module.

@anchor{design/nailboard design mps nailboard readership}@anchor{752}@ref{752,,.readership;} Any MPS developer.

@anchor{design/nailboard design mps nailboard overview}@anchor{753}@ref{753,,.overview;} A nailboard represents a set of addresses to which
ambiguous references have been found. It is implemented as a
specialized bit table that maps addresses within a range to `nails'.
The mapping has granularity, so that all addresses within a word, say,
will map to the same nail.

@anchor{design/nailboard design mps nailboard purpose}@anchor{754}@ref{754,,.purpose;} Nailboards are used by the AMC pool class to record
ambiguous references to grains within a segment. See
design.mps.poolamc.nailboard@footnote{poolamc.html#design.mps.poolamc.nailboard}.

@node Requirements<15>,Implementation<10>,Introduction<24>,Nailboards for ambiguously referenced segments
@anchor{design/nailboard design-mps-poolamc-nailboard}@anchor{755}@anchor{design/nailboard requirements}@anchor{756}
@subsection Requirements


@anchor{design/nailboard design mps nailboard req granularity}@anchor{757}@ref{757,,.req.granularity;} A nailboard must be able to set nails for
addresses down to the grain size of the segment. (Because individual
objects may be this small, and we must be able to preserve or reclaim
individual objects.)

@anchor{design/nailboard design mps nailboard req set}@anchor{758}@ref{758,,.req.set;} A nailboard must be able to set a nail corresponding to
any aligned address in the range covered. (Because ambiguous
references may have arbitrary values.)

@anchor{design/nailboard design mps nailboard req reset not}@anchor{759}@ref{759,,.req.reset.not;} A nailboard is `not' required to be able to reset a
nail. (Because resetting a nail would correspond to proving that there
is `no' ambiguous reference to that address, but that can only be
established when the trace is complete.)

@anchor{design/nailboard design mps nailboard req range}@anchor{75a}@ref{75a,,.req.range;} A nailboard must be able to determine if any nail is
set in a contiguous range. (Because we must preserve the whole object
if there is any ambiguous reference to it.)

@anchor{design/nailboard design mps nailboard req range cost}@anchor{75b}@ref{75b,,.req.range.cost;} Determining if any nail is set in a continuous
range must be cheap. That is, it must take time that is no more than
logarithmic in the size of the range. (Because scanning overhead must
be proportional to the number of objects, not to their size.)

@node Implementation<10>,Future,Requirements<15>,Nailboards for ambiguously referenced segments
@anchor{design/nailboard implementation}@anchor{75c}
@subsection Implementation


@anchor{design/nailboard design mps nailboard impl table}@anchor{75d}@ref{75d,,.impl.table;} The nailboard consists of a header structure and one
or more bit tables. Each bit table covers the whole range of
addresses, but at a different level of detail.

@anchor{design/nailboard design mps nailboard impl table level0}@anchor{75e}@ref{75e,,.impl.table.level0;} The level 0 bit table has one bit for each
aligned address in the range.

@anchor{design/nailboard design mps nailboard impl align}@anchor{75f}@ref{75f,,.impl.align;} The alignment of the nailboard need not be the same as
the pool alignment. This is because nailboards are per-segment, and
the pool may know the minimum size of an object in a particular
segment.

@anchor{design/nailboard design mps nailboard impl table k}@anchor{760}@ref{760,,.impl.table.k;} The level `k' bit table has one bit for each @code{scale}
bits in the level `k'−1 bit table (this bit is set if any bit in the
corresponding word in the level `k'−1 table is set).

@anchor{design/nailboard design mps nailboard impl scale}@anchor{761}@ref{761,,.impl.scale;} Here @code{scale} is an arbitrary scale factor that must
be a power of 2. It could in future be supplied as a parameter when
creating a nailboard, but in the current implementation it is always
@ref{187,,MPS_WORD_WIDTH}.

@anchor{design/nailboard design mps nailboard impl table last}@anchor{762}@ref{762,,.impl.table.last;} The last bit table is always shorter than one
word. This is slightly wasteful in some cases (for example, a
nailboard with 64 nails and @code{scale} 64 will have two levels, the
second level having just one bit), but allows the code to support
small nailboards without special cases in the code (consider the case
of a nailboard with just one nail).

@anchor{design/nailboard design mps nailboard impl size}@anchor{763}@ref{763,,.impl.size;} The size of the level `i' bit table is the ceiling of

@quotation

(@code{limit} − @code{base}) / (@code{align} × @code{scale}@w{^i})
@end quotation

where @code{base} and @code{limit} are the bounds of the address range being
represented in the nailboard and @code{align} is the alignment.

@anchor{design/nailboard design mps nailboard impl address}@anchor{764}@ref{764,,.impl.address;} The address `a' may be looked up in the level `i'
bit table at the bit

@quotation

(`a' − @code{base}) / (@code{align} × @code{scale}@w{^i})
@end quotation

and since @code{align} and @code{scale} are powers of 2, that’s

@quotation

(`a' − @code{base}) >> (log@w{[2]}@code{align} + `i' log@w{[2]}@code{scale})
@end quotation

@anchor{design/nailboard design mps nailboard impl set}@anchor{765}@ref{765,,.impl.set;} Setting a nail for an address `a' in a nailboard is on
the critical path: it is called for every fix of an ambiguous
reference to an address in an AMC pool. When setting a nail, we set
the corresponding bit in every level of the nailboard.

@anchor{design/nailboard design mps nailboard impl isresrange}@anchor{766}@ref{766,,.impl.isresrange;} Testing a range of addresses to see if any nails
are set is also on the critical path: it is called for every object in
any AMC segment with a nailboard when the segment is scanned and when
it is reclaimed.

@anchor{design/nailboard design mps nailboard impl isresrange strategy}@anchor{767}@ref{767,,.impl.isresrange.strategy;} The strategy for testing to see if any
nails are set in a range is to handle the cases that are expected to
be common first. In particular, we expect that there will only be few
nails in a nailboard, so most calls to @code{NailboardIsResRange()} will
return @code{TRUE}.

@anchor{design/nailboard design mps nailboard impl isresrange alignment}@anchor{768}@ref{768,,.impl.isresrange.alignment;} When testing a range against a level of
a nailboard, the base and limit of the range will typically not align
exactly to the bits of that level. Therefore we test against a
slightly larger range, as shown in the diagram:


@float Figure

@image{MemoryPoolSystem-figures/nailboard-1,,,Diagram: Testing a range against a level of a nailboard.,svg}

@caption{Testing a range against a level of a nailboard.}

@end float


@anchor{design/nailboard design mps nailboard impl isresrange empty}@anchor{769}@ref{769,,.impl.isresrange.empty;} If all bits in the range [@code{ibase},
@code{ilimit}) are reset, as shown above, then there are no nails in the
range of addresses [@code{base}, @code{limit}). This provides an early exit
with result @code{TRUE}.

@anchor{design/nailboard design mps nailboard impl isresrange level0}@anchor{76a}@ref{76a,,.impl.isresrange.level0;} If the “empty” early exit is not taken,
and we are looking at the level 0 bit table, then the range is not
empty. This provides an early exit with result @code{FALSE}.

@anchor{design/nailboard design mps nailboard impl isresrange inner}@anchor{76b}@ref{76b,,.impl.isresrange.inner;} If any bit in the range [@code{ibase}+1,
@code{ilimit}−1) is set, as shown below, then there is a nail in the
range of addresses [@code{base}, @code{limit}). This provides an early exit
with result @code{FALSE}.


@float Figure

@image{MemoryPoolSystem-figures/nailboard-2,,,Diagram: a nail is set in this range.,svg}

@caption{A nail is set in this range.}

@end float


@anchor{design/nailboard design mps nailboard impl isresrange splinter}@anchor{76c}@ref{76c,,.impl.isresrange.splinter;} If none of the three early exits is
taken, then we are in a situation like the one shown below, with one
or two `splinters'. In this situation we know that there is a nail,
but it is not clear whether the nail is inside the splinter or not. We
handle this situation by moving up to the previous level and looking
at the range of addresses covered by the splinter.


@float Figure

@image{MemoryPoolSystem-figures/nailboard-3,,,Diagram: it is not clear if a nail is set in this range.,svg}

@caption{It is not clear if a nail is set in this range.}

@end float


@anchor{design/nailboard design mps nailboard impl isresrange splinter recurse}@anchor{76d}@ref{76d,,.impl.isresrange.splinter.recurse;} When looking at a splinter, we
might reach the same situation: namely, that the interior of the
splinter is empty, but the edge of the splinter is set. We handle this
by reducing the size of the splinter and moving up to the previous
level.

@anchor{design/nailboard design mps nailboard impl isresrange splinter one-sided}@anchor{76e}@ref{76e,,.impl.isresrange.splinter.one-sided;} This splinter-of-a-splinter is
one-sided: that is, we don’t need to look at the right splinter of a
left splinter or vice versa, because we know that it is empty.

@node Future,References<10>,Implementation<10>,Nailboards for ambiguously referenced segments
@anchor{design/nailboard future}@anchor{76f}
@subsection Future


@anchor{design/nailboard design mps nailboard future tune}@anchor{770}@ref{770,,.future.tune;} The implementation makes heavy use of
@ref{771,,BTIsResRange()}, but this function is not well tuned for scanning
small arrays (which we expect to be the common case for nailboards).
Performance might be improved by special-casing the small levels.

@anchor{design/nailboard design mps nailboard future limit}@anchor{772}@ref{772,,.future.limit;} In C and C++, a pointer to “one past the last
element of an array object” (the limit of the object in our
terminology) is a valid pointer and can be used in pointer arithmetic.
See §6.5.6.8–9 of @ref{773,,[C1999a]}. So in theory a programmer could have such
a pointer as the only reference keeping an object alive, and still
expect to be able to subtract from it to get back to the object. The
current nailboard implementation does not support this use case.

@node References<10>,,Future,Nailboards for ambiguously referenced segments
@anchor{design/nailboard references}@anchor{774}
@subsection References


@anchor{design/nailboard c1999a}@anchor{773}@w{(C1999a)} 
International Standard ISO/IEC 9899:1999; “Programming languages — C”; <@indicateurl{http://www.open-std.org/jtc1/sc22/WG14/www/docs/n1256.pdf}>

@geindex pool classes; design

@node Pool classes<2>,Mutator context,Nailboards for ambiguously referenced segments,Design
@anchor{design/pool doc}@anchor{775}@anchor{design/pool design-pool}@anchor{776}@anchor{design/pool pool-classes}@anchor{777}
@section Pool classes


@menu
* Introduction: Introduction<25>. 
* Classes and structures:: 
* Fields:: 
* Methods:: 

@end menu

@node Introduction<25>,Classes and structures,,Pool classes<2>
@anchor{design/pool design mps pool}@anchor{778}@anchor{design/pool introduction}@anchor{779}
@subsection Introduction


@anchor{design/pool design mps pool intro}@anchor{77a}@ref{77a,,.intro;} This document describes the interface and protocols between
the MPM and the pool classes.

@node Classes and structures,Fields,Introduction<25>,Pool classes<2>
@anchor{design/pool classes-and-structures}@anchor{77b}
@subsection Classes and structures


@anchor{design/pool design mps pool class}@anchor{77c}@ref{77c,,.class;} Each pool belongs to a `pool class'.

@anchor{design/pool design mps pool class name}@anchor{77d}@ref{77d,,.class.name;} Each pool class has a short, pithy, cryptic name for
the pool class. It should start with @code{"A"} (for “automatic”) if
memory is managed by the garbage collector, and @code{"M"} (for “manual”)
if memory is managed by alloc/free. For example, “AMC”, “MVFF”.

@anchor{design/pool design mps pool class protocol}@anchor{77e}@ref{77e,,.class.protocol;} Pool classes use the `protocol' mechanisms (see
design.mps.protocol@footnote{protocol.html}) to implement class initialization and
inheritance.

@anchor{design/pool design mps pool class structure}@anchor{77f}@ref{77f,,.class.structure;} Each pool class has an associated `class
structure', which is a C object of type @code{PoolClass}. This is
initialized and accessed via the @ref{780,,CLASS()} macro, for example
@code{CLASS(MRGPool)} initializes and accesses the class structure for
the MRG pool class.

@anchor{design/pool design mps pool struct outer}@anchor{781}@ref{781,,.struct.outer;} The `outer structure' of a pool belonging to the ABC
pool class is a C object of type @code{ABCPoolStruct}, which is a typedef
for @code{struct PoolABCStruct}.

@anchor{design/pool design mps pool struct outer sig}@anchor{782}@ref{782,,.struct.outer.sig;} See design.mps.sig.field.end.outer@footnote{sig.txt.html#design.mps.sig.field.end.outer}.

@anchor{design/pool design mps pool struct generic}@anchor{783}@ref{783,,.struct.generic;} The `generic structure' of a pool is a C object of
type @code{PoolStruct} (found embedded in the outer structure), which is
a typedef for @code{struct PoolStruct}.

@node Fields,Methods,Classes and structures,Pool classes<2>
@anchor{design/pool fields}@anchor{784}
@subsection Fields


@anchor{design/pool design mps pool field}@anchor{785}@ref{785,,.field;} These fields are provided by pool classes as part of the
@code{PoolClass} object (see @ref{77f,,.class.structure}). They form part of the
interface which allows the MPM to treat pools in a uniform manner.

@anchor{design/pool design mps pool field name}@anchor{786}@ref{786,,.field.name;} The @code{name} field must be the pool class name
(@ref{77d,,.class.name}).

@anchor{design/pool design mps pool field size}@anchor{787}@ref{787,,.field.size;} The @code{size} field is the size of the pool instance
structure. For the @code{PoolABC} class this can reasonably be expected
to be @code{sizeof(PoolABCStruct)}.

@anchor{design/pool design mps pool field attr}@anchor{788}@ref{788,,.field.attr;} The @code{attr} field must be a bitset of pool class
attributes. See design.mps.type.attr@footnote{type.html#design.mps.type.attr}.

@anchor{design/pool design mps pool field alignShift}@anchor{789}@ref{789,,.field.alignShift;} The @code{alignShift} field is the @code{SizeLog2} of
the pool’s alignment. It is computed and initialised when a pool is
created. Mark-and-sweep pool classes use it to compute the number of
grains in a segment, which is the number of bits need in the segment’s
mark and alloc bit tables.

@anchor{design/pool design mps pool field format}@anchor{78a}@ref{78a,,.field.format;} The @code{format} field is used to refer to the object
format. The object format is passed to the pool during pool creation.

@node Methods,,Fields,Pool classes<2>
@anchor{design/pool methods}@anchor{78b}
@subsection Methods


@anchor{design/pool design mps pool method}@anchor{78c}@ref{78c,,.method;} These methods are provided by pool classes as part of the
@code{PoolClass} object (see @ref{77f,,.class.structure}). They form part of the
interface which allows the MPM to treat pools in a uniform manner.

@anchor{design/pool design mps pool method unused}@anchor{78d}@ref{78d,,.method.unused;} If a pool class is not required to provide a
certain method, the class should assign the appropriate @code{PoolNo}
method (which asserts) for that method to ensure that erroneous calls
are detected. It is not acceptable to use @code{NULL}.

@anchor{design/pool design mps pool method trivial}@anchor{78e}@ref{78e,,.method.trivial;} If a pool class if required to provide a certain
method, but the class provides no special behaviour in this case, it
should assign the appropriate @code{PoolTriv} method, which does nothing.

@anchor{design/pool design mps pool method inst}@anchor{78f}@ref{78f,,.method.inst;} Pool classes may implement the generic instance
methods (see design.mps.protocol.inst.method@footnote{inst.html#design.mps.protocol.inst.method}). In particular:


@itemize -

@item 
@anchor{design/pool design mps pool method inst finish}@anchor{790}@ref{790,,.method.inst.finish;} The @code{finish} method
(design.mps.protocol.inst.method.finish@footnote{inst.html#design.mps.protocol.inst.method.finish}) must finish the outer
structure and then call its superclass method via the
@ref{791,,NextMethod()} macro (thus calling @code{PoolAbsFinish()} which
finishes the generic structure).

@item 
@anchor{design/pool design mps pool method inst describe}@anchor{792}@ref{792,,.method.inst.describe;} The @code{describe} method
(design.mps.protocol.inst.method.describe@footnote{inst.html#design.mps.protocol.inst.method.describe}) should print a
description of the pool. Each line should begin with two spaces.
Classes are not required to provide this method.
@end itemize

@geindex PoolVarargsMethod (C type)
@anchor{design/pool c PoolVarargsMethod}@anchor{793}
@deffn {C Type} typedef void (*PoolVarargsMethod)(ArgStruct args[], va_list varargs)
@end deffn

@anchor{design/pool design mps pool method varargs}@anchor{794}@ref{794,,.method.varargs;} The @code{varargs} field decodes the variable
arguments to the deprecated function @ref{337,,mps_pool_create()} and
converts them to a list of keyword arguments (see
design.mps.keyword-arguments@footnote{keyword-arguments.html}).

@geindex PoolInitMethod (C type)
@anchor{design/pool c PoolInitMethod}@anchor{795}
@deffn {C Type} typedef @ref{55f,,Res} (*PoolInitMethod)(Pool pool, @ref{796,,Arena} arena, PoolClass klass, ArgList args)
@end deffn

@anchor{design/pool design mps pool method init}@anchor{797}@ref{797,,.method.init;} The @code{init} method must call its superclass method
via the @ref{791,,NextMethod()} macro (thus calling @code{PoolAbsInit()} which
initializes the generic structure), and then initialize the outer
structure. It is called via the generic function @code{PoolInit()}.

@geindex PoolAllocMethod (C type)
@anchor{design/pool c PoolAllocMethod}@anchor{798}
@deffn {C Type} typedef @ref{55f,,Res} (*PoolAllocMethod)(@ref{632,,Addr} *pReturn, Pool pool, @ref{40e,,Size} size)
@end deffn

@anchor{design/pool design mps pool method alloc}@anchor{799}@ref{799,,.method.alloc;} The @code{alloc} method manually allocates a block of
at least @code{size} bytes. It should update @code{*pReturn} with a pointer
to a fresh (that is, not overlapping with any other live object)
object of the required size. Failure to allocate must be indicated by
returning an appropriate error code, and in such a case, @code{*pReturn}
must not be updated. Pool classes are not required to provide this
method. It is called via the generic function @code{PoolAlloc()}.

@anchor{design/pool design mps pool method alloc size align}@anchor{79a}@ref{79a,,.method.alloc.size.align;} A pool class may allow an unaligned
@code{size} (rounding it up to the pool’s alignment).

@geindex PoolFreeMethod (C type)
@anchor{design/pool c PoolFreeMethod}@anchor{79b}
@deffn {C Type} typedef void (*PoolFreeMethod)(Pool pool, @ref{632,,Addr} old, @ref{40e,,Size} size)
@end deffn

@anchor{design/pool design mps pool method free}@anchor{79c}@ref{79c,,.method.free;} The @code{free} method manually frees a block. The
parameters are required to correspond to a previous allocation request
(possibly via a buffer, not necessarily via @code{PoolAlloc()}). It is an
assertion by the client that the indicated object is no longer
required and the resources associated with it can be recycled. Pool
classes are not required to provide this method. It is called via the
generic function @code{PoolFree()}.

@anchor{design/pool design mps pool method free size align}@anchor{79d}@ref{79d,,.method.free.size.align;} A pool class may allow an unaligned
@code{size} (rounding it up to the pool’s alignment).

@geindex PoolBufferClassMethod (C type)
@anchor{design/pool c PoolBufferClassMethod}@anchor{79e}
@deffn {C Type} typedef BufferClass (*PoolBufferClassMethod)(void)
@end deffn

@anchor{design/pool design mps pool method bufferClass}@anchor{79f}@ref{79f,,.method.bufferClass;} The @code{bufferClass} method returns the class
of buffers used by the pool. Pool classes are not required to provide
this method. It is called via the generic function
@code{PoolDefaultBufferClass()}.

@geindex PoolBufferFillMethod (C type)
@anchor{design/pool c PoolBufferFillMethod}@anchor{7a0}
@deffn {C Type} typedef @ref{55f,,Res} (*PoolBufferFillMethod)(@ref{632,,Addr} *baseReturn, @ref{632,,Addr} *limitReturn, Pool pool, Buffer buffer, @ref{40e,,Size} size)
@end deffn

@anchor{design/pool design mps pool method bufferFill}@anchor{7a1}@ref{7a1,,.method.bufferFill;} The @code{bufferFill} method should allocate a
region of least @code{size} bytes of memory for attaching to @code{buffer}.
The buffer is in the “reset” state (see design.mps.buffer.reset@footnote{buffer.html#design.mps.buffer.reset}). If
successful, it must update @code{*baseReturn} and @code{*limitReturn} to the
base and limit of the allocated region and return @code{ResOK}. Otherwise
it must leave @code{*baseReturn} and @code{*limitReturn} unchanged and
return a non-OK result code. Pool classes are not required to provide
this method. This method is called by @ref{7a2,,BufferFill()}.

@geindex PoolBufferEmptyMethod (C type)
@anchor{design/pool c PoolBufferEmptyMethod}@anchor{7a3}
@deffn {C Type} typedef void (*PoolBufferEmptyMethod)(Pool pool, Buffer buffer)
@end deffn

@anchor{design/pool design mps pool method bufferEmpty}@anchor{7a4}@ref{7a4,,.method.bufferEmpty;} The @code{bufferEmpty} method indicates that the
client program has finished with the unused part of the buffer (the
part between init and limit). The buffer is in the “ready” state (see
design.mps.buffer.ready@footnote{buffer.html#design.mps.buffer.ready}). This method must be provided if and only if
@code{bufferFill} is provided. This method is called by the generic
function @ref{7a5,,BufferDetach()}.

@geindex PoolSizeMethod (C type)
@anchor{design/pool c PoolSizeMethod}@anchor{7a6}
@deffn {C Type} typedef @ref{40e,,Size} (*PoolSizeMethod)(Pool pool)
@end deffn

@anchor{design/pool design mps pool method totalSize}@anchor{7a7}@ref{7a7,,.method.totalSize;} The @code{totalSize} method must return the total
memory allocated from the arena and managed by the pool. This method
is called by the generic function @code{PoolTotalSize()}.

@anchor{design/pool design mps pool method freeSize}@anchor{7a8}@ref{7a8,,.method.freeSize;} The @code{freeSize} method must return the free
memory allocated from the arena and managed by the pool, but not in
use by the client program. This method is called by the generic
function @code{PoolFreeSize()}.

@geindex mutator context; design

@node Mutator context,Memory protection,Pool classes<2>,Design
@anchor{design/prmc doc}@anchor{7a9}@anchor{design/prmc design-prmc}@anchor{30d}@anchor{design/prmc mutator-context}@anchor{7aa}
@section Mutator context


@menu
* Introduction: Introduction<26>. 
* Requirements: Requirements<16>. 
* Interface: Interface<10>. 
* Implementations: Implementations<2>. 

@end menu

@node Introduction<26>,Requirements<16>,,Mutator context
@anchor{design/prmc design mps prmc}@anchor{7ab}@anchor{design/prmc introduction}@anchor{7ac}
@subsection Introduction


@anchor{design/prmc design mps prmc intro}@anchor{7ad}@ref{7ad,,.intro;} This is the design of the mutator context module.

@anchor{design/prmc design mps prmc readership}@anchor{7ae}@ref{7ae,,.readership;} Any MPS developer; anyone porting the MPS to a new
platform.

@anchor{design/prmc design mps prmc overview}@anchor{7af}@ref{7af,,.overview;} The mutator context module decodes the `context' of a
mutator thread at the point when it caused a protection fault, so that
access to a protected region of memory can be handled, or when it was
suspended by the thread manager, so that its registers and control
stack can be scanned.

@anchor{design/prmc design mps prmc def context}@anchor{7b0}@ref{7b0,,.def.context;} The `context' of a thread (also called its
`continuation') is an abstract representation of the control state of
the thread at a point in time, including enough information to
continue the thread from that point.

@anchor{design/prmc design mps prmc status}@anchor{7b1}@ref{7b1,,.status;} The mutator context module does not currently present a
clean interface to the rest of the MPS: source files are
inconsistently named, and the implementation is (necessarily) mixed up
with the implementation of the memory protection module
(design.mps.prot@footnote{prot.html}) and the thread manager
(design.mps.thread-manager@footnote{thread-manager.html}).

@node Requirements<16>,Interface<10>,Introduction<26>,Mutator context
@anchor{design/prmc design-mps-thread-manager}@anchor{7b2}@anchor{design/prmc requirements}@anchor{7b3}
@subsection Requirements


@anchor{design/prmc design mps prmc req fault addr}@anchor{7b4}@ref{7b4,,.req.fault.addr;} Must determine the address that the mutator was
trying to access when it caused a protection fault. (Without this
address the MPS can’t handle the fault. See @code{ArenaAccess()}.)

@anchor{design/prmc design mps prmc req fault access}@anchor{7b5}@ref{7b5,,.req.fault.access;} Should determine whether the mutator was trying
to read or write the address when it caused a protection fault. (This
enables a performance improvement in the case of a write fault. A read
fault must be handled by ensuring the address pointed to has been
fixed, which may require scanning the segment, whereas a write fault
merely requires that the segment’s summary be discarded. See
@code{TraceSegAccess()}.)

@anchor{design/prmc design mps prmc req fault step}@anchor{7b6}@ref{7b6,,.req.fault.step;} Should be able to emulate the access that caused
the fault. (This enables a significant performance improvement for
weak hash tables. See request.dylan.160044@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/dylan/160044/}.)

@anchor{design/prmc design mps prmc req suspend scan}@anchor{7b7}@ref{7b7,,.req.suspend.scan;} Must capture enough information to ambiguously
scan all roots in the context of a thread that has been suspended by
the thread manager. (This is necessary for conservative garbage
collection to work. See design.mps.thread-manager.if.scan@footnote{thread-manager.html#design.mps.thread-manager.if.scan}.)

@node Interface<10>,Implementations<2>,Requirements<16>,Mutator context
@anchor{design/prmc design-mps-thread-manager-if-scan}@anchor{7b8}@anchor{design/prmc interface}@anchor{7b9}
@subsection Interface


@geindex MutatorContextVar (C type)
@anchor{design/prmc c MutatorContextVar}@anchor{7ba}
@deffn {C Type} typedef unsigned MutatorContextVar
@end deffn

@anchor{design/prmc design mps prmc if var}@anchor{7bb}@ref{7bb,,.if.var;} The type @ref{7ba,,MutatorContextVar} is the type of the
discriminator for the union within @code{MutatorContextStruct}:


@multitable {xxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Value

@tab

Description

@item

@code{MutatorContextFAULT}

@tab

Context of thread stopped by a protection fault.

@item

@code{MutatorContextTHREAD}

@tab

Context of thread stopped by the thread manager.

@end multitable


@geindex MutatorContext (C type)
@anchor{design/prmc c MutatorContext}@anchor{7bc}
@deffn {C Type} typedef MutatorContextStruct *MutatorContext
@end deffn

@anchor{design/prmc design mps prmc if context}@anchor{7bd}@ref{7bd,,.if.context;} A structure representing the context of the mutator at
the point when a protection fault occurred, or when it was suspended
by the thread manager. This structure should be declared in a header
so that it can be inlined in the @ref{7be,,Thread} structure if necessary.
See design.mps.thread-manager.if.thread@footnote{thread-manager.html#design.mps.thread-manager.if.thread}.

@geindex MutatorContextCheck (C function)
@anchor{design/prmc c MutatorContextCheck}@anchor{7bf}
@deffn {C Function} @ref{3a9,,Bool} MutatorContextCheck (MutatorContext context)
@end deffn

@anchor{design/prmc design mps prmc if check}@anchor{7c0}@ref{7c0,,.if.check;} The check function for mutator contexts. See
design.mps.check@footnote{check.html}.

@geindex MutatorContextInitFault (C function)
@anchor{design/prmc c MutatorContextInitFault}@anchor{7c1}
@deffn {C Function} @ref{55f,,Res} MutatorContextInitFault (MutatorContext context, ...)
@end deffn

@anchor{design/prmc design mps prmc if init fault}@anchor{7c2}@ref{7c2,,.if.init.fault;} Initialize with the context of the mutator at the
point where it was stopped by a protection fault. The arguments are
platform-specific and the return may be @code{void} instead of @ref{55f,,Res} if
this always succeeds.

@geindex MutatorContextInitThread (C function)
@anchor{design/prmc c MutatorContextInitThread}@anchor{7c3}
@deffn {C Function} @ref{55f,,Res} MutatorContextInitThread (MutatorContext context, ...)
@end deffn

@anchor{design/prmc design mps prmc if init thread}@anchor{7c4}@ref{7c4,,.if.init.thread;} Initialize with the context of the mutator at the
point where it was suspended by the thread manager. The arguments are
platform-specific and the return may be @code{void} instead of @ref{55f,,Res} if
this always succeeds.

@geindex MutatorContextCanStepInstruction (C function)
@anchor{design/prmc c MutatorContextCanStepInstruction}@anchor{7c5}
@deffn {C Function} @ref{3a9,,Bool} MutatorContextCanStepInstruction (MutatorContext context)
@end deffn

@anchor{design/prmc design mps prmc if canstep}@anchor{7c6}@ref{7c6,,.if.canstep;} Examine the context to determine whether the
protection module can single-step the instruction which is causing the
fault. Return @code{TRUE} if @ref{7c7,,MutatorContextStepInstruction()} is
capable of single-stepping the instruction, or @code{FALSE} if not.

@geindex MutatorContextStepInstruction (C function)
@anchor{design/prmc c MutatorContextStepInstruction}@anchor{7c7}
@deffn {C Function} @ref{55f,,Res} MutatorContextStepInstruction (MutatorContext context)
@end deffn

@anchor{design/prmc design mps prmc if step}@anchor{7c8}@ref{7c8,,.if.step;} Single-step the instruction which is causing the fault.
Update the mutator context according to the emulation or execution of
the instruction, so that resuming the mutator will not cause the
instruction which was caused the fault to be re-executed. Return
@code{ResOK} if the instruction was single-stepped successfully, or
@code{ResUNIMPL} if the instruction cannot be single-stepped.

This function is only called if
@code{MutatorContextCanStepInstruction(context)} returned @code{TRUE}.

@geindex MutatorContextScan (C function)
@anchor{design/prmc c MutatorContextScan}@anchor{7c9}
@deffn {C Function} @ref{55f,,Res} MutatorContextScan (ScanState ss, MutatorContext context, mps_area_scan_t scan, void *closure)
@end deffn

@anchor{design/prmc design mps prmc if context scan}@anchor{7ca}@ref{7ca,,.if.context.scan;} Scan all roots found in @code{context} using the
given scan state by calling @code{scan}, and return the result code from
the scanner.

@geindex MutatorContextSP (C function)
@anchor{design/prmc c MutatorContextSP}@anchor{7cb}
@deffn {C Function} @ref{632,,Addr} MutatorContextSP (MutatorContext context)
@end deffn

@anchor{design/prmc design mps prmc if context sp}@anchor{7cc}@ref{7cc,,.if.context.sp;} Return the pointer to the “top” of the thread’s
stack at the point given by @code{context}. In the common case, where the
stack grows downwards, this is actually the lowest stack address.

@node Implementations<2>,,Interface<10>,Mutator context
@anchor{design/prmc implementations}@anchor{7cd}
@subsection Implementations


@menu
* Generic implementation:: 
* Posix implementation:: 
* Windows implementation:: 
* macOS implementation:: 

@end menu

@node Generic implementation,Posix implementation,,Implementations<2>
@anchor{design/prmc generic-implementation}@anchor{7ce}
@subsubsection Generic implementation


@anchor{design/prmc design mps prmc impl an}@anchor{7cf}@ref{7cf,,.impl.an;} In @code{prmcan.c} and @code{prmcanan.c}.

@anchor{design/prmc design mps prmc impl an context}@anchor{7d0}@ref{7d0,,.impl.an.context;} There is no definition of
@code{MutatorContextStruct} and so the mutator context cannot be decoded.

@anchor{design/prmc design mps prmc impl an fault}@anchor{7d1}@ref{7d1,,.impl.an.fault;} Compatible only with the generic memory protection
module (design.mps.prot.impl.an@footnote{prot.html#design.mps.prot.impl.an}) where there are no protection
faults.

@anchor{design/prmc design mps prmc impl an suspend}@anchor{7d2}@ref{7d2,,.impl.an.suspend;} Compatible only with the generic thread manager
module (design.mps.thread-manager.impl.an@footnote{thread-manager.html#design.mps.thread-manager.impl.an}) where there is only one
thread, and so no threads are suspended.

@node Posix implementation,Windows implementation,Generic implementation,Implementations<2>
@anchor{design/prmc design-mps-thread-manager-impl-an}@anchor{7d3}@anchor{design/prmc posix-implementation}@anchor{7d4}
@subsubsection Posix implementation


@anchor{design/prmc design mps prmc impl ix}@anchor{7d5}@ref{7d5,,.impl.ix;} In @code{prmcix.c} and @code{protsgix.c}, with
processor-specific parts in @code{prmci3.c} and @code{prmci6.c}, and other
platform-specific parts in @code{prmcfri3.c}, @code{prmcfri6.c},
@code{prmclia6.c}, @code{prmclii3.c}, and @code{prmclii6.c}.

@anchor{design/prmc design mps prmc impl ix context}@anchor{7d6}@ref{7d6,,.impl.ix.context;} The context consists of the siginfo_t@footnote{https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/signal.h.html} and
ucontext_t@footnote{https://pubs.opengroup.org/onlinepubs/9699919799/functions/sigaction.html} structures. POSIX specifies some of the fields in
@code{siginfo_t}, but says nothing about the contents of @code{ucontext_t}.
This is decoded on a platform-by-platform basis.

@anchor{design/prmc design mps prmc impl ix fault signal}@anchor{7d7}@ref{7d7,,.impl.ix.fault.signal;} POSIX specifies that “Invalid permissions
for mapped object” (a protection fault) causes a @code{SEGV} signal.

@anchor{design/prmc design mps prmc impl ix fault code}@anchor{7d8}@ref{7d8,,.impl.ix.fault.code;} POSIX specifies that “Invalid permissions for
mapped object” (a protection fault) causes @code{siginfo_t.si_code} to be
set to @code{SEGV_ACCERR}.

@anchor{design/prmc design mps prmc impl ix fault addr}@anchor{7d9}@ref{7d9,,.impl.ix.fault.addr;} POSIX specifies that @code{siginfo_t.si_addr} is
the address that the faulting instruction was attempting to access.

@anchor{design/prmc design mps prmc impl ix fault mode}@anchor{7da}@ref{7da,,.impl.ix.fault.mode;} This implementation does not attempt to
determine whether the fault was a read or write.

@anchor{design/prmc design mps prmc impl ix fault step}@anchor{7db}@ref{7db,,.impl.ix.fault.step;} This is implemented only on IA-32, and only
for “simple MOV” instructions.

@anchor{design/prmc design mps prmc impl ix suspend}@anchor{7dc}@ref{7dc,,.impl.ix.suspend;} @ref{7dd,,PThreadextSuspend()} records the context of
each suspended thread, and @ref{7de,,ThreadRingSuspend()} stores this in the
@ref{7be,,Thread} structure.

@anchor{design/prmc design mps prmc impl ix context scan}@anchor{7df}@ref{7df,,.impl.ix.context.scan;} The context’s root registers are found in
the @code{ucontext_t.uc_mcontext} structure.

@anchor{design/prmc design mps prmc impl ix context sp}@anchor{7e0}@ref{7e0,,.impl.ix.context.sp;} The stack pointer is obtained from
@code{ucontext_t.uc_mcontext.mc_esp} (FreeBSD on IA-32),
@code{uc_mcontext.gregs[REG_ESP]} (Linux on IA-32),
@code{ucontext_t.uc_mcontext.mc_rsp} (FreeBSD on x86-64), or
@code{uc_mcontext.gregs[REG_RSP]} (Linux on x86-64).

@node Windows implementation,macOS implementation,Posix implementation,Implementations<2>
@anchor{design/prmc windows-implementation}@anchor{7e1}
@subsubsection Windows implementation


@anchor{design/prmc design mps prmc impl w3}@anchor{7e2}@ref{7e2,,.impl.w3;} In @code{prmcw3.c}, with processor-specific parts in
@code{prmci3.c}, @code{prmci6.c}, and other platform-specific parts in
@code{prmcw3i3.c} and @code{prmcw3i6.c}.

@anchor{design/prmc design mps prmc impl w3 context}@anchor{7e3}@ref{7e3,,.impl.w3.context;} The context of a thread that hit a protection
fault is given by the EXCEPTION_POINTERS@footnote{https://docs.microsoft.com/en-gb/windows/desktop/api/winnt/ns-winnt-_exception_pointers} structure passed to a
vectored exception handler, which points to EXCEPTION_RECORD@footnote{https://docs.microsoft.com/en-gb/windows/desktop/api/winnt/ns-winnt-_exception_record} and
CONTEXT@footnote{https://docs.microsoft.com/en-gb/windows/desktop/api/winnt/ns-winnt-_exception_record} structures.

@anchor{design/prmc design mps prmc impl w3 fault addr}@anchor{7e4}@ref{7e4,,.impl.w3.fault.addr;} @code{EXCEPTION_RECORD.ExceptionAddress} is the
address that the faulting instruction was trying to access.

@anchor{design/prmc design mps prmc impl w3 fault mode}@anchor{7e5}@ref{7e5,,.impl.w3.fault.mode;} @code{EXCEPTION_RECORD.ExceptionInformation[0]}
is 0 for a read fault, 1 for a write fault, and 8 for an execute
fault (which we handle as a read fault).

@anchor{design/prmc design mps prmc impl w3 fault step}@anchor{7e6}@ref{7e6,,.impl.w3.fault.step;} This is implemented only on IA-32, and only
for “simple MOV” instructions.

@anchor{design/prmc design mps prmc impl w3 suspend}@anchor{7e7}@ref{7e7,,.impl.w3.suspend;} The context of a suspended thread is returned by
GetThreadContext()@footnote{https://docs.microsoft.com/en-us/windows/desktop/api/processthreadsapi/nf-processthreadsapi-getthreadcontext}.

@anchor{design/prmc design mps prmc impl w3 context scan}@anchor{7e8}@ref{7e8,,.impl.w3.context.scan;} The context’s root registers are found in
the CONTEXT@footnote{https://docs.microsoft.com/en-gb/windows/desktop/api/winnt/ns-winnt-_exception_record} structure.

@anchor{design/prmc design mps prmc impl w3 context sp}@anchor{7e9}@ref{7e9,,.impl.w3.context.sp;} The stack pointer is obtained from
@code{CONTEXT.Esp} (on IA-32) or @code{CONTEXT.Rsp} (on x86-64).

@node macOS implementation,,Windows implementation,Implementations<2>
@anchor{design/prmc macos-implementation}@anchor{7ea}
@subsubsection macOS implementation


@anchor{design/prmc design mps prmc impl xc}@anchor{7eb}@ref{7eb,,.impl.xc;} In @code{prmcix.c} and @code{prmcxc.c}, with processor-specific
parts in @code{prmci3.c} and @code{prmci6.c}, and other platform-specific
parts in @code{prmcxca6.c}, @code{prmcxci3.c} and @code{prmcxci6.c}.

@anchor{design/prmc design mps prmc impl xc context}@anchor{7ec}@ref{7ec,,.impl.xc.context;} The context consists of the
@code{__Request__mach_exception_raise_state_identity_t} and
@code{arm_thread_state_t}, @code{x86_thread_state32_t} or
@code{x86_thread_state64_t} structures. There doesn’t seem to be any
documentation for these structures, but they are defined in the Mach
headers.

@anchor{design/prmc design mps prmc impl xc fault addr}@anchor{7ed}@ref{7ed,,.impl.xc.fault.addr;} @code{__Request__mach_exception_raise_state_identity_t.code[1]} is the
address that the faulting instruction was trying to access.

@anchor{design/prmc design mps prmc impl xc fault mode}@anchor{7ee}@ref{7ee,,.impl.xc.fault.mode;} This implementation does not attempt to
determine whether the fault was a read or write.

@anchor{design/prmc design mps prmc impl xc fault step}@anchor{7ef}@ref{7ef,,.impl.xc.fault.step;} This is implemented only on IA-32, and only
for “simple MOV” instructions.

@anchor{design/prmc design mps prmc impl xc suspend}@anchor{7f0}@ref{7f0,,.impl.xc.suspend;} The context of a suspended thread is obtained by
calling thread_get_state()@footnote{https://www.gnu.org/software/hurd/gnumach-doc/Thread-Execution.html}.

@anchor{design/prmc design mps prmc impl xc context scan}@anchor{7f1}@ref{7f1,,.impl.xc.context.scan;} The thread’s registers are found in the
@code{arm_thread_state64_t}, @code{x86_thread_state32_t} or
@code{x86_thread_state64_t} structure.

@anchor{design/prmc design mps prmc impl xc context sp}@anchor{7f2}@ref{7f2,,.impl.xc.context.sp;} The stack pointer is obtained using the
@code{arm_thread_state64_get_sp()} macro (on ARM64), or from
@code{x86_thread_state32_t.__esp} (on IA-32) or
@code{x86_thread_state64_t.__rsp} (on x86-64).

@geindex memory protection; design

@node Memory protection,POSIX implementation of protection module,Mutator context,Design
@anchor{design/prot doc}@anchor{7f3}@anchor{design/prot design-prot}@anchor{30b}@anchor{design/prot memory-protection}@anchor{7f4}
@section Memory protection


@menu
* Introduction: Introduction<27>. 
* Requirements: Requirements<17>. 
* Design: Design<4>. 
* Interface: Interface<11>. 
* Implementations: Implementations<3>. 

@end menu

@node Introduction<27>,Requirements<17>,,Memory protection
@anchor{design/prot design mps prot}@anchor{7f5}@anchor{design/prot introduction}@anchor{7f6}
@subsection Introduction


@anchor{design/prot design mps prot intro}@anchor{7f7}@ref{7f7,,.intro;} This is the design of the memory protection module.

@anchor{design/prot design mps prot readership}@anchor{7f8}@ref{7f8,,.readership;} Any MPS developer; anyone porting the MPS to a new
platform.

@anchor{design/prot design mps prot overview}@anchor{7f9}@ref{7f9,,.overview;} The memory protection module ensures that the mutator
sees a consistent view of memory during incremental collection, by
applying protection to areas of memory, ensuring that attempts to read
or write from those areas cause protection faults, and implementing
the means for the MPS to handle these faults.

@node Requirements<17>,Design<4>,Introduction<27>,Memory protection
@anchor{design/prot requirements}@anchor{7fa}
@subsection Requirements


@anchor{design/prot design mps prot req consistent}@anchor{7fb}@ref{7fb,,.req.consistent;} Must ensure that the mutator sees a consistent
view of memory during incremental collection: in particular, the
mutator must never see objects in oldspace. (Otherwise there’s no way
for the MPS to interface with uncooperative code.)

@anchor{design/prot design mps prot req prot read}@anchor{7fc}@ref{7fc,,.req.prot.read;} Should allow collections to proceed incrementally,
by read-protecting pages that are not consistent from the mutator’s
point of view. (This is the only way for the MPS to meet real-time
requirements on pause times.)

@anchor{design/prot design mps prot req prot write}@anchor{7fd}@ref{7fd,,.req.prot.write;} Should allow the MPS to maintain remembered sets
for segments that it has scanned, by write-protecting pages in these
segments. (This improves performance by allowing the MPS to avoid
scanning these segments again.)

@anchor{design/prot design mps prot req fault handle}@anchor{7fe}@ref{7fe,,.req.fault.handle;} If the module implements protection, it must
also provide a mechanism for handling protection faults. (Otherwise
the MPS cannot take the correct action: that is, fixing references in
a read-protected segment, and discarding the remembered set from a
write-protected segment. See @code{TraceSegAccess()}.)

@anchor{design/prot design mps prot req prot exec}@anchor{7ff}@ref{7ff,,.req.prot.exec;} The protection module should allow mutators to
write machine code into memory managed by the MPS and then execute
that code, for example, to implement just-in-time translation, or
other forms of dynamic compilation. Compare
design.mps.vm.req.prot.exec@footnote{vm.html#design.mps.vm.req.prot.exec}.

@node Design<4>,Interface<11>,Requirements<17>,Memory protection
@anchor{design/prot design}@anchor{800}@anchor{design/prot design-mps-vm-req-prot-exec}@anchor{801}
@subsection Design


@anchor{design/prot design mps prot sol sync}@anchor{802}@ref{802,,.sol.sync;} If memory protection is not available, the only way to
meet @ref{7fb,,.req.consistent} is to ensure that no protection is required,
by running the collector until it has no more incremental work to do.
(This makes it impossible to meet real-time requirements on pause
times, but may be the best that can be done.)

@anchor{design/prot design mps prot sol fault handle}@anchor{803}@ref{803,,.sol.fault.handle;} The protection module handles protection faults
by decoding the context of the fault (see
design.mps.prmc.req.fault.addr@footnote{prmc.html#design.mps.prmc.req.fault.addr} and design.mps.prmc.req.fault.access@footnote{prmc.html#design.mps.prmc.req.fault.access})
and calling @code{ArenaAccess()}.

@anchor{design/prot design mps prot sol prot exec}@anchor{804}@ref{804,,.sol.prot.exec;} The protection module makes memory executable
whenever it is readable by the mutator, if this is supported by the
platform.

@node Interface<11>,Implementations<3>,Design<4>,Memory protection
@anchor{design/prot interface}@anchor{805}
@subsection Interface


@geindex ProtSetup (C function)
@anchor{design/prot c ProtSetup}@anchor{806}
@deffn {C Function} void ProtSetup (void)
@end deffn

@anchor{design/prot design mps prot if setup}@anchor{807}@ref{807,,.if.setup;} Called exactly once (per process) as part of the
initialization of the first arena that is created. It must arrange for
the setup and initialization of any data structures or services that
are necessary in order to implement the memory protection module.

@geindex ProtGranularity (C function)
@anchor{design/prot c ProtGranularity}@anchor{808}
@deffn {C Function} @ref{40e,,Size} ProtGranularity (void)
@end deffn

@anchor{design/prot design mps prot if granularity}@anchor{809}@ref{809,,.if.granularity;} Return the granularity of protection. The @code{base}
and @code{limit} arguments to @ref{80a,,ProtSet()} must be multiples of the
protection granularity.

@geindex ProtSet (C function)
@anchor{design/prot c ProtSet}@anchor{80a}
@deffn {C Function} void ProtSet (Addr base, Addr limit, AccessSet mode)
@end deffn

@anchor{design/prot design mps prot if set}@anchor{80b}@ref{80b,,.if.set;} Set the protection of the range of memory between @code{base}
(inclusive) and @code{limit} (exclusive) to `forbid' the specified modes.
The addresses @code{base} and @code{limit} are multiples of the protection
granularity. The @code{mode} parameter contains the @code{AccessWRITE} bit
if write accesses to the range are to be forbidden, and contains the
@code{AccessREAD} bit if read accesses to the range are to be forbidden.

@anchor{design/prot design mps prot if set read}@anchor{80c}@ref{80c,,.if.set.read;} If the request is to forbid read accesses (that is,
@code{AccessREAD} is set) then the implementation may also forbid write
accesses, but read accesses must not be forbidden unless
@code{AccessREAD} is set.

@anchor{design/prot design mps prot if set noop}@anchor{80d}@ref{80d,,.if.set.noop;} @ref{80a,,ProtSet()} is permitted to be a no-op if
@ref{3c6,,ProtSync()} is implemented.

@geindex ProtSync (C function)
@anchor{design/prot c ProtSync}@anchor{3c6}
@deffn {C Function} void ProtSync (Arena arena)
@end deffn

@anchor{design/prot design mps prot if sync}@anchor{80e}@ref{80e,,.if.sync;} Ensure that the actual protection (as determined by the
operating system) of every segment in the arena matches the segment’s
protection mode (@code{seg->pm}).

@anchor{design/prot design mps prot if sync noop}@anchor{80f}@ref{80f,,.if.sync.noop;} @ref{3c6,,ProtSync()} is permitted to be a no-op if
@ref{80a,,ProtSet()} is implemented.

@node Implementations<3>,,Interface<11>,Memory protection
@anchor{design/prot implementations}@anchor{810}
@subsection Implementations


@anchor{design/prot design mps prot impl an}@anchor{811}@ref{811,,.impl.an;} Generic implementation in @code{protan.c}.

@anchor{design/prot design mps prot impl an set}@anchor{812}@ref{812,,.impl.an.set;} @ref{80a,,ProtSet()} does nothing.

@anchor{design/prot design mps prot impl an sync}@anchor{813}@ref{813,,.impl.an.sync;} @ref{3c6,,ProtSync()} has no way of changing the protection
of a segment, so it simulates faults on all segments that are supposed
to be protected, by calling @code{TraceSegAccess()}, until it determines
that no segments require protection any more. This forces the trace to
proceed until it is completed, preventing incremental collection.

@anchor{design/prot design mps prot impl an sync issue}@anchor{814}@ref{814,,.impl.an.sync.issue;} This relies on the pool actually removing the
protection, otherwise there is an infinite loop here. This is
therefore not compatible with implementations of the protection
mutator context module that support single-stepping of accesses (see design.mps.prmc.req.fault.step@footnote{prmc.html#design.mps.prmc.req.fault.step}).

@anchor{design/prot design mps prot impl ix}@anchor{815}@ref{815,,.impl.ix;} POSIX implementation. See design.mps.protix@footnote{protix.html}.

@anchor{design/prot design mps prot impl w3}@anchor{816}@ref{816,,.impl.w3;} Windows implementation.

@anchor{design/prot design mps prot impl xc}@anchor{817}@ref{817,,.impl.xc;} macOS implementation.

@anchor{design/prot design mps prot impl xc prot exec}@anchor{818}@ref{818,,.impl.xc.prot.exec;} The approach in @ref{804,,.sol.prot.exec} of always
making memory executable causes a difficulty on macOS on Apple
Silicon. On this platform, programs may enable Hardened Runtime@footnote{https://developer.apple.com/documentation/security/hardened_runtime}.
This feature rejects attempts to map or protect memory so that it is
simultaneously writable and executable. Moreover, the feature is
enabled by default (as of macOS 13 Ventura), so that if you install
Xcode and then use it to compile the following program, the executable
fails when run with “mmap: Permission denied”.

@example
#include <stdio.h>
#include <sys/mman.h>

int main(void)
@{
  void *p = mmap(0, 1, PROT_WRITE | PROT_EXEC, MAP_ANONYMOUS | MAP_PRIVATE, -1, 0);
  if (p == MAP_FAILED) perror("mmap");
  return 0;
@}
@end example

@anchor{design/prot design mps prot impl xc prot exec detect}@anchor{819}@ref{819,,.impl.xc.prot.exec.detect;} The protection module detects Hardened
Runtime if the operating system is macOS, the CPU architecture is
ARM64, a call to @code{mprotect()} fails, the call requested writable and
executable access, and the error code is @code{EACCES}.

@anchor{design/prot design mps prot impl xc prot exec retry}@anchor{81a}@ref{81a,,.impl.xc.prot.exec.retry;} To avoid requiring developers who don’t
need to allocate executable memory to figure out how to disable
Hardened Runtime, or enable the appropriate entitlement, the
protection module handles the @code{EACCES} error from @code{mprotect()} in
the Hardened Runtime case by retrying without the request for the
memory to be executable, and setting a global variable to prevent the
writable and executable combination being attempted again.

@geindex POSIX; protection interface design
@geindex POSIX protection interface; design

@node POSIX implementation of protection module,Ranges of addresses,Memory protection,Design
@anchor{design/protix doc}@anchor{81b}@anchor{design/protix design-protix}@anchor{81c}@anchor{design/protix posix-implementation-of-protection-module}@anchor{81d}
@section POSIX implementation of protection module


@menu
* Introduction: Introduction<28>. 
* Requirements: Requirements<18>. 
* Data structures:: 
* Functions: Functions<4>. 
* Threads: Threads<3>. 

@end menu

@node Introduction<28>,Requirements<18>,,POSIX implementation of protection module
@anchor{design/protix design mps protix}@anchor{81e}@anchor{design/protix introduction}@anchor{81f}
@subsection Introduction


@anchor{design/protix design mps protix readership}@anchor{820}@ref{820,,.readership;} Any MPS developer

@anchor{design/protix design mps protix intro}@anchor{821}@ref{821,,.intro;} This is the design of the POSIX implementation of the
protection module. It makes use of various services provided by POSIX.
It is intended to work with POSIX Threads.

@node Requirements<18>,Data structures,Introduction<28>,POSIX implementation of protection module
@anchor{design/protix requirements}@anchor{822}
@subsection Requirements


@anchor{design/protix design mps protix req general}@anchor{823}@ref{823,,.req.general;} Required to implement the general protection
interface defined in design.mps.prot.if@footnote{prot.html#design.mps.prot.if}.

@node Data structures,Functions<4>,Requirements<18>,POSIX implementation of protection module
@anchor{design/protix data-structures}@anchor{824}@anchor{design/protix design-mps-prot-if}@anchor{825}
@subsection Data structures


@anchor{design/protix design mps protix data signext}@anchor{826}@ref{826,,.data.signext;} If the SIGSEGV signal is not handled by any MPS
arena, @code{sigHandle()} needs to forward the signal to the next signal
handler in the chain (the signal handler that was installed when the
@ref{806,,ProtSetup()} was called), by temporarily reinstalling the old
signal handler and calling @code{kill()}. The only way to pass the next
signal handler to the current signal handler is via a global variable,
in this case the variable @code{sigNext}.

@node Functions<4>,Threads<3>,Data structures,POSIX implementation of protection module
@anchor{design/protix functions}@anchor{827}
@subsection Functions


@anchor{design/protix design mps protix fun setup}@anchor{828}@ref{828,,.fun.setup;} @ref{806,,ProtSetup()} installs a signal handler for the
signal @code{SIGSEGV} to catch and handle protection faults (this handler
is the function @code{sigHandle()}).

@anchor{design/protix design mps protix fun setup previous}@anchor{829}@ref{829,,.fun.setup.previous;} The previous handler is recorded (in the
variable @code{sigNext}, see @ref{826,,.data.signext}) so that it can be reached
from @code{sigHandle()} if it fails to handle the fault.

@anchor{design/protix design mps protix fun setup restart}@anchor{82a}@ref{82a,,.fun.setup.restart;} We set the @code{SA_RESTART} flag when installing
the signal handler so that if the mutator gets a protection fault
while blocked in a system call, the system call is automatically
restarted after the signal is handled, instead of failing with
@code{EINTR}. Note that unlike the corresponding case in the thread
management subsystem (see design.mps.thread-manager.req.thread.intr@footnote{thread-manager.html#design.mps.thread-manager.req.thread.intr})
we are unsure if this case can actually arise: the @code{SIGSEGV} from a
protection fault is delivered to the thread that accessed the
protected memory, but in all the cases we have checked, if this access
occurred during a blocking system call such as a @code{read()} with the
buffer in protected memory, the system call fails with @code{EFAULT} and
is not restarted. However, it costs us nothing to set the
@code{SA_RESTART} flag.

@anchor{design/protix design mps protix fun set}@anchor{82b}@ref{82b,,.fun.set;} @ref{80a,,ProtSet()} uses @code{mprotect()} to adjust the
protection for pages.

@anchor{design/protix design mps protix fun set convert}@anchor{82c}@ref{82c,,.fun.set.convert;} The requested protection (which is expressed in
the @code{mode} parameter, see design.mps.prot.if.set@footnote{prot.html#design.mps.prot.if.set}) is translated into
an operating system protection. If read accesses are to be forbidden
then all accesses are forbidden, this is done by setting the
protection of the page to @code{PROT_NONE}. If write accesses are to be
forbidden (and not read accesses) then write accesses are forbidden
and read accesses are allowed, this is done by setting the protection
of the page to @code{PROT_READ|PROT_EXEC}. Otherwise (all access are
okay), the protection is set to @code{PROT_READ|PROT_WRITE|PROT_EXEC}.

@anchor{design/protix design mps protix fun set assume mprotect}@anchor{82d}@ref{82d,,.fun.set.assume.mprotect;} We assume that the call to @code{mprotect()}
always succeeds.  We should always call the function with valid
arguments (aligned, references to mapped pages, and with an access
that is compatible with the access of the underlying object).

@anchor{design/protix design mps protix fun sync}@anchor{82e}@ref{82e,,.fun.sync;} @ref{3c6,,ProtSync()} does nothing in this implementation as
@ref{80a,,ProtSet()} sets the protection without any delay.

@node Threads<3>,,Functions<4>,POSIX implementation of protection module
@anchor{design/protix threads}@anchor{82f}
@subsection Threads


@anchor{design/protix design mps protix threads}@anchor{830}@ref{830,,.threads;} The design must operate in a multi-threaded environment
(with POSIX Threads) and cooperate with the POSIX support for locks
(see design.mps.lock@footnote{lock.html}) and the thread suspension mechanism (see
design.mps.pthreadext@footnote{pthreadext.html} ).

@anchor{design/protix design mps protix threads suspend}@anchor{831}@ref{831,,.threads.suspend;} The @code{SIGSEGV} signal handler does not mask out
any signals, so a thread may be suspended while the handler is active,
as required by the design (see
design.mps.pthreadext.req.suspend.protection@footnote{pthreadext.html#design.mps.pthreadext.req.suspend.protection}). The signal handlers
simply nest at top of stack.

@anchor{design/protix design mps protix threads async}@anchor{832}@ref{832,,.threads.async;} POSIX imposes some restrictions on signal handler
functions (see design.mps.pthreadext.analysis.signal.safety@footnote{pthreadext.html#design.mps.pthreadext.analysis.signal.safety}). Basically
the rules say the behaviour of almost all POSIX functions inside a
signal handler is undefined, except for a handful of functions which
are known to be “async-signal safe”. However, if it’s known that the
signal didn’t happen inside a POSIX function, then it is safe to call
arbitrary POSIX functions inside a handler.

@anchor{design/protix design mps protix threads async protection}@anchor{833}@ref{833,,.threads.async.protection;} If the signal handler is invoked because
of an MPS access, then we know the access must have been caused by
client code, because the client is not allowed to permit access to
protectable memory to arbitrary foreign code. In these circumstances,
it’s OK to call arbitrary POSIX functions inside the handler.

@cartouche
@quotation Note 
Need a reference for “the client is not allowed to permit access
to protectable memory to arbitrary foreign code”.
@end quotation
@end cartouche

@anchor{design/protix design mps protix threads async other}@anchor{834}@ref{834,,.threads.async.other;} If the signal handler is invoked for some
other reason (that is, one we are not prepared to handle) then there
is less we can say about what might have caused the SIGSEGV. In
general it is not safe to call arbitrary POSIX functions inside the
handler in this case.

@anchor{design/protix design mps protix threads async choice}@anchor{835}@ref{835,,.threads.async.choice;} The signal handler calls @code{ArenaAccess()}
to determine whether the segmentation fault was the result of an MPS
access. @code{ArenaAccess()} will claim various MPS locks (that is, the
arena ring lock and some arena locks). The code calls no other POSIX
functions in the case where the segmentation fault is not an MPS
access. The locks are implemented as mutexes and are claimed by
calling @code{pthread_mutex_lock()}, which is not defined to be
async-signal safe.

@anchor{design/protix design mps protix threads async choice ok}@anchor{836}@ref{836,,.threads.async.choice.ok;} However, despite the fact that POSIX
Threads documentation doesn’t define the behaviour of
@code{pthread_mutex_lock()} in these circumstances, we expect the POSIX
Threads implementation will be well-behaved unless the segmentation
fault occurs while while in the process of locking or unlocking one of
the MPS locks. But we can assume that a segmentation fault will not
happen then (because we use the locks correctly, and generally must
assume that they work). Hence we conclude that it is OK to call
@code{ArenaAccess()} directly from the signal handler.

@anchor{design/protix design mps protix threads async improve}@anchor{837}@ref{837,,.threads.async.improve;} In future it would be preferable to not
have to assume reentrant mutex locking and unlocking functions. An
alternative approach would be necessary anyway when supporting another
platform which doesn’t offer reentrant locks (if such a platform does
exist).

@anchor{design/protix design mps protix threads async improve how}@anchor{838}@ref{838,,.threads.async.improve.how;} We could avoid the assumption if we had
a means of testing whether an address lies within an arena chunk
without the need to claim any locks. Such a test might actually be
possible. For example, arenas could update a global datastructure
describing the ranges of all chunks, using atomic updates rather than
locks; the handler code would be allowed to read this without locking.
However, this is somewhat tricky; a particular consideration is that
it’s not clear when it’s safe to deallocate stale portions of the
datastructure.

@anchor{design/protix design mps protix threads sig-stack}@anchor{839}@ref{839,,.threads.sig-stack;} We do not handle signals on a separate signal
stack. Separate signal stacks apparently don’t work properly with
POSIX Threads.

@geindex address range; design

@node Ranges of addresses,Ring data structure,POSIX implementation of protection module,Design
@anchor{design/range doc}@anchor{83a}@anchor{design/range design-range}@anchor{83b}@anchor{design/range ranges-of-addresses}@anchor{83c}
@section Ranges of addresses


@menu
* Introduction: Introduction<29>. 
* Requirements: Requirements<19>. 
* Interface: Interface<12>. 

@end menu

@node Introduction<29>,Requirements<19>,,Ranges of addresses
@anchor{design/range design mps range}@anchor{83d}@anchor{design/range introduction}@anchor{83e}
@subsection Introduction


@anchor{design/range design mps range intro}@anchor{83f}@ref{83f,,.intro;} This is the design of the Range module, which implements
objects representing address ranges.

@anchor{design/range design mps range readership}@anchor{840}@ref{840,,.readership;} This document is intended for any MPS developer.

@node Requirements<19>,Interface<12>,Introduction<29>,Ranges of addresses
@anchor{design/range requirements}@anchor{841}
@subsection Requirements


@anchor{design/range design mps range req range}@anchor{842}@ref{842,,.req.range;} A range object must be able to represent an arbitrary
range of addresses that neither starts at @code{NULL} nor includes the
top grain of the address space.

@anchor{design/range design mps range req empty}@anchor{843}@ref{843,,.req.empty;} A range object must be able to represent the empty
range.

@anchor{design/range design mps range req stack-alloc}@anchor{844}@ref{844,,.req.stack-alloc;} It must be possible to allocate range objects on
the stack: that is, they do not require any heap resource.

@node Interface<12>,,Requirements<19>,Ranges of addresses
@anchor{design/range interface}@anchor{845}
@subsection Interface


@geindex Range (C type)
@anchor{design/range c Range}@anchor{686}
@deffn {C Type} typedef RangeStruct *Range
@end deffn

@ref{686,,Range} is the type of a range. It is an alias for
@code{RangeStruct *}. @code{RangeStruct} is defined in the header so that it
can be inlined in client structures or allocated on the stack. Clients
must not depend on its implementation details.

@geindex RangeInit (C function)
@anchor{design/range c RangeInit}@anchor{846}
@deffn {C Function} void RangeInit (Range range, Addr base, Addr limit)
@end deffn

Initialize a range object to represent the half-open address range
between @code{base} (inclusive) and @code{limit} (exclusive). It must be the
case that @code{base <= limit}. If @code{base == limit} then the range is
empty.

@geindex RangeCopy (C function)
@anchor{design/range c RangeCopy}@anchor{847}
@deffn {C Function} void RangeCopy (Range dest, Range src)
@end deffn

Initialize @code{dest} to be a copy of @code{src}.

@geindex RangeInitSize (C function)
@anchor{design/range c RangeInitSize}@anchor{848}
@deffn {C Function} void RangeInitSize (Range range, Addr base, Size size)
@end deffn

Initialize a range object to represent the half-open address range
between @code{base} (inclusive) and @code{base + size} (exclusive). If
@code{size == 0} then the range is empty.

@geindex RangeFinish (C function)
@anchor{design/range c RangeFinish}@anchor{849}
@deffn {C Function} void RangeFinish (Range range)
@end deffn

Finish a range object. Because a range object uses no heap resources
(@ref{844,,.req.stack-alloc}) it is not necessary to call this. However,
clients may wish to do so in order to ensure that the range object is
invalid.

@geindex RangeBase (C function)
@anchor{design/range c RangeBase}@anchor{84a}
@deffn {C Function} @ref{632,,Addr} RangeBase (Range range)
@end deffn

Return the base of the range. (This is implemented as a macro, but
there is a function too.)

@geindex RangeLimit (C function)
@anchor{design/range c RangeLimit}@anchor{84b}
@deffn {C Function} @ref{632,,Addr} RangeLimit (Range range)
@end deffn

Return the limit of the range. (This is implemented as a macro, but
there is a function too.)

@geindex RangeSetBase (C function)
@anchor{design/range c RangeSetBase}@anchor{84c}
@deffn {C Function} void RangeSetBase (Range range, Addr addr)
@end deffn

Set the base of the range. @code{addr} must not be greater than the range
limit. To set them both at once, use @ref{846,,RangeInit()}. (This is
implemented as a macro, but there is a function too.)

@geindex RangeSetLimit (C function)
@anchor{design/range c RangeSetLimit}@anchor{84d}
@deffn {C Function} void RangeSetLimit (Range range, Addr addr)
@end deffn

Set the limit of the range. @code{addr} must not be less than the range
base. To set the both at once, use @ref{846,,RangeInit()}. (This is
implemented as a macro, but there’s a function too.)

@geindex RangeSize (C function)
@anchor{design/range c RangeSize}@anchor{84e}
@deffn {C Function} @ref{40e,,Size} RangeSize (Range range)
@end deffn

Return the size of the range. (This is implemented as a macro, but
there is a function too. The macro evaluates its argument twice.)

@geindex RangeContains (C function)
@anchor{design/range c RangeContains}@anchor{84f}
@deffn {C Function} @ref{3a9,,Bool} RangeContains (Range range, Addr addr)
@end deffn

Return @code{TRUE} if @code{addr} belongs to the range, or @code{FALSE} if it
does not. (This is implemented as a macro, but there is a function
too. The macro evaluates its arguments twice.)

@geindex RangeIsEmpty (C function)
@anchor{design/range c RangeIsEmpty}@anchor{850}
@deffn {C Function} @ref{3a9,,Bool} RangeIsEmpty (Range range)
@end deffn

Return @code{TRUE} if the range is empty (contains no addresses),
@code{FALSE} otherwise. (This is implemented as a macro, but there is a
function too. The macro evaluates its argument twice.)

@geindex RangeIsAligned (C function)
@anchor{design/range c RangeIsAligned}@anchor{851}
@deffn {C Function} @ref{3a9,,Bool} RangeIsAligned (Range range, Align alignment)
@end deffn

Return @code{TRUE} if the base and limit of the range are both aligned to
the given alignment, or @code{FALSE} if either is not.

@geindex RangesOverlap (C function)
@anchor{design/range c RangesOverlap}@anchor{852}
@deffn {C Function} @ref{3a9,,Bool} RangesOverlap (Range range1, Range range2)
@end deffn

Return @code{TRUE} if the two ranges overlap (have at least one address
in common), or @code{FALSE} if they do not. Note that ranges [`A', `B') and
[`B', `C') do not overlap.

@geindex RangesNest (C function)
@anchor{design/range c RangesNest}@anchor{853}
@deffn {C Function} @ref{3a9,,Bool} RangesNest (Range outer, Range inner)
@end deffn

Return @code{TRUE} if all addresses in @code{inner} are also in @code{outer},
or @code{FALSE} otherwise.

@geindex ring structure; design

@node Ring data structure,Shield,Ranges of addresses,Design
@anchor{design/ring doc}@anchor{854}@anchor{design/ring design-ring}@anchor{855}@anchor{design/ring ring-data-structure}@anchor{856}
@section Ring data structure


@menu
* Introduction: Introduction<30>. 
* Description:: 
* Interface: Interface<13>. 
* Naming:: 
* Deques:: 
* Defects:: 

@end menu

@node Introduction<30>,Description,,Ring data structure
@anchor{design/ring design mps ring}@anchor{857}@anchor{design/ring introduction}@anchor{858}
@subsection Introduction


@anchor{design/ring design mps ring source}@anchor{859}@ref{859,,.source;} rings are derived from the earlier use of double-ended
queues (deques). RB found that most of the deque features were unused
(see item 6 of mail.richard.1996-03-25.16-02@footnote{https://info.ravenbrook.com/project/mps/mail/1996/03/25/16-02/0.txt}) and so the simple
doubly-linked list structure of rings suffices.

@node Description,Interface<13>,Introduction<30>,Ring data structure
@anchor{design/ring description}@anchor{85a}@anchor{design/ring mail-richard-1996-03-25-16-02}@anchor{85b}
@subsection Description


@geindex Ring (C type)
@anchor{design/ring c Ring}@anchor{85c}
@deffn {C Type} typedef RingStruct *Ring
@end deffn

@anchor{design/ring design mps ring def ring}@anchor{85d}@ref{85d,,.def.ring;} Rings are circular doubly-linked lists of ring “nodes”.
The nodes are fields of structures which are the “elements” of the
ring.

Ring node structures (@code{RingStruct}) are inlined in the structures on
the ring, like this:

@example
typedef struct FooStruct *Foo;     /* the element type */
typedef struct FooStruct @{         /* the element structure */
  int baz, bim;
  RingStruct ring;                 /* the ring node */
  float bip, bop;
@} FooStruct;
@end example

This arrangement means that they do not need to be managed separately.
This is especially useful in avoiding re-entrancy and bootstrapping
problems in the memory manager. Rings also provide flexible insertion
and deletion because the entire ring can be found from any node.

In the MPS, rings are used to connect a “parent” structure (such as a
@ref{796,,Arena}) to a number of “child” structures (such as @code{Pool}), as
shown in @ref{85e,,.fig.ring}.

@anchor{design/ring design mps ring fig ring}@anchor{85e}@ref{85e,,.fig.ring;} A ring of @code{Child} objects owned by a @code{Parent}
object.

[missing figure]

@anchor{design/ring design mps ring fig empty}@anchor{85f}@ref{85f,,.fig.empty;} An empty ring of @code{Child} objects owned by a @code{Parent}
object.

[missing figure]

@anchor{design/ring design mps ring def singleton}@anchor{860}@ref{860,,.def.singleton;} A “singleton” ring is a ring containing one node,
whose previous and next nodes are itself (see @ref{861,,.fig.single}).

@anchor{design/ring design mps ring fig single}@anchor{861}@ref{861,,.fig.single;} A singleton @code{Child} object not on any ring.

[missing figure]

@anchor{design/ring design mps ring fig elt}@anchor{862}@ref{862,,.fig.elt;} How @ref{863,,RING_ELT()} gets a parent pointer from a node pointer.

[missing figure]

@node Interface<13>,Naming,Description,Ring data structure
@anchor{design/ring interface}@anchor{864}
@subsection Interface


@menu
* Init / Finish:: 
* Checking: Checking<2>. 
* Iteration:: 
* Element access:: 
* Append / Remove:: 

@end menu

@node Init / Finish,Checking<2>,,Interface<13>
@anchor{design/ring init-finish}@anchor{865}
@subsubsection Init / Finish


@geindex RingInit (C function)
@anchor{design/ring c RingInit}@anchor{866}
@deffn {C Function} void RingInit (Ring ring)
@end deffn

@anchor{design/ring design mps ring init}@anchor{867}@ref{867,,.init;} Rings are initialized with the @ref{866,,RingInit()} function. They
are initialized to be a singleton ring (@ref{860,,.def.singleton}).

@geindex RingFinish (C function)
@anchor{design/ring c RingFinish}@anchor{868}
@deffn {C Function} void RingFinish (Ring ring)
@end deffn

@anchor{design/ring design mps ring finish}@anchor{869}@ref{869,,.finish;} Rings are finished with the @ref{868,,RingFinish()} function. A
ring must be a singleton ring before it can be finished (it is an
error to attempt to finish a non-singleton ring).

@node Checking<2>,Iteration,Init / Finish,Interface<13>
@anchor{design/ring checking}@anchor{86a}
@subsubsection Checking


@geindex RingCheck (C function)
@anchor{design/ring c RingCheck}@anchor{86b}
@deffn {C Function} @ref{3a9,,Bool} RingCheck (Ring ring)
@end deffn

@anchor{design/ring design mps ring check}@anchor{86c}@ref{86c,,.check;} @ref{86b,,RingCheck()} is the check function for rings. See
design.mps.check@footnote{check.html}).

@geindex RingCheckSingle (C function)
@anchor{design/ring c RingCheckSingle}@anchor{86d}
@deffn {C Function} @ref{3a9,,Bool} RingCheckSingle (Ring ring)
@end deffn

@anchor{design/ring design mps ring check single}@anchor{86e}@ref{86e,,.check.single;} @ref{86d,,RingCheckSingle()} is a check function that
additionally checks that @code{ring} is a singleton (see
@ref{860,,.def.singleton}).

@geindex RingIsSingle (C function)
@anchor{design/ring c RingIsSingle}@anchor{86f}
@deffn {C Function} @ref{3a9,,Bool} RingIsSingle (Ring ring)
@end deffn

@anchor{design/ring design mps ring is single}@anchor{870}@ref{870,,.is.single;} Return @code{TRUE} if @code{ring} is a singleton (see
@ref{860,,.def.singleton}).

@geindex RingLength (C function)
@anchor{design/ring c RingLength}@anchor{871}
@deffn {C Function} @ref{3af,,Count} RingLength (Ring ring)
@end deffn

@anchor{design/ring design mps ring length}@anchor{872}@ref{872,,.length;} Return the number of elements in the ring, not counting
@code{ring} itself. This therefore returns 0 for singleton rings, and for
parent-children rings it returns the number of children.

@node Iteration,Element access,Checking<2>,Interface<13>
@anchor{design/ring iteration}@anchor{873}
@subsubsection Iteration


@geindex RING_FOR (C macro)
@anchor{design/ring c RING_FOR}@anchor{874}
@deffn {C Macro} RING_FOR (node, ring, next)
@end deffn

@anchor{design/ring design mps ring for}@anchor{875}@ref{875,,.for;} A macro is used for iterating over the elements in a ring.
This macro is called @ref{874,,RING_FOR()}. @ref{874,,RING_FOR()} takes three arguments.
The first is an iteration variable: @code{node}. The second is the
“parent” element in the ring: @code{ring}. The third is a variable used
by the iterator for working state (it holds a pointer to the next
node): @code{next}. All arguments must be of type @ref{85c,,Ring}. The @code{node}
and @code{next} variables must be declared and in scope already. All
elements except for the “parent” element are iterated over. The macro
expands to a @code{for} statement. During execution of the loop, the
@code{node} variable (the first argument to the macro) will be the value
of successive elements in the Ring (at the beginning of the statement
in the body of the loop).

@anchor{design/ring design mps ring for error}@anchor{876}@ref{876,,.for.error;} It is an error (possibly unchecked) for the @code{node}
and @code{next} variables to be modified except implicitly by using this
iterator.

@anchor{design/ring design mps ring for safe}@anchor{877}@ref{877,,.for.safe;} It is safe to delete the current node during the
iteration.

@anchor{design/ring design mps ring for ex}@anchor{878}@ref{878,,.for.ex;} An example:

@example
Ring node, nextNode;
RING_FOR(node, &parent->childRing, nextNode) @{
  Child child = RING_ELT(Child, ParentRing, node);
  foo(child);
@}
@end example

@anchor{design/ring design mps ring for ex elt}@anchor{879}@ref{879,,.for.ex.elt;} Notice the idiomatic use of @ref{863,,RING_ELT()} which is
almost universal when using @ref{874,,RING_FOR()}.

@node Element access,Append / Remove,Iteration,Interface<13>
@anchor{design/ring element-access}@anchor{87a}
@subsubsection Element access


@geindex RingNext (C function)
@anchor{design/ring c RingNext}@anchor{87b}
@deffn {C Function} @ref{85c,,Ring} RingNext (Ring ring)
@end deffn

@anchor{design/ring design mps ring next}@anchor{87c}@ref{87c,,.next;} @ref{87b,,RingNext()} returns the next node in the ring.

@geindex RingPrev (C function)
@anchor{design/ring c RingPrev}@anchor{87d}
@deffn {C Function} @ref{85c,,Ring} RingPrev (Ring ring)
@end deffn

@anchor{design/ring design mps ring prev}@anchor{87e}@ref{87e,,.prev;} @ref{87d,,RingPrev()} returns the previous node in the ring.

@geindex RING_ELT (C macro)
@anchor{design/ring c RING_ELT}@anchor{863}
@deffn {C Macro} RING_ELT (type, field, node)
@end deffn

@anchor{design/ring design mps ring elt}@anchor{87f}@ref{87f,,.elt;} @ref{863,,RING_ELT()} is a macro that converts a pointer to a ring
structure into a pointer to the enclosing parent structure.
@ref{863,,RING_ELT()} has three arguments which are, in order: @code{type}, the
type of a pointer to the enclosing structure, @code{field}, the name of
the ring structure field within it, @code{ring}, the ring node. The
result is a pointer to the enclosing structure.

@cartouche
@quotation Note 
@ref{863,,RING_ELT()} does not work for arrays of rings.
@end quotation
@end cartouche

@node Append / Remove,,Element access,Interface<13>
@anchor{design/ring append-remove}@anchor{880}
@subsubsection Append / Remove


@geindex RingAppend (C function)
@anchor{design/ring c RingAppend}@anchor{881}
@deffn {C Function} void RingAppend (ring, new)
@end deffn

@anchor{design/ring design mps ring append}@anchor{882}@ref{882,,.append;} @ref{881,,RingAppend()} appends a singleton ring to a ring (such
that the newly added element will be last in the iteration sequence).

@geindex RingInsert (C function)
@anchor{design/ring c RingInsert}@anchor{883}
@deffn {C Function} void RingInsert (Ring ring, Ring new)
@end deffn

@anchor{design/ring design mps ring insert}@anchor{884}@ref{884,,.insert;} @ref{883,,RingInsert()} adds a singleton ring to a ring (such that
the newly added element will be first in the iteration sequence).

@geindex RingRemove (C function)
@anchor{design/ring c RingRemove}@anchor{885}
@deffn {C Function} void RingRemove (Ring old)
@end deffn

@anchor{design/ring design mps ring remove}@anchor{886}@ref{886,,.remove;} @ref{885,,RingRemove()} removes an element from a ring. The newly
removed element becomes a singleton ring. It is an error for the
element to already be a singleton.

@anchor{design/ring design mps ring improve join}@anchor{887}@ref{887,,.improve.join;} It would be possible to add a @code{RingJoin()} operation
that joined two rings. This is not done as it is not required.

@node Naming,Deques,Interface<13>,Ring data structure
@anchor{design/ring naming}@anchor{888}
@subsection Naming


@anchor{design/ring design mps ring naming}@anchor{889}@ref{889,,.naming;} By convention, when one structure @code{Parent} contains one
ring of @code{Child} structures, the field in @code{Parent} is usually known
as @code{childRing}, and the field in @code{Child} is known as
@code{parentRing}. If the @code{Parent} structure contains more than one
ring of @code{Child} structures, then they should have names like
@code{allocatedChildRing} and @code{freeChildRing}.

@anchor{design/ring design mps ring naming rule break}@anchor{88a}@ref{88a,,.naming.rule.break;} Note the slight abuse of naming convention, in
that the ring members have names ending in @ref{85c,,Ring} rather than
@code{RingStruct}.

@node Deques,Defects,Naming,Ring data structure
@anchor{design/ring deques}@anchor{88b}
@subsection Deques


This section documents where rings differ significantly from deques.

@anchor{design/ring design mps ring head}@anchor{88c}@ref{88c,,.head;} Deques used a distinguished head structure for the head of
the ring. Rings still have a separate head structure, but it is not
distinguished by type.

@node Defects,,Deques,Ring data structure
@anchor{design/ring defects}@anchor{88d}
@subsection Defects


This section documents known defects with the current design.

@anchor{design/ring design mps ring app_for misuse}@anchor{88e}@ref{88e,,.app_for.misuse;} It is easy to pass @ref{881,,RingAppend()} and
@ref{874,,RING_FOR()} the arguments in the wrong order as all the arguments
have the same type.

@anchor{design/ring design mps ring check improve}@anchor{88f}@ref{88f,,.check.improve;} There is no method for performing a full integrity
check. This could be added.

@geindex shield; design

@node Shield,Signatures in the MPS,Ring data structure,Design
@anchor{design/shield doc}@anchor{890}@anchor{design/shield design-shield}@anchor{891}@anchor{design/shield shield}@anchor{892}
@section Shield


@menu
* Introduction: Introduction<31>. 
* Overview: Overview<5>. 
* Interface: Interface<14>. 
* Mechanism:: 
* Implementation: Implementation<11>. 
* Initial ideas:: 
* Improvement Ideas:: 
* References: References<11>. 

@end menu

@node Introduction<31>,Overview<5>,,Shield
@anchor{design/shield design mps shield}@anchor{893}@anchor{design/shield introduction}@anchor{894}
@subsection Introduction


@anchor{design/shield design mps shield intro}@anchor{895}@ref{895,,.intro;} This document contains a guide to the MPS Shield. There is
no historical initial design, but in its place there are some early
ideas and discussions: see @ref{896,,.ideas}.

@anchor{design/shield design mps shield readership}@anchor{897}@ref{897,,.readership;} Any MPS developer. Not confidential.

@node Overview<5>,Interface<14>,Introduction<31>,Shield
@anchor{design/shield overview}@anchor{898}
@subsection Overview


@anchor{design/shield design mps shield overview}@anchor{899}@ref{899,,.overview;} The MPS implements incremental garbage collection using
memory barriers implemented by a combination of hardware memory
protection and thread control.  The MPS needs `separate control' of
collector access and mutator (client) access to memory: the collector
must be able to incrementally scan objects, without the mutator being
able to see them yet.

Unfortunately common operating systems do not support different access
levels (protection maps) for different parts of the same process.

The MPS Shield is an abstraction that does extra work to overcome this
limitation, and give the rest of the MPS the illusion that we can
control collector and mutator access separately.

@node Interface<14>,Mechanism,Overview<5>,Shield
@anchor{design/shield interface}@anchor{89a}
@subsection Interface


@menu
* Mutator access:: 
* Entering the shield:: 
* Collector access to segments:: 
* Collector access to the unprotectable:: 

@end menu

@node Mutator access,Entering the shield,,Interface<14>
@anchor{design/shield mutator-access}@anchor{89b}
@subsubsection Mutator access


The shield provides @ref{89c,,ShieldRaise()} and @ref{89d,,ShieldLower()} to forbid
or permit the mutator access to object memory segments. Between these
two, a segment is said to have the shield `raised' (@ref{89e,,.def.raised}).

@geindex ShieldRaise (C function)
@anchor{design/shield c ShieldRaise}@anchor{89c}
@deffn {C Function} void ShieldRaise (Arena arena, Seg seg, AccessSet mode)

Prevent the mutator accessing the memory segment in the specified
mode (@code{AccessREAD}, @code{AccessWRITE}, or both).
@end deffn

@geindex ShieldLower (C function)
@anchor{design/shield c ShieldLower}@anchor{89d}
@deffn {C Function} void ShieldLower (Arena arena, Seg seg, AccessSet mode)

Allow the mutator to access the memory segment in the specified
mode (@code{AccessREAD}, @code{AccessWRITE}, or both).
@end deffn

If the mutator attempts an access that hits the shield, the MPS gets
an OS-specific hardware protection fault which reaches
@code{ArenaAccess()}, does whatever work is necessary, then lowers the
shield and returns to the mutator.

@ref{89c,,ShieldRaise()} and @ref{89d,,ShieldLower()} do `not' nest.

@node Entering the shield,Collector access to segments,Mutator access,Interface<14>
@anchor{design/shield entering-the-shield}@anchor{89f}
@subsubsection Entering the shield


The MPS can only gain exclusive access from `inside' the shield
(@ref{8a0,,.def.inside}). To enter the shield, the MPS must call
@code{ShieldEnter()}, and to leave it, the MPS must call
@code{ShieldLeave()}.

@code{ShieldEnter()} and @code{ShieldLeave()} are called by @code{ArenaEnter()}
and @code{ArenaLeave()} so almost all of the MPS is is inside the
shield.

@node Collector access to segments,Collector access to the unprotectable,Entering the shield,Interface<14>
@anchor{design/shield collector-access-to-segments}@anchor{8a1}
@subsubsection Collector access to segments


When the MPS wants to access object memory segments from inside the
shield, it must wrap any accesses with a @code{ShieldExpose()} and
@code{ShieldCover()} pair. These calls nest. After a call to
@code{ShieldExpose()} a segment is said to be `exposed' until the last
nested call to @code{ShieldCover()}. The shield arranges that the MPS can
access the memory while it is exposed.

A segment might for example be exposed during:

@quotation


@itemize -

@item 
format-scan (when scanning);

@item 
format-skip (when marking grains in a non-moving fix);

@item 
format-isMoved and @code{AddrCopy()} (during a copying fix);

@item 
format-pad (during reclaim).
@end itemize
@end quotation

Note that there is no need to call @code{ShieldExpose()} when accessing
pool management memory such as bit tables. This is not object memory,
is never (legally) accessed by the mutator, and so is never shielded.

Similarly, a pool class that never raises the shield on its segments
need never expose them to gain access.

@node Collector access to the unprotectable,,Collector access to segments,Interface<14>
@anchor{design/shield collector-access-to-the-unprotectable}@anchor{8a2}
@subsubsection Collector access to the unprotectable


When the MPS wants to access an unprotectable object from inside the
shield, it must wrap any accesses with a @ref{8a3,,ShieldHold()} and
@ref{8a4,,ShieldRelease()} pair. This allows access to objects which cannot
be shielded by @ref{89c,,ShieldRaise()}, such as:

@quotation


@itemize -

@item 
the stack and registers of mutator threads,

@item 
lockless allocation point structures,

@item 
areas of memory that can’t be protected by operating system calls,

@item 
unprotectable roots.
@end itemize
@end quotation

@geindex ShieldHold (C function)
@anchor{design/shield c ShieldHold}@anchor{8a3}
@deffn {C Function} void ShieldHold (Arena arena)

Get exclusive access to the unprotectable.
@end deffn

@geindex ShieldRelease (C function)
@anchor{design/shield c ShieldRelease}@anchor{8a4}
@deffn {C Function} void ShieldRelease (Arena arena)

Declare that exclusive access is no longer needed.
@end deffn

@node Mechanism,Implementation<11>,Interface<14>,Shield
@anchor{design/shield mechanism}@anchor{8a5}
@subsection Mechanism


On common operating systems, the only way to allow the MPS access is
to allow access from the whole process, including the mutator. So
@code{ShieldExpose()} will suspend all mutator threads to prevent any
mutator access, and so will @ref{89c,,ShieldRaise()} on an unexposed segment.
The shield handles suspending and resuming threads, and so the rest of
the MPS does not need to worry about it.

The MPS can make multiple sequential, overlapping, or nested calls to
@code{ShieldExpose()} on the same segment, as long as each is balanced by
a corresponding @code{ShieldCover()} before @code{ShieldLeave()} is called.
A usage count is maintained on each segment in @code{seg->depth}. When
the usage count reaches zero, there is no longer any reason the
segment should be unprotected, and the shield may reinstate hardware
protection at any time.

However, as a performance-improving hysteresis, the shield defers
re-protection, maintaining a queue of segments that require attention
before mutator threads are resumed (@ref{8a6,,.impl.delay}). While a segment
is in the queue, it has @code{seg->queued} set true.

This hysteresis allows the MPS to proceed with garbage collection
during a pause without actually setting hardware protection until it
returns to the mutator. This is particularly important on operating
systems where the protection is expensive and poorly implemented, such
as macOS.

The queue also ensures that no memory protection system calls will be
needed for incremental garbage collection if a complete collection
cycle occurs during one pause.

@node Implementation<11>,Initial ideas,Mechanism,Shield
@anchor{design/shield implementation}@anchor{8a7}
@subsection Implementation


@anchor{design/shield design mps shield impl delay}@anchor{8a6}@ref{8a6,,.impl.delay;} The implementation of the shield avoids suspending
threads for as long as possible. When threads are suspended, it
maintains a queue of segments where the desired and actual protection
do not match. This queue is flushed on leaving the shield.

@menu
* Definitions: Definitions<3>. 
* Properties:: 
* Invariants:: 
* Proof Hints:: 

@end menu

@node Definitions<3>,Properties,,Implementation<11>
@anchor{design/shield definitions}@anchor{8a8}
@subsubsection Definitions


@anchor{design/shield design mps shield def raised}@anchor{89e}@ref{89e,,.def.raised;} A segment has the shield `raised' for an access mode
after a call to @ref{89c,,ShieldRaise()} and before a call to
@ref{89d,,ShieldLower()} with that mode.

@anchor{design/shield design mps shield def exposed}@anchor{8a9}@ref{8a9,,.def.exposed;} A segment is `exposed' after a call to
@code{ShieldExpose()} and before a call to @ref{89d,,ShieldLower()}.

@anchor{design/shield design mps shield def synced}@anchor{8aa}@ref{8aa,,.def.synced;} A segment is `synced' if the prot and shield modes are
the same, and unsynced otherwise.

@anchor{design/shield design mps shield def depth}@anchor{8ab}@ref{8ab,,.def.depth;} The `depth' of a segment is defined as:

@quotation


@display
depth ≔ #exposes − #covers, where@w{ }
@display
#exposes = the number of calls to @code{ShieldExpose()} on the segment@w{ }
#covers  = the number of calls to @code{ShieldCover()} on the segment@w{ }
@end display
@end display


@end quotation

@code{ShieldCover()} must not be called without a matching
@code{ShieldExpose()}, so this figure must always be non-negative.

@anchor{design/shield design mps shield def total depth}@anchor{8ac}@ref{8ac,,.def.total.depth;} The total depth is the sum of the depth over all
segments.

@anchor{design/shield design mps shield def outside}@anchor{8ad}@ref{8ad,,.def.outside;} Being outside the shield is being between calls to
@code{ShieldLeave()} and @code{ShieldEnter()}, and similarly @anchor{design/shield design mps shield def inside}@anchor{8a0}@ref{8a0,,.def.inside;}
being inside the shield is being between calls to @code{ShieldEnter()}
and @code{ShieldLeave()}. [In a multi-threaded MPS this would be
per-thread. RB 2016-03-18]

@anchor{design/shield design mps shield def shielded}@anchor{8ae}@ref{8ae,,.def.shielded;} A segment is shielded if the shield mode is
non-zero. [As set by ShieldRaise.]

@node Properties,Invariants,Definitions<3>,Implementation<11>
@anchor{design/shield properties}@anchor{8af}
@subsubsection Properties


@anchor{design/shield design mps shield prop outside running}@anchor{8b0}@ref{8b0,,.prop.outside.running;} The mutator may not be suspended while outside
the shield.

@anchor{design/shield design mps shield prop mutator access}@anchor{8b1}@ref{8b1,,.prop.mutator.access;} An attempt by the mutator to access shielded
memory must be pre-empted by a call to @code{ArenaAccess()}.

@anchor{design/shield design mps shield prop inside access}@anchor{8b2}@ref{8b2,,.prop.inside.access;} Inside the shield the MPS must be able to access
all unshielded segments and all exposed segments.

@node Invariants,Proof Hints,Properties,Implementation<11>
@anchor{design/shield invariants}@anchor{8b3}
@subsubsection Invariants


@anchor{design/shield design mps shield inv outside running}@anchor{8b4}@ref{8b4,,.inv.outside.running;} The mutator is not suspended while outside the
shield.

@anchor{design/shield design mps shield inv unsynced suspended}@anchor{8b5}@ref{8b5,,.inv.unsynced.suspended;} If any segment is not synced, the mutator is
suspended.

@anchor{design/shield design mps shield inv unsynced depth}@anchor{8b6}@ref{8b6,,.inv.unsynced.depth;} All unsynced segments have positive depth or are
in the queue.

@anchor{design/shield design mps shield inv outside depth}@anchor{8b7}@ref{8b7,,.inv.outside.depth;} The total depth is zero while outside the shield.

@anchor{design/shield design mps shield inv prot shield}@anchor{8b8}@ref{8b8,,.inv.prot.shield;} The prot mode is never more than the shield mode.

@anchor{design/shield design mps shield inv expose depth}@anchor{8b9}@ref{8b9,,.inv.expose.depth;} An exposed segment’s depth is greater than zero.

@anchor{design/shield design mps shield inv expose prot}@anchor{8ba}@ref{8ba,,.inv.expose.prot;} An exposed segment is not protected in the mode
it was exposed with.

@node Proof Hints,,Invariants,Implementation<11>
@anchor{design/shield proof-hints}@anchor{8bb}
@subsubsection Proof Hints


Hints at proofs of properties from invariants.

@anchor{design/shield design mps shield proof outside}@anchor{8bc}@ref{8bc,,.proof.outside;} @ref{8b4,,.inv.outside.running} directly ensures
@ref{8b0,,.prop.outside.running}.

@anchor{design/shield design mps shield proof sync}@anchor{8bd}@ref{8bd,,.proof.sync;} As the depth of a segment cannot be negative

@quotation


@display
total depth = 0@w{ }
@display
⇒ for all segments, depth = 0@w{ }
⇒ all segments are synced (by @ref{8b6,,.inv.unsynced.depth})@w{ }
@end display
@end display


@end quotation

@anchor{design/shield design mps shield proof access}@anchor{8be}@ref{8be,,.proof.access;} If the mutator is running then all segments must be
synced (@ref{8b5,,.inv.unsynced.suspended}). Which means that the hardware
protection (protection mode) must reflect the software protection
(shield mode). Hence all shielded memory will be hardware protected
while the mutator is running. This ensures @ref{8b1,,.prop.mutator.access}.

@anchor{design/shield design mps shield proof inside}@anchor{8bf}@ref{8bf,,.proof.inside;} @ref{8b8,,.inv.prot.shield} and @ref{8ba,,.inv.expose.prot} ensure
@ref{8b2,,.prop.inside.access}.

@node Initial ideas,Improvement Ideas,Implementation<11>,Shield
@anchor{design/shield initial-ideas}@anchor{8c0}
@subsection Initial ideas


@anchor{design/shield design mps shield ideas}@anchor{896}@ref{896,,.ideas;} There never was an initial design document, but
@ref{8c1,,[RB_1995-11-29]} and @ref{8c2,,[RB_1995-11-30]} contain some initial ideas.

@node Improvement Ideas,References<11>,Initial ideas,Shield
@anchor{design/shield improvement-ideas}@anchor{8c3}
@subsection Improvement Ideas


@menu
* Mass exposure:: 
* Segment independence:: 
* Concurrent collection:: 
* Early Resume:: 
* Expose modes:: 

@end menu

@node Mass exposure,Segment independence,,Improvement Ideas
@anchor{design/shield mass-exposure}@anchor{8c4}
@subsubsection Mass exposure


@anchor{design/shield design mps shield improv mass-expose}@anchor{8c5}@ref{8c5,,.improv.mass-expose;} If protection calls have a high overhead it might
be good to pre-emptively unprotect large ranges of memory when we
expose one segment.  With the current design this would mean
discovering adjacent shielded segments and adding them to the queue.
The collector should take advantage of this by preferentially scanning
exposed segments during a pause.

@node Segment independence,Concurrent collection,Mass exposure,Improvement Ideas
@anchor{design/shield segment-independence}@anchor{8c6}
@subsubsection Segment independence


@anchor{design/shield design mps shield improv noseg}@anchor{8c7}@ref{8c7,,.improv.noseg;} The shield is implemented in terms of segments, using
fields in the segment structure to represent its state. This forces us
to (for example) flush the shield queue when deleting a segment. The
shield could keep track of protection and shielding independently,
possibly allowing greater coalescing and more efficient and flexible
use of system calls (see @ref{8c5,,.improv.mass-expose}).

@node Concurrent collection,Early Resume,Segment independence,Improvement Ideas
@anchor{design/shield concurrent-collection}@anchor{8c8}
@subsubsection Concurrent collection


@anchor{design/shield design mps shield improv concurrent}@anchor{8c9}@ref{8c9,,.improv.concurrent;} The MPS currently does not collect
concurrently, however the only thing that makes it not-concurrent is a
critical point in the Shield abstraction where the MPS seeks to gain
privileged access to memory (usually in order to scan it). The
critical point is where @code{ShieldExpose()} in shield.c has to call
@ref{8a3,,ShieldHold()} to preserve the shield invariants. This is the only
point in the MPS that prevents concurrency, and the rest of the MPS is
designed to support it.

The restriction could be removed if either:

@quotation


@itemize *

@item 
the MPS could use a different set of protections to the mutator
program

@item 
the mutator program uses a software barrier
@end itemize
@end quotation

The first one is tricky, and the second one just hasn’t come up in any
implementation we’ve been asked to make yet. Given a VM, it could
happen, and the MPS would be concurrent.

So, I believe there’s nothing fundamentally non-concurrent about the
MPS design. It’s kind of waiting to happen.

(Originally written at <@indicateurl{http://news.ycombinator.com/item?id=4524036}>.)

@node Early Resume,Expose modes,Concurrent collection,Improvement Ideas
@anchor{design/shield early-resume}@anchor{8ca}
@subsubsection Early Resume


@anchor{design/shield design mps shield improv resume}@anchor{8cb}@ref{8cb,,.improv.resume;} There is a tradeoff between delaying flushing the
shield queue (preventing unnecessary protection and allowing us to
coalesce) and resuming mutator threads. We could resume threads
earlier under some circumstances, such as before reclaim (which does
not need to interact with the mutator). Basically, it might be worth
resuming the mutator early in a pause if we know that we’re unlikely
to suspend it again (no more calls to @ref{89c,,ShieldRaise()} or
@code{ShieldExpose()} on shielded segments).

@node Expose modes,,Early Resume,Improvement Ideas
@anchor{design/shield expose-modes}@anchor{8cc}
@subsubsection Expose modes


@anchor{design/shield design mps shield improv expose-modes}@anchor{8cd}@ref{8cd,,.improv.expose-modes;} Would it be a good idea for
@code{ShieldExpose()} to take an @ref{8ce,,AccessSet}? It might be good if we
didn’t have to raise a write barrier unless we want to write. When
scanning (for instance), we may not need to write, so when scanning a
segment behind a write barrier we shouldn’t have to call
@code{mprotect()}. That’s a bit speculative: how often do we scan a
segment and not write to it. Alternatively, and more speculatively, we
could keep the write barrier up, handle the (possibly nested) trap and
`then' expose the shield. I’m just scraping around for ways to reduce
calls to @code{mprotect()}.

Theoretically we can do this, but:

@quotation


@enumerate 

@item 
We’re mostly a moving collector so we’ll almost always want to
write to segments we scan.  That could change if we do more
non-moving collection.

@item 
The main cost of protection is changing it at all, not whether we
change just read or write.  On macOS, the main cost seems to be the
TLB flush, which affects wall-clock time of everything on the
processor!
@end enumerate
@end quotation

@node References<11>,,Improvement Ideas,Shield
@anchor{design/shield references}@anchor{8cf}
@subsection References


@anchor{design/shield rb-1995-11-29}@anchor{8c1}@w{(RB_1995-11-29)} 
Richard Brooksby. Harlequin. 1995-11-29. “Shield protocol for barriers@footnote{https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mminfo/idea/shield/index.txt}”.

@anchor{design/shield rb-1995-11-30}@anchor{8c2}@w{(RB_1995-11-30)} 
Richard Brooksby. Harlequin. 1995-11-30. “Exegesis of Incremental Tracing@footnote{https://info.ravenbrook.com/project/mps/mail/1995/11/30/15-07/0.txt}”.

@geindex structure signatures; design
@geindex signatures

@node Signatures in the MPS,Stack probe,Shield,Design
@anchor{design/sig doc}@anchor{8d0}@anchor{design/sig design-sig}@anchor{8d1}@anchor{design/sig signatures-in-the-mps}@anchor{8d2}
@section Signatures in the MPS

@anchor{design/sig design mps sig}@anchor{8d3}
@c TODO: Use RFC-2119 keywords.

@menu
* Introduction: Introduction<32>. 
* Overview: Overview<6>. 
* Definitions: Definitions<4>. 
* Init and Finish:: 
* Checking: Checking<3>. 
* Rules:: 
* Tools:: 
* References: References<12>. 

@end menu

@node Introduction<32>,Overview<6>,,Signatures in the MPS
@anchor{design/sig introduction}@anchor{8d4}
@subsection Introduction


Integrity of data structures is absolutely critical to the cost of
deploying the Memory Pool System.  Memory corruption and memory
management bugs are incredibly hard to detect and debug, often
manifesting themselves hours or days after they occur.  One of the key
ways the MPS detects corruption or the passing of illegal data is using
`signatures'.  This simple technique has proved invaluable at catching
defects early.

This document is based on @ref{8d5,,[RB_1995-08-25]}.

@node Overview<6>,Definitions<4>,Introduction<32>,Signatures in the MPS
@anchor{design/sig overview}@anchor{8d6}
@subsection Overview


@anchor{design/sig design mps sig overview}@anchor{8d7}@ref{8d7,,.overview;} Signatures are magic numbers@footnote{https://en.wikipedia.org/wiki/Magic_number_(programming)} which are written into
structures when they are created and invalidated (by overwriting with
@code{SigInvalid}) when they are destroyed. They provide a limited form
of run-time type checking and dynamic scope checking. They are a
simplified form of “Structure Marking”, a technique used in the
Multics filesystem @ref{8d8,,[THVV_1995]}.

@node Definitions<4>,Init and Finish,Overview<6>,Signatures in the MPS
@anchor{design/sig definitions}@anchor{8d9}@anchor{design/sig magic-numbers}@anchor{8da}
@subsection Definitions


@anchor{design/sig design mps sig field}@anchor{8db}@ref{8db,,.field;} Nearly every structure should start with a field of type
@ref{8dc,,Sig} with the name @code{sig}.  For example:

@example
typedef struct mps_message_s @{
  Sig sig;                      /* design.mps.sig.field */
  Arena arena;                  /* owning arena */
  MessageClass class;           /* Message Class Structure */
  Clock postedClock;            /* mps_clock() at post time, or 0 */
  RingStruct queueRing;         /* Message queue ring */
@} MessageStruct;
@end example

@anchor{design/sig design mps sig value}@anchor{8dd}@ref{8dd,,.value;} There must also be a definition for the valid value for
that signature:

@example
#define MessageSig      ((Sig)0x5193e559) /* SIG MESSaGe */
@end example

@anchor{design/sig design mps sig value unique}@anchor{8de}@ref{8de,,.value.unique;} The hex value should be unique to the structure
type.  (See @ref{8df,,.test.uniq} for a method of ensuring this.)

@anchor{design/sig design mps sig value hex}@anchor{8e0}@ref{8e0,,.value.hex;} This is a 32-bit hex constant, spelled using `hex
transliteration' according to guide.hex.trans@footnote{guide.hex.trans.rst}:

@example
ABCDEFGHIJKLMNOPQRSTUVWXYZ
ABCDEF9811C7340BC6520F3812
@end example

@anchor{design/sig design mps sig value hex just}@anchor{8e1}@ref{8e1,,.value.hex.just;} Hex transliteration allows the structure to be
recognised when looking at memory in a hex dump or memory window, or
found using memory searches.

@anchor{design/sig design mps sig field end}@anchor{8e2}@ref{8e2,,.field.end;} In some circumstances the signature should be placed at
the end of the structure.

@anchor{design/sig design mps sig field end outer}@anchor{8e3}@ref{8e3,,.field.end.outer;} When a structure extends an `inner structure'
that already has a signature, it is good practice to put the signature
for the outer structure at the end. This gives some extra fencepost
checking.  For example:

@example
typedef struct MVFFStruct @{     /* MVFF pool outer structure */
  PoolStruct poolStruct;        /* generic structure */
  LocusPrefStruct locusPrefStruct; /* the preferences for allocation */
...
  Sig sig;                      /* design.mps.sig.field.end.outer */
@} MVFFStruct;
@end example

@node Init and Finish,Checking<3>,Definitions<4>,Signatures in the MPS
@anchor{design/sig init-and-finish}@anchor{8e4}
@subsection Init and Finish


@anchor{design/sig design mps sig init}@anchor{8e5}@ref{8e5,,.init;} When the structure is initialised, the signature is
initialised as the `last' action, just before validating it.  (Think
of it as putting your signature at the bottom of a document to say
it’s done.)  This ensures that the structure will appear invalid until
it is completely initialized and ready to use.  For example:

@example
void MessageInit(...) @{
  ...
  message->arena = arena;
  message->class = class;
  RingInit(&message->queueRing);
  message->postedClock = 0;
  message->sig = MessageSig;
  AVERT(Message, message);
@}
@end example

@anchor{design/sig design mps sig finish}@anchor{8e6}@ref{8e6,,.finish;} When the structure is finished, the signature is
invalidated just after checking the structure, before finishing any of
other fields.  This ensures that the structure appears invalid while
it is being torn down and can’t be used after.  For example:

@example
void MessageFinish(Message message)
@{
  AVERT(Message, message);
  AVER(RingIsSingle(&message->queueRing));

  message->sig = SigInvalid;
  RingFinish(&message->queueRing);
@}
@end example

@anchor{design/sig design mps sig ambit}@anchor{8e7}@ref{8e7,,.ambit;} Do not do anything else with signatures.  See
@ref{8e8,,.rule.purpose}.

@node Checking<3>,Rules,Init and Finish,Signatures in the MPS
@anchor{design/sig checking}@anchor{8e9}
@subsection Checking


@anchor{design/sig design mps sig check arg}@anchor{8ea}@ref{8ea,,.check.arg;} Every function that takes a pointer to a signed
structure should check its argument.

@anchor{design/sig design mps sig check arg unlocked}@anchor{8eb}@ref{8eb,,.check.arg.unlocked;} A function that does not hold the arena lock
should check the argument using @code{AVER(TESTT(type, val))}, which
checks that @code{val->sig} is the correct signature for @code{type}.

@anchor{design/sig design mps sig check arg locked}@anchor{8ec}@ref{8ec,,.check.arg.locked;} A function that holds the arena lock should
check the argument using the @code{AVERT} macro. This macro has different
definitions depending on how the MPS is compiled (see
design.mps.config.def.var@footnote{config.txt.html#design.mps.config.def.var}). It may simply check the signature, or
call the full checking function for the structure.

@anchor{design/sig design mps sig check sig}@anchor{8ed}@ref{8ed,,.check.sig;} The checking function for the structure should also
validate the signature as its first step using the @ref{8ee,,CHECKS()} macro
(see design.mps.check.macro.sig@footnote{check.txt}). For example:

@example
Bool MessageCheck(Message message)
@{
  CHECKS(Message, message);
  CHECKU(Arena, message->arena);
  CHECKD(MessageClass, message->class);
  ...
@end example

This combination makes it extremely difficult to get an object of the
wrong type, an uninitialized object, or a dead object, or a random
pointer into a function.

@node Rules,Tools,Checking<3>,Signatures in the MPS
@anchor{design/sig rules}@anchor{8ef}
@subsection Rules


@anchor{design/sig design mps sig rule purpose}@anchor{8e8}@ref{8e8,,.rule.purpose;} `Do not' use signatures for any other purpose.
The code must function in exactly the same way (modulo defects) if
they are removed.  For example, don’t use them to make any actual
decisions within the code.  They must not be used to discriminate
between structure variants (or union members). They must not be used
to try to detect `whether' a structure has been initialised or
finished.  They are there to double-check whether these facts are
true. They lose their value as a consistency check if the code uses
them as well.

@node Tools,References<12>,Rules,Signatures in the MPS
@anchor{design/sig tools}@anchor{8f0}
@subsection Tools


@anchor{design/sig design mps sig test uniq}@anchor{8df}@ref{8df,,.test.uniq;} The Unix command:

@example
sed -n '/^#define [a-zA-Z]*Sig/s/[^(]*(/(/p' code/*.[ch] | sort | uniq -c
@end example

will display all signatures defined in the MPS along with a count of how
many times they are defined.  If any counts are greater than 1, then the
same signature value is being used for different signatures.  This is
undesirable and the problem should be investigated.

@node References<12>,,Tools,Signatures in the MPS
@anchor{design/sig references}@anchor{8f1}
@subsection References


@anchor{design/sig rb-1995-08-25}@anchor{8d5}@w{(RB_1995-08-25)} 
Richard Brooksby. Harlequin. 1995-08-25. “design.mps.sig: The design of the Memory Pool System Signature System@footnote{https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mminfo/design/mps/sig/}”.

@anchor{design/sig thvv-1995}@anchor{8d8}@w{(THVV_1995)} 
Tom Van Vleck. 1995. “Structure Marking@footnote{https://www.multicians.org/thvv/marking.html}”.

@geindex stack probe; design

@node Stack probe,Splay trees,Signatures in the MPS,Design
@anchor{design/sp doc}@anchor{8f2}@anchor{design/sp design-sp}@anchor{1d8}@anchor{design/sp stack-probe}@anchor{8f3}
@section Stack probe


@menu
* Introduction: Introduction<33>. 
* Requirements: Requirements<20>. 
* Design: Design<5>. 
* Interface: Interface<15>. 
* Issues:: 
* Implementations: Implementations<4>. 

@end menu

@node Introduction<33>,Requirements<20>,,Stack probe
@anchor{design/sp design mps sp}@anchor{8f4}@anchor{design/sp introduction}@anchor{8f5}
@subsection Introduction


@anchor{design/sp design mps sp intro}@anchor{8f6}@ref{8f6,,.intro;} This is the design of the stack probe module.

@anchor{design/sp design mps sp readership}@anchor{8f7}@ref{8f7,,.readership;} Any MPS developer; anyone porting the MPS to a new
platform.

@anchor{design/sp design mps sp overview}@anchor{8f8}@ref{8f8,,.overview;} This module ensures that the stack cannot overflow while
the MPS is holding a lock, so that a mutator can handle stack overflow
faults and call into the MPS from the handler.

@node Requirements<20>,Design<5>,Introduction<33>,Stack probe
@anchor{design/sp requirements}@anchor{8f9}
@subsection Requirements


@anchor{design/sp design mps sp req overflow}@anchor{8fa}@ref{8fa,,.req.overflow;} The mutator should be able to call into the MPS from
a stack overflow fault handler. (This is a convenient way to handle
stack overflows in dynamic language implementations: if the stack
overflow exception and associated backtrace are to be represented as
objects, this may require allocation, and hence a call into the MPS.)

@anchor{design/sp design mps sp req complete}@anchor{8fb}@ref{8fb,,.req.complete;} In an application where the mutator might call into
the MPS from a stack overflow fault handler, then whenever the MPS
takes a lock, it must complete the operation and release the lock
without running out of stack. (This is because running out of stack
would cause a stack overflow fault, causing the mutator to enter the
MPS recursively, which would fail because the lock is held.)

@node Design<5>,Interface<15>,Requirements<20>,Stack probe
@anchor{design/sp design}@anchor{8fc}
@subsection Design


@anchor{design/sp design mps sp sol probe}@anchor{8fd}@ref{8fd,,.sol.probe;} Before taking the arena lock in @code{ArenaEnterLock()},
the MPS `probes' the stack: that is, it checks whether there are at
least @code{StackProbeDEPTH} words available, and provokes a stack
overflow fault if there are not. (This ensures that the fault occurs
outside of the arena lock where it can be handled safely.)

@anchor{design/sp design mps sp sol depth}@anchor{8fe}@ref{8fe,,.sol.depth;} The configuration parameter @code{StackProbeDEPTH}
specifies the maximum number of words of stack that the MPS might use.
(It is simpler, faster, and more reliable, to determine this globally
than to try to figure it out dynamically.)

@anchor{design/sp design mps sp sol depth constraint}@anchor{8ff}@ref{8ff,,.sol.depth.constraint;} Operating systems typically use a single
“guard page” to detect stack overflow and grow the stack. (See for
example the documentation for Windows@footnote{https://docs.microsoft.com/en-us/windows/desktop/procthread/thread-stack-size}.) This means that the probe
will be ineffective if it skips over the guard page into the memory
beyond. If @code{StackProbeDEPTH} is greater than or equal to the number
of words per page, the implementation might need to carry out multiple
probes. (This constraint is checked in @code{MPMCheck()}.)

@anchor{design/sp design mps sp sol depth no-recursion}@anchor{900}@ref{900,,.sol.depth.no-recursion;} In order to implement this design, the MPS
must have constant bounded stack depth, and therefore, no recursion.

@anchor{design/sp design mps sp sol depth analysis}@anchor{901}@ref{901,,.sol.depth.analysis;} Here’s a table showing a deep call into the
MPS (in the master sources at changelevel 187378), starting in
@code{ArenaAccess()} at the point where the arena ring lock is taken. The
access forces a scan of a segment in an AMC pool, which fixes a
reference to an object in an AMC pool’s oldspace, which has to be
forwarded, and this overflows the forwarding buffer, which requires
the arena to allocate a new buffer in an appropriate zone, by
searching the splay tree representing free memory.

The “Args” column gives the number of arguments to the function (all
arguments to functions in the MPS are word-sized or smaller, since we
prohibit passing structures by value), and the “Locals” column gives
the number of words in local variables. The value “≤64” for the stack
usage of the object format’s scan method is the limit that’s
documented in the manual.


@multitable {xxxxxx} {xxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Args

@tab

Locals

@tab

Function

@item

5

@tab

0

@tab

@code{SegAccess()}

@item

5

@tab

0

@tab

@code{SegWholeAccess()}

@item

3

@tab

8

@tab

@code{TraceSegAccess()}

@item

4

@tab

1

@tab

@code{traceScanSeg()}

@item

4

@tab

9

@tab

@code{traceScanSegRes()}

@item

4

@tab

0

@tab

@code{SegScan()}

@item

4

@tab

5

@tab

@ref{902,,amcSegScan()}

@item

3

@tab

0

@tab

@code{TraceScanFormat()}

@item

3

@tab

≤64

@tab

@code{format->scan()}

@item

3

@tab

0

@tab

@code{SegFix()}

@item

4

@tab

15

@tab

@ref{4bf,,amcSegFix()}

@item

3

@tab

5

@tab

@ref{7a2,,BufferFill()}

@item

5

@tab

11

@tab

@ref{903,,AMCBufferFill()}

@item

5

@tab

73

@tab

@code{PoolGenAlloc()}

@item

6

@tab

5

@tab

@code{SegAlloc()}

@item

4

@tab

4

@tab

@code{ArenaAlloc()}

@item

5

@tab

6

@tab

@ref{904,,PolicyAlloc()}

@item

6

@tab

10

@tab

@code{ArenaFreeLandAlloc()}

@item

7

@tab

1

@tab

@ref{40c,,LandFindInZones()}

@item

7

@tab

16

@tab

@code{cbsFindInZones()}

@item

5

@tab

3

@tab

@code{cbsFindFirst()}

@item

6

@tab

7

@tab

@ref{41b,,SplayFindFirst()}

@item

3

@tab

7

@tab

@code{SplaySplay()}

@item

4

@tab

8

@tab

@code{SplaySplitDown()}

@item

3

@tab

0

@tab

@code{SplayZig()}

@item

111

@tab

≤258

@tab

`Total'

@end multitable


We expect that a compiler will not need to push all local variables
onto the stack, but even in the case where it pushes all of them, this
call requires no more than 369 words of stack space.

This isn’t necessarily the deepest call into the MPS (the MPS’s
modular design and class system makes it hard to do a complete
analysis using call graph tools), but it’s probably close. The value
for @code{StackProbeDEPTH} is thus chosen to be a round number that’s
comfortably larger than this.

@node Interface<15>,Issues,Design<5>,Stack probe
@anchor{design/sp interface}@anchor{905}
@subsection Interface


@geindex StackProbe (C function)
@anchor{design/sp c StackProbe}@anchor{906}
@deffn {C Function} void StackProbe (Size depth)
@end deffn

@anchor{design/sp design mps sp if probe}@anchor{907}@ref{907,,.if.probe;} If there are at least @code{depth} words of stack
available, return. If not, provoke a stack overflow fault.

@node Issues,Implementations<4>,Interface<15>,Stack probe
@anchor{design/sp issues}@anchor{908}
@subsection Issues


@anchor{design/sp design mps sp issue an}@anchor{909}@ref{909,,.issue.an;} The generic implementation is non-functional. This means
that it is only suitable for use with programs that do not handle
stack overflow faults, or do not call into the MPS from the handler.
This is because our customers have only required @ref{8fa,,.req.overflow} on
Windows so far. If this becomes a requirement on other platforms, the
following Standard C implementation might work:

@example
void StackProbe(Size depth) @{
  volatile Word w;
  Word *p = &w - depth;
  w = *p;
@}
@end example

The use of @code{volatile} here is to prevent compilers from warning
about the variable @code{w} being written but never read, or worse,
optimizing away the whole statement under the “as if” rule.

@node Implementations<4>,,Issues,Stack probe
@anchor{design/sp implementations}@anchor{90a}
@subsection Implementations


@anchor{design/sp design mps sp impl an}@anchor{90b}@ref{90b,,.impl.an;} Generic implementation in @code{span.c}. This implementation
does nothing. See @ref{909,,.issue.an}.

@anchor{design/sp design mps sp impl w3i3}@anchor{90c}@ref{90c,,.impl.w3i3;} Implementation for Windows on IA-32 in @code{spw3i3.c}.
This uses assembly to get the stack pointer (from the ESP register)
and to read the location @code{depth} words below the stack pointer.

@anchor{design/sp design mps sp impl w3i6}@anchor{90d}@ref{90d,,.impl.w3i6;} Implementation for Windows on x86-64 in @code{spw3i6.c}.
This passes the argument @code{depth*sizeof(Word)} to the Windows
function _alloca()@footnote{https://docs.microsoft.com/en-gb/cpp/c-runtime-library/reference/alloca}, for which the documentation says, “A stack
overflow exception is generated if the space cannot be allocated.”

@geindex splay trees; design

@node Splay trees,Stack and register scanning,Stack probe,Design
@anchor{design/splay doc}@anchor{90e}@anchor{design/splay alloca}@anchor{90f}@anchor{design/splay design-splay}@anchor{910}@anchor{design/splay splay-trees}@anchor{911}
@section Splay trees


@menu
* Introduction: Introduction<34>. 
* Overview: Overview<7>. 
* Definitions: Definitions<5>. 
* Requirements: Requirements<21>. 
* Generic binary tree interface:: 
* Splay tree interface:: 
* Client-determined properties:: 
* Usage:: 
* Implementation: Implementation<12>. 
* Testing: Testing<4>. 
* Error Handling:: 
* Future: Future<2>. 
* References: References<13>. 

@end menu

@node Introduction<34>,Overview<7>,,Splay trees
@anchor{design/splay design mps splay}@anchor{912}@anchor{design/splay introduction}@anchor{913}
@subsection Introduction


@anchor{design/splay design mps splay intro}@anchor{914}@ref{914,,.intro;} This document explains the design of impl.c.splay, an
implementation of Splay Trees, including its interface and
implementation.

@anchor{design/splay design mps splay readership}@anchor{915}@ref{915,,.readership;} This document is intended for any MM developer.

@anchor{design/splay design mps splay source}@anchor{916}@ref{916,,.source;} The primary sources for this design are @ref{917,,[ST85]} and
@ref{918,,[Sleator96]}. As CBS is a client, design.mps.cbs@footnote{cbs.html}. As PoolMVFF is an
indirect client, design.mps.poolmvff@footnote{poolmvff.html}. Also, as PoolMVT is an indirect
client, design.mps.poolmvt@footnote{poolmvt.html}.

@anchor{design/splay design mps splay background}@anchor{919}@ref{919,,.background;} The following background documents influence the design:
guide.impl.c.adt(0).

@node Overview<7>,Definitions<5>,Introduction<34>,Splay trees
@anchor{design/splay overview}@anchor{91a}
@subsection Overview


@anchor{design/splay design mps splay overview}@anchor{91b}@ref{91b,,.overview;} Splay trees are a form of binary tree where each access
brings the accessed element (or the nearest element) to the root of
the tree. The restructuring of the tree caused by the access gives
excellent amortised performance, as the splay tree adapts its shape to
usage patterns. Unused nodes have essentially no time overhead.

@node Definitions<5>,Requirements<21>,Overview<7>,Splay trees
@anchor{design/splay definitions}@anchor{91c}
@subsection Definitions


@anchor{design/splay design mps splay def splay-tree}@anchor{91d}@ref{91d,,.def.splay-tree;} A `splay tree' is a self-adjusting binary tree as
described in @ref{917,,[ST85]} and @ref{918,,[Sleator96]}.

@anchor{design/splay design mps splay def node}@anchor{91e}@ref{91e,,.def.node;} A `node' is used in the typical data structure sense to
mean an element of a tree (see also @ref{91f,,.type.tree}).

@anchor{design/splay design mps splay def key}@anchor{920}@ref{920,,.def.key;} A `key' is a value associated with each node; the keys
are totally ordered by a client provided comparator.

@anchor{design/splay design mps splay def comparator}@anchor{921}@ref{921,,.def.comparator;} A `comparator' is a function that compares keys to
determine their ordering (see also @ref{922,,.type.tree.compare.function}).

@anchor{design/splay design mps splay def successor}@anchor{923}@ref{923,,.def.successor;} Node `N'@w{[2]} is the `successor' of node
`N'@w{[1]} if `N'@w{[1]} and `N'@w{[2]} are
both in the same tree, and the key of `N'@w{[2]} immediately
follows the key of `N'@w{[1]} in the ordering of all keys for
the tree.

@anchor{design/splay design mps splay def left-child}@anchor{924}@ref{924,,.def.left-child;} Each node `N' contains a `left child', which is a
(possibly empty) sub-tree of nodes. The key of `N' is ordered after
the keys of all nodes in this sub-tree.

@anchor{design/splay design mps splay def right-child}@anchor{925}@ref{925,,.def.right-child;} Each node `N' contains a `right child', which is
a (possibly empty) sub-tree of nodes. The key of `N' is ordered before
the keys of all nodes in this sub-tree.

@anchor{design/splay design mps splay def neighbour}@anchor{926}@ref{926,,.def.neighbour;} The `left neighbour' of a key `K' is the node `N'
with the largest key that compares less than `K' in the total order.
The `right neighbour' of a key `K' is the node `N' with the smaller
key that compares greater than `K' in the total order. A node is a
`neighbour' of a key if it is either the left or right neighbour of
the key.

@anchor{design/splay design mps splay def first}@anchor{927}@ref{927,,.def.first;} A node is the `first' node in a set of nodes if its key
compares less than the keys of all other nodes in the set.

@anchor{design/splay design mps splay def last}@anchor{928}@ref{928,,.def.last;} A node is the `last' node in a set of nodes if its key
compares greater than the keys of all other nodes in the set.

@anchor{design/splay design mps splay def client-property}@anchor{929}@ref{929,,.def.client-property;} A `client property' is a value that the
client may associate with each node in addition to the key (a block
size, for example). This splay tree implementation provides support
for efficiently finding the first or last nodes with suitably large
client property values. See also @ref{92a,,.prop} below.

@node Requirements<21>,Generic binary tree interface,Definitions<5>,Splay trees
@anchor{design/splay requirements}@anchor{92b}
@subsection Requirements


@anchor{design/splay design mps splay req}@anchor{92c}@ref{92c,,.req;} These requirements are drawn from those implied by
design.mps.poolmvt@footnote{poolmvt.html}, design.mps.poolmvff@footnote{poolmvff.html}, design.mps.cbs@footnote{cbs.html}, and
general inferred MPS requirements.

@anchor{design/splay design mps splay req order}@anchor{92d}@ref{92d,,.req.order;} Must maintain a set of abstract keys which is totally
ordered for a comparator.

@anchor{design/splay design mps splay req fast}@anchor{92e}@ref{92e,,.req.fast;} Common operations must have low amortized cost.

@anchor{design/splay design mps splay req add}@anchor{92f}@ref{92f,,.req.add;} Must be able to add new nodes. This is a common
operation.

@anchor{design/splay design mps splay req remove}@anchor{930}@ref{930,,.req.remove;} Must be able to remove nodes. This is a common
operation.

@anchor{design/splay design mps splay req locate}@anchor{931}@ref{931,,.req.locate;} Must be able to locate a node, given a key. This is
a common operation.

@anchor{design/splay design mps splay req neighbours}@anchor{932}@ref{932,,.req.neighbours;} Must be able to locate the neighbouring nodes of a
key (see @ref{926,,.def.neighbour}). This is a common operation.

@anchor{design/splay design mps splay req iterate}@anchor{933}@ref{933,,.req.iterate;} Must be able to iterate over all nodes in key order
with reasonable efficiency.

@anchor{design/splay design mps splay req protocol}@anchor{934}@ref{934,,.req.protocol;} Must support detection of protocol violations.

@anchor{design/splay design mps splay req debug}@anchor{935}@ref{935,,.req.debug;} Must support debugging of clients.

@anchor{design/splay design mps splay req stack}@anchor{936}@ref{936,,.req.stack;} Must do all non-debugging operations with stack usage
bounded by a constant size.

@anchor{design/splay design mps splay req adapt}@anchor{937}@ref{937,,.req.adapt;} Must adapt to regularities in usage pattern, for better
performance.

@anchor{design/splay design mps splay req property}@anchor{938}@ref{938,,.req.property;} Must permit a client to associate a client property
(such as a size) with each node in the tree.

@anchor{design/splay design mps splay req property change}@anchor{939}@ref{939,,.req.property.change;} Must permit a client to dynamically reassign
client properties to nodes in the tree. This is a common operation.

@anchor{design/splay design mps splay req property find}@anchor{93a}@ref{93a,,.req.property.find;} Must support rapid finding of the first and
last nodes which have a suitably large value for their client
property. This is a common operation.

@anchor{design/splay design mps splay req root}@anchor{93b}@ref{93b,,.req.root;} Must be able to find the root of a splay tree (if one
exists).

@node Generic binary tree interface,Splay tree interface,Requirements<21>,Splay trees
@anchor{design/splay generic-binary-tree-interface}@anchor{93c}
@subsection Generic binary tree interface


@menu
* Types: Types<7>. 
* Functions: Functions<5>. 

@end menu

@node Types<7>,Functions<5>,,Generic binary tree interface
@anchor{design/splay types}@anchor{93d}
@subsubsection Types


@geindex Tree (C type)
@anchor{design/splay c Tree}@anchor{93e}
@deffn {C Type} typedef struct TreeStruct *Tree
@end deffn

@anchor{design/splay design mps splay type tree}@anchor{91f}@ref{91f,,.type.tree;} @code{Tree} is the type of a node in a binary tree.
@code{Tree} contains no fields to store the key associated with the node,
or the client property. Again, it is intended that the @code{TreeStruct}
can be embedded in another structure, and that this is how the
association will be made (see @ref{93f,,.usage.client-node} for an example).
No convenience functions are provided for allocation or deallocation.

@geindex TreeKey (C type)
@anchor{design/splay c TreeKey}@anchor{940}
@deffn {C Type} typedef void *TreeKey
@end deffn

@anchor{design/splay design mps splay type treekey}@anchor{941}@ref{941,,.type.treekey;} @code{TreeKey} is the type of a key associated with a
node in a binary tree. It is an alias for @code{void *} but expresses the
intention.

@geindex TreeKeyFunction (C type)
@anchor{design/splay c TreeKeyFunction}@anchor{601}
@deffn {C Type} typedef @ref{940,,TreeKey} (*TreeKeyFunction)(@ref{93e,,Tree} tree)
@end deffn

@anchor{design/splay design mps splay type tree key function}@anchor{942}@ref{942,,.type.tree.key.function;} A function of type @code{TreeKey} returns the
key associated with a node in a binary tree. (Since there is no space
in a @code{TreeStruct} to store a key, it is expected that the
@code{TreeStruct} is embedded in another structure from which the key can
be extracted.)

@geindex TreeCompareFunction (C type)
@anchor{design/splay c TreeCompareFunction}@anchor{943}
@deffn {C Type} typedef @ref{944,,Compare} (*TreeCompareFunction)(@ref{93e,,Tree} tree, @ref{940,,TreeKey} key)
@end deffn

@anchor{design/splay design mps splay type tree compare function}@anchor{922}@ref{922,,.type.tree.compare.function;} A function of type @ref{943,,TreeCompareFunction} is
required to compare @code{key} with the key the client associates with
that splay tree node @code{tree}, and return the appropriate Compare
value (see @ref{945,,.usage.compare} for an example). The function compares a
key with a node, rather than a pair of keys or nodes as might seem
more obvious. This is because the details of the mapping between nodes
and keys is left to the client (see @ref{91f,,.type.tree}), and the splaying
operations compare keys with nodes (see @ref{946,,.impl.splay}).

@geindex TreeDescribeFunction (C type)
@anchor{design/splay c TreeDescribeFunction}@anchor{947}
@deffn {C Type} typedef @ref{55f,,Res} (*TreeDescribeFunction)(@ref{93e,,Tree} tree, @ref{2d3,,mps_lib_FILE} *stream)
@end deffn

@anchor{design/splay design mps splay type tree describe function}@anchor{948}@ref{948,,.type.tree.describe.function;} A function of type
@ref{947,,TreeDescribeFunction} is required to write (via @ref{446,,WriteF()}) a
client-oriented representation of the splay node. The output should be
non-empty, short, and without newline characters. This is provided for
debugging only.

@node Functions<5>,,Types<7>,Generic binary tree interface
@anchor{design/splay functions}@anchor{949}
@subsubsection Functions


@geindex TreeCheck (C function)
@anchor{design/splay c TreeCheck}@anchor{94a}
@deffn {C Function} @ref{3a9,,Bool} TreeCheck (Tree tree)
@end deffn

@anchor{design/splay design mps splay function tree check}@anchor{94b}@ref{94b,,.function.tree.check;} This is a check function for the
@code{Tree} type (see guide.impl.c.adt.method.check and
design.mps.check@footnote{check.html}).

@node Splay tree interface,Client-determined properties,Generic binary tree interface,Splay trees
@anchor{design/splay design-mps-check}@anchor{94c}@anchor{design/splay splay-tree-interface}@anchor{94d}
@subsection Splay tree interface


@menu
* Types: Types<8>. 
* Functions: Functions<6>. 

@end menu

@node Types<8>,Functions<6>,,Splay tree interface
@anchor{design/splay id5}@anchor{94e}
@subsubsection Types


@geindex SplayTree (C type)
@anchor{design/splay c SplayTree}@anchor{94f}
@deffn {C Type} typedef struct SplayTreeStruct *SplayTree
@end deffn

@anchor{design/splay design mps splay type splay tree}@anchor{950}@ref{950,,.type.splay.tree;} @ref{94f,,SplayTree} is the type of the main object at
the root of the splay tree. It is intended that the
@code{SplayTreeStruct} can be embedded in another structure (see
@ref{951,,.usage.client-tree} for an example). No convenience functions are
provided for allocation or deallocation.

@geindex SplayTestNodeFunction (C type)
@anchor{design/splay c SplayTestNodeFunction}@anchor{952}
@deffn {C Type} typedef @ref{3a9,,Bool} (*SplayTestNodeFunction)(@ref{94f,,SplayTree} splay, @ref{93e,,Tree} tree, void *closure)
@end deffn

@anchor{design/splay design mps splay type splay test node function}@anchor{953}@ref{953,,.type.splay.test.node.function;} A function of type
@ref{952,,SplayTestNodeFunction} required to determine whether the node itself
meets some client determined property (see @ref{92a,,.prop} and
@ref{954,,.usage.test.node} for an example). The @code{closure}
parameter describes the environment for the function (see
@ref{955,,.function.splay.find.first} and @ref{956,,.function.splay.find.last}).

@geindex SplayTestTreeFunction (C type)
@anchor{design/splay c SplayTestTreeFunction}@anchor{957}
@deffn {C Type} typedef @ref{3a9,,Bool} (*SplayTestTreeFunction)(@ref{94f,,SplayTree} splay, @ref{93e,,Tree} tree, void *closure)
@end deffn

@anchor{design/splay design mps splay type splay test tree function}@anchor{958}@ref{958,,.type.splay.test.tree.function;} A function of type
@ref{957,,SplayTestTreeFunction} is required to determine whether any of the
nodes in the sub-tree rooted at the given node meet some client
determined property (see @ref{92a,,.prop} and @ref{959,,.usage.test.tree} for an
example). In particular, it must be a precise (not conservative)
indication of whether there are any nodes in the sub-tree for which
the @code{testNode} function (see @ref{953,,.type.splay.test.node.function}) would
return @code{TRUE}. The @code{closure} parameter describes the
environment for the function (see @ref{955,,.function.splay.find.first} and
@ref{956,,.function.splay.find.last}).

@geindex SplayUpdateNodeFunction (C type)
@anchor{design/splay c SplayUpdateNodeFunction}@anchor{95a}
@deffn {C Type} typedef void (*SplayUpdateNodeFunction)(@ref{94f,,SplayTree} splay, @ref{93e,,Tree} tree)
@end deffn

@anchor{design/splay design mps splay type splay update node function}@anchor{95b}@ref{95b,,.type.splay.update.node.function;} A function of type
@ref{95a,,SplayUpdateNodeFunction} is required to update any client data
structures associated with a node to maintain some client determined
property (see @ref{92a,,.prop}) given that the children of the node have
changed. (See @ref{95c,,.usage.callback} for an example)

@node Functions<6>,,Types<8>,Splay tree interface
@anchor{design/splay id6}@anchor{95d}
@subsubsection Functions


@anchor{design/splay design mps splay function no-thread}@anchor{95e}@ref{95e,,.function.no-thread;} The interface functions are not designed to be
either thread-safe or re-entrant. Clients of the interface are
responsible for synchronization, and for ensuring that client-provided
functions invoked by the splay module (@ref{922,,.type.tree.compare.function},
@ref{942,,.type.tree.key.function}, @ref{953,,.type.splay.test.node.function},
@ref{958,,.type.splay.test.tree.function}, @ref{95b,,.type.splay.update.node.function}) do
not call functions of the splay module.

@geindex SplayTreeCheck (C function)
@anchor{design/splay c SplayTreeCheck}@anchor{95f}
@deffn {C Function} @ref{3a9,,Bool} SplayTreeCheck (SplayTree splay)
@end deffn

@anchor{design/splay design mps splay function splay tree check}@anchor{960}@ref{960,,.function.splay.tree.check;} This is a check function for the
@ref{94f,,SplayTree} type (see guide.impl.c.adt.method.check and
design.mps.check@footnote{check.html}).

@geindex SplayTreeInit (C function)
@anchor{design/splay c SplayTreeInit}@anchor{961}
@deffn {C Function} void SplayTreeInit (SplayTree splay, TreeCompareFunction compare, TreeKeyFunction nodeKey, SplayUpdateNodeFunction updateNode)
@end deffn

@anchor{design/splay design mps splay function splay tree init}@anchor{962}@ref{962,,.function.splay.tree.init;} This function initialises a
@ref{94f,,SplayTree} (see guide.impl.c.adt.method.init). The @code{nodeKey}
function extracts a key from a tree node, and the @code{compare} function
defines a total ordering on keys of nodes (see @ref{92d,,.req.order}). The
effect of supplying a compare function that does not implement a total
ordering is undefined. The @code{updateNode} function is used to keep
client properties up to date when the tree structure changes; the
value @code{SplayTrivUpdate} may be used for this function if there is no
need to maintain client properties. (See @ref{963,,.usage.initialization} for
an example use).

@geindex SplayTreeFinish (C function)
@anchor{design/splay c SplayTreeFinish}@anchor{964}
@deffn {C Function} void SplayTreeFinish (SplayTree splay)
@end deffn

@anchor{design/splay design mps splay function splay tree finish}@anchor{965}@ref{965,,.function.splay.tree.finish;} This function clears the fields of a
@ref{94f,,SplayTree} (see guide.impl.c.adt.method.finish). Note that it does
not attempt to finish or deallocate any associated @code{Tree}
objects; clients wishing to destroy a non-empty @ref{94f,,SplayTree} must
first explicitly descend the tree and call @code{TreeFinish()} on
each node from the bottom up.

@geindex SplayTreeInsert (C function)
@anchor{design/splay c SplayTreeInsert}@anchor{966}
@deffn {C Function} @ref{3a9,,Bool} SplayTreeInsert (SplayTree splay, Tree tree, void *key)
@end deffn

@anchor{design/splay design mps splay function splay tree insert}@anchor{967}@ref{967,,.function.splay.tree.insert;} This function is used to insert into a
splay tree a new node which is associated with the supplied key (see
@ref{92f,,.req.add}). It first splays the tree at the key. If an attempt is
made to insert a node that compares @code{CompareEQUAL} to an existing
node in the tree, then @code{FALSE} will be returned and the node will
not be inserted. (See @ref{968,,.usage.insert} for an example use).

@geindex SplayTreeDelete (C function)
@anchor{design/splay c SplayTreeDelete}@anchor{969}
@deffn {C Function} @ref{3a9,,Bool} SplayTreeDelete (SplayTree splay, Tree tree, void *key)
@end deffn

@anchor{design/splay design mps splay function splay tree delete}@anchor{96a}@ref{96a,,.function.splay.tree.delete;} This function is used to delete from a
splay tree a node which is associated with the supplied key (see
@ref{930,,.req.remove}). If the tree does not contain the given node, or the
given node does not compare @code{CompareEQUAL} with the given key, then
@code{FALSE} will be returned, and the node will not be deleted. The
function first splays the tree at the given key. (See @ref{96b,,.usage.delete}
for an example use).

@geindex SplayTreeFind (C function)
@anchor{design/splay c SplayTreeFind}@anchor{96c}
@deffn {C Function} @ref{3a9,,Bool} SplayTreeFind (Tree *nodeReturn, SplayTree splay, TreeKey key)
@end deffn

@anchor{design/splay design mps splay function splay tree find}@anchor{96d}@ref{96d,,.function.splay.tree.find;} Search the splay tree for a node that
compares @code{CompareEQUAL} to the given key (see @ref{931,,.req.locate}), and
splay the tree at the key. Return @code{FALSE} if there is no such node
in the tree, otherwise set @code{*nodeReturn} to the node and return
@code{TRUE}.

@geindex SplayTreeNeighbours (C function)
@anchor{design/splay c SplayTreeNeighbours}@anchor{96e}
@deffn {C Function} @ref{3a9,,Bool} SplayTreeNeighbours (Tree *leftReturn, Tree *rightReturn, SplayTree splay, TreeKey key)
@end deffn

@anchor{design/splay design mps splay function splay tree neighbours}@anchor{96f}@ref{96f,,.function.splay.tree.neighbours;} Search a splay tree for the two
nodes that are the neighbours of the given key (see
@ref{932,,.req.neighbours}). Splay the tree at the key. If any node in the
tree compares @code{CompareEQUAL} with the given key, return @code{FALSE}.
Otherwise return @code{TRUE}, set @code{*leftReturn} to the left neighbour
of the key (or @code{TreeEMPTY} if the key has no left neighbour), and
set @code{*rightReturn} to the right neighbour of the key (or
@code{TreeEMPTY} if the key has no right neighbour). See @ref{968,,.usage.insert}
for an example of use.

@geindex SplayTreeFirst (C function)
@anchor{design/splay c SplayTreeFirst}@anchor{970}
@deffn {C Function} @ref{93e,,Tree} SplayTreeFirst (SplayTree splay)
@end deffn

@anchor{design/splay design mps splay function splay tree first}@anchor{971}@ref{971,,.function.splay.tree.first;} If the tree has no nodes, return
@code{TreeEMPTY}. Otherwise, splay the tree at the first node, and return
that node (see @ref{933,,.req.iterate}).

@geindex SplayTreeNext (C function)
@anchor{design/splay c SplayTreeNext}@anchor{972}
@deffn {C Function} @ref{93e,,Tree} SplayTreeNext (SplayTree splay, TreeKey key)
@end deffn

@anchor{design/splay design mps splay function splay tree next}@anchor{973}@ref{973,,.function.splay.tree.next;} If the tree contains a right neighbour
for @code{key}, splay the tree at that node and return it. Otherwise
return @code{TreeEMPTY}. See @ref{933,,.req.iterate}.

@geindex SplayTreeDescribe (C function)
@anchor{design/splay c SplayTreeDescribe}@anchor{974}
@deffn {C Function} @ref{55f,,Res} SplayTreeDescribe (SplayTree splay, mps_lib_FILE *stream, Count depth, TreeDescribeFunction nodeDescribe)
@end deffn

@anchor{design/splay design mps splay function splay tree describe}@anchor{975}@ref{975,,.function.splay.tree.describe;} This function prints (using
@ref{446,,WriteF()}) to the stream a textual representation of the given
splay tree, using @code{nodeDescribe} to print client-oriented
representations of the nodes (see @ref{935,,.req.debug}). Provided for
debugging only.

@geindex SplayFindFirst (C function)
@anchor{design/splay c SplayFindFirst}@anchor{41b}
@deffn {C Function} @ref{3a9,,Bool} SplayFindFirst (Tree *nodeReturn, SplayTree splay, SplayTestNodeFunction testNode, SplayTestTreeFunction testTree, void *closure)
@end deffn

@anchor{design/splay design mps splay function splay find first}@anchor{955}@ref{955,,.function.splay.find.first;} Find the first node in the tree that
satisfies some client property, as determined by the @code{testNode} and
@code{testTree} functions (see @ref{93a,,.req.property.find}). @code{closure}
is an arbitrary value, and is passed to the @code{testNode}
and @code{testTree} functions. If there is no satisfactory node, return @code{FALSE};
otherwise set @code{*nodeReturn} to the node and return @code{TRUE}. See
@ref{96b,,.usage.delete} for an example.

@geindex SplayFindLast (C function)
@anchor{design/splay c SplayFindLast}@anchor{976}
@deffn {C Function} @ref{3a9,,Bool} SplayFindLast (Tree *nodeReturn, SplayTree splay, SplayTestNodeFunction testNode, SplayTestTreeFunction testTree, void *closure)
@end deffn

@anchor{design/splay design mps splay function splay find last}@anchor{956}@ref{956,,.function.splay.find.last;} As @ref{41b,,SplayFindFirst()}, but find the
last node in the tree that satisfies the client property.

@geindex SplayNodeRefresh (C function)
@anchor{design/splay c SplayNodeRefresh}@anchor{977}
@deffn {C Function} void SplayNodeRefresh (SplayTree splay, Tree tree, TreeKey key)
@end deffn

@anchor{design/splay design mps splay function splay node refresh}@anchor{978}@ref{978,,.function.splay.node.refresh;} Call the @code{updateNode} function on the
given node, and on any other nodes that may require updating. The
client key for the node must also be supplied; the function splays the
tree at this key. (See @ref{968,,.usage.insert} for an example use). This
function must be called whenever the client property (see @ref{92a,,.prop}) at
a node changes (see @ref{939,,.req.property.change}).

@geindex SplayNodeUpdate (C function)
@anchor{design/splay c SplayNodeUpdate}@anchor{979}
@deffn {C Function} void SplayNodeUpdate (SplayTree splay, Tree node)
@end deffn

@anchor{design/splay design mps splay function splay node update}@anchor{97a}@ref{97a,,.function.splay.node.update;} Call the @code{updateNode} function on the
given node, but leave other nodes unchanged. This may be called when a
new node is created, to get the client property off the ground.

@node Client-determined properties,Usage,Splay tree interface,Splay trees
@anchor{design/splay client-determined-properties}@anchor{97b}
@subsection Client-determined properties


@anchor{design/splay design mps splay prop}@anchor{92a}@ref{92a,,.prop;} To support @ref{93a,,.req.property.find}, this splay tree
implementation provides additional features to permit clients to cache
maximum (or minimum) values of client properties for all the nodes in
a subtree. The splay tree implementation uses the cached values as
part of @ref{41b,,SplayFindFirst()} and @ref{976,,SplayFindLast()} via the
@code{testNode} and @code{testTree} functions. The client is free to choose
how to represent the client property, and how to compute and store the
cached value.

@anchor{design/splay design mps splay prop update}@anchor{97c}@ref{97c,,.prop.update;} The cached values depend upon the topology of the
tree, which may vary as a result of operations on the tree. The client
is given the opportunity to compute new cache values whenever
necessary, via the @code{updateNode} function (see
@ref{962,,.function.splay.tree.init}). This happens whenever the tree is
restructured. The client may use the @ref{977,,SplayNodeRefresh()} function to
indicate that the client attributes at a node have changed (see
@ref{939,,.req.property.change}). A call to @ref{977,,SplayNodeRefresh()} splays the
tree at the specified node, which may provoke calls to the
@code{updateNode} function as a result of the tree restructuring. The
@code{updateNode} function will also be called whenever a new splay node is
inserted into the tree.

@anchor{design/splay design mps splay prop example}@anchor{97d}@ref{97d,,.prop.example;} For example, if implementing an address-ordered tree
of free blocks using a splay tree, a client might choose to use the
base address of each block as the key for each node, and the size of
each block as the client property. The client can then maintain as a
cached value in each node the size of the largest block in the subtree
rooted at that node. This will permit a fast search for the first or
last block of at least a given size. See @ref{95c,,.usage.callback} for an
example @code{updateNode} function for such a client.

@anchor{design/splay design mps splay prop ops}@anchor{97e}@ref{97e,,.prop.ops;} The splay operations must cause client properties for
nodes to be updated in the following circumstances (see @ref{97f,,.impl} for
details):

@anchor{design/splay design mps splay prop ops rotate}@anchor{980}@ref{980,,.prop.ops.rotate;} rotate left, rotate right – We need to update
the value at the original root, and the new root, in that order.

@anchor{design/splay design mps splay prop ops link}@anchor{981}@ref{981,,.prop.ops.link;} link left, link right – We know that the line of
right descent from the root of the left tree and the line of left
descent from the root of the right tree will both need to be updated.
This is performed at the assembly stage. (We could update these chains
every time we do a link left or link right instead, but this would be
less efficient)

@anchor{design/splay design mps splay prop ops assemble}@anchor{982}@ref{982,,.prop.ops.assemble;} assemble – This operation also invalidates the
lines of right and left descent of the left and right trees
respectively which need to be updated (see below). It also invalidates
the root which must be updated last.

@anchor{design/splay design mps splay prop ops assemble reverse}@anchor{983}@ref{983,,.prop.ops.assemble.reverse;} To correct the chains of the left and
right trees without requiring stack or high complexity, we use a
judicious amount of pointer reversal.

@anchor{design/splay design mps splay prop ops assemble traverse}@anchor{984}@ref{984,,.prop.ops.assemble.traverse;} During the assembly, after the root’s
children have been transplanted, we correct the chains of the left and
right trees. For the left tree, we traverse the right child line,
reversing pointers, until we reach the node that was the last node
prior to the transplantation of the root’s children. Then we update
from that node back to the left tree’s root, restoring pointers.
Updating the right tree is the same, mutatis mutandis.

@node Usage,Implementation<12>,Client-determined properties,Splay trees
@anchor{design/splay usage}@anchor{985}
@subsection Usage


@anchor{design/splay design mps splay usage}@anchor{986}@ref{986,,.usage;} Here’s a simple example of a client which uses a splay tree
to implement an address ordered tree of free blocks. The significant
client usages of the splay tree interface might look as follows:-

@anchor{design/splay design mps splay usage client-tree}@anchor{951}@ref{951,,.usage.client-tree;} Tree structure to embed a @ref{94f,,SplayTree} (see
@ref{950,,.type.splay.tree}):

@example
typedef struct FreeTreeStruct @{
  SplayTreeStruct splayTree;  /* Embedded splay tree */
  /* no obvious client fields for this simple example */
@} FreeTreeStruct;
@end example

@anchor{design/splay design mps splay usage client-node}@anchor{93f}@ref{93f,,.usage.client-node;} Node structure to embed a @code{Tree} (see @ref{91f,,.type.tree}):

@example
typedef struct FreeBlockStruct @{
  TreeStruct treeStruct; /* embedded splay node */
  Addr base;             /* base address of block is also the key */
  Size size;             /* size of block is also the client property */
  Size maxSize;          /* cached value for maximum size in subtree */
@} FreeBlockStruct;
@end example

@anchor{design/splay design mps splay usage callback}@anchor{95c}@ref{95c,,.usage.callback;} @code{updateNode} callback function (see
@ref{95b,,.type.splay.update.node.function}):

@example
void FreeBlockUpdateNode(SplayTree splay, Tree tree)
@{
  /* Compute the maximum size of any block in this subtree. */
  /* The value to cache is the maximum of the size of this block, */
  /* the cached value for the left subtree (if any) and the cached */
  /* value of the right subtree (if any) */

  FreeBlock freeNode = FreeBlockOfTree(tree);

  Size maxSize = freeNode.size;

  if (TreeHasLeft(tree)) @{
    FreeBlock leftNode = FreeBlockOfTree(TreeLeft(tree));
    if(leftNode.maxSize > maxSize)
      maxSize = leftNode->maxSize;
  @}

  if (TreeHasRight(tree)) @{
    FreeBlock rightNode = FreeBlockOfTree(TreeRight(tree));
    if(rightNode.maxSize > maxSize)
      maxSize = rightNode->maxSize;
  @}

  freeNode->maxSize = maxSize;
@}
@end example

@anchor{design/splay design mps splay usage compare}@anchor{945}@ref{945,,.usage.compare;} Comparison function (see @ref{922,,.type.tree.compare.function}):

@example
Compare FreeBlockCompare(Tree tree, TreeKey key) @{
  Addr base1, base2, limit2;
  FreeBlock freeNode = FreeBlockOfTree(tree);

  base1 = (Addr)key;
  base2 = freeNode->base;
  limit2 = AddrAdd(base2, freeNode->size);

  if (base1 < base2)
    return CompareLESS;
  else if (base1 >= limit2)
    return CompareGREATER;
  else
    return CompareEQUAL;
@}
@end example

@anchor{design/splay design mps splay usage test tree}@anchor{959}@ref{959,,.usage.test.tree;} Test tree function (see
@ref{958,,.type.splay.test.tree.function}):

@example
Bool FreeBlockTestTree(SplayTree splay, Tree tree,
                       void *closure) @{
  /* Closure environment has wanted size as value of *closure. */
  /* Look at the cached value for the node to see if any */
  /* blocks in the subtree are big enough. */

  Size size = *(Size *)closure;
  FreeBlock freeNode = FreeBlockOfTree(tree);
  return freeNode->maxSize >= size;
@}
@end example

@anchor{design/splay design mps splay usage test node}@anchor{954}@ref{954,,.usage.test.node;} Test node function (see
@ref{953,,.type.splay.test.node.function}):

@example
Bool FreeBlockTestNode(SplayTree splay, Tree tree,
                       void *closure) @{
  /* Closure environment has wanted size as value of *closure. */
  /* Look at the size of the node to see if is big enough. */

  Size size = *(Size *)closure;
  FreeBlock freeNode = FreeBlockOfTree(tree);
  return freeNode->size >= size;
@}
@end example

@anchor{design/splay design mps splay usage initialization}@anchor{963}@ref{963,,.usage.initialization;} Client’s initialization function (see
@ref{962,,.function.splay.tree.init}):

@example
void FreeTreeInit(FreeTree freeTree) @{
  /* Initialize the embedded splay tree. */
  SplayTreeInit(&freeTree->splayTree, FreeBlockCompare, FreeBlockUpdateNode);
@}
@end example

@anchor{design/splay design mps splay usage insert}@anchor{968}@ref{968,,.usage.insert;} Client function to add a new free block into the
tree, merging it with an existing block if possible:

@example
void FreeTreeInsert(FreeTree freeTree, Addr base, Addr limit) @{
  SplayTree splayTree = &freeTree->splayTree;
  Tree leftNeighbour, rightNeighbour;
  TreeKey key = base;  /* use the base of the block as the key */
  Res res;

  /* Look for any neighbouring blocks. (.function.splay.tree.neighbours) */
  res = SplayTreeNeighbours(&leftNeighbour, &rightNeighbour,
                            splayTree, key);
  AVER(res == ResOK);  /* this client doesn't duplicate free blocks */

  /* Look to see if the neighbours are contiguous. */

  if (leftNeighbour != TreeEMPTY &&
      FreeBlockLimitOfSplayNode(leftNeighbour) == base) @{
    /* Inserted block is contiguous with left neighbour, so merge it. */
    /* The client housekeeping is left as an exercise to the reader. */
    /* This changes the size of a block, which is the client */
    /* property of the splay node. See :mps:ref:`.function.splay.node.refresh` */
    SplayNodeRefresh(splayTree, leftNeighbour, key);

  @} else if (rightNeighbour != TreeEMPTY &&
             FreeBlockBaseOfSplayNode(rightNeighbour) == limit) @{
    /* Inserted block is contiguous with right neighbour, so merge it. */
    /* The client housekeeping is left as an exercise to the reader. */
    /* This changes the size of a block, which is the client */
    /* property of the splay node. See :mps:ref:`.function.splay.node.refresh` */
    SplayNodeRefresh(splayTree, rightNeighbour, key);

  @} else @{
    /* Not contiguous - so insert a new node */
    FreeBlock newBlock = (FreeBlock)allocate(sizeof(FreeBlockStruct));
    Tree newTree = &newBlock->treeStruct;

    newBlock->base = base;
    newBlock->size = AddrOffset(base, limit);
    TreeInit(newTree);  /* :mps:ref:`.function.tree.init` */
    SplayNodeUpdate(splayTree, newTree); /* :mps:ref:`.function.splay.node.update` */
    /* :mps:ref:`.function.splay.tree.insert` */
    res = SplayTreeInsert(splayTree, newTree, key);
    AVER(res == ResOK);  /* this client doesn't duplicate free blocks */
  @}
@}
@end example

@anchor{design/splay design mps splay usage delete}@anchor{96b}@ref{96b,,.usage.delete;} Client function to allocate the first block of a
given size in address order. For simplicity, this allocates the entire
block:

@example
Bool FreeTreeAllocate(Addr *baseReturn, Size *sizeReturn,
                      FreeTree freeTree, Size size) @{
  SplayTree splayTree = &freeTree->splayTree;
  Tree splayNode;
  Bool found;

  /* look for the first node of at least the given size. */
  /* closure parameter is not used. See `.function.splay.find.first.`_  */
  found = SplayFindFirst(&splayNode, splayTree,
                         FreeBlockTestNode, FreeBlockTestTree,
                         NULL, size);

  if (found) @{
    FreeBlock freeNode = FreeBlockOfTree(splayNode);
    Void *key = (void *)freeNode->base;  /* use base of block as the key */
    Res res;

    /* allocate the block */
    *baseReturn = freeNode->base;
    *sizeReturn = freeNode->size;

    /* :mps:ref:`.function.splay.tree.delete` */
    res = SplayTreeDelete(splayTree, splayNode, key);
    AVER(res == ResOK);  /* Must be possible to delete node */

    /* Delete the block */
    deallocate(freeNode, (sizeof(FreeBlockStruct));

    return TRUE;

  @} else @{
    /* No suitable block */
    return FALSE;
  @}
@}
@end example

@node Implementation<12>,Testing<4>,Usage,Splay trees
@anchor{design/splay implementation}@anchor{987}
@subsection Implementation


@anchor{design/splay design mps splay impl}@anchor{97f}@ref{97f,,.impl;} For more details of how splay trees work, see @ref{917,,[ST85]}.
For more details of how to implement operations on splay trees, see
@ref{918,,[Sleator96]}. Here we describe the operations involved.

@menu
* Top-down splaying:: 
* Top-level operations:: 

@end menu

@node Top-down splaying,Top-level operations,,Implementation<12>
@anchor{design/splay top-down-splaying}@anchor{988}
@subsubsection Top-down splaying


@anchor{design/splay design mps splay impl top-down}@anchor{989}@ref{989,,.impl.top-down;} The method chosen to implement the splaying
operation is called “top-down splay”. This is described as “procedure
top-down splay” in @ref{917,,[ST85]}, but the implementation here additionally
permits attempts to access items which are not known to be in the
tree. Top-down splaying is particularly efficient for the common case
where the location of the node in a tree is not known at the start of
an operation. Tree restructuring happens as the tree is descended,
whilst looking for the node.

@anchor{design/splay design mps splay impl splay}@anchor{946}@ref{946,,.impl.splay;} The key to the operation of the splay tree is the
internal function @code{SplaySplay()}. It searches the tree for a node
with a given key. In the process, it brings the found node, or an
arbitrary neighbour if not found, to the root of the tree. This
“bring-to-root” operation is performed top-down during the search, and
it is not the simplest possible bring-to-root operation, but the
resulting tree is well-balanced, and will give good amortised cost for
future calls to @code{SplaySplay()}. See @ref{917,,[ST85]}.

@anchor{design/splay design mps splay impl splay how}@anchor{98a}@ref{98a,,.impl.splay.how;} To perform this top-down splay, the tree is broken
into three parts, a left tree, a middle tree and a right tree. We
store the left tree and right tree in the right and left children
respectively of a “sides” node to eliminate some boundary conditions.
The initial condition is that the middle tree is the entire splay
tree, and the left and right trees are empty. We also keep pointers to
the last node in the left tree, and the first node in the right tree.
Note that, at all times, the three trees are each validly ordered, and
they form a partition with the ordering left, middle, right. The splay
is then performed by comparing the middle tree with the following six
cases, and performing the indicated operations, until none apply.

@anchor{design/splay design mps splay impl splay cases}@anchor{98b}@ref{98b,,.impl.splay.cases;} Note that figure 3 of @ref{917,,[ST85]} describes only 3
cases: `zig', `zig-zig' and `zig-zag'. The additional cases described
here are the symmetric variants which are respectively called `zag',
`zag-zag' and `zag-zig'. In the descriptions of these cases, @code{root}
is the root of the middle tree; @code{node->left} is the left child of
@code{node}; @code{node->right} is the right child of @code{node}. The
comparison operators (@code{<}, @code{>}, @code{==}) are defined to compare a
key and a node in the obvious way by comparing the supplied key with
the node’s associated key.

@anchor{design/splay design mps splay impl splay zig}@anchor{98c}@ref{98c,,.impl.splay.zig;} The “zig” case is where @code{key < root}, and
either:


@itemize -

@item 
@code{key == root->left};

@item 
@code{key < root->left && root->left->left == NULL}; or

@item 
@code{key > root->left && root->left->right == NULL}.
@end itemize

The operation for the zig case is: link right (see
@ref{98d,,.impl.link.right}).

@anchor{design/splay design mps splay impl splay zag}@anchor{98e}@ref{98e,,.impl.splay.zag;} The “zag” case is where @code{key > root}, and
either:


@itemize -

@item 
@code{key == root->right};

@item 
@code{key < root->right && root->right->left == NULL}; or

@item 
@code{key > root->right && root->right->right == NULL}.
@end itemize

The operation for the zag case is: link left (see @ref{98f,,.impl.link.left}).

@anchor{design/splay design mps splay impl splay zig zig}@anchor{990}@ref{990,,.impl.splay.zig.zig;} The “zig-zig” case is where


@itemize -

@item 
@code{key < root && key < root->left && root->left->left != NULL}.
@end itemize

The operation for the zig-zig case is: rotate right (see
@ref{991,,.impl.rotate.right}) followed by link right (see
@ref{98d,,.impl.link.right}).

@anchor{design/splay design mps splay impl splay zig zag}@anchor{992}@ref{992,,.impl.splay.zig.zag;} The “zig-zag” case is where


@itemize -

@item 
@code{key < root && key > root->left && root->left->right != NULL}.
@end itemize

The operation for the zig-zag case is: link right (see
@ref{98d,,.impl.link.right}) followed by link left (see @ref{98f,,.impl.link.left}).

@anchor{design/splay design mps splay impl splay zag zig}@anchor{993}@ref{993,,.impl.splay.zag.zig;} The “zag-zig” case is where


@itemize -

@item 
@code{key > root && key < root->right && root->right->left != NULL}.
@end itemize

The operation for the zag-zig case is: link left (see
@ref{98f,,.impl.link.left}) followed by link right (see @ref{98d,,.impl.link.right}).

@anchor{design/splay design mps splay impl splay zag zag}@anchor{994}@ref{994,,.impl.splay.zag.zag;} The “zag-zag” case is where


@itemize -

@item 
@code{key > root && key > root->right && root->right->right != NULL}.
@end itemize

The operation for the zag-zag case is: rotate left (see
@ref{995,,.impl.rotate.left}) followed by link left (see @ref{98f,,.impl.link.left}).

@anchor{design/splay design mps splay impl splay terminal null}@anchor{996}@ref{996,,.impl.splay.terminal.null;} A special terminal case is when


@itemize -

@item 
@code{root == NULL}.
@end itemize

This can only happen at the beginning, and cannot arise from the
operations above. In this case, the splay operation must return
@code{NULL}, and “not found”.

@anchor{design/splay design mps splay impl splay terminal found}@anchor{997}@ref{997,,.impl.splay.terminal.found;} One typical terminal case is when


@itemize -

@item 
@code{key == root}.
@end itemize

This case is tested for at the beginning, in which case “found” is
returned immediately. If this case happens as a result of other
operations, the splay operation is complete, the three trees are
assembled (see @ref{998,,.impl.assemble}), and “found” is returned.

@anchor{design/splay design mps splay impl splay terminal not-found}@anchor{999}@ref{999,,.impl.splay.terminal.not-found;} The other typical terminal cases are:


@itemize -

@item 
@code{key < root && root->left == NULL}; and

@item 
@code{key > root && root->right == NULL}.
@end itemize

In these cases, the splay operation is complete, the three trees are
assembled (see @ref{998,,.impl.assemble}), and “not found” is returned.

@anchor{design/splay design mps splay impl rotate left}@anchor{995}@ref{995,,.impl.rotate.left;} The “rotate left” operation (see @ref{917,,[ST85]}
figure 1) rearranges the middle tree as follows (where any of sub-trees
A, B and C may be empty):


@float Figure

@image{MemoryPoolSystem-figures/splay-rotate-left,,,Diagram: the rotate left operation.,svg}

@end float


@anchor{design/splay design mps splay impl rotate right}@anchor{991}@ref{991,,.impl.rotate.right;} The “rotate right” operation (see @ref{917,,[ST85]}
figure 1) rearranges the middle tree as follows (where any of sub-trees
A, B and C may be empty):


@float Figure

@image{MemoryPoolSystem-figures/splay-rotate-right,,,Diagram: the rotate right operation.,svg}

@end float


@anchor{design/splay design mps splay impl link left}@anchor{98f}@ref{98f,,.impl.link.left;} The “link left” operation (see @ref{917,,[ST85]} figure
11a for symmetric variant) rearranges the left and middle trees as
follows (where any of sub-trees A, B, L and R may be empty):


@float Figure

@image{MemoryPoolSystem-figures/splay-link-left,,,Diagram: the link left operation.,svg}

@end float


The last node of the left tree is now x.

@anchor{design/splay design mps splay impl link right}@anchor{98d}@ref{98d,,.impl.link.right;} The “link right” operation (see @ref{917,,[ST85]} figure
11a) rearranges the middle and right trees as follows (where any of
sub-trees A, B, L and R may be empty):


@float Figure

@image{MemoryPoolSystem-figures/splay-link-right,,,Diagram: the link left operation.,svg}

@end float


The first node of the right tree is now x.

@anchor{design/splay design mps splay impl assemble}@anchor{998}@ref{998,,.impl.assemble;} The “assemble” operation (see @ref{917,,[ST85]} figure 12)
merges the left and right trees with the middle tree as follows (where
any of sub-trees A, B, L and R may be empty):


@float Figure

@image{MemoryPoolSystem-figures/splay-assemble,,,Diagram: the assemble operation.,svg}

@end float


@node Top-level operations,,Top-down splaying,Implementation<12>
@anchor{design/splay top-level-operations}@anchor{99a}
@subsubsection Top-level operations


@anchor{design/splay design mps splay impl insert}@anchor{99b}@ref{99b,,.impl.insert;} @ref{966,,SplayTreeInsert()}: (See @ref{918,,[Sleator96]}, chapter
4, function insert). If the tree has no nodes, [how does it smell?]
add the inserted node and we’re done; otherwise splay the tree around
the supplied key. If the splay successfully found a matching node,
return failure. Otherwise, add the inserted node as a new root, with
the old (newly splayed, but non-matching) root as its left or right
child as appropriate, and the opposite child of the old root as the
other child of the new root.

@anchor{design/splay design mps splay impl delete}@anchor{99c}@ref{99c,,.impl.delete;} @ref{969,,SplayTreeDelete()}: (See @ref{918,,[Sleator96]}, chapter
4, function delete). Splay the tree around the supplied key. Check
that the newly splayed root is the same node as given by the caller,
and that it matches the key; return failure if not. If the given node
(now at the root) has fewer than two children, replace it (as root),
with the non-null child or null. Otherwise, set the root of the tree
to be the left child (arbitrarily) of the node to be deleted, and
splay around the same key. The new root will be the last node in the
sub-tree and will have a null right child; this is set to be the right
child of the node to be deleted.

@anchor{design/splay design mps splay impl find}@anchor{99d}@ref{99d,,.impl.find;} @ref{96c,,SplayTreeFind()}: Splay the node around the
supplied key. If the splay found a matching node, return it; otherwise
return failure.

@anchor{design/splay design mps splay impl neighbours}@anchor{99e}@ref{99e,,.impl.neighbours;} @ref{96e,,SplayTreeNeighbours()}: Splay the tree around
the supplied key. If the splay found a matching node, return failure.
Otherwise, determine whether the (non-matching) found node is the left
or right neighbour of the key (by comparison with the key). Set the
tree root to be the right or left child of that first neighbour
respectively, and again splay the tree around the supplied key. The
new root will be the second neighbour, and will have a null left or
right child respectively. Set this null child to be the first
neighbour. Return the two neighbours.

@anchor{design/splay design mps splay impl neighbours note}@anchor{99f}@ref{99f,,.impl.neighbours.note;} Note that it would be possible to implement
@ref{96e,,SplayTreeNeighbours()} with only one splay, and then a normal
binary tree search for the left or right neighbour of the root. This
would be a cheaper operation, but would give poorer amortised cost if
the call to @ref{96e,,SplayTreeNeighbours()} typically precedes a call to
@ref{966,,SplayTreeInsert()} (which is expected to be a common usage
pattern - see @ref{968,,.usage.insert}). It’s also possible to implement
@ref{96e,,SplayTreeNeighbours()} by simply keeping track of both neighbours
during a single splay. This has about the same cost as a single splay,
and hence about the same amortised cost if the call to
@ref{96e,,SplayTreeNeighbours()} typically precedes a call to
@ref{966,,SplayTreeInsert()}.

@anchor{design/splay design mps splay impl next}@anchor{9a0}@ref{9a0,,.impl.next;} @ref{972,,SplayTreeNext()}: Splay the tree around the supplied
@code{oldKey}. During iteration the “old node” found is probably already
at the root, in which case this will be a null operation with little
cost. If this old node has no right child, return @code{NULL}. Otherwise,
split the tree into a right tree (which contains just the right child
of the old node) and a left tree (which contains the old node, its
left child and no right child). The next node is the first node in the
right tree. Find this by splaying the right tree around @code{oldKey}
(which is known to compare @code{CompareLESS} than any keys in the right
tree). Rejoin the full tree, using the right tree as the root and
setting the left child of root to be the left tree. Return the root of
this tree.

@node Testing<4>,Error Handling,Implementation<12>,Splay trees
@anchor{design/splay testing}@anchor{9a1}
@subsection Testing


@anchor{design/splay design mps splay test}@anchor{9a2}@ref{9a2,,.test;} There is no plan to test splay trees directly. It is
believed that the testing described in design.mps.cbs.test@footnote{cbs.html#design.mps.cbs.test} will be
sufficient to test this implementation.

@node Error Handling,Future<2>,Testing<4>,Splay trees
@anchor{design/splay design-mps-cbs-test}@anchor{9a3}@anchor{design/splay error-handling}@anchor{9a4}
@subsection Error Handling


@anchor{design/splay design mps splay error}@anchor{9a5}@ref{9a5,,.error;} This module detects and reports most common classes of
protocol error. The cases it doesn’t handle will result in undefined
behaviour and probably cause an @code{AVER} to fire. These are:

@anchor{design/splay design mps splay error bad-pointer}@anchor{9a6}@ref{9a6,,.error.bad-pointer;} Passing an invalid pointer in place of a
@ref{94f,,SplayTree} or @code{Tree}.

@anchor{design/splay design mps splay error bad-compare}@anchor{9a7}@ref{9a7,,.error.bad-compare;} Initialising a @ref{94f,,SplayTree} with a compare
function that is not a valid compare function, or which doesn’t
implement a total ordering on splay nodes.

@anchor{design/splay design mps splay error bad-describe}@anchor{9a8}@ref{9a8,,.error.bad-describe;} Passing an invalid describe function to
@ref{974,,SplayTreeDescribe()}.

@anchor{design/splay design mps splay error out-of-stack}@anchor{9a9}@ref{9a9,,.error.out-of-stack;} Stack exhaustion under @ref{974,,SplayTreeDescribe()}.

@node Future<2>,References<13>,Error Handling,Splay trees
@anchor{design/splay future}@anchor{9aa}
@subsection Future


@anchor{design/splay design mps splay future parent}@anchor{9ab}@ref{9ab,,.future.parent;} The iterator could be made more efficient (in an
amortized sense) if it didn’t splay at each node. To implement this
(whilst meeting @ref{936,,.req.stack}) we really need parent pointers from the
nodes. We could use the (first-child, right-sibling/parent) trick
described in @ref{917,,[ST85]} to implement this, at a slight cost to all
other tree operations, and an increase in code complexity. @ref{917,,[ST85]}
doesn’t describe how to distinguish the first-child between left-child
and right-child, and the right-sibling/parent between right-sibling
and parent. One could either use the comparator to make these
distinctions, or steal some bits from the pointers.

@node References<13>,,Future<2>,Splay trees
@anchor{design/splay references}@anchor{9ac}
@subsection References


@anchor{design/splay st85}@anchor{917}@w{(ST85)} 
“Self-Adjusting Binary Search Trees”; Daniel Dominic Sleator, Robert Endre Tarjan; AT&T Bell Laboratories, Murray Hill, NJ; 1985-07; Journal of the ACM, Vol. 32, Num. 3, pp. 652-686, July 1985; <@indicateurl{https://www.cs.cmu.edu/~sleator/papers/self-adjusting.pdf}>.

@anchor{design/splay sleator96}@anchor{918}@w{(Sleator96)} 
“Splay Trees”; Daniel Dominic Sleator; CMU, 22/02/96; CMU 15-211; <@indicateurl{https://langevin.usc.edu/BST/Sleator-SplayTrees.ps}>.

@geindex stack and register scanning; design

@node Stack and register scanning,Tests,Splay trees,Design
@anchor{design/stack-scan doc}@anchor{9ad}@anchor{design/stack-scan design-stack-scan}@anchor{30e}@anchor{design/stack-scan stack-and-register-scanning}@anchor{9ae}
@section Stack and register scanning


@menu
* Introduction: Introduction<35>. 
* Requirements: Requirements<22>. 
* Design: Design<6>. 
* Analysis: Analysis<2>. 
* Interface: Interface<16>. 
* Implementations: Implementations<5>. 
* References: References<14>. 

@end menu

@node Introduction<35>,Requirements<22>,,Stack and register scanning
@anchor{design/stack-scan design mps stack-scan}@anchor{9af}@anchor{design/stack-scan introduction}@anchor{9b0}
@subsection Introduction


@anchor{design/stack-scan design mps stack-scan intro}@anchor{9b1}@ref{9b1,,.intro;} This is the design of the stack and register scanning
module.

@anchor{design/stack-scan design mps stack-scan readership}@anchor{9b2}@ref{9b2,,.readership;} Any MPS developer; anyone porting the MPS to a new
platform.

@anchor{design/stack-scan design mps stack-scan overview}@anchor{9b3}@ref{9b3,,.overview;} This module locates and scans references in the control
stack and registers of the `current' thread (the one that has called
in to the MPS).

@anchor{design/stack-scan design mps stack-scan other}@anchor{9b4}@ref{9b4,,.other;} The thread manager module is responsible for scanning the
control stack and registers of `other' threads. See
design.mps.thread-manager.if.scan@footnote{thread-manager.html#design.mps.thread-manager.if.scan}.

@anchor{design/stack-scan design mps stack-scan origin}@anchor{9b5}@ref{9b5,,.origin;} This design was originally proposed in
mail.richard.2012-08-03.14-36@footnote{https://info.ravenbrook.com/mail/2012/08/03/14-36-35/0/}. Calling conventions for supported
platforms are documented in @ref{9b6,,[Fog]} and @ref{9b7,,[x86_64_registers]}.

@node Requirements<22>,Design<6>,Introduction<35>,Stack and register scanning
@anchor{design/stack-scan mail-richard-2012-08-03-14-36}@anchor{9b8}@anchor{design/stack-scan requirements}@anchor{9b9}
@subsection Requirements


@anchor{design/stack-scan design mps stack-scan req stack hot}@anchor{9ba}@ref{9ba,,.req.stack.hot;} Must locate the hot end of the mutator’s stack. (This
is needed for conservative garbage collection of uncooperative code,
where references might be stored by the mutator on its stack.)

@anchor{design/stack-scan design mps stack-scan req stack cold not}@anchor{9bb}@ref{9bb,,.req.stack.cold.not;} There is no requirement to locate the cold end
of the stack. (The mutator supplies this as an argument to
@ref{a9,,mps_root_create_thread()}.)

@anchor{design/stack-scan design mps stack-scan req stack platform}@anchor{9bc}@ref{9bc,,.req.stack.platform;} Must support the platform’s stack
conventions.

@anchor{design/stack-scan design mps stack-scan req stack platform full-empty}@anchor{9bd}@ref{9bd,,.req.stack.platform.full-empty;} The implementation must take into
account whether the stack is `full' (the stack pointer points to the
last full location) or `empty' (the stack pointer points to the
first empty location).

@anchor{design/stack-scan design mps stack-scan req stack platform desc-asc}@anchor{9be}@ref{9be,,.req.stack.platform.desc-asc;} The implementation must take into
account whether the stack is `descending' (the hot end of the stack is
at a lower address than the cold end) or `ascending' (the hot end of
the stack is at a higher address than the cold end).

@anchor{design/stack-scan design mps stack-scan req registers}@anchor{9bf}@ref{9bf,,.req.registers;} Must locate and scan all references in the
mutator’s `root registers', the subset of registers which might
contain references that do not also appear on the stack. (This is
needed for conservative garbage collection of uncooperative code,
where references might appear in registers.)

@anchor{design/stack-scan design mps stack-scan req entry}@anchor{9c0}@ref{9c0,,.req.entry;} Should save the mutator’s context (stack and registers)
at the point where it enters the MPS. (This avoids scanning registers
and stack that belong to the MPS rather than the mutator, leading to
unnecessary pinning and zone pollution; see job003525@footnote{https://www.ravenbrook.com/project/mps/issue/job003525/}.)

@anchor{design/stack-scan design mps stack-scan req setjmp}@anchor{9c1}@ref{9c1,,.req.setjmp;} The implementation must follow the C Standard in its
use of the @code{setjmp()} macro. (So that it is reliable and portable.)

@anchor{design/stack-scan design mps stack-scan req assembly not}@anchor{9c2}@ref{9c2,,.req.assembly.not;} The implementation should not use assembly
language. (So that it can be developed in tools like Microsoft Visual
Studio that don’t support this.)

@node Design<6>,Analysis<2>,Requirements<22>,Stack and register scanning
@anchor{design/stack-scan design}@anchor{9c3}
@subsection Design


@anchor{design/stack-scan design mps stack-scan sol entry-points}@anchor{9c4}@ref{9c4,,.sol.entry-points;} To meet @ref{9c0,,.req.entry}, the mutator’s registers
and stack must be recorded when the mutator enters the MPS, if there
is a possibility that the MPS might need to know the mutator context.

@anchor{design/stack-scan design mps stack-scan sol entry-points fragile}@anchor{9c5}@ref{9c5,,.sol.entry-points.fragile;} The analysis of which entry points might
need to save the context (see @ref{9c6,,.analysis.entry-points} below) is fragile.
It might be incorrect now, or become incomplete if we refactor the
internals of tracing and polling. As a defence against errors of this
form, @ref{9c7,,StackScan()} asserts that the context was saved, but if the
client program continues from the assertion, it saves the context
anyway and continues.

@anchor{design/stack-scan design mps stack-scan sol registers}@anchor{9c8}@ref{9c8,,.sol.registers;} Implementations spill the root registers onto the
stack so that they can be scanned there.

@anchor{design/stack-scan design mps stack-scan sol registers root}@anchor{9c9}@ref{9c9,,.sol.registers.root;} The `root registers' are the subset of the
callee-save registers that may contain pointers.

@anchor{design/stack-scan design mps stack-scan sol registers root justify}@anchor{9ca}@ref{9ca,,.sol.registers.root.justify;} The caller-save registers will have
been spilled onto the stack by the time the MPS is entered, so will be
scanned by the stack scan.

@anchor{design/stack-scan design mps stack-scan sol setjmp}@anchor{9cb}@ref{9cb,,.sol.setjmp;} The values in callee-save registers can be found by
invoking @code{setjmp()}. This forces any of the caller’s callee-save
registers into either the @code{jmp_buf} or the current stack frame.

@anchor{design/stack-scan design mps stack-scan sol setjmp scan}@anchor{9cc}@ref{9cc,,.sol.setjmp.scan;} Although we might be able to decode the jump
buffer in a platform-dependent way, it’s hard to guarantee that an
uncooperative compiler won’t temporarily store a reference in any
register or stack location. We must conservatively scan the whole of
both.

@anchor{design/stack-scan design mps stack-scan sol setjmp justify}@anchor{9cd}@ref{9cd,,.sol.setjmp.justify;} The @ref{118,,[C1990]} standard specifies that
@code{jmp_buf}:

@quotation

is an array type suitable for holding the information needed to
restore a calling environment. The environment of a call to the
@code{setjmp()} macro consists of information sufficient for a call
to the @code{longjmp()} function to return execution to the correct
block and invocation of that block, were it called recursively.
@end quotation

We believe that any reasonable implementation of @code{setjmp()} must
copy the callee-save registers either into the jump buffer or into the
stack frame that invokes it in order to work as described. Otherwise,
once the callee-save registers have been overwritten by other function
calls, a @code{longjmp()} would result in the callee-save registers
having the wrong values. A @code{longjmp()} can come from anywhere, and
so the function using @code{setjmp()} can’t rely on callee-save registers
being saved by callees.

@anchor{design/stack-scan design mps stack-scan sol stack hot}@anchor{9ce}@ref{9ce,,.sol.stack.hot;} We could decode the frame of the function that
invokes @code{setjmp()} from the jump buffer in a platform-specific way,
but we can do something simpler (if more hacky) by calling the stub
function @code{StackHot()} which takes the address of its argument. So
long as this stub function is not inlined into the caller, then on all
supported platforms this yields a pointer that is pretty much at the
hot end of the frame.

@anchor{design/stack-scan design mps stack-scan sol stack hot noinline}@anchor{9cf}@ref{9cf,,.sol.stack.hot.noinline;} The reason that @code{StackHot()} must not be
inlined is that after inlining, the compiler might place @code{stackOut}
at a colder stack address than the @code{StackContextStruct}, causing the
latter not to be scanned. See mail.gdr.2018-07-11.09-48@footnote{https://info.ravenbrook.com/mail/2018/07/11/09-48-49/0/}.

@anchor{design/stack-scan design mps stack-scan sol stack nest}@anchor{9d0}@ref{9d0,,.sol.stack.nest;} We can take care of scanning the jump buffer
itself by storing it in the same stack frame. That way a scan from the
hot end determined by @ref{9ce,,.sol.stack.hot} to the cold end will contain
all of the roots.

@anchor{design/stack-scan design mps stack-scan sol stack platform}@anchor{9d1}@ref{9d1,,.sol.stack.platform;} As of version 1.115, all supported platforms
are `full' and `descending' so the implementation in @ref{9c7,,StackScan()}
assumes this. New platforms must check this assumption.

@anchor{design/stack-scan design mps stack-scan sol xc alternative}@anchor{9d2}@ref{9d2,,.sol.xc.alternative;} On macOS, we could use @code{getcontext()} from
libunwind (see here@footnote{https://stackoverflow.com/questions/3592914/}), but that produces deprecation warnings and
introduces a dependency on that library.

@node Analysis<2>,Interface<16>,Design<6>,Stack and register scanning
@anchor{design/stack-scan analysis}@anchor{9d3}@anchor{design/stack-scan here}@anchor{9d4}
@subsection Analysis


@anchor{design/stack-scan design mps stack-scan analysis setjmp}@anchor{9d5}@ref{9d5,,.analysis.setjmp;} The @ref{118,,[C1990]} standard says:

@quotation

An invocation of the @code{setjmp} macro shall appear only in one of
the following contexts:


@itemize -

@item 
the entire controlling expression of a selection or iteration
statement;

@item 
one operand of a relational or equality operator with the other
operand an integral constant expression, with the resulting
expression being the entire controlling expression of a
selection or iteration statement;

@item 
the operand of a unary @code{!} operator with the resulting
expression being the entire controlling expression of a
selection or iteration statement; or

@item 
the entire expression of an expression statement (possibly cast
to @code{void}).
@end itemize
@end quotation

And the @ref{9d6,,[C1999]} standard adds:

@quotation

If the invocation appears in any other context, the behavior is
undefined.
@end quotation

@anchor{design/stack-scan design mps stack-scan analysis entry-points}@anchor{9c6}@ref{9c6,,.analysis.entry-points;} Here’s a reverse call graph (in the master
sources at changelevel 189652) showing which entry points might call
@ref{9c7,,StackScan()} and so need to record the stack context:

@example
StackScan
 └ThreadScan
   └RootScan
     ├traceScanRootRes
     │ └traceScanRoot
     │   └rootFlip
     │     └traceFlip
     │       └TraceStart
     │         ├PolicyStartTrace
     │         │ └TracePoll
     │         │   ├ArenaStep
     │         │   │ └mps_arena_step
     │         │   └ArenaPoll
     │         │     ├mps_alloc
     │         │     ├mps_ap_fill
     │         │     ├mps_ap_alloc_pattern_end
     │         │     ├mps_ap_alloc_pattern_reset
     │         │     └ArenaRelease
     │         │       ├mps_arena_release
     │         │       └ArenaStartCollect
     │         │         ├mps_arena_start_collect
     │         │         └ArenaCollect
     │         │           └mps_arena_collect
     │         └TraceStartCollectAll
     │           ├ArenaStep [see above]
     │           ├ArenaStartCollect [see above]
     │           └PolicyStartTrace [see above]
     └rootsWalk
       └ArenaRootsWalk
         └mps_arena_roots_walk
@end example

So the entry points that need to save the stack context are
@ref{19c,,mps_arena_step()}, @ref{ad,,mps_alloc()}, @ref{1cc,,mps_ap_fill()},
@ref{274,,mps_ap_alloc_pattern_end()}, @ref{275,,mps_ap_alloc_pattern_reset()},
@ref{cf,,mps_arena_release()}, @ref{19b,,mps_arena_start_collect()},
@ref{ce,,mps_arena_collect()}, and @ref{19e,,mps_arena_roots_walk()}.

@node Interface<16>,Implementations<5>,Analysis<2>,Stack and register scanning
@anchor{design/stack-scan interface}@anchor{9d7}
@subsection Interface


@geindex StackContext (C type)
@anchor{design/stack-scan c StackContext}@anchor{9d8}
@deffn {C Type} typedef StackContextStruct *StackContext
@end deffn

@anchor{design/stack-scan design mps stack-scan if sc}@anchor{9d9}@ref{9d9,,.if.sc;} A structure encapsulating the mutator context.

@geindex StackScan (C function)
@anchor{design/stack-scan c StackScan}@anchor{9c7}
@deffn {C Function} @ref{55f,,Res} StackScan (ScanState ss, void *stackCold, mps_area_scan_t scan_area, void *closure)
@end deffn

@anchor{design/stack-scan design mps stack-scan if scan}@anchor{9da}@ref{9da,,.if.scan;} Scan the stack of the current thread, between
@code{stackCold} and the hot end of the mutator’s stack that was recorded
by @ref{9db,,STACK_CONTEXT_SAVE()} when the arena was entered. This will
include any roots which were in the mutator’s callee-save registers on
entry to the MPS (see @ref{9cb,,.sol.setjmp} and @ref{9d0,,.sol.stack.nest}). Return
@code{ResOK} if successful, or another result code if not.

@anchor{design/stack-scan design mps stack-scan if scan begin-end}@anchor{9dc}@ref{9dc,,.if.scan.begin-end;} This function must be called between
@ref{9dd,,STACK_CONTEXT_BEGIN()} and @ref{9de,,STACK_CONTEXT_END()}.

@geindex STACK_CONTEXT_SAVE (C macro)
@anchor{design/stack-scan c STACK_CONTEXT_SAVE}@anchor{9db}
@deffn {C Macro} STACK_CONTEXT_SAVE (sc)
@end deffn

@anchor{design/stack-scan design mps stack-scan if save}@anchor{9df}@ref{9df,,.if.save;} Store the mutator context in the structure @code{sc}.

@anchor{design/stack-scan design mps stack-scan if save macro}@anchor{9e0}@ref{9e0,,.if.save.macro;} This must be implemented as a macro because it
needs to run in the stack frame of the entry point (if it runs in some
other function it does not necessarily get the mutator’s registers).
This necessity to have the definition in scope in @code{mpsi.c}, while
also having different definitions on different platforms, requires a
violation of design.mps.config.no-spaghetti@footnote{config.html#design.mps.config.no-spaghetti} in ss.h.

@geindex STACK_CONTEXT_BEGIN (C macro)
@anchor{design/stack-scan c STACK_CONTEXT_BEGIN}@anchor{9dd}
@deffn {C Macro} STACK_CONTEXT_BEGIN (arena)
@end deffn

@anchor{design/stack-scan design mps stack-scan if begin}@anchor{9e1}@ref{9e1,,.if.begin;} Start an MPS operation that may need to know the mutator
context (see @ref{9c4,,.sol.entry-points}). This macro must be used like this:

@example
Res res;
ArenaEnter(arena);
STACK_CONTEXT_BEGIN(arena) @{
  res = ArenaStartCollect(...);
@} STACK_CONTEXT_END(arena);
ArenaLeave(arena);
return res;
@end example

That is, it must be paired with @ref{9de,,STACK_CONTEXT_END()}, and there
must be no @code{return} between the two macro invocations.

This macro stores the mutator context in a @ref{9d8,,StackContext} structure
allocated on the stack, and sets @code{arena->stackWarm} to the hot end
of the current frame (using @ref{9ce,,.sol.stack.hot}).

@geindex STACK_CONTEXT_END (C macro)
@anchor{design/stack-scan c STACK_CONTEXT_END}@anchor{9de}
@deffn {C Macro} STACK_CONTEXT_END (arena)
@end deffn

@anchor{design/stack-scan design mps stack-scan if end}@anchor{9e2}@ref{9e2,,.if.end;} Finish the MPS operation that was started by
@ref{9dd,,STACK_CONTEXT_BEGIN()}.

This macro sets @code{arena->stackWarm} to @code{NULL}.

@node Implementations<5>,References<14>,Interface<16>,Stack and register scanning
@anchor{design/stack-scan implementations}@anchor{9e3}
@subsection Implementations


@anchor{design/stack-scan design mps stack-scan impl}@anchor{9e4}@ref{9e4,,.impl;} Generic implementation of @ref{9c7,,StackScan()} in @code{ss.c} scans
the whole area between @code{arena->stackWarm} and the cold end of the
mutator’s stack, implementing @ref{9d0,,.sol.stack.nest} and also the backup
strategy in @ref{9c5,,.sol.entry-points.fragile}.


@float Figure

@image{MemoryPoolSystem-figures/stack-scan-areas,,,Diagram: scanned areas of the stack.,svg}

@end float


@node References<14>,,Implementations<5>,Stack and register scanning
@anchor{design/stack-scan references}@anchor{9e5}
@subsection References


@anchor{design/stack-scan c1990}@anchor{118}@w{(C1990)} 
International Standard ISO/IEC 9899:1990. “Programming languages — C”.

@anchor{design/stack-scan c1999}@anchor{9d6}@w{(C1999)} 
International Standard ISO/IEC 9899:1999. “Programming languages — C@footnote{http://www.open-std.org/jtc1/sc22/WG14/www/docs/n1256.pdf}”.

@anchor{design/stack-scan fog}@anchor{9b6}@w{(Fog)} 
Agner Fog; “Calling conventions for different C++ compilers and operating systems@footnote{https://agner.org/optimize/calling_conventions.pdf}”; Copenhagen University College of Engineering; 2014-08-07.

@anchor{design/stack-scan x86-64-registers}@anchor{9b7}@w{(x86_64_registers)} 
Microsoft Corporation; “Caller/Callee Saved Registers@footnote{https://msdn.microsoft.com/en-us/library/6t169e9c.aspx}”.

@geindex tests; design

@node Tests,Multi-threaded testing,Stack and register scanning,Design
@anchor{design/tests doc}@anchor{9e6}@anchor{design/tests design-tests}@anchor{9e7}@anchor{design/tests tests}@anchor{9e8}
@section Tests


@menu
* Introduction: Introduction<36>. 
* Running tests:: 
* Test targets:: 
* Test features:: 
* Test list:: 
* Test database:: 
* Test runner:: 
* Performance test:: 
* Adding a new test:: 
* Continuous integration:: 
* MMQA tests:: 
* Other tests:: 
* References: References<15>. 

@end menu

@node Introduction<36>,Running tests,,Tests
@anchor{design/tests design mps tests}@anchor{9e9}@anchor{design/tests introduction}@anchor{9ea}
@subsection Introduction


@anchor{design/tests design mps tests intro}@anchor{9eb}@ref{9eb,,.intro;} This document contains a guide to the Memory Pool System
tests.

@anchor{design/tests design mps tests readership}@anchor{9ec}@ref{9ec,,.readership;} This document is intended for any MPS developer.

@node Running tests,Test targets,Introduction<36>,Tests
@anchor{design/tests running-tests}@anchor{9ed}
@subsection Running tests


@anchor{design/tests design mps tests run}@anchor{9ee}@ref{9ee,,.run;} Run these commands:

@example
cd code
make -f <makefile> VARIETY=<variety> <target>  # Unix
nmake /f <makefile> VARIETY=<variety> <target> # Windows
@end example

where @code{<makefile>} is the appropriate makefile for the platform (see
manual/build.txt@footnote{https://www.ravenbrook.com/project/mps/master/manual/build.txt}), @code{<variety>} is the variety (see
design.mps.config.var.codes@footnote{config.html#design.mps.config.var.codes}) and @code{<target>} is the collection of tests
(see @ref{9ef,,.target} below). For example:

@example
make -f lii6ll VARIETY=cool testrun
@end example

If @code{<variety>} is omitted, tests are run in both the cool and hot
varieties.

@node Test targets,Test features,Running tests,Tests
@anchor{design/tests manual-build-txt}@anchor{9f0}@anchor{design/tests test-targets}@anchor{9f1}
@subsection Test targets


@anchor{design/tests design mps tests target}@anchor{9ef}@ref{9ef,,.target;} The makefiles provide the following targets for common
sets of tests:

@anchor{design/tests design mps tests target testall}@anchor{9f2}@ref{9f2,,.target.testall;} The @code{testall} target runs all test cases (even
if known to fail).

@anchor{design/tests design mps tests target testrun}@anchor{9f3}@ref{9f3,,.target.testrun;} The @code{testrun} target runs the “smoke tests”.
This subset of tests are quick checks that the MPS is working. They
run quickly enough for it to be practical to run them every time the
MPS is built.

@anchor{design/tests design mps tests target testci}@anchor{9f4}@ref{9f4,,.target.testci;} The @code{testci} target runs the continuous
integration tests, the subset of tests that are expected to pass in
full-featured build configurations.

@anchor{design/tests design mps tests target testansi}@anchor{9f5}@ref{9f5,,.target.testansi;} The @code{testansi} target runs the subset of the
tests that are expected to pass in the generic (“ANSI”) build
configuration (see design.mps.config.opt.ansi@footnote{config.html#design.mps.config.opt.ansi}).

@anchor{design/tests design mps tests target testpollnone}@anchor{9f6}@ref{9f6,,.target.testpollnone;} The @code{testpollnone} target runs the subset
of the tests that are expected to pass in the generic (“ANSI”) build
configuration (see design.mps.config.opt.ansi@footnote{config.html#design.mps.config.opt.ansi}) with the option
@code{CONFIG_POLL_NONE} (see design.mps.config.opt.poll@footnote{config.html#design.mps.config.opt.poll}).

@anchor{design/tests design mps tests target testratio}@anchor{9f7}@ref{9f7,,.target.testratio;} The @code{testratio} target compares the
performance of the HOT and RASH varieties. See @ref{9f8,,.ratio}.

@anchor{design/tests design mps tests target testscheme}@anchor{9f9}@ref{9f9,,.target.testscheme;} The @code{testscheme} target builds the example
Scheme interpreter (example/scheme) and runs its test suite.

@anchor{design/tests design mps tests target testmmqa}@anchor{9fa}@ref{9fa,,.target.testmmqa;} The @code{testmmqa} target runs the tests in the
MMQA test suite. See @ref{9fb,,.mmqa}.

@node Test features,Test list,Test targets,Tests
@anchor{design/tests test-features}@anchor{9fc}
@subsection Test features


@anchor{design/tests design mps tests randomize}@anchor{9fd}@ref{9fd,,.randomize;} Each time a test case is run, it randomly chooses some
of its parameters (for example, the sizes of objects, or how many
links to create in a graph of references). This allows a fast test
to cover many cases over time.

@anchor{design/tests design mps tests randomize seed}@anchor{9fe}@ref{9fe,,.randomize.seed;} The random numbers are chosen pseudo-randomly
based on a seed initialized from environmental data (the time and the
processor cycle count). The seed is reported at test startup, for
example:

@example
code$ xci6ll/cool/apss
xci6ll/cool/apss: randomize(): choosing initial state (v3): 2116709187.
...
xci6ll/cool/apss: Conclusion: Failed to find any defects.
@end example

Here, the number 2116709187 is the random seed.

@anchor{design/tests randomize-specific-seed}@anchor{9ff}.randomize.specific-seed Each test can be run with a specified seed
by passing the seed on the command line, for example:

@example
code$ xci6ll/cool/apss 2116709187
xci6ll/cool/apss: randomize(): resetting initial state (v3) to: 2116709187.
...
xci6ll/cool/apss: Conclusion: Failed to find any defects.
@end example

@anchor{design/tests design mps tests randomize repeatable}@anchor{a00}@ref{a00,,.randomize.repeatable;} This ensures that the single-threaded tests
are repeatable. (Multi-threaded tests are not repeatable even if the
same seed is used; see job003719@footnote{https://www.ravenbrook.com/project/mps/issue/job003719/}.)

@node Test list,Test database,Test features,Tests
@anchor{design/tests job003719}@anchor{a01}@anchor{design/tests test-list}@anchor{a02}
@subsection Test list


See manual/code-index@footnote{https://www.ravenbrook.com/project/mps/master/manual/html/code-index.html} for the full list of automated test cases.

@anchor{design/tests design mps tests test finalcv}@anchor{a03}@ref{a03,,.test.finalcv;} Registers objects for finalization, makes them
unreachable, deregisters them, etc. Churns to provoke minor (nursery)
collection.

@anchor{design/tests design mps tests test finaltest}@anchor{a04}@ref{a04,,.test.finaltest;} Creates a large binary tree, and registers every
node. Drops the top reference, requests collection, and counts the
finalization messages.

@anchor{design/tests design mps tests test zcoll}@anchor{a05}@ref{a05,,.test.zcoll;} Collection scheduling, and collection feedback.

@anchor{design/tests design mps tests test zmess}@anchor{a06}@ref{a06,,.test.zmess;} Message lifecycle and finalization messages.

@node Test database,Test runner,Test list,Tests
@anchor{design/tests test-database}@anchor{a07}
@subsection Test database


@anchor{design/tests design mps tests db}@anchor{a08}@ref{a08,,.db;} The automated tests are described in the test database
(tool/testcases.txt).

@anchor{design/tests design mps tests db format}@anchor{a09}@ref{a09,,.db.format;} This is a self-documenting plain-text database which
gives for each test case its name and an optional set of features. For
example the feature @code{=P} means that the test case requires polling
to succeed, and therefore is expected to fail in build configurations
without polling (see design.mps.config.opt.poll@footnote{config.html#design.mps.config.opt.poll}).

@anchor{design/tests design mps tests db format simple}@anchor{a0a}@ref{a0a,,.db.format.simple;} The format must be very simple because the test
runner on Windows is written as a batch file (.bat), in order to avoid
having to depend on any tools that are did not come as standard with
Windows XP, and batch files are inflexible. (But note that we no
longer support Windows XP, so it would now be possible to rewrite the
test runner in PowerShell if we thought that made sense.)

@anchor{design/tests design mps tests db testrun}@anchor{a0b}@ref{a0b,,.db.testrun;} The test runner (tool/testrun.sh on Unix or
tool/testrun.bat on Windows) parses the test database to work out
which tests to run according to the target. For example the
@code{testpollnone} target must skip all test cases with the @code{P}
feature.

@node Test runner,Performance test,Test database,Tests
@anchor{design/tests test-runner}@anchor{a0c}
@subsection Test runner


@anchor{design/tests design mps tests runner req automated}@anchor{a0d}@ref{a0d,,.runner.req.automated;} The test runner must execute without user
interaction, so that it can be used for continuous integration.

@anchor{design/tests design mps tests runner req output pass}@anchor{a0e}@ref{a0e,,.runner.req.output.pass;} Test cases are expected to pass nearly all the
time, and in these cases we almost never want to see the output, so
the test runner must suppress the output for passing tests.

@anchor{design/tests design mps tests runner req output fail}@anchor{a0f}@ref{a0f,,.runner.req.output.fail;} However, if a test case fails then the
test runner must preserve the output from the failing test, including
the random seed (see @ref{9fe,,.randomize.seed}), so that this can be analyzed
and the test repeated. Moreover, it must print the output from the
failing test, so that if the test is being run on a @ref{a10,,continuous integration} system (see @ref{a11,,.ci}), then the output of the failing
tests is included in the failure report. (See job003489@footnote{https://www.ravenbrook.com/project/mps/issue/job003489/}.)

@node Performance test,Adding a new test,Test runner,Tests
@anchor{design/tests job003489}@anchor{a12}@anchor{design/tests performance-test}@anchor{a13}
@subsection Performance test


@anchor{design/tests design mps tests ratio}@anchor{9f8}@ref{9f8,,.ratio;} The @code{testratio} target checks that the hot variety
is not too much slower than the rash variety. A failure of this test
usually is expected to indicate that there are assertions on the
critical path using @code{AVER} instead of @code{AVER_CRITICAL} (and so on).
This works by running gcbench for the AMC pool class and djbench for
the MVFF pool class, in the hot variety and the rash variety,
computing the ratio of CPU time taken in the two varieties, and
testing that this falls under an acceptable limit.

@anchor{design/tests design mps tests ratio cpu-time}@anchor{a14}@ref{a14,,.ratio.cpu-time;} Note that we use the CPU time (reported by
@code{/usr/bin/time}) and not the elapsed time (as reported by the
benchmark) because we want to be able to run this test on continuous
integration machines that might be heavily loaded.

@anchor{design/tests design mps tests ratio platform}@anchor{a15}@ref{a15,,.ratio.platform;} This target is currently supported only on Unix
platforms using GNU Makefiles.

@node Adding a new test,Continuous integration,Performance test,Tests
@anchor{design/tests adding-a-new-test}@anchor{a16}
@subsection Adding a new test


To add a new test to the MPS, carry out the following steps. (The
procedure uses the name “newtest” throughout but you should of
course replace this with the name of your test case.)

@anchor{design/tests design mps tests new source}@anchor{a17}@ref{a17,,.new.source;} Create a C source file in the code directory,
typically named “newtest.c”. In additional to the usual copyright
boilerplate, it should contain a call to @code{testlib_init()} (this
ensures reproducibility of pseudo-random numbers), and a @code{printf()}
reporting the absence of defects (this output is recognized by the
test runner):

@example
#include <stdio.h>
#include "testlib.h"

int main(int argc, char *argv[])
@{
  testlib_init(argc, argv);
  /* test happens here */
  printf("%s: Conclusion: Failed to find any defects.\n", argv[0]);
  return 0;
@}
@end example

@anchor{design/tests design mps tests new unix}@anchor{a18}@ref{a18,,.new.unix;} If the test case builds on the Unix platforms (FreeBSD,
Linux and macOS), edit code/comm.gmk adding the test case to the
@code{TEST_TARGETS} macro, and adding a rule describing how to build it,
typically:

@example
$(PFM)/$(VARIETY)/newtest: $(PFM)/$(VARIETY)/newtest.o \
        $(TESTLIBOBJ) $(PFM)/$(VARIETY)/mps.a
@end example

@anchor{design/tests design mps tests new windows}@anchor{a19}@ref{a19,,.new.windows;} If the test case builds on Windows, edit
code/commpre.nmk adding the test case to the @code{TEST_TARGETS} macro,
and edit code/commpost.nmk adding a rule describing how to build it,
typically:

@example
$(PFM)\$(VARIETY)\newtest.exe: $(PFM)\$(VARIETY)\newtest.obj \
        $(PFM)\$(VARIETY)\mps.lib $(FMTTESTOBJ) $(TESTLIBOBJ)
@end example

@anchor{design/tests design mps tests new macos}@anchor{a1a}@ref{a1a,,.new.macos;} If the test case builds on macOS, open
code/mps.xcodeproj/project.pbxproj for edit and open this project in
Xcode. If the project navigator is not visible at the left, select
View → Navigators → Show Project Navigator (⌘1). Right click on the
Tests folder and choose Add Files to “mps”…. Select code/newtest.c
and then click Add. Move the new file into alphabetical order in the
Tests folder. Click on “mps” at the top of the project navigator to
reveal the targets. Select a test target that is similar to the one
you have just created. Right click on that target and select Duplicate
(⌘D). Select the new target and change its name to “newtest”. Select
the “Build Phases” tab and check that “Dependencies” contains the mps
library, and that “Compile Sources” contains newtest.c and
testlib.c. Close the project.

@anchor{design/tests design mps tests new database}@anchor{a1b}@ref{a1b,,.new.database;} Edit tool/testcases.txt and add the new test case to
the database. Use the appropriate flags to indicate the properties of
the test case. These flags are used by the test runner to select the
appropriate sets of test cases. For example tests marked @code{=P} are
expected to fail in build configurations without polling (see
design.mps.config.opt.poll@footnote{config.html#design.mps.config.opt.poll}).

@anchor{design/tests design mps tests new manual}@anchor{a1c}@ref{a1c,,.new.manual;} Edit manual/source/code-index.rst and add the new test
case to the “Automated test cases” section.

@node Continuous integration,MMQA tests,Adding a new test,Tests
@anchor{design/tests continuous-integration}@anchor{a10}
@subsection Continuous integration


[This section might need to become a document in its own right.  CI
has grown in importance and complexity.  RB 2023-01-15]

@anchor{design/tests design mps tests ci}@anchor{a11}@ref{a11,,.ci;} Ravenbrook uses both GitHub CI@footnote{https://docs.github.com/en/actions/automating-builds-and-tests/about-continuous-integration} and Travis CI@footnote{https://travis-ci.com/} for
continuous integration of the MPS via GitHub.

[This section needs: definition of CI goals and requirements, what we
need CI to do and why, how the testci target meets those
requirements.  ‘taint really a design without this.  Mention how CI
supports the pull request merge procedure (except that exists on a
separate branch at the moment).  RB 2023-01-15]

[Need to discuss compilers and toolchains.  RB 2023-01-15]

@anchor{design/tests design mps tests ci run posix}@anchor{a1d}@ref{a1d,,.ci.run.posix;} On Posix systems where we have autoconf, the CI
services run commands equivalent to:

@example
./configure
make install
make test
@end example

which exercises the testci target, as defined by Makefile.in@footnote{../Makefile.in} in the root of the MPS tree.

@anchor{design/tests design mps tests ci run windows}@anchor{a1e}@ref{a1e,,.ci.run.windows;} On Windows the CI services run commands that do at
least:

@example
make /f w3i6mv.nmk all testci
@end example

as defined by the @ref{a1f,,.ci.github.config}.

@anchor{design/tests design mps tests ci run other targets}@anchor{a20}@ref{a20,,.ci.run.other.targets;} On some platforms we arrange to run the testansi,
testpollnone, testratio, and testscheme targets.  [Need to explain
why, where, etc.  RB 2023-01-15]

@anchor{design/tests design mps tests ci run other checks}@anchor{a21}@ref{a21,,.ci.run.other.checks;} We could also run various non-build checks
using CI to check:


@itemize -

@item 
document formatting

@item 
shell script syntax
@end itemize

[In the branch of writing, these do not yet exist.  They are the
subject of GitHub pull request #113@footnote{https://github.com/Ravenbrook/mps/pull/112} of
branch/2023-01-13/rst-check.  When merged, they can be linked.  RB
2023-01-15]

@anchor{design/tests ci-when}@anchor{a22}.ci.when:: CI is triggered on the mps GitHub repo@footnote{https://github.com/ravenbrook/mps} by:


@itemize -

@item 
commits (pushes)

@item 
new pull requests

@item 
manually, using tools (see @ref{a23,,.ci.tools})
@end itemize

@anchor{design/tests design mps tests ci results}@anchor{a24}@ref{a24,,.ci.results;} CI results are visible via the GitHub web interface:


@itemize -

@item 
in pull requests, under “Checks”,

@item 
on the branches page@footnote{https://github.com/Ravenbrook/mps/branches}
as green ticks or red crosses that link to details.
@end itemize

as well as in logs specific to the type of CI.

@anchor{design/tests design mps tests ci results travis}@anchor{a25}@ref{a25,,.ci.results.travis;} Results from Travis CI can be found at the
Travis CI build history for the MPS GitHub repo@footnote{https://app.travis-ci.com/github/Ravenbrook/mps/builds}.

@anchor{design/tests design mps tests ci results github}@anchor{a26}@ref{a26,,.ci.results.github;} Results from GitHub CI can be found at build and test actions on the Actions tab at the Ravenbrook GitHub repo@footnote{https://github.com/Ravenbrook/mps/actions/workflows/build-and-test.yml}.

@anchor{design/tests design mps tests ci github}@anchor{a27}@ref{a27,,.ci.github;} [Insert overview of GitHub CI here.  RB 2023-01-15]

@anchor{design/tests design mps tests ci github platforms}@anchor{a28}@ref{a28,,.ci.github.platforms;} GitHub provides runners@footnote{https://docs.github.com/en/actions/using-github-hosted-runners/about-github-hosted-runners#supported-runners-and-hardware-resources} for Linux, Windows,
and macOS, but only on x86_64.  See @ref{a29,,.ci.travis.platforms} for ARM64
and FreeBSD.

@anchor{design/tests design mps tests ci github config}@anchor{a1f}@ref{a1f,,.ci.github.config;} GitHub CI is configured using the
build-and-test.yml@footnote{../.github/workflows/build-and-test.yml} file
in the .github/workflows directory of the MPS tree.

@anchor{design/tests design mps tests ci travis}@anchor{a2a}@ref{a2a,,.ci.travis;} [Insert overview of Travis CI here.  RB 2023-01-15]

@anchor{design/tests design mps tests ci travis platforms}@anchor{a29}@ref{a29,,.ci.travis.platforms;} Where possible, we use GitHub CI@footnote{https://docs.github.com/en/actions/automating-builds-and-tests/about-continuous-integration} for
platforms, because Travis CI is slow and expensive@footnote{https://github.com/Ravenbrook/mps/issues/109}.  However
GitHub CI@footnote{https://docs.github.com/en/actions/automating-builds-and-tests/about-continuous-integration} does not provide ARM64 or FreeBSD, so we use Travis CI@footnote{https://travis-ci.com/}
for those.

@anchor{design/tests design mps tests ci travis config}@anchor{a2b}@ref{a2b,,.ci.travis.config;} Travis is configured using the .travis.yml@footnote{../.travis.yml} file at top level of the MPS tree.

@anchor{design/tests design mps tests ci tools}@anchor{a23}@ref{a23,,.ci.tools;} The MPS tree contains some simple tools for managing CI
without the need to install whole packages such as the GitHub CLI or
Travis CI’s Ruby gem.

@anchor{design/tests design mps tests ci tools kick}@anchor{a2c}@ref{a2c,,.ci.tools.kick;} tool/github-ci-kick@footnote{../tool/github-ci-kick} and
tool/travis-ci-kick@footnote{../tool/travis-ci-kick} both trigger CI builds
without the need to push a change or make a pull request in the mps GitHub repo@footnote{https://github.com/ravenbrook/mps}.  In particular, they are useful for applying CI to work
that was pushed while CI was disabled, for whatever reason.

@node MMQA tests,Other tests,Continuous integration,Tests
@anchor{design/tests mmqa-tests}@anchor{a2d}
@subsection MMQA tests


@anchor{design/tests design mps tests mmqa}@anchor{9fb}@ref{9fb,,.mmqa;} The Memory Management Quality Assurance test suite is
another suite of test cases.

@anchor{design/tests design mps tests mmqa why}@anchor{a2e}@ref{a2e,,.mmqa.why;} The existence of two test suites originates in the
departmental structure at Harlequin Ltd where the MPS was originally
developed. Tests written by members of the Memory Management Group
went into the code directory along with the MPS itself, while tests
written by members of the Quality Assurance Group went into the test
directory. (Conway’s Law states that “organizations which design
systems … are constrained to produce designs which are copies of the
communication structures of these organizations” @ref{a2f,,[Conway_1968]}.)

@anchor{design/tests design mps tests mmqa run}@anchor{a30}@ref{a30,,.mmqa.run;} See test/README for how to run the MMQA tests.

@node Other tests,References<15>,MMQA tests,Tests
@anchor{design/tests other-tests}@anchor{a31}
@subsection Other tests


@anchor{design/tests design mps tests coverage}@anchor{a32}@ref{a32,,.coverage;} The program tool/testcoverage compiles the MPS with
coverage enabled, runs the smoke tests (@ref{9f3,,.target.testrun}) and
outputs a coverage report.

@anchor{design/tests design mps tests opendylan}@anchor{a33}@ref{a33,,.opendylan;} The program tool/testopendylan pulls Open Dylan from
GitHub and builds it against the MPS.

@node References<15>,,Other tests,Tests
@anchor{design/tests references}@anchor{a34}
@subsection References


@anchor{design/tests conway-1968}@anchor{a2f}@w{(Conway_1968)} 
“How do Committees Invent?”; Melvin E. Conway; `Datamation' 14:5, pp. 28–31; April 1968; <@indicateurl{http://www.melconway.com/Home/Committees_Paper.html}>

@geindex threads; testing

@node Multi-threaded testing,Thread manager,Tests,Design
@anchor{design/testthr doc}@anchor{a35}@anchor{design/testthr design-testthr}@anchor{a36}@anchor{design/testthr multi-threaded-testing}@anchor{a37}
@section Multi-threaded testing


@menu
* Introduction: Introduction<37>. 
* Requirements: Requirements<23>. 
* Implementation: Implementation<13>. 
* Interface: Interface<17>. 
* References: References<16>. 

@end menu

@node Introduction<37>,Requirements<23>,,Multi-threaded testing
@anchor{design/testthr design mps testthr}@anchor{a38}@anchor{design/testthr introduction}@anchor{a39}
@subsection Introduction


@anchor{design/testthr design mps testthr intro}@anchor{a3a}@ref{a3a,,.intro;} This is the design of the multi-threaded testing module
in the Memory Pool System.

@anchor{design/testthr design mps testthr readership}@anchor{a3b}@ref{a3b,,.readership;} Any MPS developer.

@anchor{design/testthr design mps testthr overview}@anchor{a3c}@ref{a3c,,.overview;} The MPS is designed to work in a multi-threaded
environment (see design.mps.thread-safety@footnote{thread-safety.html}) and this needs to be
tested on all supported platforms. The multi-threaded testing module
provides an interface for creating and joining threads, so that
multi-threaded test cases are portable to all platforms on which the
MPS runs.

@node Requirements<23>,Implementation<13>,Introduction<37>,Multi-threaded testing
@anchor{design/testthr design-mps-thread-safety}@anchor{a3d}@anchor{design/testthr requirements}@anchor{a3e}
@subsection Requirements


@anchor{design/testthr design mps testthr req create}@anchor{a3f}@ref{a3f,,.req.create;} The module must provide an interface for creating
threads and running code in them. (Because there is no such interface
in the Standard C Library.)

@anchor{design/testthr design mps testthr req join}@anchor{a40}@ref{a40,,.req.join;} The module must provide an interface for joining a
running thread: that is, waiting for the thread to finish and
collecting a result. (Because we want to be able to test that the MPS
behaves correctly when interacting with a finished thread.)

@anchor{design/testthr design mps testthr req portable}@anchor{a41}@ref{a41,,.req.portable;} The module must be easily portable to all the
platforms on which the MPS runs.

@anchor{design/testthr design mps testthr req usable}@anchor{a42}@ref{a42,,.req.usable;} The module must be simple to use, not requiring
elaborate setup or tear-down or error handling. (Because we want test
cases to be easy to write.)

@node Implementation<13>,Interface<17>,Requirements<23>,Multi-threaded testing
@anchor{design/testthr implementation}@anchor{a43}
@subsection Implementation


@anchor{design/testthr design mps testthr impl posix}@anchor{a44}@ref{a44,,.impl.posix;} To meet @ref{a41,,.req.portable} and @ref{a42,,.req.usable}, the
module presents an interface that is essentially identical to the
POSIX Threads interface @ref{a45,,[pthreads]}, except for the names. On POSIX
platforms the implementation is trivial; on Windows it is
necessary to translate the concepts back and forth.

@anchor{design/testthr design mps testthr impl storage}@anchor{a46}@ref{a46,,.impl.storage;} To meet @ref{a42,,.req.usable}, the module defines the
@code{testthr_t} type in the header @code{testthr.h} (even though this
requires an @code{#if}), so that test cases can easily declare variables
and allocate storage for thread identifiers.

@anchor{design/testthr design mps testthr impl error}@anchor{a47}@ref{a47,,.impl.error;} To meet @ref{a42,,.req.usable}, the module does not propagate
error codes, but calls @code{error()} from the test library if anything
goes wrong. There is thus no need for the test cases to check result
codes.

@node Interface<17>,References<16>,Implementation<13>,Multi-threaded testing
@anchor{design/testthr interface}@anchor{a48}
@subsection Interface


@geindex testthr_t (C type)
@anchor{design/testthr c testthr_t}@anchor{a49}
@deffn {C Type} type testthr_t
@end deffn

The type of thread identifiers.

@geindex testthr_routine_t (C type)
@anchor{design/testthr c testthr_routine_t}@anchor{a4a}
@deffn {C Type} typedef void *(*testthr_routine_t)(void*)
@end deffn

The type of a function that can be called when a thread is created.

@geindex testthr_create (C function)
@anchor{design/testthr c testthr_create}@anchor{a4b}
@deffn {C Function} void testthr_create (testthr_t *thread_o, testthr_routine_t start, void *arg)
@end deffn

Create a thread. Store the identifier of the newly created thread in
@code{*thread_o}, and call @code{start()}, passing @code{arg} as the single
parameter.

@geindex testthr_join (C function)
@anchor{design/testthr c testthr_join}@anchor{a4c}
@deffn {C Function} void testthr_join (testthr_t *thread, void **result_o)
@end deffn

Wait for a thread to complete. Suspend execution of the calling thread
until the target thread terminates (if necessary), and if @code{result_o}
is non-NULL, update @code{*result_o} with the return value of the
thread’s @code{start()} function.

@node References<16>,,Interface<17>,Multi-threaded testing
@anchor{design/testthr references}@anchor{a4d}
@subsection References


@anchor{design/testthr pthreads}@anchor{a45}@w{(pthreads)} 
The Open Group; “The Single UNIX Specification, Version 2—Threads”; <@indicateurl{https://pubs.opengroup.org/onlinepubs/7990989775/xsh/threads.html}>

@geindex thread manager; design

@node Thread manager,Thread safety in the MPS,Multi-threaded testing,Design
@anchor{design/thread-manager doc}@anchor{a4e}@anchor{design/thread-manager design-thread-manager}@anchor{30f}@anchor{design/thread-manager thread-manager}@anchor{a4f}
@section Thread manager


@menu
* Introduction: Introduction<38>. 
* Requirements: Requirements<24>. 
* Design: Design<7>. 
* Interface: Interface<18>. 
* Implementations: Implementations<6>. 

@end menu

@node Introduction<38>,Requirements<24>,,Thread manager
@anchor{design/thread-manager design mps thread-manager}@anchor{a50}@anchor{design/thread-manager introduction}@anchor{a51}
@subsection Introduction


@anchor{design/thread-manager design mps thread-manager intro}@anchor{a52}@ref{a52,,.intro;} This is the design of the thread manager module.

@anchor{design/thread-manager design mps thread-manager readership}@anchor{a53}@ref{a53,,.readership;} Any MPS developer; anyone porting the MPS to a new
platform.

@anchor{design/thread-manager design mps thread-manager overview}@anchor{a54}@ref{a54,,.overview;} The thread manager implements two features that allow
the MPS to work in a multi-threaded environment: exclusive access to
memory, and scanning of roots in a thread’s registers and control
stack.

@node Requirements<24>,Design<7>,Introduction<38>,Thread manager
@anchor{design/thread-manager requirements}@anchor{a55}
@subsection Requirements


@anchor{design/thread-manager design mps thread-manager req exclusive}@anchor{a56}@ref{a56,,.req.exclusive;} The thread manager must provide the MPS with
exclusive access to the memory it manages in critical sections of the
code. (This is necessary to avoid for the MPS to be able to flip
atomically from the point of view of the mutator.)

@anchor{design/thread-manager design mps thread-manager req scan}@anchor{a57}@ref{a57,,.req.scan;} The thread manager must be able to locate references in
the registers and control stack of the current thread, or of a
suspended thread. (This is necessary in order to implement
conservative collection, in environments where the registers and
control stack contain ambiguous roots. Scanning of roots is carried
out during the flip, hence while other threads are suspended.)

@anchor{design/thread-manager design mps thread-manager req register multi}@anchor{a58}@ref{a58,,.req.register.multi;} It must be possible to register the same
thread multiple times. (This is needed to support the situation where
a program that does not use the MPS is calling into MPS-using code
from multiple threads. On entry to the MPS-using code, the thread can
be registered, but it may not be possible to ensure that the thread is
deregistered on exit, because control may be transferred by some
non-local mechanism such as an exception or @code{longjmp()}. We don’t
want to insist that the client program keep a table of threads it has
registered, because maintaining the table might require allocation,
which might provoke a collection. See request.dylan.160252@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/dylan/160252/}.)

@anchor{design/thread-manager design mps thread-manager req thread die}@anchor{a59}@ref{a59,,.req.thread.die;} It would be nice if the MPS coped with threads
that die while registered. (This makes it easier for a client program
to interface with foreign code that terminates threads without the
client program being given an opportunity to deregister them. See
request.dylan.160022@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/dylan/160022} and request.mps.160093@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/mps/160093/}.)

@anchor{design/thread-manager design mps thread-manager req thread intr}@anchor{a5a}@ref{a5a,,.req.thread.intr;} It would be nice if on POSIX systems the MPS does
not cause system calls in the mutator to fail with EINTR due to the
MPS thread-management signals being delivered while the mutator is
blocked in a system call. (See GitHub issue #9@footnote{https://github.com/ravenbrook/mps/issues/9}.)

@anchor{design/thread-manager design mps thread-manager req thread errno}@anchor{a5b}@ref{a5b,,.req.thread.errno;} It would be nice if on POSIX systems the MPS
does not cause system calls in the mutator to update @code{errno} due to
the MPS thread-management signals being delivered while the mutator is
blocked in a system call, and the MPS signal handlers updating
@code{errno}. (See GitHub issue #10@footnote{https://github.com/ravenbrook/mps/issues/10}.)

@anchor{design/thread-manager design mps thread-manager req thread lasterror}@anchor{a5c}@ref{a5c,,.req.thread.lasterror;} It would be nice if on Windows systems the
MPS does not cause system calls in the mutator to update the value
returned from @code{GetLastError()} when the exception handler is called
due to a fault. This may cause the MPS to destroy the previous value
there. (See GitHub issue #61@footnote{https://github.com/Ravenbrook/mps/issues/61}.)

@node Design<7>,Interface<18>,Requirements<24>,Thread manager
@anchor{design/thread-manager design}@anchor{a5d}@anchor{design/thread-manager github-issue-61}@anchor{a5e}
@subsection Design


@anchor{design/thread-manager design mps thread-manager sol exclusive}@anchor{a5f}@ref{a5f,,.sol.exclusive;} In order to meet @ref{a56,,.req.exclusive}, the arena
maintains a ring of threads (in @code{arena->threadRing}) that have been
registered by the client program. When the MPS needs exclusive access
to memory, it suspends all the threads in the ring except for the
currently running thread. When the MPS no longer needs exclusive
access to memory, it resumes all threads in the ring.

@anchor{design/thread-manager design mps thread-manager sol exclusive assumption}@anchor{a60}@ref{a60,,.sol.exclusive.assumption;} This relies on the assumption that any
thread that might refer to, read from, or write to memory in
automatically managed pool classes is registered with the MPS. This is
documented in the manual under @ref{a8,,mps_thread_reg()}.

@anchor{design/thread-manager design mps thread-manager sol thread term}@anchor{a61}@ref{a61,,.sol.thread.term;} The thread manager cannot reliably detect that a
thread has terminated. The reason is that threading systems do not
guarantee behaviour in this case. For example, POSIX@footnote{https://pubs.opengroup.org/onlinepubs/9699919799/functions/V2_chap02.html#tag_15_09_02} says, “A
conforming implementation is free to reuse a thread ID after its
lifetime has ended. If an application attempts to use a thread ID
whose lifetime has ended, the behavior is undefined.” For this reason,
the documentation for @ref{a8,,mps_thread_reg()} specifies that it is an
error if a thread dies while registered.

@anchor{design/thread-manager design mps thread-manager sol thread term attempt}@anchor{a62}@ref{a62,,.sol.thread.term.attempt;} Nonetheless, the thread manager makes a
“best effort” to continue running after detecting a terminated thread,
by moving the thread to a ring of dead threads, and avoiding scanning
it. This might allow a malfunctioning client program to limp along.

@anchor{design/thread-manager design mps thread-manager sol thread intr}@anchor{a63}@ref{a63,,.sol.thread.intr;} The POSIX specification for sigaction@footnote{https://pubs.opengroup.org/onlinepubs/9699919799/functions/sigaction.html} says that
if the @code{SA_RESTART} flag is set, and if “a function specified as
interruptible is interrupted by this signal, the function shall
restart and shall not fail with @code{EINTR} unless otherwise specified.”

@anchor{design/thread-manager design mps thread-manager sol thread intr linux}@anchor{a64}@ref{a64,,.sol.thread.intr.linux;} Linux does not fully implement the POSIX
specification, so that some system calls are “never restarted after
being interrupted by a signal handler, regardless of the use of
SA_RESTART; they always fail with the error EINTR when interrupted by
a signal handler”. The exceptional calls are listed in the signal(7)@footnote{https://man7.org/linux/man-pages/man7/signal.7.html}
manual. There is nothing that the MPS can do about this except to warn
users in the reference manual.

@anchor{design/thread-manager design mps thread-manager sol thread errno}@anchor{a65}@ref{a65,,.sol.thread.errno;} The POSIX specification for sigaction@footnote{https://pubs.opengroup.org/onlinepubs/9699919799/functions/sigaction.html} says,
“Note in particular that even the “safe” functions may modify
@code{errno}; the signal-catching function, if not executing as an
independent thread, should save and restore its value.” All MPS
signals handlers therefore save and restore @code{errno} using the macros
@code{ERRNO_SAVE} and @code{ERRNO_RESTORE}.

@anchor{design/thread-manager design mps thread-manager sol thread lasterror}@anchor{a66}@ref{a66,,.sol.thread.lasterror;} The documentation for @code{AddVectoredExceptionHandler}
does not mention @code{GetLastError()} at all, but testing@footnote{https://github.com/Ravenbrook/mps/issues/61} the behaviour
reveals that any value in @code{GetLastError()} is not preserved. Therefore,
this value is saved using @code{LAST_ERROR_SAVE} and @code{LAST_ERROR_RESTORE}.

@node Interface<18>,Implementations<6>,Design<7>,Thread manager
@anchor{design/thread-manager interface}@anchor{a67}@anchor{design/thread-manager testing}@anchor{a68}
@subsection Interface


@geindex Thread (C type)
@anchor{design/thread-manager c Thread}@anchor{7be}
@deffn {C Type} typedef struct mps_thr_s *Thread
@end deffn

@anchor{design/thread-manager design mps thread-manager if thread}@anchor{a69}@ref{a69,,.if.thread;} The type of threads. It is a pointer to an opaque
structure, which must be defined by the implementation.

@geindex ThreadCheck (C function)
@anchor{design/thread-manager c ThreadCheck}@anchor{a6a}
@deffn {C Function} @ref{3a9,,Bool} ThreadCheck (Thread thread)
@end deffn

@anchor{design/thread-manager design mps thread-manager if check}@anchor{a6b}@ref{a6b,,.if.check;} The check function for threads. See design.mps.check@footnote{check.html}.

@geindex ThreadCheckSimple (C function)
@anchor{design/thread-manager c ThreadCheckSimple}@anchor{a6c}
@deffn {C Function} @ref{3a9,,Bool} ThreadCheckSimple (Thread thread)
@end deffn

@anchor{design/thread-manager design mps thread-manager if check simple}@anchor{a6d}@ref{a6d,,.if.check.simple;} A thread-safe check function for threads, for use
by @ref{16b,,mps_thread_dereg()}. It can’t use @code{AVER(TESTT(Thread,
thread))}, as recommended by design.mps.sig.check.arg.unlocked@footnote{sig.html#design.mps.sig.check.arg.unlocked},
since @ref{7be,,Thread} is an opaque type.

@geindex ThreadArena (C function)
@anchor{design/thread-manager c ThreadArena}@anchor{660}
@deffn {C Function} @ref{796,,Arena} ThreadArena (Thread thread)
@end deffn

@anchor{design/thread-manager design mps thread-manager if arena}@anchor{a6e}@ref{a6e,,.if.arena;} Return the arena that the thread is registered with.
Must be thread-safe as it needs to be called by @ref{16b,,mps_thread_dereg()}
before taking the arena lock.

@geindex ThreadRegister (C function)
@anchor{design/thread-manager c ThreadRegister}@anchor{a6f}
@deffn {C Function} @ref{55f,,Res} ThreadRegister (Thread *threadReturn, Arena arena)
@end deffn

@anchor{design/thread-manager design mps thread-manager if register}@anchor{a70}@ref{a70,,.if.register;} Register the current thread with the arena,
allocating a new @ref{7be,,Thread} object. If successful, update
@code{*threadReturn} to point to the new thread and return @code{ResOK}.
Otherwise, return a result code indicating the cause of the error.

@geindex ThreadDeregister (C function)
@anchor{design/thread-manager c ThreadDeregister}@anchor{a71}
@deffn {C Function} void ThreadDeregister (Thread thread, Arena arena)
@end deffn

@anchor{design/thread-manager design mps thread-manager if deregister}@anchor{a72}@ref{a72,,.if.deregister;} Remove @code{thread} from the list of threads managed
by the arena and free it.

@geindex ThreadRingSuspend (C function)
@anchor{design/thread-manager c ThreadRingSuspend}@anchor{7de}
@deffn {C Function} void ThreadRingSuspend (Ring threadRing, Ring deadRing)
@end deffn

@anchor{design/thread-manager design mps thread-manager if ring suspend}@anchor{a73}@ref{a73,,.if.ring.suspend;} Suspend all the threads on @code{threadRing}, except
for the current thread. If any threads are discovered to have
terminated, move them to @code{deadRing}.

@geindex ThreadRingResume (C function)
@anchor{design/thread-manager c ThreadRingResume}@anchor{a74}
@deffn {C Function} void ThreadRingResume (Ring threadRing, Ring deadRing)
@end deffn

@anchor{design/thread-manager design mps thread-manager if ring resume}@anchor{a75}@ref{a75,,.if.ring.resume;} Resume all the threads on @code{threadRing}. If any
threads are discovered to have terminated, move them to @code{deadRing}.

@geindex ThreadRingThread (C function)
@anchor{design/thread-manager c ThreadRingThread}@anchor{a76}
@deffn {C Function} @ref{7be,,Thread} ThreadRingThread (Ring threadRing)
@end deffn

@anchor{design/thread-manager design mps thread-manager if ring thread}@anchor{a77}@ref{a77,,.if.ring.thread;} Return the thread that owns the given element of
the thread ring.

@geindex ThreadScan (C function)
@anchor{design/thread-manager c ThreadScan}@anchor{a78}
@deffn {C Function} @ref{55f,,Res} ThreadScan (ScanState ss, Thread thread, Word *stackCold, mps_area_scan_t scan_area, void *closure)
@end deffn

@anchor{design/thread-manager design mps thread-manager if scan}@anchor{a79}@ref{a79,,.if.scan;} Scan the stacks and root registers of @code{thread}, using
@code{ss} and @code{scan_area}. @code{stackCold} points to the cold end of the
thread’s stack—this is the value that was supplied by the client
program when it called @ref{a9,,mps_root_create_thread()}. In the common
case, where the stack grows downwards, @code{stackCold} is the highest
stack address. Return @code{ResOK} if successful, another result code
otherwise.

@node Implementations<6>,,Interface<18>,Thread manager
@anchor{design/thread-manager implementations}@anchor{a7a}
@subsection Implementations


@menu
* Generic implementation: Generic implementation<2>. 
* POSIX threads implementation:: 
* Windows implementation: Windows implementation<2>. 
* macOS implementation: macOS implementation<2>. 

@end menu

@node Generic implementation<2>,POSIX threads implementation,,Implementations<6>
@anchor{design/thread-manager generic-implementation}@anchor{a7b}
@subsubsection Generic implementation


@anchor{design/thread-manager design mps thread-manager impl an}@anchor{a7c}@ref{a7c,,.impl.an;} In @code{than.c}.

@anchor{design/thread-manager design mps thread-manager impl an single}@anchor{a7d}@ref{a7d,,.impl.an.single;} Supports a single thread. (This cannot be enforced
because of @ref{a58,,.req.register.multi}.)

@anchor{design/thread-manager design mps thread-manager impl an register multi}@anchor{a7e}@ref{a7e,,.impl.an.register.multi;} There is no need for any special treatment
of multiple threads, because @ref{7de,,ThreadRingSuspend()} and
@ref{a74,,ThreadRingResume()} do nothing.

@anchor{design/thread-manager design mps thread-manager impl an suspend}@anchor{a7f}@ref{a7f,,.impl.an.suspend;} @ref{7de,,ThreadRingSuspend()} does nothing because
there are no other threads.

@anchor{design/thread-manager design mps thread-manager impl an resume}@anchor{a80}@ref{a80,,.impl.an.resume;} @ref{a74,,ThreadRingResume()} does nothing because no
threads are ever suspended.

@anchor{design/thread-manager design mps thread-manager impl an scan}@anchor{a81}@ref{a81,,.impl.an.scan;} Just calls @ref{9c7,,StackScan()} since there are no
suspended threads.

@node POSIX threads implementation,Windows implementation<2>,Generic implementation<2>,Implementations<6>
@anchor{design/thread-manager posix-threads-implementation}@anchor{a82}
@subsubsection POSIX threads implementation


@anchor{design/thread-manager design mps thread-manager impl ix}@anchor{a83}@ref{a83,,.impl.ix;} In @code{thix.c} and @code{pthrdext.c}. See
design.mps.pthreadext@footnote{pthreadext.html}.

@anchor{design/thread-manager design mps thread-manager impl ix multi}@anchor{a84}@ref{a84,,.impl.ix.multi;} Supports multiple threads.

@anchor{design/thread-manager design mps thread-manager impl ix register}@anchor{a85}@ref{a85,,.impl.ix.register;} @ref{a6f,,ThreadRegister()} records the thread id
the current thread by calling pthread_self()@footnote{https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_self.html}.

@anchor{design/thread-manager design mps thread-manager impl ix register multi}@anchor{a86}@ref{a86,,.impl.ix.register.multi;} Multiply-registered threads are handled
specially by the POSIX thread extensions. See
design.mps.pthreadext.req.suspend.multiple@footnote{pthreadext.html#design.mps.pthreadext.req.suspend.multiple} and
design.mps.pthreadext.req.resume.multiple@footnote{pthreadext.html#design.mps.pthreadext.req.resume.multiple}.

@anchor{design/thread-manager design mps thread-manager impl ix suspend}@anchor{a87}@ref{a87,,.impl.ix.suspend;} @ref{7de,,ThreadRingSuspend()} calls
@ref{7dd,,PThreadextSuspend()}. See design.mps.pthreadext.if.suspend@footnote{pthreadext.html#design.mps.pthreadext.if.suspend}.

@anchor{design/thread-manager design mps thread-manager impl ix resume}@anchor{a88}@ref{a88,,.impl.ix.resume;} @ref{a74,,ThreadRingResume()} calls
@ref{a89,,PThreadextResume()}. See design.mps.pthreadext.if.resume@footnote{pthreadext.html#design.mps.pthreadext.if.resume}.

@anchor{design/thread-manager design mps thread-manager impl ix scan current}@anchor{a8a}@ref{a8a,,.impl.ix.scan.current;} @ref{a78,,ThreadScan()} calls @ref{9c7,,StackScan()} if
the thread is current.

@anchor{design/thread-manager design mps thread-manager impl ix scan suspended}@anchor{a8b}@ref{a8b,,.impl.ix.scan.suspended;} @ref{7dd,,PThreadextSuspend()} records the
context of each suspended thread, and @ref{7de,,ThreadRingSuspend()} stores
this in the @ref{7be,,Thread} structure, so that is available by the time
@ref{a78,,ThreadScan()} is called.

@node Windows implementation<2>,macOS implementation<2>,POSIX threads implementation,Implementations<6>
@anchor{design/thread-manager windows-implementation}@anchor{a8c}
@subsubsection Windows implementation


@anchor{design/thread-manager design mps thread-manager impl w3}@anchor{a8d}@ref{a8d,,.impl.w3;} In @code{thw3.c}.

@anchor{design/thread-manager design mps thread-manager impl w3 multi}@anchor{a8e}@ref{a8e,,.impl.w3.multi;} Supports multiple threads.

@anchor{design/thread-manager design mps thread-manager impl w3 register}@anchor{a8f}@ref{a8f,,.impl.w3.register;} @ref{a6f,,ThreadRegister()} records the following
information for the current thread:

@quotation


@itemize -

@item 
A @code{HANDLE} to the process, with access flags
@code{THREAD_SUSPEND_RESUME} and @code{THREAD_GET_CONTEXT}. This handle
is needed as parameter to SuspendThread()@footnote{https://docs.microsoft.com/en-gb/windows/desktop/api/processthreadsapi/nf-processthreadsapi-suspendthread} and
ResumeThread()@footnote{https://docs.microsoft.com/en-gb/windows/desktop/api/processthreadsapi/nf-processthreadsapi-resumethread}.

@item 
The result of GetCurrentThreadId()@footnote{https://docs.microsoft.com/en-gb/windows/desktop/api/processthreadsapi/nf-processthreadsapi-getcurrentthreadid}, so that the current thread
may be identified in the ring of threads.
@end itemize
@end quotation

@anchor{design/thread-manager design mps thread-manager impl w3 register multi}@anchor{a90}@ref{a90,,.impl.w3.register.multi;} There is no need for any special treatment
of multiple threads, because Windows maintains a suspend count that is
incremented on SuspendThread()@footnote{https://docs.microsoft.com/en-gb/windows/desktop/api/processthreadsapi/nf-processthreadsapi-suspendthread} and decremented on
ResumeThread()@footnote{https://docs.microsoft.com/en-gb/windows/desktop/api/processthreadsapi/nf-processthreadsapi-resumethread}.

@anchor{design/thread-manager design mps thread-manager impl w3 suspend}@anchor{a91}@ref{a91,,.impl.w3.suspend;} @ref{7de,,ThreadRingSuspend()} calls SuspendThread()@footnote{https://docs.microsoft.com/en-gb/windows/desktop/api/processthreadsapi/nf-processthreadsapi-suspendthread}.

@anchor{design/thread-manager design mps thread-manager impl w3 resume}@anchor{a92}@ref{a92,,.impl.w3.resume;} @ref{a74,,ThreadRingResume()} calls ResumeThread()@footnote{https://docs.microsoft.com/en-gb/windows/desktop/api/processthreadsapi/nf-processthreadsapi-resumethread}.

@anchor{design/thread-manager design mps thread-manager impl w3 scan current}@anchor{a93}@ref{a93,,.impl.w3.scan.current;} @ref{a78,,ThreadScan()} calls @ref{9c7,,StackScan()} if
the thread is current. This is because GetThreadContext()@footnote{https://docs.microsoft.com/en-us/windows/desktop/api/processthreadsapi/nf-processthreadsapi-getthreadcontext} doesn’t
work on the current thread: the context would not necessarily have the
values which were in the saved registers on entry to the MPS.

@anchor{design/thread-manager design mps thread-manager impl w3 scan suspended}@anchor{a94}@ref{a94,,.impl.w3.scan.suspended;} Otherwise, @ref{a78,,ThreadScan()} calls
GetThreadContext()@footnote{https://docs.microsoft.com/en-us/windows/desktop/api/processthreadsapi/nf-processthreadsapi-getthreadcontext} to get the root registers and the stack
pointer.

@node macOS implementation<2>,,Windows implementation<2>,Implementations<6>
@anchor{design/thread-manager macos-implementation}@anchor{a95}
@subsubsection macOS implementation


@anchor{design/thread-manager design mps thread-manager impl xc}@anchor{a96}@ref{a96,,.impl.xc;} In @code{thxc.c}.

@anchor{design/thread-manager design mps thread-manager impl xc multi}@anchor{a97}@ref{a97,,.impl.xc.multi;} Supports multiple threads.

@anchor{design/thread-manager design mps thread-manager impl xc register}@anchor{a98}@ref{a98,,.impl.xc.register;} @ref{a6f,,ThreadRegister()} records the Mach port of
the current thread by calling mach_thread_self()@footnote{https://www.gnu.org/software/hurd/gnumach-doc/Thread-Information.html}.

@anchor{design/thread-manager design mps thread-manager impl xc register multi}@anchor{a99}@ref{a99,,.impl.xc.register.multi;} There is no need for any special treatment
of multiple threads, because Mach maintains a suspend count that is
incremented on thread_suspend()@footnote{https://www.gnu.org/software/hurd/gnumach-doc/Thread-Execution.html} and decremented on
thread_resume()@footnote{https://www.gnu.org/software/hurd/gnumach-doc/Thread-Execution.html}.

@anchor{design/thread-manager design mps thread-manager impl xc suspend}@anchor{a9a}@ref{a9a,,.impl.xc.suspend;} @ref{7de,,ThreadRingSuspend()} calls
thread_suspend()@footnote{https://www.gnu.org/software/hurd/gnumach-doc/Thread-Execution.html}.

@anchor{design/thread-manager design mps thread-manager impl xc resume}@anchor{a9b}@ref{a9b,,.impl.xc.resume;} @ref{a74,,ThreadRingResume()} calls thread_resume()@footnote{https://www.gnu.org/software/hurd/gnumach-doc/Thread-Execution.html}.

@anchor{design/thread-manager design mps thread-manager impl xc scan current}@anchor{a9c}@ref{a9c,,.impl.xc.scan.current;} @ref{a78,,ThreadScan()} calls @ref{9c7,,StackScan()} if
the thread is current.

@anchor{design/thread-manager design mps thread-manager impl xc scan suspended}@anchor{a9d}@ref{a9d,,.impl.xc.scan.suspended;} Otherwise, @ref{a78,,ThreadScan()} calls
thread_get_state()@footnote{https://www.gnu.org/software/hurd/gnumach-doc/Thread-Execution.html} to get the root registers and the stack pointer.

@geindex thread safety; design

@node Thread safety in the MPS,Transforms<2>,Thread manager,Design
@anchor{design/thread-safety doc}@anchor{a9e}@anchor{design/thread-safety design-thread-safety}@anchor{a9f}@anchor{design/thread-safety thread-get-state}@anchor{aa0}@anchor{design/thread-safety thread-safety-in-the-mps}@anchor{aa1}
@section Thread safety in the MPS


@menu
* Introduction: Introduction<39>. 
* Requirements: Requirements<25>. 
* Analysis: Analysis<3>. 
* Design: Design<8>. 
* Fork safety: Fork safety<3>. 

@end menu

@node Introduction<39>,Requirements<25>,,Thread safety in the MPS
@anchor{design/thread-safety design mps thread-safety}@anchor{aa2}@anchor{design/thread-safety introduction}@anchor{aa3}
@subsection Introduction


@anchor{design/thread-safety design mps thread-safety intro}@anchor{aa4}@ref{aa4,,.intro;} This describes how thread safety is achieved in the MPS.

@anchor{design/thread-safety design mps thread-safety overview}@anchor{aa5}@ref{aa5,,.overview;} The MPS is expected to run in an environment with
multiple threads calling into the MPS. The initial approach is very
simple. Some of the code is known to operate with exclusive access to
the data it manipulates, so this code is safe. For the rest of the
code, shared data structures are locked by the use of a single binary
lock (design.mps.lock@footnote{lock.html}) per arena. This lock is claimed on entry to
the MPS and released on exit from it. So there is at most a single
thread (per arena) running “inside” the MPS at a time.

@node Requirements<25>,Analysis<3>,Introduction<39>,Thread safety in the MPS
@anchor{design/thread-safety design-mps-lock}@anchor{aa6}@anchor{design/thread-safety requirements}@anchor{aa7}
@subsection Requirements


@anchor{design/thread-safety design mps thread-safety req threads}@anchor{aa8}@ref{aa8,,.req.threads;} Code must work correctly in presence of multiple
threads all calling into the MPS.

@anchor{design/thread-safety design mps thread-safety req arena}@anchor{aa9}@ref{aa9,,.req.arena;} The MPS must safely manage per-arena non-shared data.

@anchor{design/thread-safety design mps thread-safety req global mutable}@anchor{aaa}@ref{aaa,,.req.global.mutable;} The MPS must safely manage global data that
may be updated many times (that is, the arena ring).

@anchor{design/thread-safety design mps thread-safety req global once}@anchor{aab}@ref{aab,,.req.global.once;} The MPS must safely manage global data that is
updated at most once (that is, the protocol classes).

@anchor{design/thread-safety design mps thread-safety req deadlock}@anchor{aac}@ref{aac,,.req.deadlock;} The MPS must not deadlock.

@anchor{design/thread-safety design mps thread-safety req fork}@anchor{aad}@ref{aad,,.req.fork;} On Unix platforms, the MPS should be able to continue in
the child process after a @code{fork()}. (Source: job004062@footnote{https://www.ravenbrook.com/project/mps/issue/job004062/}.)

@anchor{design/thread-safety design mps thread-safety req perf}@anchor{aae}@ref{aae,,.req.perf;} Performance should not be unreasonably hindered.

@node Analysis<3>,Design<8>,Requirements<25>,Thread safety in the MPS
@anchor{design/thread-safety analysis}@anchor{aaf}
@subsection Analysis


@anchor{design/thread-safety design mps thread-safety analysis simple}@anchor{ab0}@ref{ab0,,.analysis.simple;} To have the code functioning correctly it should be
easy to change correctly. So a simple approach is desirable. We have
to also ensure that performance is not unreasonably downgraded.

@menu
* Performance cost of locking:: 
* Recursive vs binary locks:: 
* Fork safety: Fork safety<2>. 

@end menu

@node Performance cost of locking,Recursive vs binary locks,,Analysis<3>
@anchor{design/thread-safety performance-cost-of-locking}@anchor{ab1}
@subsubsection Performance cost of locking


@anchor{design/thread-safety design mps thread-safety lock-cost}@anchor{ab2}@ref{ab2,,.lock-cost;} The cost of locking in performance terms are:


@itemize -

@item 
@anchor{design/thread-safety design mps thread-safety lock-cost overhead}@anchor{ab3}@ref{ab3,,.lock-cost.overhead;} the overhead of claiming and releasing locks;

@item 
@anchor{design/thread-safety design mps thread-safety lock-cost pause}@anchor{ab4}@ref{ab4,,.lock-cost.pause;} the pauses caused by one thread being blocked
on another thread.

@item 
@anchor{design/thread-safety design mps thread-safety lock-cost wait}@anchor{ab5}@ref{ab5,,.lock-cost.wait;} the time wasted by one thread being blocked on
another thread.
@end itemize

@anchor{design/thread-safety design mps thread-safety analysis perf signif}@anchor{ab6}@ref{ab6,,.analysis.perf.signif;} @ref{ab4,,.lock-cost.pause} is significant if there are
MPS functions that take a long time. Using more locks, e.g. having a
lock per pool as well as a lock per arena, is a way of decreasing the
locking conflict between threads (@ref{ab4,,.lock-cost.pause} and
@ref{ab5,,.lock-cost.wait}). However this could increase
@ref{ab3,,.lock-cost.overhead} significantly.

@anchor{design/thread-safety design mps thread-safety analysis perf work}@anchor{ab7}@ref{ab7,,.analysis.perf.work;} But all MPS functions imply a small work-load
unless a collection is taking place. In the case of a collection, in
practice and certainly in the near future, all threads will most
likely be suspended while the collection work is going on. (The pages
being scanned will need to be unprotected which implies the mutator
will have to be stopped.) We also have to remember that unless we are
running on genuine multiprocessor @ref{ab5,,.lock-cost.wait} is irrelevant.

@anchor{design/thread-safety design mps thread-safety analysis perf alloc}@anchor{ab8}@ref{ab8,,.analysis.perf.alloc;} During typical use we expect that it is
allocation that is the most frequent activity. Allocation buffers
(design.mps.buffer@footnote{buffer.html}) are designed to allow allocation in concurrent
threads without needing a lock. So the most significant time a thread
spends in the MPS will be on a buffer-fill or during a collection. The
next most significant use is likely to be buffer create and deletion,
as a separate buffer will be required for each thread.

@anchor{design/thread-safety design mps thread-safety analysis perf lock}@anchor{ab9}@ref{ab9,,.analysis.perf.lock;} So overall the performance cost of locking is, I
estimate, most significantly the overhead of calling the locking
functions. Hence it would be undesirable from a performance point of
view to have more than one lock.

@node Recursive vs binary locks,Fork safety<2>,Performance cost of locking,Analysis<3>
@anchor{design/thread-safety recursive-vs-binary-locks}@anchor{aba}
@subsubsection Recursive vs binary locks


@anchor{design/thread-safety design mps thread-safety analysis reentrance}@anchor{abb}@ref{abb,,.analysis.reentrance;} The simplest way to lock the code safely is to
define which code runs inside or outside the lock. Calling from the
outside to the inside implies a lock has to be claimed. Returning
means the lock has to be released. Control flow from outside to
outside and from inside to inside needs no locking action. To
implement this a function defined on the external interface needs to
claim the lock on entry and release it on exit. Our code currently
uses some external functions with the lock already held. There are two
ways to implement this:


@enumerate 

@item 
@anchor{design/thread-safety design mps thread-safety recursive}@anchor{abc}@ref{abc,,.recursive;} Each external function claims a recursive lock.


@itemize -

@item 
simple;

@item 
have to worry about locking depth;

@item 
extra locking overhead on internal calls of external functions;
@end itemize

@item 
@anchor{design/thread-safety design mps thread-safety binary}@anchor{abd}@ref{abd,,.binary;} Each external function claims a binary lock. Replace
each internal call of an external function with a call to a newly
defined internal one.


@itemize -

@item 
more code

@item 
slightly easier to reason about
@end itemize
@end enumerate

@anchor{design/thread-safety design mps thread-safety analysis strategy}@anchor{abe}@ref{abe,,.analysis.strategy;} It seems that the @ref{abc,,.recursive} strategy is the
easiest to implement first, but could be evolved into a @ref{abd,,.binary}
strategy. (That evolution has now happened. tony 1999-08-31).

@node Fork safety<2>,,Recursive vs binary locks,Analysis<3>
@anchor{design/thread-safety fork-safety}@anchor{abf}
@subsubsection Fork safety


In order to support @code{fork()}, we need to solve the following problems:

@anchor{design/thread-safety design mps thread-safety analysis fork lock}@anchor{ac0}@ref{ac0,,.analysis.fork.lock;} Any MPS lock might be held by another thread at
the point where @code{fork()} is called. The lock would be protecting the
integrity of some data structure. But in the child the thread holding
the lock no longer exists, and so there is no way to restore the
integrity.

@anchor{design/thread-safety design mps thread-safety analysis fork threads}@anchor{ac1}@ref{ac1,,.analysis.fork.threads;} In the child process after a @code{fork()}, there
is only one thread, which is a copy of the thread that called
@code{fork()} in the parent process. All other threads no longer exist.
But the MPS maintains references to these threads, via the
@code{ThreadStruct} object` created by calls to @ref{a8,,mps_thread_reg()}. If
we try to communicate with these threads it will fail or crash.

@anchor{design/thread-safety design mps thread-safety analysis fork exc-thread}@anchor{ac2}@ref{ac2,,.analysis.fork.exc-thread;} On macOS, the MPS handles protection faults
using a dedicated thread. But in the child process after a @code{fork()},
this dedicated thread no longer exists. Also, the Mach port on which
the dedicated thread receives its messages does not exist in the child
either.

@anchor{design/thread-safety design mps thread-safety analysis fork mach-port}@anchor{ac3}@ref{ac3,,.analysis.fork.mach-port;} On macOS, the MPS identifies threads via
their Mach port numbers, which are stashed in the @code{ThreadStruct} and
used to identify the current thread, for example in
@code{ThreadSuspend()}. But in the child process after @code{fork()} the
running thread has a different Mach port number than it did in the
parent.

@node Design<8>,Fork safety<3>,Analysis<3>,Thread safety in the MPS
@anchor{design/thread-safety design}@anchor{ac4}
@subsection Design


@anchor{design/thread-safety design mps thread-safety sol locks}@anchor{ac5}@ref{ac5,,.sol.locks;} Use MPS locks (design.mps.lock@footnote{lock.html}) to implement the
locking.

@anchor{design/thread-safety design mps thread-safety sol arena}@anchor{ac6}@ref{ac6,,.sol.arena;} Each arena has a binary lock that protects the
non-shared data for that arena. Functions in the public interface fall
into the following categories:


@itemize -

@item 
@anchor{design/thread-safety design mps thread-safety sol arena entry}@anchor{ac7}@ref{ac7,,.sol.arena.entry;} Must be called with the arena lock not held
(thus, these functions are not callable from format methods and
other callbacks). Claims arena binary lock on entry, releases it on
exit. The usual case. For example, @ref{b9,,mps_arena_park()}.

@item 
@anchor{design/thread-safety design mps thread-safety sol arena recursive}@anchor{ac8}@ref{ac8,,.sol.arena.recursive;} May be called with the arena lock held (for
example, from format methods and other callbacks). Claim arena lock
recursively on entry, release it on exit. For example,
@ref{1a5,,mps_addr_fmt()}.

@item 
@anchor{design/thread-safety design mps thread-safety sol arena lock-free}@anchor{ac9}@ref{ac9,,.sol.arena.lock-free;} May be called at any time and does not
claim or release any locks, because it is documented as being up to
the client program to ensure thread safety (for example,
@ref{f6,,mps_ld_add()}).

@item 
@anchor{design/thread-safety design mps thread-safety sol arena maybe-entry}@anchor{aca}@ref{aca,,.sol.arena.maybe-entry;} Must be called with the arena lock not
held. In the common case, does not claim or release any locks
(because it is documented as being up to the client program to
ensure thread safety, as for @ref{ac9,,.sol.arena.lock-free}), but may need
to claim and release the arena binary lock (as for
@ref{ac7,,.sol.arena.entry}). For example, @ref{b0,,mps_reserve()},
@ref{b2,,mps_commit()}, @ref{16e,,mps_ap_frame_push()}, and
@ref{16d,,mps_ap_frame_pop()}.
@end itemize

@anchor{design/thread-safety design mps thread-safety sol global mutable}@anchor{acb}@ref{acb,,.sol.global.mutable;} There is a global binary lock (see
design.mps.lock.req.global.binary@footnote{lock.html#design.mps.lock.req.global.binary}) that protects mutable data shared
between all arenas (that is, the arena ring lock: see
design.mps.arena.static.ring.lock@footnote{arena.html#design.mps.arena.static.ring.lock}).

@anchor{design/thread-safety design mps thread-safety sol global once}@anchor{acc}@ref{acc,,.sol.global.once;} There is a global recursive lock (see
design.mps.lock.req.global.recursive@footnote{lock.html#design.mps.lock.req.global.recursive}) that protects static data which
must be initialized at most once (that is, the protocol classes). Each
static data structure is accessed only via an “ensure” function that
claims the global recursive lock, checks to see if the data structure
has been initialized yet, and does so if necessary (see
design.mps.protocol.impl.define-class.lock@footnote{protocol.html#design.mps.protocol.impl.define-class.lock}).

@anchor{design/thread-safety design mps thread-safety sol deadlock}@anchor{acd}@ref{acd,,.sol.deadlock;} A strict ordering is required between the global and
arena locks to prevent deadlock. The binary global lock may not be
claimed while either the arena or recursive global lock is held; the
arena lock may not be claimed while the recursive global lock is held.
Each arena lock is independent of all other arena locks; that is, a
thread may not attempt to claim more than one arena lock at a time.
See design.mps.arena.lock.avoid@footnote{arena.html#design.mps.arena.lock.avoid}.

@anchor{design/thread-safety design mps thread-safety sol check}@anchor{ace}@ref{ace,,.sol.check;} The MPS interface design requires that a function must
check the signatures on the data structures pointed to by its
parameters (see design.mps.sig.check.arg@footnote{sig.html#design.mps.sig.check.arg}). In particular, for
functions in the class @ref{ac7,,.sol.arena.entry} it is necessary to check
some data structure signatures before taking the arena lock. The
checking interface provides a @code{TESTT()} macro that checks the
signature in a thread-safe way (see
design.mps.sig.check.arg.unlocked@footnote{sig.html#design.mps.sig.check.arg.unlocked}).

@node Fork safety<3>,,Design<8>,Thread safety in the MPS
@anchor{design/thread-safety design-mps-sig-check-arg-unlocked}@anchor{acf}@anchor{design/thread-safety id2}@anchor{ad0}
@subsection Fork safety


@anchor{design/thread-safety design mps thread-safety sol fork atfork}@anchor{ad1}@ref{ad1,,.sol.fork.atfork;} The MPS solves the fork-safety problems by
calling pthread_atfork()@footnote{https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_atfork.html} to install handler functions that are
called in the parent process just before fork (the “prepare” handler),
and in the parent and child processes just after fork (the “parent”
and “child” handlers respectively).

@anchor{design/thread-safety design mps thread-safety sol fork lock}@anchor{ad2}@ref{ad2,,.sol.fork.lock;} In the prepare handler, the MPS takes all the
locks: that is, the global locks, and then the arena lock for every
arena. Note that a side-effect of this is that the shield is entered
for each arena. In the parent handler, the MPS releases all the locks.
In the child handler, the MPS would like to release the locks but this
does not work on any supported platform, so instead it reinitializes
them, by calling @ref{6d3,,LockInitGlobal()}.

@anchor{design/thread-safety design mps thread-safety sol fork thread}@anchor{ad3}@ref{ad3,,.sol.fork.thread;} On macOS, in the prepare handler, the MPS
identifies for each arena the current thread, that is, the one calling
@code{fork()} which will survive into the child process, and marks this
thread by setting a flag in the appropriate @code{ThreadStruct}. In the
parent handler, this flag is cleared. On all Unix platforms, in the
child handler, all threads (except for the current thread) are marked
as dead and transferred to the ring of dead threads. (The MPS can’t
destroy the thread structures at this point because they are owned by
the client program.)

@anchor{design/thread-safety design mps thread-safety sol fork exc-thread}@anchor{ad4}@ref{ad4,,.sol.fork.exc-thread;} On macOS, in the child handler, the exception
port and dedicated thread are re-created, and the current thread
re-registered with the exception port.

@anchor{design/thread-safety design mps thread-safety sol fork mach-port}@anchor{ad5}@ref{ad5,,.sol.fork.mach-port;} On macOS, in the child handler, the thread
flagged as forking gets its port number updated.

@geindex transforms; design

@node Transforms<2>,General MPS types,Thread safety in the MPS,Design
@anchor{design/transform doc}@anchor{ad6}@anchor{design/transform design-transform}@anchor{ad7}@anchor{design/transform transforms}@anchor{ad8}
@section Transforms


@menu
* Introduction: Introduction<40>. 
* Background: Background<2>. 
* Overview: Overview<8>. 
* Not yet written:: 
* References: References<17>. 

@end menu

@node Introduction<40>,Background<2>,,Transforms<2>
@anchor{design/transform design mps transform}@anchor{ad9}@anchor{design/transform introduction}@anchor{ada}
@subsection Introduction


This document describes the Transform mechanism of the Memory Pool System.
Transforms allow the client code to replace a set of object references on the
heap.

The readership of this document is any developer intending to modify the
Transform implementation.

@node Background<2>,Overview<8>,Introduction<40>,Transforms<2>
@anchor{design/transform background}@anchor{adb}
@subsection Background


Göran Rydqvist of Configura originally expressed the requirement for the
MPS to support the change of layout of objects in CET @ref{adc,,[GR_2010-02-25]}.
Ravenbrook proposed several methods @ref{add,,[RHSK_2010-09-21]} including:

@quotation

If you need to add fields, then use a special new MPS function (that
doesn’t exist yet):

@example
mps_arena_transform_objects(&my_transform_function);
@end example

This traverses the object graph, lets your transform_function
basically @code{realloc()} the field-block, and MPS fixes up all
references from other objects to point to the new field-block.

Unfortunately, this idea is probably killed off by ambiguous
references :-(. You could only run the patch if you could
`guarantee' there are no ambiguous refs you want. In other words,
any object refs on the stack would become instant death (or worse:
subtle slow death :-). Therefore we don’t really like this idea
(unfortunately). There are safer and simpler ways to do it, we
think…
@end quotation

which Configura selected @ref{ade,,[GR_2010-09-22]}.

An initial implementation was made by RHSK and released to Configura as
“experimental”, however Configura put it into production.

During work on adapting the MPS to 64-bit Windows, RB reformed and
reimplemented transforms based on RHSK’s original work.

@node Overview<8>,Not yet written,Background<2>,Transforms<2>
@anchor{design/transform overview}@anchor{adf}
@subsection Overview


The client program builds a table mapping “old” references to “new” ones
in a @code{Transform} object. This is then “applied”, causing a garbage
collection trace in which the fix function is substituted by
@code{transformFix()}, which spots “old” references and replaces them with
“new” ones, in addition to applying the usual garbage collection fix
function.

This design was arrived at after some pain.  The MPS isn’t really
designed for generalized transformation of the object graph, and the
pools generally assume that they’re doing a garbage collection when
they’re asked to condemn, scan, fix, and reclaim stuff.  This makes it
very hard to apply the transform without also doing a garbage
collection.  Changing this would require a significant reworking of
the MPS to generalise its ideas, and would bloat the pool classes.

@node Not yet written,References<17>,Overview<8>,Transforms<2>
@anchor{design/transform not-yet-written}@anchor{ae0}
@subsection Not yet written



@itemize *

@item 
Ambiguous references and aborting the transform.

@item 
How ambiguous references are avoided using @code{arena->stackWarm}.

@item 
Why it does a garbage collection and not just a transforming scan.
[This is partly explained in @ref{adf,,Overview} above.  RB 2023-06-16]

@item 
Nice side-effect is that “old” objects are killed.

@item 
Why the arena must be parked [When writing this up see
impl.c.trans.park and impl.c.trans.assume.parked. RB 2023-06-16].

@item 
Why we can’t transform arbitrary references (see
impl.c.trans.old-white).
@end itemize

@node References<17>,,Not yet written,Transforms<2>
@anchor{design/transform references}@anchor{ae1}
@subsection References


@anchor{design/transform gr-2010-02-25}@anchor{adc}@w{(GR_2010-02-25)} 
“Incremental object” (e-mail); Göran Rydqvist; Configura; 2010-02-25; <@indicateurl{https://info.ravenbrook.com/mail/2010/02/25/16-35-45/0/}>.

@anchor{design/transform rhsk-2010-09-21}@anchor{add}@w{(RHSK_2010-09-21)} 
“Incremental object ideas” (e-mail); Richard Kistruck; Ravenbrook Limited; 2010-09-21; <@indicateurl{https://info.ravenbrook.com/mail/2010/09/21/16-54-59/0/}>.

@anchor{design/transform gr-2010-09-22}@anchor{ade}@w{(GR_2010-09-22)} 
“Incremental object ideas” (e-mail); Göran Rydqvist; Configura; 2010-09-22; <@indicateurl{https://info.ravenbrook.com/mail/2010/09/22/09-27-53/0/}>.

@geindex general types; design

@node General MPS types,Library version mechanism,Transforms<2>,Design
@anchor{design/type doc}@anchor{ae2}@anchor{design/type design-type}@anchor{ae3}@anchor{design/type general-mps-types}@anchor{ae4}
@section General MPS types


@menu
* Introduction: Introduction<41>. 
* Rationale:: 
* Concrete types:: 
* Abstract types:: 

@end menu

@node Introduction<41>,Rationale,,General MPS types
@anchor{design/type design mps type}@anchor{ae5}@anchor{design/type introduction}@anchor{ae6}
@subsection Introduction


@anchor{design/type design mps type intro}@anchor{ae7}@ref{ae7,,.intro;} See impl.h.mpmtypes.

@node Rationale,Concrete types,Introduction<41>,General MPS types
@anchor{design/type rationale}@anchor{ae8}
@subsection Rationale


Some types are declared to resolve a point of design, such as the best
type to use for array indexing.

Some types are declared so that the intention of code is clearer. For
example, @ref{ae9,,Byte} is necessarily @code{unsigned char}, but it’s better to
say @ref{ae9,,Byte} in your code if it’s what you mean.

@node Concrete types,Abstract types,Rationale,General MPS types
@anchor{design/type concrete-types}@anchor{aea}
@subsection Concrete types


@geindex AccessSet (C type)
@anchor{design/type c AccessSet}@anchor{8ce}
@deffn {C Type} typedef unsigned AccessSet
@end deffn

@anchor{design/type design mps type access-set}@anchor{aeb}@ref{aeb,,.access-set;} An @ref{8ce,,AccessSet} is a bitset of @code{Access} modes,
which are @code{AccessREAD} and @code{AccessWRITE}. @code{AccessSetEMPTY} is
the empty @ref{8ce,,AccessSet}.

@geindex Addr (C type)
@anchor{design/type c Addr}@anchor{632}
@deffn {C Type} typedef struct AddrStruct *Addr
@end deffn

@anchor{design/type design mps type addr}@anchor{aec}@ref{aec,,.addr;} @ref{632,,Addr} is the type used for “managed addresses”, that is,
addresses of objects managed by the MPS.

@anchor{design/type design mps type addr def}@anchor{aed}@ref{aed,,.addr.def;} @ref{632,,Addr} is defined as @code{struct AddrStruct *}, but
@code{AddrStruct} is never defined. This means that @ref{632,,Addr} is always an
incomplete type, which prevents accidental dereferencing, arithmetic,
or assignment to other pointer types.

@anchor{design/type design mps type addr use}@anchor{aee}@ref{aee,,.addr.use;} @ref{632,,Addr} should be used whenever the code needs to deal
with addresses. It should not be used for the addresses of memory
manager data structures themselves, so that the memory manager remains
amenable to working in a separate address space. Be careful not to
confuse @ref{632,,Addr} with @code{void *}.

@anchor{design/type design mps type addr ops}@anchor{aef}@ref{aef,,.addr.ops;} Limited arithmetic is allowed on addresses using
@code{AddrAdd()} and @code{AddrOffset()} (impl.c.mpm). Addresses may also be
compared using the relational operators @code{==}, @code{!=}, @code{<}, @code{<=},
@code{>}, and @code{>=}.

@anchor{design/type design mps type addr ops mem}@anchor{af0}@ref{af0,,.addr.ops.mem;} We need efficient operators similar to @code{memset()},
@code{memcpy()}, and @code{memcmp()} on @ref{632,,Addr}; these are called @code{AddrSet()},
@code{AddrCopy()}, and @code{AddrComp()}. When @ref{632,,Addr} is compatible with
@code{void *}, these are implemented through the functions
@ref{2db,,mps_lib_memset()}, @ref{2da,,mps_lib_memcpy()}, and @ref{2d9,,mps_lib_memcmp()}
functions in the plinth (impl.h.mpm).

@anchor{design/type design mps type addr conv c}@anchor{af1}@ref{af1,,.addr.conv.c;} @ref{632,,Addr} is converted to @ref{11d,,mps_addr_t} in the MPS C
Interface. @ref{11d,,mps_addr_t} is defined to be the same as @code{void *}, so
using the MPS C Interface confines the memory manager to the same
address space as the client data.

@anchor{design/type design mps type addr readonly}@anchor{af2}@ref{af2,,.addr.readonly;} For read-only addresses, see @ref{af3,,.readonlyaddr}.

@geindex Align (C type)
@anchor{design/type c Align}@anchor{af4}
@deffn {C Type} typedef @ref{653,,Word} Align
@end deffn

@anchor{design/type design mps type align}@anchor{af5}@ref{af5,,.align;} @ref{af4,,Align} is an unsigned integral type which is used to
represent the alignment of managed addresses. All alignments are
positive powers of two. @ref{af4,,Align} is large enough to hold the maximum
possible alignment.

@anchor{design/type design mps type align use}@anchor{af6}@ref{af6,,.align.use;} @ref{af4,,Align} should be used whenever the code needs to
deal with the alignment of a managed address.

@anchor{design/type design mps type align conv c}@anchor{af7}@ref{af7,,.align.conv.c;} @ref{af4,,Align} is converted to @ref{128,,mps_align_t} in the MPS
C Interface.

@geindex Attr (C type)
@anchor{design/type c Attr}@anchor{af8}
@deffn {C Type} typedef unsigned Attr
@end deffn

@anchor{design/type design mps type attr}@anchor{af9}@ref{af9,,.attr;} Pool attributes. A bitset of pool class attributes, which
are:


@multitable {xxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Attribute

@tab

Description

@item

@code{AttrGC}

@tab

Is garbage collecting, that is, parts may be
reclaimed. Used to decide which segments are
condemned.

@item

@code{AttrMOVINGGC}

@tab

Is moving, that is, objects may move in memory.
Used to update the set of zones that might have
moved and so implement location dependency.

@end multitable


There is an attribute field in the pool class (@code{PoolClassStruct})
which declares the attributes of that class. See
design.mps.pool.field.attr@footnote{pool.html#design.mps.pool.field.attr}.

@geindex Bool (C type)
@anchor{design/type c Bool}@anchor{3a9}
@deffn {C Type} typedef int Bool
@end deffn

@anchor{design/type design mps type bool}@anchor{afa}@ref{afa,,.bool;} The @ref{3a9,,Bool} type is mostly defined so that the intention of
code is clearer. In C, Boolean expressions evaluate to @code{int}, so
@ref{3a9,,Bool} is in fact an alias for @code{int}.

@anchor{design/type design mps type bool value}@anchor{afb}@ref{afb,,.bool.value;} @ref{3a9,,Bool} has two values, @code{TRUE} and @code{FALSE}. These
are defined to be @code{1} and @code{0} respectively, for compatibility with
C Boolean expressions (so one may set a @ref{3a9,,Bool} to the result of a C
Boolean expression).

@anchor{design/type design mps type bool use}@anchor{afc}@ref{afc,,.bool.use;} @ref{3a9,,Bool} is a type which should be used when a Boolean
value is intended, for example, as the result of a function. Using a
Boolean type in C is a tricky thing. Non-zero values are “true” (when
used as control conditions) but are not all equal to @code{TRUE}. Use
with care.

@anchor{design/type design mps type bool check}@anchor{afd}@ref{afd,,.bool.check;} @code{BoolCheck()} simply checks whether the argument is
@code{TRUE} (@code{1}) or @code{FALSE} (@code{0}).

@anchor{design/type design mps type bool check inline}@anchor{afe}@ref{afe,,.bool.check.inline;} The inline macro version of @code{BoolCheck} casts
the @code{int} to @code{unsigned} and checks that it is @code{<= 1}. This is
safe, well-defined, uses the argument exactly once, and generates
reasonable code.

@anchor{design/type design mps type bool check inline smaller}@anchor{aff}@ref{aff,,.bool.check.inline.smaller;} In fact we can expect that the “inline”
version of @code{BoolCheck()} to be smaller than the equivalent function
call. On IA-32 for example, a function call will be 3 instructions
(total 9 bytes), the inline code for @code{BoolCheck()} will be 1
instruction (total 3 bytes) (both sequences not including the test
which is the same length in either case).

@anchor{design/type design mps type bool check inline why}@anchor{b00}@ref{b00,,.bool.check.inline.why;} As well as being smaller (see
@ref{aff,,.bool.check.inline.smaller}) it is faster. On 1998-11-16 drj
compared @code{w3i3mv\hi\amcss.exe} running with and without the macro
for @code{BoolCheck} on the PC Aaron. “With” ran in 97.7% of the time
(averaged over 3 runs).

@anchor{design/type design mps type bool bitfield}@anchor{b01}@ref{b01,,.bool.bitfield;} When a Boolean needs to be stored in a bitfield,
the type of the bitfield must be @code{unsigned:1}, not @code{Bool:1}.
(That’s because the two values of the type @code{Bool:1} are @code{0} and
@code{-1}, which means that assigning @code{TRUE} would require a sign
conversion.) To make it clear why this is done, @code{misc.h} provides
the @code{BOOLFIELD} macro.

@anchor{design/type design mps type bool bitfield assign}@anchor{b02}@ref{b02,,.bool.bitfield.assign;} To avoid warnings about loss of data from
GCC with the @code{-Wconversion} option, @code{misc.h} provides the
@code{BOOLOF} macro for coercing a value to an unsigned single-bit field.

@anchor{design/type design mps type bool bitfield check}@anchor{b03}@ref{b03,,.bool.bitfield.check;} A Boolean bitfield cannot have an incorrect
value, and if you call @code{BoolCheck()} on such a bitfield then GCC 4.2
issues the warning “comparison is always true due to limited range of
data type”. When avoiding such a warning, reference this tag.

@geindex BufferMode (C type)
@anchor{design/type c BufferMode}@anchor{b04}
@deffn {C Type} typedef unsigned BufferMode
@end deffn

@anchor{design/type design mps type buffermode}@anchor{b05}@ref{b05,,.buffermode;} @ref{b04,,BufferMode} is a bitset of buffer attributes. See
design.mps.buffer@footnote{buffer.html}. It is a sum of the following:


@multitable {xxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Mode

@tab

Description

@item

@code{BufferModeATTACHED}

@tab

Buffer is attached to a region of memory.

@item

@code{BufferModeFLIPPED}

@tab

Buffer has been flipped.

@item

@code{BufferModeLOGGED}

@tab

Buffer remains permanently trapped, so that
all reserve and commit events can be logged.

@item

@code{BufferModeTRANSITION}

@tab

Buffer is in the process of being detached.

@end multitable


@geindex Byte (C type)
@anchor{design/type c Byte}@anchor{ae9}
@deffn {C Type} typedef unsigned char Byte
@end deffn

@anchor{design/type design mps type byte}@anchor{b06}@ref{b06,,.byte;} @ref{ae9,,Byte} is an unsigned integral type corresponding to the
unit in which most sizes are measured, and also the units of
@code{sizeof}.

@anchor{design/type design mps type byte use}@anchor{b07}@ref{b07,,.byte.use;} @ref{ae9,,Byte} should be used in preference to @code{char} or
@code{unsigned char} wherever it is necessary to deal with bytes
directly.

@anchor{design/type design mps type byte source}@anchor{b08}@ref{b08,,.byte.source;} @ref{ae9,,Byte} is a just pedagogic version of @code{unsigned
char}, since @code{char} is the unit of @code{sizeof}.

@geindex Clock (C type)
@anchor{design/type c Clock}@anchor{b09}
@deffn {C Type} typedef @ref{653,,Word} Clock
@end deffn

@anchor{design/type design mps type clock}@anchor{b0a}@ref{b0a,,.clock;} @ref{b09,,Clock} is an unsigned integral type representing clock
time since some epoch.

@anchor{design/type design mps type clock use}@anchor{b0b}@ref{b0b,,.clock.use;} A @ref{b09,,Clock} value is returned by the plinth function
@code{mps_clock}. It is used to make collection scheduling decisions and
to calibrate the time stamps on events in the telemetry stream.

@anchor{design/type design mps type clock units}@anchor{b0c}@ref{b0c,,.clock.units;} The plinth function @code{mps_clocks_per_sec} defines
the units of a @ref{b09,,Clock} value.

@anchor{design/type design mps type clock conv c}@anchor{b0d}@ref{b0d,,.clock.conv.c;} @ref{b09,,Clock} is converted to @ref{12a,,mps_clock_t} in the MPS
C Interface.

@geindex Compare (C type)
@anchor{design/type c Compare}@anchor{944}
@deffn {C Type} typedef unsigned Compare
@end deffn

@anchor{design/type design mps type compare}@anchor{b0e}@ref{b0e,,.compare;} @ref{944,,Compare} is the type of tri-state comparison
values.


@multitable {xxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Value

@tab

Description

@item

@code{CompareLESS}

@tab

A value compares less than another value.

@item

@code{CompareEQUAL}

@tab

Two values compare the same.

@item

@code{CompareGREATER}

@tab

A value compares greater than another value.

@end multitable


@geindex Count (C type)
@anchor{design/type c Count}@anchor{3af}
@deffn {C Type} typedef @ref{653,,Word} Count
@end deffn

@anchor{design/type design mps type count}@anchor{b0f}@ref{b0f,,.count;} @ref{3af,,Count} is an unsigned integral type which is large
enough to hold the size of any collection of objects in the MPS.

@anchor{design/type design mps type count use}@anchor{b10}@ref{b10,,.count.use;} @ref{3af,,Count} should be used for a number of objects
(control or managed) where the maximum number of objects cannot be
statically determined. If the maximum number can be statically
determined then the smallest unsigned integer with a large enough
range may be used instead (although @ref{3af,,Count} may be preferable for
clarity).

@anchor{design/type design mps type count use other}@anchor{b11}@ref{b11,,.count.use.other;} @ref{3af,,Count} may also be used to count things that
aren’t represented by objects (for example, levels), but only where it
can be determined that the maximum count is less than the number of
objects.

@geindex Epoch (C type)
@anchor{design/type c Epoch}@anchor{b12}
@deffn {C Type} typedef @ref{40e,,Size} Epoch
@end deffn

@anchor{design/type design mps type epoch}@anchor{b13}@ref{b13,,.epoch;} An @ref{b12,,Epoch} is a count of the number of flips that have
occurred, in which objects may have moved. It is used in the
implementation of location dependencies.

@ref{b12,,Epoch} is converted to @ref{6d,,mps_word_t} in the MPS C Interface, as a
field of @ref{f4,,mps_ld_s}.

@geindex FindDelete (C type)
@anchor{design/type c FindDelete}@anchor{b14}
@deffn {C Type} typedef unsigned FindDelete
@end deffn

@anchor{design/type design mps type finddelete}@anchor{b15}@ref{b15,,.finddelete;} @ref{b14,,FindDelete} represents an instruction to one of the
`find' methods of a @ref{53c,,Land} as to what it should do if it finds a
suitable block. See design.mps.land@footnote{land.html}. It takes one of the following
values:


@multitable {xxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Value

@tab

Description

@item

@code{FindDeleteNONE}

@tab

Don’t delete after finding.

@item

@code{FindDeleteLOW}

@tab

Delete from low end of block.

@item

@code{FindDeleteHIGH}

@tab

Delete from high end of block.

@item

@code{FindDeleteENTIRE}

@tab

Delete entire block.

@end multitable


@geindex Fun (C type)
@anchor{design/type c Fun}@anchor{b16}
@deffn {C Type} typedef void (*Fun)(void)
@end deffn

@anchor{design/type design mps type fun}@anchor{b17}@ref{b17,,.fun;} @ref{b16,,Fun} is the type of a pointer to a function about which
nothing more is known.

@anchor{design/type design mps type fun use}@anchor{b18}@ref{b18,,.fun.use;} @ref{b16,,Fun} should be used where it’s necessary to handle a
function in a polymorphic way without calling it. For example, if you
need to write a function @code{g} which passes another function @code{f}
through to a third function @code{h}, where @code{h} knows the real type of
@code{f} but @code{g} doesn’t.

@geindex Index (C type)
@anchor{design/type c Index}@anchor{b19}
@deffn {C Type} typedef @ref{653,,Word} Index
@end deffn

@anchor{design/type design mps type index}@anchor{b1a}@ref{b1a,,.index;} @ref{b19,,Index} is an unsigned integral type which is large
enough to hold any array index.

@anchor{design/type design mps type index use}@anchor{b1b}@ref{b1b,,.index.use;} @ref{b19,,Index} should be used where the maximum size of the
array cannot be statically determined. If the maximum size can be
determined then the smallest unsigned integer with a large enough
range may be used instead.

@geindex LocusPrefKind (C type)
@anchor{design/type c LocusPrefKind}@anchor{b1c}
@deffn {C Type} typedef unsigned LocusPrefKind
@end deffn

@anchor{design/type design mps type locusprefkind}@anchor{b1d}@ref{b1d,,.locusprefkind;} The type @ref{b1c,,LocusPrefKind} expresses a preference for
addresses within an address space. It takes one of the following
values:


@multitable {xxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Kind

@tab

Description

@item

@code{LocusPrefHIGH}

@tab

Prefer high addresses.

@item

@code{LocusPrefLOW}

@tab

Prefer low addresses.

@item

@code{LocusPrefZONESET}

@tab

Prefer addresses in specified zones.

@end multitable


@geindex MessageType (C type)
@anchor{design/type c MessageType}@anchor{708}
@deffn {C Type} typedef unsigned MessageType
@end deffn

@anchor{design/type design mps type messagetype}@anchor{b1e}@ref{b1e,,.messagetype;} @ref{708,,MessageType} is the type of a message. See
design.mps.message@footnote{message.html}. It takes one of the following values:


@multitable {xxxxxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Message type

@tab

Description

@item

@code{MessageTypeFINALIZATION}

@tab

A block is finalizable.

@item

@code{MessageTypeGC}

@tab

A garbage collection finished.

@item

@code{MessageTypeGCSTART}

@tab

A garbage collection started.

@end multitable


@geindex Rank (C type)
@anchor{design/type c Rank}@anchor{b1f}
@deffn {C Type} typedef unsigned Rank
@end deffn

@anchor{design/type design mps type rank}@anchor{b20}@ref{b20,,.rank;} @ref{b1f,,Rank} is an enumeration which represents the rank of a
reference. The ranks are:


@multitable {xxxxxxxxxxxxxxx} {xxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Rank

@tab

Index

@tab

Description

@item

@code{RankAMBIG}

@tab

0

@tab

The reference is ambiguous. That is, it must be
assumed to be a reference, but not updated in
case it isn’t.

@item

@code{RankEXACT}

@tab

1

@tab

The reference is exact, and refers to an object.

@item

@code{RankFINAL}

@tab

2

@tab

The reference is exact and final, so special
action is required if only final or weak
references remain to the object.

@item

@code{RankWEAK}

@tab

3

@tab

The reference is exact and weak, so should
be deleted if only weak references remain to the
object.

@end multitable


@ref{b1f,,Rank} is stored with segments and roots, and passed around.

@ref{b1f,,Rank} is converted to @ref{146,,mps_rank_t} in the MPS C Interface.

The ordering of the ranks is important. It is the order in which the
references must be scanned in order to respect the properties of
references of the ranks. Therefore they are declared explicitly with
their integer values.

@cartouche
@quotation Note 
Could @ref{b1f,,Rank} be an @code{unsigned short} or @code{unsigned char}?
@end quotation
@end cartouche

@cartouche
@quotation Note 
This documentation should be expanded and moved to its own
document, then referenced from the implementation more thoroughly.
@end quotation
@end cartouche

@geindex RankSet (C type)
@anchor{design/type c RankSet}@anchor{b21}
@deffn {C Type} typedef unsigned RankSet
@end deffn

@anchor{design/type design mps type rankset}@anchor{b22}@ref{b22,,.rankset;} @ref{b21,,RankSet} is a set of ranks, represented as a bitset.

@geindex ReadonlyAddr (C type)
@anchor{design/type c ReadonlyAddr}@anchor{b23}
@deffn {C Type} typedef const struct AddrStruct *ReadonlyAddr
@end deffn

@anchor{design/type design mps type readonlyaddr}@anchor{af3}@ref{af3,,.readonlyaddr;} @ref{b23,,ReadonlyAddr} is the type used for managed
addresses that an interface promises it will only read through, never
write. Otherwise it is identical to @ref{632,,Addr}.

@geindex Ref (C type)
@anchor{design/type c Ref}@anchor{b24}
@deffn {C Type} typedef @ref{632,,Addr} Ref
@end deffn

@anchor{design/type design mps type ref}@anchor{b25}@ref{b25,,.ref;} @ref{b24,,Ref} is a reference to a managed object (as opposed to any
old managed address). @ref{b24,,Ref} should be used where a reference is
intended.

@cartouche
@quotation Note 
This isn’t too clear – richard
@end quotation
@end cartouche

@geindex RefSet (C type)
@anchor{design/type c RefSet}@anchor{b26}
@deffn {C Type} typedef @ref{653,,Word} RefSet
@end deffn

@anchor{design/type design mps type refset}@anchor{b27}@ref{b27,,.refset;} @ref{b26,,RefSet} is a conservative approximation to a set of
references. See design.mps.collection.refsets@footnote{collection.html#design.mps.collection.refsets}.

@geindex Res (C type)
@anchor{design/type c Res}@anchor{55f}
@deffn {C Type} typedef int Res
@end deffn

@anchor{design/type design mps type res}@anchor{b28}@ref{b28,,.res;} @ref{55f,,Res} is the type of result codes. A result code indicates
the success or failure of an operation, along with the reason for
failure. Like Unix error codes, the meaning of the code depends on the
call that returned it. These codes are just broad categories with
mnemonic names for various sorts of problems.


@multitable {xxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Result code

@tab

Description

@item

@code{ResOK}

@tab

The operation succeeded. Return parameters may only
be updated if OK is returned, otherwise they must
be left untouched.

@item

@code{ResCOMMIT_LIMIT}

@tab

The arena’s commit limit would have been exceeded
as a result of allocation.

@item

@code{ResFAIL}

@tab

Something went wrong which doesn’t fall into any of
the other categories. The exact meaning depends
on the call. See documentation.

@item

@code{ResIO}

@tab

An I/O error occurred. Exactly what depends on the
function.

@item

@code{ResLIMIT}

@tab

An internal limitation was reached.  For example,
the maximum number of somethings was reached. We
should avoid returning this by not including
static limitations in our code, as far as
possible. (See rule.impl.constrain and
rule.impl.limits.)

@item

@code{ResMEMORY}

@tab

Needed memory (committed memory, not address space)
could not be obtained.

@item

@code{ResPARAM}

@tab

An invalid parameter was passed.  Normally reserved
for parameters passed from the client.

@item

@code{ResRESOURCE}

@tab

A needed resource could not be obtained. Which
resource depends on the call. See also
@code{ResMEMORY}, which is a special case of this.

@item

@code{ResUNIMPL}

@tab

The operation, or some vital part of it, is
unimplemented. This might be returned by
functions which are no longer supported, or by
operations which are included for future
expansion, but not yet supported.

@end multitable


@anchor{design/type design mps type res use}@anchor{b29}@ref{b29,,.res.use;} @ref{55f,,Res} should be returned from any function which might
fail. Any other results of the function should be passed back in
“return” parameters (pointers to locations to fill in with the
results).

@cartouche
@quotation Note 
This is documented elsewhere, I think – richard
@end quotation
@end cartouche

@anchor{design/type design mps type res use spec}@anchor{b2a}@ref{b2a,,.res.use.spec;} The most specific code should be returned.

@geindex RootMode (C type)
@anchor{design/type c RootMode}@anchor{b2b}
@deffn {C Type} typedef unsigned RootMode
@end deffn

@anchor{design/type design mps type rootmode}@anchor{b2c}@ref{b2c,,.rootmode;} @ref{b2b,,RootMode} is an unsigned integral type which is used
to represent an attribute of a root:


@multitable {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Root mode

@tab

Description

@item

@code{RootModeCONSTANT}

@tab

Client program will not change the root
after it is registered.

@item

@code{RootModePROTECTABLE}

@tab

Root is protectable: the MPS may place
a barrier on any page containing any
part of the root.

@item

@code{RootModePROTECTABLE_INNER}

@tab

Root is protectable: the MPS may place
a barrier on any page completely covered
by part of the root.

@end multitable


@anchor{design/type design mps type rootmode const unused}@anchor{b2d}@ref{b2d,,.rootmode.const.unused;} @code{RootModeCONSTANT} has no effect. This
mode was introduced in the hope of being able to maintain a remembered
set for the root without needing a write barrier, but it can’t work as
described, since you can’t reliably create a valid registered constant
root that contains any references. (If you add the references before
registering the root, they may have become invalid; but you can’t add
them afterwards because the root is supposed to be constant.)

@anchor{design/type design mps type rootmode conv c}@anchor{b2e}@ref{b2e,,.rootmode.conv.c;} @ref{b2b,,RootMode} is converted to @ref{20f,,mps_rm_t} in the
MPS C Interface.

@geindex RootVar (C type)
@anchor{design/type c RootVar}@anchor{b2f}
@deffn {C Type} typedef unsigned RootVar
@end deffn

@anchor{design/type design mps type rootvar}@anchor{b30}@ref{b30,,.rootvar;} The type @ref{b2f,,RootVar} is the type of the discriminator for
the union within @code{RootStruct}.

@geindex Serial (C type)
@anchor{design/type c Serial}@anchor{b31}
@deffn {C Type} typedef unsigned Serial
@end deffn

@anchor{design/type design mps type serial}@anchor{b32}@ref{b32,,.serial;} A @ref{b31,,Serial} is a number which is assigned to a structure
when it is initialized. The serial number is taken from a field in the
parent structure, which is incremented. Thus, every instance of a
structure has a unique “name” which is a path of structures from the
global root. For example, “the third arena’s fifth pool’s second
buffer”.

Why? Consistency checking, debugging, and logging. Not well thought
out.

@geindex Shift (C type)
@anchor{design/type c Shift}@anchor{b33}
@deffn {C Type} typedef unsigned Shift
@end deffn

@anchor{design/type design mps type shift}@anchor{b34}@ref{b34,,.shift;} @ref{b33,,Shift} is an unsigned integral type which can hold the
amount by which a @ref{653,,Word} can be shifted. It is therefore large
enough to hold the word width (in bits).

@anchor{design/type design mps type shift use}@anchor{b35}@ref{b35,,.shift.use;} @ref{b33,,Shift} should be used whenever a shift value (the
right-hand operand of the @code{<<} or @code{>>} operators) is intended, to
make the code clear. It should also be used for structure fields which
have this use.

@cartouche
@quotation Note 
Could @ref{b33,,Shift} be an @code{unsigned short} or @code{unsigned char}?
@end quotation
@end cartouche

@geindex Sig (C type)
@anchor{design/type c Sig}@anchor{8dc}
@deffn {C Type} typedef unsigned long Sig
@end deffn

@anchor{design/type design mps type sig}@anchor{b36}@ref{b36,,.sig;} @ref{8dc,,Sig} is the type of signatures, which are written into
structures when they are created, and invalidated when they are
destroyed. They provide a limited form of run-time type checking and
dynamic scope checking. See design.mps.sig@footnote{sig.html}.

@geindex Size (C type)
@anchor{design/type c Size}@anchor{40e}
@deffn {C Type} typedef @ref{653,,Word} Size
@end deffn

@anchor{design/type design mps type size}@anchor{b37}@ref{b37,,.size;} @ref{40e,,Size} is an unsigned integral type large enough to
hold the size of any object which the MPS might manage.

@anchor{design/type design mps type size byte}@anchor{b38}@ref{b38,,.size.byte;} @ref{40e,,Size} should hold a size calculated in bytes.

@cartouche
@quotation Warning 
This is violated by @code{GenParams.capacity} (which is measured in
kilobytes).
@end quotation
@end cartouche

@anchor{design/type design mps type size use}@anchor{b39}@ref{b39,,.size.use;} @ref{40e,,Size} should be used whenever the code needs to deal
with the size of managed memory or client objects. It should not be
used for the sizes of the memory manager’s own data structures, so
that the memory manager is amenable to working in a separate address
space. Be careful not to confuse it with @code{size_t}.

@anchor{design/type design mps type size ops}@anchor{b3a}@ref{b3a,,.size.ops;} @code{SizeIsAligned()}, @code{SizeAlignUp()},
@code{SizeAlignDown()} and @code{SizeRoundUp()}.

@anchor{design/type design mps type size conv c}@anchor{b3b}@ref{b3b,,.size.conv.c;} @ref{40e,,Size} is converted to @code{size_t} in the MPS C
Interface. This constrains the memory manager to the same address
space as the client data.

@geindex TraceId (C type)
@anchor{design/type c TraceId}@anchor{b3c}
@deffn {C Type} typedef unsigned TraceId
@end deffn

@anchor{design/type design mps type traceid}@anchor{b3d}@ref{b3d,,.traceid;} A @ref{b3c,,TraceId} is an unsigned integer which is less than
@code{TraceLIMIT}. Each running trace has a different @ref{b3c,,TraceId} which
is used to index into the tables and bitfields that record the state
of that trace. See design.mps.trace.instance.limit@footnote{trace.html#design.mps.trace.instance.limit}.

@geindex TraceSet (C type)
@anchor{design/type c TraceSet}@anchor{b3e}
@deffn {C Type} typedef unsigned TraceSet
@end deffn

@anchor{design/type design mps type traceset}@anchor{b3f}@ref{b3f,,.traceset;} A @ref{b3e,,TraceSet} is a bitset of @ref{b3c,,TraceId},
represented in the obvious way:

@example
member(ti, ts) ⇔ ((1<<ti) & ts) != 0
@end example

In the multiple-traces design, each region of memory may be a
different colour for each trace. Thus the set of traces for which a
segment is grey (say) is represented by a @ref{b3e,,TraceSet}. See
design.mps.trace@footnote{trace.html}.

@geindex TraceStartWhy (C type)
@anchor{design/type c TraceStartWhy}@anchor{b40}
@deffn {C Type} typedef unsigned TraceStartWhy
@end deffn

@anchor{design/type design mps type tracestartwhy}@anchor{b41}@ref{b41,,.tracestartwhy;} @ref{b40,,TraceStartWhy} represents the reason that a
trace was started. It takes one of the following values:


@multitable {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Reason

@tab

Description

@item

@code{TraceStartWhyCHAIN_GEN0CAP}

@tab

Generation zero of a chain
reached capacity.

@item

@code{TraceStartWhyDYNAMICCRITERION}

@tab

Need to start full collection
now, or there won’t be enough
memory to complete it.

@item

@code{TraceStartWhyOPPORTUNISM}

@tab

Client had idle time available.

@item

@code{TraceStartWhyCLIENTFULL_INCREMENTAL}

@tab

Client requested incremental
collection.

@item

@code{TraceStartWhyCLIENTFULL_BLOCK}

@tab

Client requested full
collection.

@item

@code{TraceStartWhyWALK}

@tab

Walking references.

@item

@code{TraceStartWhyEXTENSION}

@tab

Request by MPS extension.

@end multitable


@geindex TraceState (C type)
@anchor{design/type c TraceState}@anchor{b42}
@deffn {C Type} typedef unsigned TraceState
@end deffn

@anchor{design/type design mps type tracestate}@anchor{b43}@ref{b43,,.tracestate;} @ref{b42,,TraceState} represents the current state in a
trace’s lifecycle. See design.mps.trace@footnote{trace.html}. It takes one of the
following values:


@multitable {xxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

State

@tab

Description

@item

@code{TraceINIT}

@tab

Nothing happened yet.

@item

@code{TraceUNFLIPPED}

@tab

Segments condemned (made white); initial grey set
created; scanning rate calculated.

@item

@code{TraceFLIPPED}

@tab

Buffers flipped; roots scanned; location
dependencies made stale; grey segments protected.

@item

@code{TraceRECLAIM}

@tab

There are no outstanding grey segments.

@item

@code{TraceFINISHED}

@tab

All segments reclaimed.

@end multitable


@geindex ULongest (C type)
@anchor{design/type c ULongest}@anchor{b44}
@deffn {C Type} typedef @ref{2fd,,MPS_T_ULONGEST} ULongest
@end deffn

@anchor{design/type design mps type ulongest}@anchor{b45}@ref{b45,,.ulongest;} @ref{b44,,ULongest} is the longest unsigned integer on the
platform. (We used to use @code{unsigned long} but this assumption is
violated by 64-bit Windows.) This type should be used for calculations
where any integer might be passed. Notably, it is used in @ref{446,,WriteF()}
to print any integer.

@geindex Word (C type)
@anchor{design/type c Word}@anchor{653}
@deffn {C Type} typedef @ref{2fe,,MPS_T_WORD} Word
@end deffn

@anchor{design/type design mps type word}@anchor{b46}@ref{b46,,.word;} @ref{653,,Word} is an unsigned integral type which matches the size
of the machine word, that is, the natural size of the machine
registers and addresses.

@anchor{design/type design mps type word use}@anchor{b47}@ref{b47,,.word.use;} @ref{653,,Word} should be used where an unsigned integer is
required that might range as large as the machine word.

@anchor{design/type design mps type word source}@anchor{b48}@ref{b48,,.word.source;} @ref{653,,Word} is derived from the macro @ref{2fe,,MPS_T_WORD}
which is declared in impl.h.mpstd according to the target platform
(design.mps.config.pf.word@footnote{config.html#design.mps.config.pf.word}).

@anchor{design/type design mps type word conv c}@anchor{b49}@ref{b49,,.word.conv.c;} @ref{653,,Word} is converted to @ref{6d,,mps_word_t} in the MPS C
Interface.

@anchor{design/type design mps type word ops}@anchor{b4a}@ref{b4a,,.word.ops;} @code{WordIsAligned()}, @code{WordAlignUp()},
@code{WordAlignDown()} and @code{WordRoundUp()}.

@geindex Work (C type)
@anchor{design/type c Work}@anchor{b4b}
@deffn {C Type} typedef @ref{2fe,,MPS_T_WORD} Work
@end deffn

@anchor{design/type design mps type work}@anchor{b4c}@ref{b4c,,.work;} @code{Work} is an unsigned integral type representing
accumulated work done by the collector.

@anchor{design/type design mps type work impl}@anchor{b4d}@ref{b4d,,.work.impl;} Work is implemented as a count of the bytes scanned by
the collector in segments and roots. This is a very crude measure,
because it depends on the scanning functions supplied by the mutator,
which we know very little about.

@geindex ZoneSet (C type)
@anchor{design/type c ZoneSet}@anchor{b4e}
@deffn {C Type} typedef @ref{653,,Word} ZoneSet
@end deffn

@anchor{design/type design mps type zoneset}@anchor{b4f}@ref{b4f,,.zoneset;} @ref{b4e,,ZoneSet} is a conservative approximation to a set of
zones. See design.mps.collection.refsets@footnote{collection.html#design.mps.collection.refsets}.

@node Abstract types,,Concrete types,General MPS types
@anchor{design/type abstract-types}@anchor{b50}
@subsection Abstract types


@anchor{design/type design mps type adts}@anchor{b51}@ref{b51,,.adts;} The following types are abstract data types, implemented as
pointers to structures. For example, @ref{85c,,Ring} is a pointer to a
@code{RingStruct}. They are described elsewhere.

@ref{b52,,AllocFrame}, @code{AllocPattern}, @code{AP}, @ref{796,,Arena}, @code{BootBlock},
@code{Buffer}, @code{Chain}, @code{Chunk}, @code{Format}, @code{Globals}, @ref{53c,,Land},
@code{LD}, @ref{6ca,,Lock}, @code{LocusPref}, @ref{7bc,,MutatorContext}, @code{PoolClass},
@code{Page}, @code{Pool}, @code{PoolDebugMixin}, @ref{686,,Range}, @ref{85c,,Ring}, @code{Root},
@code{ScanState}, @ref{b53,,Seg}, @code{SegBuf}, @ref{9d8,,StackContext}, @ref{7be,,Thread},
@code{Trace}, @ref{b54,,VM}.

@geindex Pointer (C type)
@anchor{design/type c Pointer}@anchor{b55}
@deffn {C Type} typedef void *Pointer
@end deffn

@anchor{design/type design mps type pointer}@anchor{b56}@ref{b56,,.pointer;} The type @ref{b55,,Pointer} is the same as @code{void *}, and
exists to sanctify functions such as @code{PointerAdd()}.

@geindex library version mechanism; design

@node Library version mechanism,Virtual mapping,General MPS types,Design
@anchor{design/version-library doc}@anchor{b57}@anchor{design/version-library design-version-library}@anchor{b58}@anchor{design/version-library library-version-mechanism}@anchor{b59}
@section Library version mechanism


@menu
* Introduction: Introduction<42>. 
* Readership:: 
* Source:: 
* Overview: Overview<9>. 
* Architecture: Architecture<3>. 
* Implementation: Implementation<14>. 

@end menu

@node Introduction<42>,Readership,,Library version mechanism
@anchor{design/version-library design mps version-library}@anchor{b5a}@anchor{design/version-library introduction}@anchor{b5b}
@subsection Introduction


@anchor{design/version-library design mps version-library intro}@anchor{b5c}@ref{b5c,,.intro;} This describes the design of a mechanism to be used to
determine the version (that is, product, version, and release) of an
MPS library.

@node Readership,Source,Introduction<42>,Library version mechanism
@anchor{design/version-library readership}@anchor{b5d}
@subsection Readership


@anchor{design/version-library design mps version-library readership}@anchor{b5e}@ref{b5e,,.readership;} Any MPS developer.

@node Source,Overview<9>,Readership,Library version mechanism
@anchor{design/version-library source}@anchor{b5f}
@subsection Source


@anchor{design/version-library design mps version-library source}@anchor{b60}@ref{b60,,.source;} Various requirements demand such a mechanism. See
request.epcore.160021@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/epcore/160021}: There is no way to tell which version and
release of the MM one is using.

@node Overview<9>,Architecture<3>,Source,Library version mechanism
@anchor{design/version-library overview}@anchor{b61}@anchor{design/version-library request-epcore-160021}@anchor{b62}
@subsection Overview


@anchor{design/version-library design mps version-library overview}@anchor{b63}@ref{b63,,.overview;} This is the design for determining which version of the
library one has linked against. There are two aspects to the design,
allowing humans to determine the version of an MPS library, and
allowing programs to determine the version of an MPS library. Only the
former is currently designed (a method for humans to determine which
version of an MPS library is being used).

@anchor{design/version-library design mps version-library overview impl}@anchor{b64}@ref{b64,,.overview.impl;} The overall design is to have a distinctive string
compiled into the library binary. Various programs and tools will be
able to extract the string and display it. The string will identify
the version of the MPS begin used.

@node Architecture<3>,Implementation<14>,Overview<9>,Library version mechanism
@anchor{design/version-library architecture}@anchor{b65}
@subsection Architecture


@anchor{design/version-library design mps version-library arch structure}@anchor{b66}@ref{b66,,.arch.structure;} The design consists of two components:


@enumerate 

@item 
@anchor{design/version-library design mps version-library arch string}@anchor{b67}@ref{b67,,.arch.string;} A string embedded into any delivered library
binaries (which will encode the necessary information).

@item 
@anchor{design/version-library design mps version-library arch proc}@anchor{b68}@ref{b68,,.arch.proc;} Procedures by which the string is modified
appropriately whenever releases are made.

@item 
@anchor{design/version-library design mps version-library arch tool}@anchor{b69}@ref{b69,,.arch.tool;} A tool and its documentation (it is expected that
standard tools can be used). The tool will be used to extract the
version string from a delivered library or an executable linked
with the library.
@end enumerate

The string will contain information to identify the following items:


@enumerate 

@item 
@anchor{design/version-library design mps version-library arch string platform}@anchor{b6a}@ref{b6a,,.arch.string.platform;} the platform being used.

@item 
@anchor{design/version-library design mps version-library arch string product}@anchor{b6b}@ref{b6b,,.arch.string.product;} the name of the product.

@item 
@anchor{design/version-library design mps version-library arch string variety}@anchor{b6c}@ref{b6c,,.arch.string.variety;} the variety of the product.

@item 
@anchor{design/version-library design mps version-library arch string version}@anchor{b6d}@ref{b6d,,.arch.string.version;} the version and release of the product.
@end enumerate

@node Implementation<14>,,Architecture<3>,Library version mechanism
@anchor{design/version-library implementation}@anchor{b6e}
@subsection Implementation


@anchor{design/version-library design mps version-library impl file}@anchor{b6f}@ref{b6f,,.impl.file;} The version string itself is a declared C object
@code{MPSVersionString} in the file @code{version.c} (impl.c.version). It
consists of a concatenation of various strings which are defined in
other modules.

@anchor{design/version-library design mps version-library impl variety}@anchor{b70}@ref{b70,,.impl.variety;} The string containing the name of the variety is the
expansion of the macro @code{MPS_VARIETY_STRING} defined by @code{config.h}
(impl.h.config).

@anchor{design/version-library design mps version-library impl product}@anchor{b71}@ref{b71,,.impl.product;} The string containing the name of the product is the
expansion of the macro @code{MPS_PROD_STRING} defined by @code{config.h}
(impl.h.config). Note that there is now only one product, so this is
always @code{"mps"} (see design.mps.config.req.prod@footnote{config.html#design.mps.config.req.prod}).

@anchor{design/version-library design mps version-library impl platform}@anchor{b72}@ref{b72,,.impl.platform;} The string containing the name of the platform is
the expansion of the macro @ref{2f6,,MPS_PF_STRING} defined by @code{mpstd.h}
(impl.h.mpstd).

@anchor{design/version-library design mps version-library impl date}@anchor{b73}@ref{b73,,.impl.date;} The string contains the date and time of compilation by
using the @code{__DATE__} and @code{__TIME__} macros defined by ISO C
§6.8.8.

@anchor{design/version-library design mps version-library impl version}@anchor{b74}@ref{b74,,.impl.version;} The string contains the version and release of the
product. This is by the expansion of the macro @code{MPS_RELEASE} which
is defined in this module (@code{version.c}).

@anchor{design/version-library design mps version-library impl proc}@anchor{b75}@ref{b75,,.impl.proc;} The @code{MPS_RELEASE} macro (see impl.c.version.release)
is edited after making a release so that it contains the name of the
next release to be made from the sources on that branch. For example, after
making version 1.117, the source on the master branch is updated to say:

@example
#define MPS_RELEASE "release/1.118.0"
@end example

and after making release 1.117.0, the source on the version/1.117 branch is updated to say:

@example
#define MPS_RELEASE "release/1.117.1"
@end example

See the version creation and release build procedures respectively.

@anchor{design/version-library design mps version-library impl tool}@anchor{b76}@ref{b76,,.impl.tool;} The version string starts with the characters
@code{"@@(#)"}. This is recognized by the standard Unix utility what(1)@footnote{https://pubs.opengroup.org/onlinepubs/9699919799/utilities/what.html}. For example:

@example
$ what mps.a
mps.a
        Ravenbrook MPS, product.mps, release/1.117.0, platform.xci6ll, variety.asserted.logging.nonstats, compiled on Oct 18 2016 13:57:08
@end example

@geindex virtual mapping; design

@node Virtual mapping,Walking formatted objects,Library version mechanism,Design
@anchor{design/vm doc}@anchor{b77}@anchor{design/vm design-vm}@anchor{312}@anchor{design/vm virtual-mapping}@anchor{b78}@anchor{design/vm what}@anchor{b79}
@section Virtual mapping


@menu
* Introduction: Introduction<43>. 
* Requirements: Requirements<26>. 
* Design: Design<9>. 
* Interface: Interface<19>. 
* Implementations: Implementations<7>. 
* Testing: Testing<5>. 

@end menu

@node Introduction<43>,Requirements<26>,,Virtual mapping
@anchor{design/vm design mps vm}@anchor{b7a}@anchor{design/vm introduction}@anchor{b7b}
@subsection Introduction


@anchor{design/vm design mps vm intro}@anchor{b7c}@ref{b7c,,.intro;} This is the design of the virtual mapping module.

@anchor{design/vm design mps vm readership}@anchor{b7d}@ref{b7d,,.readership;} Any MPS developer; anyone porting the MPS to a new
platform.

@anchor{design/vm design mps vm overview}@anchor{b7e}@ref{b7e,,.overview;} The virtual mapping module provides a simple, portable,
low-level interface to address space, with functions for reserving,
releasing, mapping and unmapping ranges of addresses.

@anchor{design/vm design mps vm motivation}@anchor{b7f}@ref{b7f,,.motivation;} The virtual mapping module is heavily used by the VM
Arena Class (see design.mps.arena.vm@footnote{arenavm.html}).

@node Requirements<26>,Design<9>,Introduction<43>,Virtual mapping
@anchor{design/vm design-mps-arena-vm}@anchor{b80}@anchor{design/vm requirements}@anchor{b81}
@subsection Requirements


@anchor{design/vm design mps vm req granularity}@anchor{b82}@ref{b82,,.req.granularity;} The virtual mapping module must report the
`granularity' with which address space can be managed. (This is
necessary for the arena to be able to portably determine its grain
size; see design.mps.arena.def.grain@footnote{arena.html#design.mps.arena.def.grain}.)

@anchor{design/vm design mps vm req reserve}@anchor{b83}@ref{b83,,.req.reserve;} The `reserve' operation must reserves a chunk of
address space.

@anchor{design/vm design mps vm req reserve exclusive}@anchor{b84}@ref{b84,,.req.reserve.exclusive;} The MPS should have exclusive use of the
reserved chunk. (None of our supported operating systems can actually
provide this feature, alas. We rely on co-operation with the client
program.)

@anchor{design/vm design mps vm req reserve contiguous}@anchor{b85}@ref{b85,,.req.reserve.contiguous;} The reserved chunk is a `contiguous'
portion of address space. (Contiguity is needed for zones to work; see
design.mps.arena.vm.overview.gc.zone@footnote{arenavm.html#design.mps.arena.vm.overview.gc.zone}.)

@anchor{design/vm design mps vm req reserve size}@anchor{b86}@ref{b86,,.req.reserve.size;} The reserved chunk is at least a `specified
size'. (This is necessary for zones to work.)

@anchor{design/vm design mps vm req reserve align}@anchor{b87}@ref{b87,,.req.reserve.align;} The reserved chunk is aligned to a `specified
alignment'. (This is necessary for the arena to be able to manage
address space in terms of grains.)

@anchor{design/vm design mps vm req reserve overhead}@anchor{b88}@ref{b88,,.req.reserve.overhead;} The reserved chunk is not much larger than
specified, preferably with no more than a grain of overhead. (This is
necessary in order to allow the client program to specify the amount
of address space the MPS uses, so that it can co-operate with other
subsystems that use address space.)

@anchor{design/vm design mps vm req reserve address not}@anchor{b89}@ref{b89,,.req.reserve.address.not;} There is no requirement to be able to
reserve address space at a particular address. (The zone
implementation uses bits from the middle of the address, so can cope
wherever the portion is placed in the address space.)

@anchor{design/vm design mps vm req reserve map not}@anchor{b8a}@ref{b8a,,.req.reserve.map.not;} The reserve operation should not map the
chunk into main memory or swap space. (The zone strategy is most
efficient if address space is use sparsely, but main memory is a
limited resource.)

@anchor{design/vm design mps vm req release}@anchor{b8b}@ref{b8b,,.req.release;} The `release' operation should release a previously
reserved chunk of address space so that it may be used by other
subsystems of the client program. (This is needed to support client
programs on systems where address space is tight, and the client’s
subsystems need to co-operate in their use of address space.)

@anchor{design/vm design mps vm req reserved}@anchor{b8c}@ref{b8c,,.req.reserved;} The virtual mapping module must report the total
amount of reserved memory in each chunk of address space. (This is
needed to implement @ref{196,,mps_arena_reserved()}.)

@anchor{design/vm design mps vm req map}@anchor{b8d}@ref{b8d,,.req.map;} The `map' operation must arrange for a (previously
reserved) range of address space to be mapped into main memory or swap
space, so that addresses in the range can be read and written.

@anchor{design/vm design mps vm req unmap}@anchor{b8e}@ref{b8e,,.req.unmap;} The `unmap' operation should arrange for a previously
mapped range of address space to no longer be mapped into main memory
or swap space. (This is needed to support client programs on systems
where main memory is scarce, and the client’s subsystems need to
co-operate in their use of main memory.)

@anchor{design/vm design mps vm req mapped}@anchor{b8f}@ref{b8f,,.req.mapped;} The virtual mapping module must maintain the total
amount of mapped memory in each chunk of address space. (This is
needed to allow the client program to limit the use of main memory by
the MPS via the “commit limit” mechanism.)

@anchor{design/vm design mps vm req bootstrap}@anchor{b90}@ref{b90,,.req.bootstrap;} The virtual mapping module must be usable without
allocating heap memory. (This is necessary for the VM arena to get off
the ground.)

@anchor{design/vm design mps vm req params}@anchor{b91}@ref{b91,,.req.params;} The interface should make it possible for MPS to allow
the client program to modify the behaviour of the virtual mapping
implementation. (This is needed to implement the
@code{MPS_KEY_VMW3_MEM_TOP_DOWN} keyword argument.)

@anchor{design/vm design mps vm req prot exec}@anchor{b92}@ref{b92,,.req.prot.exec;} The virtual mapping module should allow mutators to
write machine code into memory allocated by the MPS and then execute
that code, for example, to implement just-in-time translation, or
other forms of dynamic compilation. Compare
design.mps.prot.req.prot.exec@footnote{prot.html#design.mps.prot.req.prot.exec}.

@node Design<9>,Interface<19>,Requirements<26>,Virtual mapping
@anchor{design/vm design}@anchor{b93}@anchor{design/vm design-mps-prot-req-prot-exec}@anchor{b94}
@subsection Design


@anchor{design/vm design mps vm sol overhead}@anchor{b95}@ref{b95,,.sol.overhead;} To meet @ref{b85,,.req.reserve.contiguous},
@ref{b87,,.req.reserve.align} and @ref{b88,,.req.reserve.overhead}, most VM
implementations ask the operating system for @code{size + grainSize -
pageSize} bytes of address space. This ensures that wherever the
operating system places the reserved address space, it contains a
contiguous region of @code{size} bytes aligned to a multiple of
@code{grainSize}. The overhead is thus @code{grainSize - pageSize}, and in
the common case where @code{grainSize} is equal to @code{pageSize}, this is
zero.

@anchor{design/vm design mps vm sol bootstrap}@anchor{b96}@ref{b96,,.sol.bootstrap;} To meet @ref{b90,,.req.bootstrap}, the interface provides
the function @ref{b97,,VMCopy()}. This allows the initialization of a
@code{VMChunk} to proceed in four steps. First, allocate space for a
temporary VM descriptor on the stack. Second, call @ref{3ec,,VMInit()} to
reserve address space and initialize the temporary VM descriptor.
Third, call @ref{3ed,,VMMap()} on the new VM to map enough memory to store a
@code{VMChunk}. Fourth, call @ref{b97,,VMCopy()} to copy the temporary VM
descriptor into its place in the @code{VMChunk}.

@anchor{design/vm design mps vm sol params}@anchor{b98}@ref{b98,,.sol.params;} To meet @ref{b91,,.req.params}, the interface provides the
function @ref{b99,,VMParamFromArgs()}, which decodes relevant keyword
arguments into a temporary buffer provided by the caller; this buffer
is then passed to @ref{3ec,,VMInit()}. The size of the buffer must be
statically determinable so that the caller can allocate it on the
stack: it is given by the constant @code{VMParamSize}. Since this is
potentially platform-dependent it is defined in @code{config.h}.

@anchor{design/vm design mps vm sol prot exec}@anchor{b9a}@ref{b9a,,.sol.prot.exec;} The virtual mapping module maps memory as
executable, if this is supported by the platform.

@node Interface<19>,Implementations<7>,Design<9>,Virtual mapping
@anchor{design/vm interface}@anchor{b9b}
@subsection Interface


@geindex VM (C type)
@anchor{design/vm c VM}@anchor{b54}
@deffn {C Type} typedef VMStruct *VM
@end deffn

@anchor{design/vm design mps vm if vm}@anchor{b9c}@ref{b9c,,.if.vm;} @ref{b54,,VM} is a descriptor for a reserved chunk of address
space. It points to a @code{VMStruct} structure, which is defined in
@code{vm.h} so that it can be inlined in the @code{VMChunkStruct} by the VM
arena class.

@geindex PageSize (C function)
@anchor{design/vm c PageSize}@anchor{b9d}
@deffn {C Function} @ref{40e,,Size} PageSize (void)
@end deffn

@anchor{design/vm design mps vm if page size}@anchor{b9e}@ref{b9e,,.if.page.size;} Return the “page size”: that is, the granularity
with which the operating system can reserve and map address space.

@anchor{design/vm design mps vm if page size cache}@anchor{b9f}@ref{b9f,,.if.page.size.cache;} On some systems (for example, Windows),
determining the page size requires a system call, so for speed the
page size is cached in each VM descriptor and should be retrieved by
calling the @code{VMPageSize()} function.

@geindex VMParamFromArgs (C function)
@anchor{design/vm c VMParamFromArgs}@anchor{b99}
@deffn {C Function} @ref{55f,,Res} VMParamFromArgs (void *params, size_t paramSize, ArgList args)
@end deffn

@anchor{design/vm design mps vm if param from args}@anchor{ba0}@ref{ba0,,.if.param.from.args;} Decode the relevant keyword arguments in the
@code{args} parameter, and store a description of them in the buffer
pointed to by @code{params} (which is @code{paramSize} bytes long). It is an
error if the buffer is not big enough store the parameters for the VM
implementation.

@geindex VMInit (C function)
@anchor{design/vm c VMInit}@anchor{3ec}
@deffn {C Function} @ref{55f,,Res} VMInit (VM vm, Size size, Size grainSize, void *params)
@end deffn

@anchor{design/vm design mps vm if init}@anchor{ba1}@ref{ba1,,.if.init;} Reserve a chunk of address space that contains at least
@code{size} addresses, starting at an address which is a multiple of
@code{grainSize}. The @code{params} argument points to a parameter block
that was initialized by a call to @ref{b99,,VMParamFromArgs()}. If
successful, update @code{vm} to describe the reserved chunk, and
return @code{ResOK}. Otherwise, return @code{ResRESOURCE}.

@geindex VMFinish (C function)
@anchor{design/vm c VMFinish}@anchor{ba2}
@deffn {C Function} void VMFinish (VM vm)
@end deffn

@anchor{design/vm design mps vm if finish}@anchor{ba3}@ref{ba3,,.if.finish;} Release the chunk of address space described by @code{vm}.
Any addresses that were mapped through this VM are now unmapped.

@geindex VMMap (C function)
@anchor{design/vm c VMMap}@anchor{3ed}
@deffn {C Function} @ref{55f,,Res} VMMap (VM vm, Addr base, Addr limit)
@end deffn

@anchor{design/vm design mps vm if map}@anchor{ba4}@ref{ba4,,.if.map;} Map the range of addresses from @code{base} (inclusive) to
@code{limit} (exclusive) into main memory. It is an error if the range
does not lie between @code{VMBase(vm)} and @code{VMLimit(vm)}, or if
@code{base} and @code{limit} are not multiples of @code{VMPageSize(vm)}. Return
@code{ResOK} if successful, @code{ResMEMORY} otherwise.

@geindex VMUnmap (C function)
@anchor{design/vm c VMUnmap}@anchor{ba5}
@deffn {C Function} void VMUnmap (VM vm, Addr base, Addr limit)
@end deffn

@anchor{design/vm design mps vm if unmap}@anchor{ba6}@ref{ba6,,.if.unmap;} Unmap the range of addresses from @code{base} (inclusive)
to @code{limit} (exclusive). The conditions are the same as for
@ref{3ed,,VMMap()}.

@geindex VMBase (C function)
@anchor{design/vm c VMBase}@anchor{ba7}
@deffn {C Function} @ref{632,,Addr} VMBase (VM vm)
@end deffn

@anchor{design/vm design mps vm if base}@anchor{ba8}@ref{ba8,,.if.base;} Return the base address of the VM (the lowest address in
the VM that is a multiple of the grain size).

@geindex VMLimit (C function)
@anchor{design/vm c VMLimit}@anchor{ba9}
@deffn {C Function} @ref{632,,Addr} VMLimit (VM vm)
@end deffn

@anchor{design/vm design mps vm if limit}@anchor{baa}@ref{baa,,.if.limit;} Return the limit address of the VM (the limit of the
last grain that is wholly inside the VM).

@geindex VMReserved (C function)
@anchor{design/vm c VMReserved}@anchor{bab}
@deffn {C Function} @ref{40e,,Size} VMReserved (VM vm)
@end deffn

@anchor{design/vm design mps vm if reserved}@anchor{bac}@ref{bac,,.if.reserved;} Return the amount of address space (in bytes)
reserved by the VM. This may include addresses that are not available
for mapping because of the requirement for @code{VMBase(vm)} and
@code{VMLimit(vm)} to be multiples of the grain size.

@geindex VMMapped (C function)
@anchor{design/vm c VMMapped}@anchor{bad}
@deffn {C Function} @ref{40e,,Size} VMMapped (VM vm)
@end deffn

@anchor{design/vm design mps vm if mapped}@anchor{bae}@ref{bae,,.if.mapped;} Return the amount of address space (in bytes) currently
mapped into memory by the VM.

@geindex VMCopy (C function)
@anchor{design/vm c VMCopy}@anchor{b97}
@deffn {C Function} void VMCopy (VM dest, VM src)
@end deffn

@anchor{design/vm design mps vm if copy}@anchor{baf}@ref{baf,,.if.copy;} Copy the VM descriptor from @code{src} to @code{dest}.

@node Implementations<7>,Testing<5>,Interface<19>,Virtual mapping
@anchor{design/vm implementations}@anchor{bb0}
@subsection Implementations


@menu
* Generic implementation: Generic implementation<3>. 
* Unix implementation:: 
* Windows implementation: Windows implementation<3>. 

@end menu

@node Generic implementation<3>,Unix implementation,,Implementations<7>
@anchor{design/vm generic-implementation}@anchor{bb1}
@subsubsection Generic implementation


@anchor{design/vm design mps vm impl an}@anchor{bb2}@ref{bb2,,.impl.an;} In @code{vman.c}.

@anchor{design/vm design mps vm impl an page size}@anchor{bb3}@ref{bb3,,.impl.an.page.size;} The generic VM uses a fake page size, given by
the constant @code{VMAN_PAGE_SIZE} in @code{config.h}.

@anchor{design/vm design mps vm impl an param}@anchor{bb4}@ref{bb4,,.impl.an.param;} Decodes no keyword arguments.

@anchor{design/vm design mps vm impl an reserve}@anchor{bb5}@ref{bb5,,.impl.an.reserve;} Address space is “reserved” by calling
@code{malloc()}.

@anchor{design/vm design mps vm impl an release}@anchor{bb6}@ref{bb6,,.impl.an.release;} Address space is “released” by calling
@code{free()}.

@anchor{design/vm design mps vm impl an map}@anchor{bb7}@ref{bb7,,.impl.an.map;} Mapping (and unmapping) just fills the mapped region
with copies of @code{VMJunkBYTE} to emulate the erasure of freshly mapped
pages by virtual memory systems.

@node Unix implementation,Windows implementation<3>,Generic implementation<3>,Implementations<7>
@anchor{design/vm unix-implementation}@anchor{bb8}
@subsubsection Unix implementation


@anchor{design/vm design mps vm impl ix}@anchor{bb9}@ref{bb9,,.impl.ix;} In @code{vmix.c}.

@anchor{design/vm design mps vm impl ix page size}@anchor{bba}@ref{bba,,.impl.ix.page.size;} The page size is given by
@code{sysconf(_SC_PAGESIZE)}.  We avoid @code{getpagesize()}, which is a
legacy function in Posix:

@quotation

Applications should use the sysconf() function instead.


@center --- The Single UNIX ® Specification@comma{} Version 2@footnote{https://pubs.opengroup.org/onlinepubs/7908799/xsh/getpagesize.html}

@end quotation

@anchor{design/vm design mps vm impl ix param}@anchor{bbb}@ref{bbb,,.impl.ix.param;} Decodes no keyword arguments.

@anchor{design/vm design mps vm impl ix reserve}@anchor{bbc}@ref{bbc,,.impl.ix.reserve;} Address space is reserved by calling mmap()@footnote{https://pubs.opengroup.org/onlinepubs/9699919799/functions/mmap.html},
passing @code{PROT_NONE} and @code{MAP_PRIVATE | MAP_ANON}.

@anchor{design/vm design mps vm impl ix anon trans}@anchor{bbd}@ref{bbd,,.impl.ix.anon.trans;} Note that @code{MAP_ANON} (“map anonymous
memory not associated with any specific file”) is an extension to
POSIX, but it is supported by FreeBSD, Linux, and macOS. A work-around
that was formerly used on systems lacking @code{MAP_ANON} was to map
the file @code{/dev/zero}.

@anchor{design/vm design mps vm impl ix release}@anchor{bbe}@ref{bbe,,.impl.ix.release;} Address space is released by calling munmap()@footnote{https://pubs.opengroup.org/onlinepubs/9699919799/functions/munmap.html}.

@anchor{design/vm design mps vm impl ix map}@anchor{bbf}@ref{bbf,,.impl.ix.map;} Address space is mapped to main memory by calling
mmap()@footnote{https://pubs.opengroup.org/onlinepubs/9699919799/functions/mmap.html}, passing @code{PROT_READ | PROT_WRITE | PROT_EXEC} and
@code{MAP_ANON | MAP_PRIVATE | MAP_FIXED}.

@anchor{design/vm design mps vm impl ix unmap}@anchor{bc0}@ref{bc0,,.impl.ix.unmap;} Address space is unmapped from main memory by
calling mmap()@footnote{https://pubs.opengroup.org/onlinepubs/9699919799/functions/mmap.html}, passing @code{PROT_NONE} and @code{MAP_ANON | MAP_PRIVATE |
MAP_FIXED}.

@anchor{design/vm design mps vm impl xc prot exec}@anchor{bc1}@ref{bc1,,.impl.xc.prot.exec;} The approach in @ref{b9a,,.sol.prot.exec} of always
making memory executable causes a difficulty on macOS on Apple
Silicon. The virtual mapping module uses the same solution as the
protection module, that is, detecting Apple Hardened Runtime, and
retrying without the request for the memory to be executable. See
design.mps.prot.impl.xc.prot.exec@footnote{prot.html#design.mps.prot.impl.xc.prot.exec} for details.

@node Windows implementation<3>,,Unix implementation,Implementations<7>
@anchor{design/vm design-mps-prot-impl-xc-prot-exec}@anchor{bc2}@anchor{design/vm windows-implementation}@anchor{bc3}
@subsubsection Windows implementation


@anchor{design/vm design mps vm impl w3}@anchor{bc4}@ref{bc4,,.impl.w3;} In @code{vmw3.c}.

@anchor{design/vm design mps vm impl w3 page size}@anchor{bc5}@ref{bc5,,.impl.w3.page.size;} The page size is retrieved by calling
GetSystemInfo()@footnote{https://docs.microsoft.com/en-us/windows/desktop/api/sysinfoapi/nf-sysinfoapi-getsysteminfo} and consulting @code{SYSTEMINFO.dwPageSize}.

@anchor{design/vm design mps vm impl w3 param}@anchor{bc6}@ref{bc6,,.impl.w3.param;} Decodes the keyword argument
@code{MPS_KEY_VMW3_MEM_TOP_DOWN}, and if it is set, arranges for
@ref{3ec,,VMInit()} to pass the @code{MEM_TOP_DOWN} flag to VirtualAlloc()@footnote{https://msdn.microsoft.com/en-us/library/windows/desktop/aa366887.aspx}.

@anchor{design/vm design mps vm impl w3 reserve}@anchor{bc7}@ref{bc7,,.impl.w3.reserve;} Address space is reserved by calling
VirtualAlloc()@footnote{https://msdn.microsoft.com/en-us/library/windows/desktop/aa366887.aspx}, passing @code{MEM_RESERVE} (and optionally
@code{MEM_TOP_DOWN}) and @code{PAGE_NOACCESS}.

@anchor{design/vm design mps vm impl w3 release}@anchor{bc8}@ref{bc8,,.impl.w3.release;} Address space is released by calling
VirtualFree()@footnote{https://msdn.microsoft.com/en-us/library/windows/desktop/aa366892.aspx}, passing @code{MEM_RELEASE}.

@anchor{design/vm design mps vm impl w3 map}@anchor{bc9}@ref{bc9,,.impl.w3.map;} Address space is mapped to main memory by calling
VirtualAlloc()@footnote{https://msdn.microsoft.com/en-us/library/windows/desktop/aa366887.aspx}, passing @code{MEM_COMMIT} and
@code{PAGE_EXECUTE_READWRITE}.

@anchor{design/vm design mps vm impl w3 unmap}@anchor{bca}@ref{bca,,.impl.w3.unmap;} Address space is unmapped from main memory by
calling VirtualFree()@footnote{https://msdn.microsoft.com/en-us/library/windows/desktop/aa366892.aspx}, passing @code{MEM_DECOMMIT}.

@node Testing<5>,,Implementations<7>,Virtual mapping
@anchor{design/vm testing}@anchor{bcb}
@subsection Testing


@anchor{design/vm design mps vm testing}@anchor{bcc}@ref{bcc,,.testing;} It is important to test that a VM implementation works in
extreme cases.

@anchor{design/vm design mps vm testing large}@anchor{bcd}@ref{bcd,,.testing.large;} It must be able to reserve a large address space.
Clients will want multi-GB spaces, more than that OSs will allow. If
they ask for too much, @ref{335,,mps_arena_create()} (and hence
@ref{3ec,,VMInit()}) must fail in a predictable way.

@anchor{design/vm design mps vm testing larger}@anchor{bce}@ref{bce,,.testing.larger;} It must be possible to allocate in a large space;
sometimes committing will fail, because there’s not enough space to
replace the “reserve” mapping. See request.epcore.160201@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/epcore/160201} for details.

@anchor{design/vm design mps vm testing lots}@anchor{bcf}@ref{bcf,,.testing.lots;} It must be possible to have lots of mappings. The OS
must either combine adjacent mappings or have lots of space in the
kernel tables. See request.epcore.160117@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/epcore/160117} for ideas on how to test
this.

@geindex walk; design

@node Walking formatted objects,Write barrier,Virtual mapping,Design
@anchor{design/walk doc}@anchor{bd0}@anchor{design/walk design-walk}@anchor{bd1}@anchor{design/walk request-epcore-160117}@anchor{bd2}@anchor{design/walk walking-formatted-objects}@anchor{bd3}
@section Walking formatted objects


@menu
* Introduction: Introduction<44>. 
* Use cases:: 
* Requirements: Requirements<27>. 
* Design: Design<10>. 
* References: References<18>. 

@end menu

@node Introduction<44>,Use cases,,Walking formatted objects
@anchor{design/walk design mps walk}@anchor{bd4}@anchor{design/walk introduction}@anchor{bd5}
@subsection Introduction


@anchor{design/walk design mps walk intro}@anchor{bd6}@ref{bd6,,.intro;} This is the design of the formatted objects walk interface.
The intended audience is MPS developers.

@anchor{design/walk design mps walk source}@anchor{bd7}@ref{bd7,,.source;} Based on @ref{bd8,,[GDR_2020-08-30]}.

@node Use cases,Requirements<27>,Introduction<44>,Walking formatted objects
@anchor{design/walk use-cases}@anchor{bd9}
@subsection Use cases


@anchor{design/walk design mps walk case reload}@anchor{bda}@ref{bda,,.case.reload;} A language runtime that offers hot reloading of code
will need to walk all objects belonging to a class (say) in order to
modify the references in the objects so they refer to the updated
class definition. @ref{bdb,,[Strömbäck_2020-08-20]}

@anchor{design/walk design mps walk case serialize}@anchor{bdc}@ref{bdc,,.case.serialize;} A language runtime that offers serialization and
deserialization of the heap will need to walk all formatted objects in
order to identify references to globals (during serialization) and
modify references to refer to the new locations of the globals (after
deserialization). @ref{bdd,,[GDR_2018-08-30]}

@node Requirements<27>,Design<10>,Use cases,Walking formatted objects
@anchor{design/walk requirements}@anchor{bde}
@subsection Requirements


@anchor{design/walk design mps walk req walk all}@anchor{bdf}@ref{bdf,,.req.walk.all;} It must be possible for the client program to visit
all automatically managed formatted objects using a callback.

@anchor{design/walk design mps walk req walk assume-format}@anchor{be0}@ref{be0,,.req.walk.assume-format;} The callback should not need to switch on
the format, as this may be awkward in a program which has modules
using different pools with different formats.

@anchor{design/walk design mps walk req walk examine}@anchor{be1}@ref{be1,,.req.walk.examine;} It must be possible for the callback to examine
other automatically managed memory while walking the objects.

@anchor{design/walk design mps walk req walk modify}@anchor{be2}@ref{be2,,.req.walk.modify;} It must be possible for the callback to modify
the references in the objects.

@anchor{design/walk design mps walk req walk overhead}@anchor{be3}@ref{be3,,.req.walk.overhead;} The overhead of calling the callback should be
minimized.

@anchor{design/walk design mps walk req walk perf}@anchor{be4}@ref{be4,,.req.walk.perf;} The performance of subsequent collections should
not be affected.

@anchor{design/walk design mps walk req walk closure}@anchor{be5}@ref{be5,,.req.walk.closure;} The callback must have access to arbitrary data
from the caller.

@anchor{design/walk design mps walk req walk maint}@anchor{be6}@ref{be6,,.req.walk.maint;} The interface should be easy to implement and
maintain.

@node Design<10>,References<18>,Requirements<27>,Walking formatted objects
@anchor{design/walk design}@anchor{be7}
@subsection Design


A new public function @ref{1a6,,mps_pool_walk()} visits the live formatted
objects in an automatically managed pool.

@anchor{design/walk design mps walk sol walk all}@anchor{be8}@ref{be8,,.sol.walk.all;} The client program must know which pools it has
created so it can call @ref{1a6,,mps_pool_walk()} for each pool.

@anchor{design/walk design mps walk sol walk assume-format}@anchor{be9}@ref{be9,,.sol.walk.assume-format;} All objects in a pool share the same
format, so the callback does not need to switch on the format.

@anchor{design/walk design mps walk sol walk examine}@anchor{bea}@ref{bea,,.sol.walk.examine;} @ref{1a6,,mps_pool_walk()} must only be called when the
arena is parked, and so there is no read barrier on any object.

@anchor{design/walk design mps walk sol walk modify}@anchor{beb}@ref{beb,,.sol.walk.modify;} @ref{1a6,,mps_pool_walk()} arranges for write-protection
to be removed from each segment while it is being walked and restored
afterwards if necessary.

@anchor{design/walk design mps walk sol walk overhead}@anchor{bec}@ref{bec,,.sol.walk.overhead;} The callback is called for contiguous regions
of formatted objects (not just for each object) where possible so that
the per-object function call overhead is minimized.

@anchor{design/walk design mps walk sol walk perf}@anchor{bed}@ref{bed,,.sol.walk.perf;} The callback uses the scanning protocol so that
every reference is fixed and the summary is maintained.

@anchor{design/walk design mps walk sol walk closure}@anchor{bee}@ref{bee,,.sol.walk.closure;} @ref{1a6,,mps_pool_walk()} takes a closure pointer
which is stored in the @code{ScanState} and passed to the callback.

@anchor{design/walk design mps walk sol walk maint}@anchor{bef}@ref{bef,,.sol.walk.maint;} We reuse the scanning protocol and provide a
generic implementation that iterates over the ring of segments in the
pool. We set up an empty white set in the @code{ScanState} so that the
@ref{75,,MPS_FIX1()} test always fails and @code{_mps_fix2()} is never called.
This avoids any per-pool code to support the interface.

@node References<18>,,Design<10>,Walking formatted objects
@anchor{design/walk references}@anchor{bf0}
@subsection References


@anchor{design/walk gdr-2018-08-30}@anchor{bdd}@w{(GDR_2018-08-30)} 
Gareth Rees. 2018-08-30. “Save/restore draft proposal@footnote{https://info.ravenbrook.com/mail/2018/08/30/12-57-09/0/}”.

@anchor{design/walk gdr-2020-08-30}@anchor{bd8}@w{(GDR_2020-08-30)} 
Gareth Rees. 2020-08-30. “Re: Modifying objects during mps_formatted_objects_walk@footnote{https://info.ravenbrook.com/mail/2020/08/31/19-17-03/0/}”.

@anchor{design/walk stromback-2020-08-20}@anchor{bdb}@w{(Strömbäck_2020-08-20)} 
Filip Strömbäck. 2020-08-20. “Modifying objects during mps_formatted_objects_walk@footnote{https://info.ravenbrook.com/mail/2020/08/20/21-01-34/0/}”.

@geindex write barrier; design

@node Write barrier,The WriteF function,Walking formatted objects,Design
@anchor{design/write-barrier doc}@anchor{bf1}@anchor{design/write-barrier design-write-barrier}@anchor{bf2}@anchor{design/write-barrier write-barrier}@anchor{bf3}
@section Write barrier


@menu
* Introduction: Introduction<45>. 
* Overview: Overview<10>. 
* Write Barrier Processes:: 
* Write barrier deferral:: 
* Improvements:: 
* References: References<19>. 

@end menu

@node Introduction<45>,Overview<10>,,Write barrier
@anchor{design/write-barrier design mps write-barrier}@anchor{bf4}@anchor{design/write-barrier introduction}@anchor{bf5}
@subsection Introduction


@anchor{design/write-barrier design mps write-barrier intro}@anchor{bf6}@ref{bf6,,.intro;} This document explains the design of the write barrier of the
Memory Pool System (MPS).

@anchor{design/write-barrier design mps write-barrier readership}@anchor{bf7}@ref{bf7,,.readership;} This document is intended for developers of the MPS.

@anchor{design/write-barrier design mps write-barrier source}@anchor{bf8}@ref{bf8,,.source;} This is based on @ref{bf9,,[job003975]}.

@node Overview<10>,Write Barrier Processes,Introduction<45>,Write barrier
@anchor{design/write-barrier overview}@anchor{bfa}
@subsection Overview


@anchor{design/write-barrier design mps write-barrier overview}@anchor{bfb}@ref{bfb,,.overview;} The MPS uses a combination of hardware memory protection
and BIBOP techniques to maintain an approximate remembered set.  The
remembered set keeps track of areas of memory that refer to each
other, so that the MPS can avoid scanning areas that are irrelevant
during a garbage collection.  The MPS write barrier is implemented by
a one-word “summary” of the zones referenced by a segment.  That
summary can be compared with the “white set” of a trace by a simple
logical AND operation.

@node Write Barrier Processes,Write barrier deferral,Overview<10>,Write barrier
@anchor{design/write-barrier write-barrier-processes}@anchor{bfc}
@subsection Write Barrier Processes


@anchor{design/write-barrier design mps write-barrier scan summary}@anchor{bfd}@ref{bfd,,.scan.summary;} As the MPS scans a segment during garbage collection,
it accumulates a summary of references.  This summary is represented
by single word @ref{b4e,,ZoneSet}, derived from the bit patterns of the
references.  After the scan the MPS can decide to store the summary
with the segment, and use it in future garbage collections to avoid
future scans.

If the summary does not intersect any of the zones containing
condemned objects, the MPS does not have to scan them in order to
determine if those objects are live.

The mutator could update the references in a segment and make the
summary invalid.  To avoid this, when the MPS stores a summary, it
raises a write barrier on the segment memory.  If the mutator does
update the segment, the barrier is hit, and the MPS resets the
summary, so that the segment will be scanned in future.

[At this point I was interrupted by a man from Porlock.]

@node Write barrier deferral,Improvements,Write Barrier Processes,Write barrier
@anchor{design/write-barrier write-barrier-deferral}@anchor{bfe}
@subsection Write barrier deferral


@anchor{design/write-barrier design mps write-barrier deferral}@anchor{bff}@ref{bff,,.deferral;} Both scanning and the write barrier cost CPU time, and
these must be balanced.  There is no point spending 1000 CPU units
raising a write barrier to avoid 10 CPU units of scanning cost.
Therefore we do not raise the write barrier immediately.

@anchor{design/write-barrier design mps write-barrier deferral heuristic}@anchor{c00}@ref{c00,,.deferral.heuristic;} We apply a simple heuristic: A segment which was
found to be “interesting” while scanning is likely to be interesting
again, and so raising the write barrier is not worthwhile.  If we scan
a segment several times and find it “boring” then we raise the barrier
to avoid future boring scans.

@anchor{design/write-barrier design mps write-barrier def boring}@anchor{c01}@ref{c01,,.def.boring;} A scan is “boring” if it was unnecessary for a garbage
collection because it found no references to condemned objects.

@anchor{design/write-barrier design mps write-barrier def interesting}@anchor{c02}@ref{c02,,.def.interesting;} A scan is “interesting” if it was not boring
(@ref{c01,,.def.boring}).  Note that this does not mean it preserved comdemned
objects, only that we would have scanned it even if we had had the
scan summary beforehand.

@anchor{design/write-barrier design mps write-barrier deferral count}@anchor{c03}@ref{c03,,.deferral.count;} We store a deferral count with the segment.  The
count is decremented after each boring scan (@ref{c01,,.def.boring}).  The write
barrier is raised only when the count reaches zero.

@anchor{design/write-barrier design mps write-barrier deferral reset}@anchor{c04}@ref{c04,,.deferral.reset;} The count is reset after three events:

@quotation


@enumerate 

@item 
segment creation (@code{WB_DEFER_INIT})

@item 
an interesting scan (@code{WB_DEFER_DELAY})

@item 
a barrier hit (@code{WB_DEFER_HIT})
@end enumerate
@end quotation

@anchor{design/write-barrier design mps write-barrier deferral dabble}@anchor{c05}@ref{c05,,.deferral.dabble;} The set of objects condemned by the garbage
collector changes, and so does what is interesting or boring.  For
example, a collection of a nursery space in zone 3 might be followed
by a collection of a top generation in zone 7.  This will upset
@ref{c00,,.deferral.heuristic} somewhat.  We assume that the garbage collector
will spend most of its time repeatedly collecting the same zones.

@node Improvements,References<19>,Write barrier deferral,Write barrier
@anchor{design/write-barrier improvements}@anchor{c06}
@subsection Improvements


@anchor{design/write-barrier design mps write-barrier improv by-os}@anchor{c07}@ref{c07,,.improv.by-os;} The overheads hardware barriers varies widely between
operating systems.  On Windows it is very cheap to change memory
protection and to handle protection faults.  On macOS it is very
expensive.  The balance between barriers and scanning work is
different.  We should measure the relative costs and tune the deferral
for each separately.

@anchor{design/write-barrier design mps write-barrier improv balance}@anchor{c08}@ref{c08,,.improv.balance;} Hardware costs of write barriers vary by OS, but
scanning costs vary depending on many factors including client code.
The MPS could dynamically measure these costs, perhaps using fast
cycle counters such as RDTSC, and use this to dynamically balance the
write barrier deferral.

@node References<19>,,Improvements,Write barrier
@anchor{design/write-barrier references}@anchor{c09}
@subsection References


@anchor{design/write-barrier job003975}@anchor{bf9}@w{(job003975)} 
Richard Brooksby. Ravenbrook Limited. 2016-03-11. “Poor performance due to imbalance between protection and scanning costs@footnote{https://www.ravenbrook.com/project/mps/issue/job003975}”.

@geindex WriteF function; design

@node The WriteF function,,Write barrier,Design
@anchor{design/writef doc}@anchor{c0a}@anchor{design/writef design-writef}@anchor{c0b}@anchor{design/writef the-writef-function}@anchor{c0c}
@section The WriteF function


@menu
* Introduction: Introduction<46>. 
* Design: Design<11>. 
* References: References<20>. 

@end menu

@node Introduction<46>,Design<11>,,The WriteF function
@anchor{design/writef design mps writef}@anchor{c0d}@anchor{design/writef introduction}@anchor{c0e}
@subsection Introduction


@anchor{design/writef design mps writef intro}@anchor{c0f}@ref{c0f,,.intro;} This document describes the @ref{446,,WriteF()} function, which
allows formatted output in a manner similar to @code{printf()} from the
Standard C library, but allows the Memory Pool Manager (MPM) to
operate in a freestanding environment (see design.mps.exec-env@footnote{exec-env.html}).

@anchor{design/writef design mps writef background}@anchor{c10}@ref{c10,,.background;} The documents design.mps.exec-env@footnote{exec-env.html} and design.mps.lib@footnote{lib.html}
describe the design of the library interface and the reason that it
exists.

@node Design<11>,References<20>,Introduction<46>,The WriteF function
@anchor{design/writef design}@anchor{c11}@anchor{design/writef design-mps-lib}@anchor{c12}
@subsection Design


@anchor{design/writef design mps writef no-printf}@anchor{c13}@ref{c13,,.no-printf;} There is no dependency on @code{printf()}. The MPM only
depends on @code{mps_io_fputc()} and @code{mps_io_fputs()}, via the library
interface (design.mps.lib@footnote{lib.html}), part of the `plinth'. This makes it much
easier to deploy the MPS in a freestanding environment. This is
achieved by implementing our own output routines.

@anchor{design/writef design mps writef writef}@anchor{c14}@ref{c14,,.writef;} Our output requirements are few, so the code is short. The
only output function which should be used in the rest of the MPM is
@ref{446,,WriteF()}.

@geindex WriteF (C function)
@anchor{design/writef c WriteF}@anchor{446}
@deffn {C Function} @ref{55f,,Res} WriteF (mps_lib_FILE *stream, Count depth, ...)
@end deffn

If @code{depth} is greater than zero, then the first output character,
and each output character after a newline in a format string, is
preceded by @code{depth} spaces.

@ref{446,,WriteF()} expects a format string followed by zero or more items to
insert into the output, followed by another format string, more items,
and so on, and finally a @code{NULL} format string. For example:

@example
res = WriteF(stream, depth,
             "Hello: $A\n", (WriteFA)address,
             "Spong: $U ($S)\n", (WriteFU)number, (WriteFS)string,
             NULL);
if (res != ResOK)
  return res;
@end example

This makes @code{Describe()} methods much easier to write. For example, @code{BufferDescribe()} contains the following code:

@example
res = WriteF(stream, depth,
             "Buffer $P ($U) @{\n",
             (WriteFP)buffer, (WriteFU)buffer->serial,
             "  class $P (\"$S\")\n",
             (WriteFP)buffer->class, (WriteFS)buffer->class->name,
             "  Arena $P\n",       (WriteFP)buffer->arena,
             "  Pool $P\n",        (WriteFP)buffer->pool,
             "  ", buffer->isMutator ? "Mutator" : "Internal", " Buffer\n",
             "  mode $C$C$C$C (TRANSITION, LOGGED, FLIPPED, ATTACHED)\n",
             (WriteFC)((buffer->mode & BufferModeTRANSITION) ? 't' : '_'),
             (WriteFC)((buffer->mode & BufferModeLOGGED)     ? 'l' : '_'),
             (WriteFC)((buffer->mode & BufferModeFLIPPED)    ? 'f' : '_'),
             (WriteFC)((buffer->mode & BufferModeATTACHED)   ? 'a' : '_'),
             "  fillSize $UKb\n",  (WriteFU)(buffer->fillSize / 1024),
             "  emptySize $UKb\n", (WriteFU)(buffer->emptySize / 1024),
             "  alignment $W\n",   (WriteFW)buffer->alignment,
             "  base $A\n",        (WriteFA)buffer->base,
             "  initAtFlip $A\n",  (WriteFA)buffer->initAtFlip,
             "  init $A\n",        (WriteFA)buffer->ap_s.init,
             "  alloc $A\n",       (WriteFA)buffer->ap_s.alloc,
             "  limit $A\n",       (WriteFA)buffer->ap_s.limit,
             "  poolLimit $A\n",   (WriteFA)buffer->poolLimit,
             "  alignment $W\n",   (WriteFW)buffer->alignment,
             "  rampCount $U\n",   (WriteFU)buffer->rampCount,
             NULL);
if (res != ResOK)
  return res;
@end example

@anchor{design/writef design mps writef types}@anchor{c15}@ref{c15,,.types;} For each format @code{$X} that @ref{446,,WriteF()} supports, there is
a type @code{WriteFX} defined in mpmtypes.h, which is the promoted
version of that type. These types are provided both to ensure
promotion and to avoid any confusion about what type should be used in
a cast. It is easy to check the casts against the formats to ensure
that they correspond.

@anchor{design/writef design mps writef types cast}@anchor{c16}@ref{c16,,.types.cast;} Every argument to @ref{446,,WriteF()} must be cast, because
in variable-length argument lists the “default argument promotion”
rules apply and this could cause an argument to be read incorrectly on
some platforms: for example on a 64-bit platform the @code{$W} format,
which expects a 64-bit argument, is incompatible with a 32-bit
@code{unsigned} argument, which will not be promoted to 64 bits by the
default argument promotion rules. (Note that most of these casts are
unnecessary, but requiring them all makes it easy to check that the
necessary ones are all there.)

@anchor{design/writef design mps writef types future}@anchor{c17}@ref{c17,,.types.future;} It is possibly that this type set or similar may be
used in future in some generalisation of varargs in the MPS.

@anchor{design/writef design mps writef formats}@anchor{c18}@ref{c18,,.formats;} The formats supported are as follows.


@multitable {xxxxxxxxx} {xxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

Code

@tab

Name

@tab

Type

@tab

Example rendering

@item

@code{$A}

@tab

address

@tab

@ref{632,,Addr}

@tab

@code{000000019EF60010}

@item

@code{$P}

@tab

pointer

@tab

@code{void *}

@tab

@code{000000019EF60100}

@item

@code{$F}

@tab

function

@tab

@code{void (*)(void)}

@tab

@code{0001D69E01000000} (see @ref{c19,,.function})

@item

@code{$S}

@tab

string

@tab

@code{char *}

@tab

@code{hello}

@item

@code{$C}

@tab

character

@tab

@code{char}

@tab

@code{x}

@item

@code{$W}

@tab

word

@tab

@ref{b44,,ULongest}

@tab

@code{0000000000109AE0}

@item

@code{$U}

@tab

decimal

@tab

@ref{b44,,ULongest}

@tab

@code{42}

@item

@code{$B}

@tab

binary

@tab

@ref{b44,,ULongest}

@tab

@code{00000000000000001011011110010001}

@item

@code{$$}

@tab

dollar

@tab

–

@tab

@code{$}

@end multitable


Note that @code{WriteFC} is an @code{int}, because that is the default
promotion of a @code{char} (see @ref{c15,,.types}).

@anchor{design/writef design mps writef snazzy}@anchor{c1a}@ref{c1a,,.snazzy;} We should resist the temptation to make @ref{446,,WriteF()} an
incredible snazzy output engine. We only need it for @code{Describe()}
methods. At the moment it’s a simple bit of code – let’s keep it that
way.

@anchor{design/writef design mps writef function}@anchor{c19}@ref{c19,,.function;} The @code{F} code is used for function pointers. The C
standard @ref{c1b,,[C1999c]} defines conversion between pointer-to-function
types (§6.3.2.3.8), but it does not define conversion between pointers
to functions and pointers to data. To work around this, the bytes of
their representation are written sequentially, and may have a
different endianness to other pointer types. This output could be
smarter, or even look up function names, but see @ref{c1a,,.snazzy}. The
particular type @code{void (*)(void)} is chosen because in GCC
(version 8) this suppresses the warning that we would otherwise get
from @code{-Wcast-function-type}. See job004156@footnote{https://www.ravenbrook.com/project/mps/issue/job004156/} and GCC Warning Options@footnote{https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html}.

@node References<20>,,Design<11>,The WriteF function
@anchor{design/writef gcc-warning-options}@anchor{c1c}@anchor{design/writef references}@anchor{c1d}
@subsection References


@anchor{design/writef c1999c}@anchor{c1b}@w{(C1999c)} 
International Standard ISO/IEC 9899:1999; “Programming languages — C”; <@indicateurl{http://www.open-std.org/jtc1/sc22/WG14/www/docs/n1256.pdf}>

@node Old design,Bibliography,Design,Top
@anchor{design/old doc}@anchor{c1e}@anchor{design/old design-old}@anchor{c1f}@anchor{design/old old-design}@anchor{c20}
@chapter Old design


@cartouche
@quotation Warning 
Much of the documentation in this section is very old: some of it
dates back to the origin of the MPS in 1995. It has not been
brought up to date or checked for correctness, so it is mainly of
historical interest. As pieces of documentation are brought up to
date, they will be moved to the main @ref{31a,,Design} section.
@end quotation
@end cartouche

@geindex allocation frames; design

@menu
* Allocation frame protocol:: 
* Arena:: 
* Virtual Memory Arena:: 
* Bit tables:: 
* Allocation buffers and allocation points:: 
* Checking: Checking<4>. 
* Collection framework:: 
* Diagnostic feedback:: 
* The generic fix function:: 
* I/O subsystem:: 
* Library interface:: 
* Locus manager:: 
* GC messages:: 
* Debugging features for client objects:: 
* AMC pool class:: 
* AMS pool class:: 
* AWL pool class:: 
* LO pool class:: 
* MFS pool class:: 
* MRG pool class:: 
* Manual Variable Temporal (MVT) pool design: Manual Variable Temporal MVT pool design. 
* MVFF pool class:: 
* Protocol inheritance:: 
* POSIX thread extensions:: 
* Root manager:: 
* The generic scanner:: 
* Segment data structure:: 
* MPS Strategy:: 
* Telemetry: Telemetry<3>. 
* Tracer:: 

@end menu

@node Allocation frame protocol,Arena,,Old design
@anchor{design/alloc-frame doc}@anchor{c21}@anchor{design/alloc-frame allocation-frame-protocol}@anchor{c22}@anchor{design/alloc-frame design-alloc-frame}@anchor{c23}
@section Allocation frame protocol


@menu
* Introduction: Introduction<47>. 
* Definitions: Definitions<6>. 
* Purpose:: 
* Requirements: Requirements<28>. 
* Overview: Overview<11>. 
* Operations:: 
* Interface: Interface<20>. 
* Lightweight frames:: 

@end menu

@node Introduction<47>,Definitions<6>,,Allocation frame protocol
@anchor{design/alloc-frame design mps alloc-frame}@anchor{c24}@anchor{design/alloc-frame introduction}@anchor{c25}
@subsection Introduction


@anchor{design/alloc-frame design mps alloc-frame intro}@anchor{c26}@ref{c26,,.intro;} This document explains the design of the support for
allocation frames in MPS.

@anchor{design/alloc-frame design mps alloc-frame readership}@anchor{c27}@ref{c27,,.readership;} This document is intended for any MM developer.

@anchor{design/alloc-frame design mps alloc-frame overview}@anchor{c28}@ref{c28,,.overview;} Allocation frames are used for implementing stack pools;
each stack frame corresponds to an allocation frame. Allocation frames
may also be suitable for implementing other sub-pool groupings, such
as generations and ramp allocation patterns.

@anchor{design/alloc-frame design mps alloc-frame overview ambition}@anchor{c29}@ref{c29,,.overview.ambition;} We now believe this to be a design that loses
too many advantages of stack allocation for questionable gains. The
requirements are almost entirely based on unanalysed anecdote, instead
of actual clients.

@cartouche
@quotation Note 
We plan to supersede this with a stack pool design at some point
in the future. Pekka P. Pirinen, 2000-03-09.
@end quotation
@end cartouche

@node Definitions<6>,Purpose,Introduction<47>,Allocation frame protocol
@anchor{design/alloc-frame definitions}@anchor{c2a}
@subsection Definitions


@anchor{design/alloc-frame design mps alloc-frame def alloc-frame}@anchor{c2b}@ref{c2b,,.def.alloc-frame;} An allocation frame is a generic name for a
device which groups objects together with other objects at allocation
time, and which may have a parent/child relationship with other
allocation frames.

@node Purpose,Requirements<28>,Definitions<6>,Allocation frame protocol
@anchor{design/alloc-frame purpose}@anchor{c2c}
@subsection Purpose


@anchor{design/alloc-frame design mps alloc-frame purpose stack-allocation}@anchor{c2d}@ref{c2d,,.purpose.stack-allocation;} The allocation frame protocol is
intended to support efficient memory management for stack allocation,
that is, the allocation of objects which have dynamic extent.

@anchor{design/alloc-frame design mps alloc-frame purpose general}@anchor{c2e}@ref{c2e,,.purpose.general;} The allocation frame protocol is intended to be
sufficiently general that it will be useful in supporting other types
of nested allocation patterns too. For example, it could be used to
for EPVM-style save and restore, ramp allocation patterns or
generations.

@node Requirements<28>,Overview<11>,Purpose,Allocation frame protocol
@anchor{design/alloc-frame requirements}@anchor{c2f}
@subsection Requirements


@menu
* Known requirements:: 
* Proto-requirements:: 

@end menu

@node Known requirements,Proto-requirements,,Requirements<28>
@anchor{design/alloc-frame known-requirements}@anchor{c30}
@subsubsection Known requirements


@anchor{design/alloc-frame design mps alloc-frame req stack-alloc}@anchor{c31}@ref{c31,,.req.stack-alloc;} Provide a interface for clients to describe a
stack allocation pattern, as an alternative to using the control
stack.

@anchor{design/alloc-frame design mps alloc-frame req efficient}@anchor{c32}@ref{c32,,.req.efficient;} Permit an implementation which is comparable in
efficiency to allocating on the control stack.

@anchor{design/alloc-frame design mps alloc-frame req ap}@anchor{c33}@ref{c33,,.req.ap;} Support allocation via allocation points (APs).

@anchor{design/alloc-frame design mps alloc-frame req format}@anchor{c34}@ref{c34,,.req.format;} Support the allocation of formatted objects.

@anchor{design/alloc-frame design mps alloc-frame req scan}@anchor{c35}@ref{c35,,.req.scan;} Ensure that objects in allocation frames can participate
in garbage collection by being scanned.

@anchor{design/alloc-frame design mps alloc-frame req fix}@anchor{c36}@ref{c36,,.req.fix;} Ensure that objects in allocation frames can participate
in garbage collection by accepting Fix requests.

@anchor{design/alloc-frame design mps alloc-frame req condemn}@anchor{c37}@ref{c37,,.req.condemn;} Ensure that objects in allocation frames can
participate in garbage collection by being condemned.

@anchor{design/alloc-frame design mps alloc-frame attr locking}@anchor{c38}@ref{c38,,.attr.locking;} Minimize the synchronization cost for the creation
and destruction of frames.

@node Proto-requirements,,Known requirements,Requirements<28>
@anchor{design/alloc-frame proto-requirements}@anchor{c39}
@subsubsection Proto-requirements


@anchor{design/alloc-frame design mps alloc-frame proto-req}@anchor{c3a}@ref{c3a,,.proto-req;} The following are possible requirements that might be
important in the future. The design does not necessarily meet all
these requirements, but it does consider them all. Each requirement
either has direct support in the framework, or could be supported with
future additions to the framework.

@anchor{design/alloc-frame design mps alloc-frame req parallels}@anchor{c3b}@ref{c3b,,.req.parallels;} The allocation frame protocol should provide a
framework for exploiting the parallels between stack extents,
generations and “ramps”.

@anchor{design/alloc-frame design mps alloc-frame req pool-destroy}@anchor{c3c}@ref{c3c,,.req.pool-destroy;} It should be possible to use allocation frames
to free all objects in a pool without destroying the pool.

@anchor{design/alloc-frame design mps alloc-frame req epvm}@anchor{c3d}@ref{c3d,,.req.epvm;} It should be possible to implement EPVM-style save and
restore operations by creating and destroying allocation frames.

@anchor{design/alloc-frame design mps alloc-frame req subst}@anchor{c3e}@ref{c3e,,.req.subst;} It should be possible to substitute a stack pool with a
GC-ed pool so that erroneous use of a stack pool can be detected.

@anchor{design/alloc-frame design mps alloc-frame req format-extensions}@anchor{c3f}@ref{c3f,,.req.format-extensions;} It should be possible for stack pools to
utilize the same format as any other pool, including debugging formats
that include fenceposting, etc.

@anchor{design/alloc-frame design mps alloc-frame req mis-nest}@anchor{c40}@ref{c40,,.req.mis-nest;} Should ensure “mis-nested” stacks are safe.

@anchor{design/alloc-frame design mps alloc-frame req non-top-level}@anchor{c41}@ref{c41,,.req.non-top-level;} Should support allocation in the non-top stack
extent.

@anchor{design/alloc-frame design mps alloc-frame req copy-if-necessary}@anchor{c42}@ref{c42,,.req.copy-if-necessary;} Should ensure that stack pools can support
“copy-if-necessary” (so that low-level system code can heapify stack
objects.)

@anchor{design/alloc-frame design mps alloc-frame req preserve}@anchor{c43}@ref{c43,,.req.preserve;} When an object is in an allocation frame which is
being destroyed, it should be possible to preserve that object in the
parent frame.

@anchor{design/alloc-frame design mps alloc-frame req contained}@anchor{c44}@ref{c44,,.req.contained;} Should allow clients to ask if an object is
“contained” in a frame. The object is contained in a frame if it is
affected when the frame is ended.

@anchor{design/alloc-frame design mps alloc-frame req alloc-with-other}@anchor{c45}@ref{c45,,.req.alloc-with-other;} Should allow clients to allocate an object
in the same frame as another object.

@node Overview<11>,Operations,Requirements<28>,Allocation frame protocol
@anchor{design/alloc-frame overview}@anchor{c46}
@subsection Overview


@anchor{design/alloc-frame design mps alloc-frame frame-classes}@anchor{c47}@ref{c47,,.frame-classes;} The protocol supports different types of allocation
frames, which are represented as “frame classes”. It’s up to pools to
determine which classes of allocation frames they support. Pools which
support more than one frame class rely on the client to indicate which
class is currently of interest. The client indicates this by means of
an operation which stores the class in the buffer to which the
allocation point is attached.

@anchor{design/alloc-frame design mps alloc-frame frame-handles}@anchor{c48}@ref{c48,,.frame-handles;} Allocation frames are described via abstract “frame
handles”. Pools may choose what the representation of a frame handle
should be. Frame handles are static, and the client need not store
them in a GC root.

@anchor{design/alloc-frame design mps alloc-frame lightweight-frames}@anchor{c49}@ref{c49,,.lightweight-frames;} The design includes an extension to the
allocation point protocol, which permits the creation and destruction
of allocation frames without the necessity for claiming the arena
lock. Such frames are called “lightweight frames”.

@node Operations,Interface<20>,Overview<11>,Allocation frame protocol
@anchor{design/alloc-frame operations}@anchor{c4a}
@subsection Operations


@anchor{design/alloc-frame design mps alloc-frame op intro}@anchor{c4b}@ref{c4b,,.op.intro;} Each operation has both an external (client) interface
and an internal (MPS) interface. The external function takes an
allocation point as a parameter, determines which buffer and pool it
belongs to, and calls the internal function with the buffer and pool
as parameters.

@anchor{design/alloc-frame design mps alloc-frame op obligatory}@anchor{c4c}@ref{c4c,,.op.obligatory;} The following operations are supported on any
allocation point which supports allocation frames:-

@anchor{design/alloc-frame design mps alloc-frame operation push}@anchor{c4d}@ref{c4d,,.operation.push;} The `FramePush' operation creates a new
allocation frame of the currently chosen frame class, makes this new
frame the current frame, and returns a handle for the frame.

@anchor{design/alloc-frame design mps alloc-frame operation pop}@anchor{c4e}@ref{c4e,,.operation.pop;} The `FramePop' operation takes a frame handle
as a parameter. Some pool classes might insist or assume that this is
the handle for the current frame. It finds the parent of that frame
and makes it the current frame. The operation indicates that all
children of the new current frame contain objects which are likely to
be dead. The reclaim policy is up to the pool; some classes might
insist or assume that the objects must be dead, and eagerly free them.
Note that this might introduce the possibility of leaving dangling
pointers elsewhere in the arena. If so, it’s up to the pool to decide
what to do about this.

@anchor{design/alloc-frame design mps alloc-frame op optional}@anchor{c4f}@ref{c4f,,.op.optional;} The following operations are supported for some
allocation frames, but not all. Pools may choose to support some or
all of these operations for certain frame classes. An unsupported
operation will return a failure value:-

@anchor{design/alloc-frame design mps alloc-frame operation select}@anchor{c50}@ref{c50,,.operation.select;} The `FrameSelect' operation takes a frame
handle as a parameter and makes that frame the current frame. It does
not indicate that any children of the current frame contain objects
which are likely to be dead.

@anchor{design/alloc-frame design mps alloc-frame operation select-addr}@anchor{c51}@ref{c51,,.operation.select-addr;} The `FrameSelectOfAddr' operation takes
an address as a parameter and makes the frame of that address the
current frame. It does not indicate that any children of the current
frame contain objects which are likely to be dead.

@anchor{design/alloc-frame design mps alloc-frame operation in-frame}@anchor{c52}@ref{c52,,.operation.in-frame;} The `FrameHasAddr' operation determines
whether the supplied address is the address of an object allocated in
the supplied frame, or any child of that frame.

@anchor{design/alloc-frame design mps alloc-frame operation set}@anchor{c53}@ref{c53,,.operation.set;} The `SetFrameClass' operation takes a frame
class and an allocation point as parameters, and makes that the
current frame class for the allocation point. The next `FramePush'
operation will create a new frame of that class.

@node Interface<20>,Lightweight frames,Operations,Allocation frame protocol
@anchor{design/alloc-frame interface}@anchor{c54}
@subsection Interface


@menu
* External types: External types<2>. 
* External functions:: 
* Internal types:: 

@end menu

@node External types<2>,External functions,,Interface<20>
@anchor{design/alloc-frame external-types}@anchor{c55}
@subsubsection External types


@anchor{design/alloc-frame design mps alloc-frame type client frame-handle}@anchor{c56}@ref{c56,,.type.client.frame-handle;} Frame handles are defined as the abstract
type @ref{27c,,mps_frame_t}.

@geindex mps_frame_class_t (C type)
@anchor{design/alloc-frame c mps_frame_class_t}@anchor{c57}
@deffn {C Type} typedef struct mps_frame_class_s *mps_frame_class_t
@end deffn

@anchor{design/alloc-frame design mps alloc-frame type client frame-class}@anchor{c58}@ref{c58,,.type.client.frame-class;} Frame classes are defined as an abstract
type.

@anchor{design/alloc-frame design mps alloc-frame type client frame-class access}@anchor{c59}@ref{c59,,.type.client.frame-class.access;} Clients access frame classes by
means of dedicated functions for each frame class.

@node External functions,Internal types,External types<2>,Interface<20>
@anchor{design/alloc-frame external-functions}@anchor{c5a}
@subsubsection External functions


@anchor{design/alloc-frame design mps alloc-frame fn client push}@anchor{c5b}@ref{c5b,,.fn.client.push;} @ref{16e,,mps_ap_frame_push()} is used by clients to
invoke the `FramePush' operation. For lightweight frames, this
might not invoke the corresponding internal function.

@anchor{design/alloc-frame design mps alloc-frame fn client pop}@anchor{c5c}@ref{c5c,,.fn.client.pop;} @ref{16d,,mps_ap_frame_pop()} is used by clients to invoke
the `FramePop' operation. For lightweight frames, this might not
invoke the corresponding internal function.

@geindex mps_ap_frame_select (C function)
@anchor{design/alloc-frame c mps_ap_frame_select}@anchor{c5d}
@deffn {C Function} @ref{14d,,mps_res_t} mps_ap_frame_select (mps_ap_t buf, mps_frame_t frame)
@end deffn

@anchor{design/alloc-frame design mps alloc-frame fn client select}@anchor{c5e}@ref{c5e,,.fn.client.select;} This following function is used by clients to
invoke the `FrameSelect' operation.

@geindex mps_ap_frame_select_from_addr (C function)
@anchor{design/alloc-frame c mps_ap_frame_select_from_addr}@anchor{c5f}
@deffn {C Function} @ref{14d,,mps_res_t} mps_ap_frame_select_from_addr (mps_ap_t buf, mps_addr_t addr)
@end deffn

@anchor{design/alloc-frame design mps alloc-frame fn client select-addr}@anchor{c60}@ref{c60,,.fn.client.select-addr;} This function is used by clients to invoke
the `FrameSelectOfAddr' operation.

@geindex mps_ap_addr_in_frame (C function)
@anchor{design/alloc-frame c mps_ap_addr_in_frame}@anchor{c61}
@deffn {C Function} @ref{14d,,mps_res_t} mps_ap_addr_in_frame (mps_bool_t *inframe_o, mps_ap_t buf, mps_addr_t *addrref, mps_frame_t frame)
@end deffn

@anchor{design/alloc-frame design mps alloc-frame fn client in-frame}@anchor{c62}@ref{c62,,.fn.client.in-frame;} This function is used by clients to invoke the
`FrameHasAddr' operation.

@geindex mps_ap_set_frame_class (C function)
@anchor{design/alloc-frame c mps_ap_set_frame_class}@anchor{c63}
@deffn {C Function} @ref{14d,,mps_res_t} mps_ap_set_frame_class (mps_ap_t buf, mps_frame_class_t class)
@end deffn

@anchor{design/alloc-frame design mps alloc-frame fn client set}@anchor{c64}@ref{c64,,.fn.client.set;} This function is used by clients to invoke the
`SetFrameClass' operation.

@geindex mps_alloc_frame_class_stack (C function)
@anchor{design/alloc-frame c mps_alloc_frame_class_stack}@anchor{c65}
@deffn {C Function} @ref{c57,,mps_frame_class_t} mps_alloc_frame_class_stack (void)
@end deffn

@anchor{design/alloc-frame design mps alloc-frame fn client stack-frame-class}@anchor{c66}@ref{c66,,.fn.client.stack-frame-class;} This function is used by clients to
access the frame class used for simple stack allocation.

@node Internal types,,External functions,Interface<20>
@anchor{design/alloc-frame internal-types}@anchor{c67}
@subsubsection Internal types


@geindex AllocFrame (C type)
@anchor{design/alloc-frame c AllocFrame}@anchor{b52}
@deffn {C Type} typedef struct AllocFrameStruct *AllocFrame
@end deffn

@anchor{design/alloc-frame design mps alloc-frame type frame-handle}@anchor{c68}@ref{c68,,.type.frame-handle;} Frame handles are defined as an abstract type.

@geindex AllocFrameClass (C type)
@anchor{design/alloc-frame c AllocFrameClass}@anchor{c69}
@deffn {C Type} typedef struct AllocFrameClassStruct *AllocFrameClass
@end deffn

@anchor{design/alloc-frame design mps alloc-frame type frame-class}@anchor{c6a}@ref{c6a,,.type.frame-class;} Frame classes are defined as an abstract type.

@geindex PoolFramePushMethod (C type)
@anchor{design/alloc-frame c PoolFramePushMethod}@anchor{c6b}
@deffn {C Type} typedef @ref{55f,,Res} (*PoolFramePushMethod)(@ref{b52,,AllocFrame} *frameReturn, Pool pool, Buffer buf)
@end deffn

@anchor{design/alloc-frame design mps alloc-frame fn push}@anchor{c6c}@ref{c6c,,.fn.push;} A pool method of this type is called (if needed) to
invoke the `FramePush' operation.

@geindex PoolFramePopMethod (C type)
@anchor{design/alloc-frame c PoolFramePopMethod}@anchor{c6d}
@deffn {C Type} typedef @ref{55f,,Res} (*PoolFramePopMethod)(Pool pool, Buffer buf, @ref{b52,,AllocFrame} frame)
@end deffn

@anchor{design/alloc-frame design mps alloc-frame fn pop}@anchor{c6e}@ref{c6e,,.fn.pop;} A pool method of this type is called (if needed)
to invoke the `FramePop' operation:

@geindex PoolFrameSelectMethod (C type)
@anchor{design/alloc-frame c PoolFrameSelectMethod}@anchor{c6f}
@deffn {C Type} typedef @ref{55f,,Res} (*PoolFrameSelectMethod)(Pool pool, Buffer buf, @ref{b52,,AllocFrame} frame)
@end deffn

@anchor{design/alloc-frame design mps alloc-frame fn select}@anchor{c70}@ref{c70,,.fn.select;} A pool method of this type is called to invoke the
`FrameSelect' operation.

@geindex PoolFrameSelectFromAddrMethod (C type)
@anchor{design/alloc-frame c PoolFrameSelectFromAddrMethod}@anchor{c71}
@deffn {C Type} typedef @ref{55f,,Res} (*PoolFrameSelectFromAddrMethod)(Pool pool, Buffer buf, @ref{632,,Addr} addr)
@end deffn

@anchor{design/alloc-frame design mps alloc-frame fn select-addr}@anchor{c72}@ref{c72,,.fn.select-addr;} A pool method of this type is called to invoke the
`FrameSelectOfAddr' operation.

@geindex PoolFrameHasAddrMethod (C type)
@anchor{design/alloc-frame c PoolFrameHasAddrMethod}@anchor{c73}
@deffn {C Type} typedef @ref{55f,,Res} (*PoolFrameHasAddrMethod)(@ref{3a9,,Bool} *inframeReturn, Pool pool, @ref{b53,,Seg} seg, @ref{632,,Addr} *addrref, @ref{b52,,AllocFrame} frame)
@end deffn

@anchor{design/alloc-frame design mps alloc-frame fn in-frame}@anchor{c74}@ref{c74,,.fn.in-frame;} A pool method of this type is called to invoke the
`FrameHasAddr' operation.

@geindex PoolSetFrameClassMethod (C type)
@anchor{design/alloc-frame c PoolSetFrameClassMethod}@anchor{c75}
@deffn {C Type} typedef @ref{55f,,Res} (*PoolSetFrameClassMethod)(Pool pool, Buffer buf, @ref{c69,,AllocFrameClass} class)
@end deffn

@anchor{design/alloc-frame design mps alloc-frame fn set}@anchor{c76}@ref{c76,,.fn.set;} A pool method of this type is called to invoke the
`SetFrameClass' operation.

@node Lightweight frames,,Interface<20>,Allocation frame protocol
@anchor{design/alloc-frame lightweight-frames}@anchor{c77}
@subsection Lightweight frames


@menu
* Overview: Overview<12>. 
* Synchronization:: 
* Implementation: Implementation<15>. 

@end menu

@node Overview<12>,Synchronization,,Lightweight frames
@anchor{design/alloc-frame id1}@anchor{c78}
@subsubsection Overview


@anchor{design/alloc-frame design mps alloc-frame lw-frame overview}@anchor{c79}@ref{c79,,.lw-frame.overview;} Allocation points provide direct support for
lightweight frames, and are designed to permit `FramePush' and
`FramePop' operations without the need for locking and delegation to
the pool method. The pool method will be called whenever
synchronization is required for other reasons (e.g. the buffer is
tripped).

@anchor{design/alloc-frame design mps alloc-frame lw-frame model}@anchor{c7a}@ref{c7a,,.lw-frame.model;} Lightweight frames offer direct support for a
particular model of allocation frame use, whereby the `FramePush'
operation returns the current allocation pointer as a frame handle,
and the `FramePop' operation causes the allocation pointer to be reset
to the address of the frame handle. This model should be suitable for
simple stack frames, where more advanced operations like `FrameSelect'
are not supported. It may also be suitable for more advanced
allocation frame models when they are being used simply. The use of a
complex operation always involves synchronization via locking, and the
pool may disable lightweight synchronization temporarily at this time.

@node Synchronization,Implementation<15>,Overview<12>,Lightweight frames
@anchor{design/alloc-frame synchronization}@anchor{c7b}
@subsubsection Synchronization


@anchor{design/alloc-frame design mps alloc-frame lw-frame sync}@anchor{c7c}@ref{c7c,,.lw-frame.sync;} The purpose of the design is that mutator may
access the state of an AP without locking with MPS (via the external
functions). The design assumes the normal MPS restriction that an
operation on an AP may only be performed by a single mutator thread at
a time. Each of the operations on allocation frames counts as an
operation on an AP.

@node Implementation<15>,,Synchronization,Lightweight frames
@anchor{design/alloc-frame implementation}@anchor{c7d}
@subsubsection Implementation


@anchor{design/alloc-frame design mps alloc-frame lw-frame push}@anchor{c7e}@ref{c7e,,.lw-frame.push;} The external `FramePush' operation
@ref{16e,,mps_ap_frame_push()} performs the following operations:

@example
IF ap->init != ap->alloc
   FAIL
ELSE IF ap->init < ap->limit
   *frame_o = ap->init;
ELSE
  WITH_ARENA_LOCK
    PerformInternalFramePushOperation(...)
  END
END
@end example

@anchor{design/alloc-frame design mps alloc-frame lw-frame push limit}@anchor{c7f}@ref{c7f,,.lw-frame.push.limit;} The reason for testing @code{ap->init <
ap->limit} and not @code{ap->init <= ap->limit} is that a frame pointer
at the limit of a buffer (and possibly therefore of a segment) would
be ambiguous: is it at the limit of the segment, or at the base of the
segment that’s adjacent in memory? The internal operation must handle
this case, for example by refilling the buffer and setting the frame
at the beginning.

@anchor{design/alloc-frame design mps alloc-frame lw-frame pop}@anchor{c80}@ref{c80,,.lw-frame.pop;} The external `FramePop' operation
(@ref{16d,,mps_ap_frame_pop()}) performs the following operations:

@example
IF ap->init != ap->alloc
   FAIL
ELSE IF BufferBase(ap) <= frame AND frame < ap->init
   ap->init = ap->alloc = frame;
ELSE
  WITH_ARENA_LOCK
    PerformInternalFramePopOperation(...)
  END
END
@end example

@anchor{design/alloc-frame design mps alloc-frame lw-frame pop buffer}@anchor{c81}@ref{c81,,.lw-frame.pop.buffer;} The reason for testing that @code{frame} is in
the buffer is that if it’s not, then we’re popping to an address in
some other segment, and that means that some objects in the other
segment (and all objects in any segments on the stack in between) are
now dead, and the only way for the pool to mark them as being dead is
to do a heavyweight pop.

@geindex arena; design

@node Arena,Virtual Memory Arena,Allocation frame protocol,Old design
@anchor{design/arena doc}@anchor{c82}@anchor{design/arena arena}@anchor{c83}@anchor{design/arena design-arena}@anchor{c84}
@section Arena


@menu
* Introduction: Introduction<48>. 
* Overview: Overview<13>. 
* Definitions: Definitions<7>. 
* Requirements: Requirements<29>. 
* Architecture: Architecture<4>. 
* Implementation: Implementation<16>. 

@end menu

@node Introduction<48>,Overview<13>,,Arena
@anchor{design/arena design mps arena}@anchor{c85}@anchor{design/arena introduction}@anchor{c86}
@subsection Introduction


@anchor{design/arena design mps arena intro}@anchor{c87}@ref{c87,,.intro;} This is the design of the arena structure.

@anchor{design/arena design mps arena readership}@anchor{c88}@ref{c88,,.readership;} MPS developers.

@node Overview<13>,Definitions<7>,Introduction<48>,Arena
@anchor{design/arena overview}@anchor{c89}
@subsection Overview


@anchor{design/arena design mps arena overview}@anchor{c8a}@ref{c8a,,.overview;} The arena serves two purposes. It is a structure that is
the top-level state of the MPS, and as such contains a lot of fields
which are considered “global”. And it provides raw memory to pools.

An arena belongs to a particular arena class. The class is selected
when the arena is created. Classes encapsulate both policy (such as
how pool placement preferences map into actual placement) and
mechanism (such as where the memory originates: operating system
virtual memory, client provided, or via malloc). Some behaviour
(mostly serving the “top-level datastructure” purpose) is implemented
by generic arena code, and some by arena class code.

@node Definitions<7>,Requirements<29>,Overview<13>,Arena
@anchor{design/arena definitions}@anchor{c8b}
@subsection Definitions


@anchor{design/arena design mps arena def grain}@anchor{c8c}@ref{c8c,,.def.grain;} The arena manages memory in units called `arena
grains', whose size is returned by the macro @code{ArenaGrainSize()}.
Memory allocated by @code{ArenaAlloc()} is a contiguous sequence of arena
grains, whose base address and size are multiples of the arena grain
size.

@anchor{design/arena design mps arena def tract}@anchor{c8d}@ref{c8d,,.def.tract;} A tract is a data structure containing information
about a region of address space: which pool it belongs to (if any),
which segment contains it, and so on. Tracts are the hook on which the
segment module is implemented. Pools which don’t use segments may use
tracts for associating their own data with ranges of address.

@node Requirements<29>,Architecture<4>,Definitions<7>,Arena
@anchor{design/arena requirements}@anchor{c8e}
@subsection Requirements


@cartouche
@quotation Note 
Where do these come from? Need to identify and document the
sources of requirements so that they are traceable to client
requirements. Most of these come from the architectural design
(design.mps.architecture) or the fix function design
(design.mps.fix@footnote{fix.html}). Richard Brooksby, 1995-08-28.

They were copied from design.mps.arena.vm@footnote{arenavm.html} and edited slightly.
David Jones, 1999-06-23.
@end quotation
@end cartouche

@menu
* Block management:: 
* Address translation:: 
* Arena partition:: 
* Constraints: Constraints<2>. 

@end menu

@node Block management,Address translation,,Requirements<29>
@anchor{design/arena block-management}@anchor{c8f}
@subsubsection Block management


@anchor{design/arena design mps arena req fun block alloc}@anchor{c90}@ref{c90,,.req.fun.block.alloc;} The arena must provide allocation of
contiguous blocks of memory.

@anchor{design/arena design mps arena req fun block free}@anchor{c91}@ref{c91,,.req.fun.block.free;} It must also provide freeing of contiguously
allocated blocks owned by a pool, whether or not the block was
allocated via a single request.

@anchor{design/arena design mps arena req attr block size min}@anchor{c92}@ref{c92,,.req.attr.block.size.min;} The arena must support management of
blocks down to the larger of (i) the grain size of the virtual mapping
interface (if a virtual memory interface is being used); and (ii) the
grain size of the memory protection interface (if protection is used).

@cartouche
@quotation Note 
On all the operating systems we support, these grain sizes are the
same and are equal to the operating system page size. But we want
the MPS to remain flexible enough to be ported to operating
systems where these are different.
@end quotation
@end cartouche

@anchor{design/arena design mps arena req attr block size max}@anchor{c93}@ref{c93,,.req.attr.block.size.max;} It must also support management of blocks
up to the maximum size allowed by the combination of operating system
and architecture. This is derived from req.dylan.attr.obj.max (at
least).

@anchor{design/arena design mps arena req attr block align min}@anchor{c94}@ref{c94,,.req.attr.block.align.min;} The alignment of blocks shall not be less
than @ref{6f,,MPS_PF_ALIGN} for the architecture. This is so that pool
classes can conveniently guarantee pool allocated blocks are aligned
to @ref{6f,,MPS_PF_ALIGN}. (A trivial requirement.)

@node Address translation,Arena partition,Block management,Requirements<29>
@anchor{design/arena address-translation}@anchor{c95}
@subsubsection Address translation


@anchor{design/arena design mps arena req fun trans}@anchor{c96}@ref{c96,,.req.fun.trans;} The arena must provide a translation from any
address to the following information:

@anchor{design/arena design mps arena req fun trans arena}@anchor{c97}@ref{c97,,.req.fun.trans.arena;} Whether the address is managed by the arena.

@anchor{design/arena design mps arena req fun trans pool}@anchor{c98}@ref{c98,,.req.fun.trans.pool;} Whether the address is managed by a pool
within the arena, and if it is, the pool.

@anchor{design/arena design mps arena req fun trans arbitrary}@anchor{c99}@ref{c99,,.req.fun.trans.arbitrary;} If the address is managed by a pool, an
arbitrary pointer value that the pool can associate with a group of
contiguous addresses at any time.

@anchor{design/arena design mps arena req fun trans white}@anchor{c9a}@ref{c9a,,.req.fun.trans.white;} If the address is managed by an automatic
pool, the set of traces for which the address is white. This is
required so that the second-stage fix protocol can reject non-white
addresses quickly. See design.mps.critical-path@footnote{critical-path.html}.

@anchor{design/arena design mps arena req attr trans time}@anchor{c9b}@ref{c9b,,.req.attr.trans.time;} The translation shall take no more than @@@@@@@@
[something not very large – drj 1999-06-23]

@node Arena partition,Constraints<2>,Address translation,Requirements<29>
@anchor{design/arena arena-partition}@anchor{c9c}
@subsubsection Arena partition


@anchor{design/arena design mps arena req fun set}@anchor{c9d}@ref{c9d,,.req.fun.set;} The arena must provide a method for approximating
sets of addresses.

@anchor{design/arena design mps arena req fun set time}@anchor{c9e}@ref{c9e,,.req.fun.set.time;} The determination of membership shall take no
more than @@@@@@@@ [something very small indeed]. (the non-obvious
solution is refsets)

@node Constraints<2>,,Arena partition,Requirements<29>
@anchor{design/arena constraints}@anchor{c9f}
@subsubsection Constraints


@anchor{design/arena design mps arena req attr space overhead}@anchor{ca0}@ref{ca0,,.req.attr.space.overhead;} req.dylan.attr.space.struct implies that
the arena must limit the space overhead. The arena is not the only
part that introduces an overhead (pool classes being the next most
obvious), so multiple parts must cooperate in order to meet the
ultimate requirements.

@anchor{design/arena design mps arena req attr time overhead}@anchor{ca1}@ref{ca1,,.req.attr.time.overhead;} Time overhead constraint?

@cartouche
@quotation Note 
How can there be a time “overhead” on a necessary component? David
Jones, 1999-06-23.
@end quotation
@end cartouche

@node Architecture<4>,Implementation<16>,Requirements<29>,Arena
@anchor{design/arena architecture}@anchor{ca2}
@subsection Architecture


@menu
* Statics:: 
* Arena classes:: 
* Chunks:: 
* Tracts:: 
* Control pool:: 
* Polling:: 
* Commit limit:: 
* Spare committed (aka “hysteresis”): Spare committed aka “hysteresis”. 
* Pause time control:: 
* Locks:: 
* Location dependencies:: 
* Finalization: Finalization<4>. 

@end menu

@node Statics,Arena classes,,Architecture<4>
@anchor{design/arena statics}@anchor{ca3}
@subsubsection Statics


@anchor{design/arena design mps arena static}@anchor{ca4}@ref{ca4,,.static;} There is no higher-level data structure than a arena, so in
order to support several arenas, we have to have some static data in
impl.c.arena. See impl.c.arena.static.

@anchor{design/arena design mps arena static init}@anchor{ca5}@ref{ca5,,.static.init;} All the static data items are initialized when the
first arena is created.

@anchor{design/arena design mps arena static serial}@anchor{ca6}@ref{ca6,,.static.serial;} @code{arenaSerial} is a static @ref{b31,,Serial}, containing
the serial number of the next arena to be created. The serial of any
existing arena is less than this.

@anchor{design/arena design mps arena static ring}@anchor{ca7}@ref{ca7,,.static.ring;} @code{arenaRing} is the sentinel of the ring of arenas.

@anchor{design/arena design mps arena static ring init}@anchor{ca8}@ref{ca8,,.static.ring.init;} @code{arenaRingInit} is a @ref{3a9,,Bool} showing whether
the ring of arenas has been initialized.

@anchor{design/arena design mps arena static ring lock}@anchor{ca9}@ref{ca9,,.static.ring.lock;} The ring of arenas has to be locked when
traversing the ring, to prevent arenas being added or removed. This is
achieved by using the (non-recursive) global lock facility, provided
by the lock module.

@anchor{design/arena design mps arena static check}@anchor{caa}@ref{caa,,.static.check;} The statics are checked each time any arena is
checked.

@node Arena classes,Chunks,Statics,Architecture<4>
@anchor{design/arena arena-classes}@anchor{cab}
@subsubsection Arena classes


@geindex Arena (C type)
@anchor{design/arena c Arena}@anchor{796}
@deffn {C Type} typedef mps_arena_s *Arena
@end deffn

@anchor{design/arena design mps arena class}@anchor{cac}@ref{cac,,.class;} The @ref{796,,Arena} data structure is designed to be subclassable
(see design.mps.protocol@footnote{protocol.html}). Clients can select what arena class
they’d like when instantiating one with @ref{52,,mps_arena_create_k()}. The
arguments to @ref{52,,mps_arena_create_k()} are class-dependent.

@anchor{design/arena design mps arena class fields}@anchor{cad}@ref{cad,,.class.fields;} The @code{grainSize} (for allocation and freeing) and
@code{zoneShift} (for computing zone sizes and what zone an address is
in) fields in the arena are the responsibility of the each class, and
are initialized by the @code{init} method. The responsibility for
maintaining the @code{commitLimit}, @code{spareCommitted}, and
@code{spareCommitLimit} fields is shared between the (generic) arena and
the arena class. @code{commitLimit} (see @ref{cae,,.commit-limit}) is changed by
the generic arena code, but arena classes are responsible for ensuring
the semantics. For @code{spareCommitted} and @code{spareCommitLimit} see
@ref{caf,,.spare-committed} below.

@anchor{design/arena design mps arena class abstract}@anchor{cb0}@ref{cb0,,.class.abstract;} The basic arena class (@code{AbstractArenaClass}) is
abstract and must not be instantiated. It provides little useful
behaviour, and exists primarily as the root of the tree of arena
classes. Each concrete class must specialize each of the class method
fields, with the exception of the describe method (which has a trivial
implementation) and the @code{extend}, @code{retract} and
@code{spareCommitExceeded} methods which have non-callable methods for
the benefit of arena classes which don’t implement these features.

@node Chunks,Tracts,Arena classes,Architecture<4>
@anchor{design/arena chunks}@anchor{cb1}
@subsubsection Chunks


@anchor{design/arena design mps arena chunk}@anchor{cb2}@ref{cb2,,.chunk;} Each contiguous region of address space managed by the MPS
is represented by a `chunk'.

@anchor{design/arena design mps arena chunk tracts}@anchor{cb3}@ref{cb3,,.chunk.tracts;} A chunk contains a table of tracts. See
@ref{cb4,,.tract.table}.

@anchor{design/arena design mps arena chunk lookup}@anchor{cb5}@ref{cb5,,.chunk.lookup;} Looking of the chunk of an address is the first
step in the second-stage fix operation, and so on the critical path.
See design.mps.critical-path@footnote{critical-path.html}.

@anchor{design/arena design mps arena chunk tree}@anchor{cb6}@ref{cb6,,.chunk.tree;} For efficient lookup, chunks are stored in a balanced
tree; @code{arena->chunkTree} points to the root of the tree. Operations
on this tree must ensure that the tree remains balanced, otherwise
performance degrades badly with many chunks.

@anchor{design/arena design mps arena chunk insert}@anchor{cb7}@ref{cb7,,.chunk.insert;} New chunks are inserted into the tree by calling
@code{ArenaChunkInsert()}. This calls @code{TreeInsert()}, followed by
@code{TreeBalance()} to ensure that the tree is balanced.

@anchor{design/arena design mps arena chunk delete}@anchor{cb8}@ref{cb8,,.chunk.delete;} There is no corresponding function
@code{ArenaChunkDelete()}. Instead, deletions from the chunk tree are
carried out by calling @code{TreeToVine()}, iterating over the vine
(where deletion is possible, if care is taken) and then calling
@code{TreeBalance()} on the remaining tree. The function
@code{TreeTraverseAndDelete()} implements this.

@anchor{design/arena design mps arena chunk delete justify}@anchor{cb9}@ref{cb9,,.chunk.delete.justify;} This is because we don’t have a function
that deletes an item from a balanced tree efficiently, and because all
functions that delete chunks do so in a loop over the chunks (so the
best we can do is O(`n') time in any case).

@anchor{design/arena design mps arena chunk delete tricky}@anchor{cba}@ref{cba,,.chunk.delete.tricky;} Deleting chunks from the chunk tree is tricky
in the virtual memory arena because @code{vmChunkDestroy()} unmaps the
memory containing the chunk, which includes the tree node. So the next
chunk must be looked up before deleting the current chunk. The function
@code{TreeTraverseAndDelete()} ensures that this is done.

@node Tracts,Control pool,Chunks,Architecture<4>
@anchor{design/arena tracts}@anchor{cbb}
@subsubsection Tracts


@anchor{design/arena design mps arena tract table}@anchor{cb4}@ref{cb4,,.tract.table;} The arena maintains tables of tract structures such
that every address managed by the arena belongs to exactly one tract.

@anchor{design/arena design mps arena tract size}@anchor{cbc}@ref{cbc,,.tract.size;} Each tract covers exactly one arena grain. This is an
implementation detail, not a requirement.

@anchor{design/arena design mps arena tract structure}@anchor{cbd}@ref{cbd,,.tract.structure;} The tract structure definition looks like this:

@example
typedef struct TractStruct @{ /* Tract structure */
  Pool pool;      /* MUST BE FIRST <design/arena#.tract.field.pool> */
  Seg seg;                     /* NULL or segment containing tract */
  Addr base;                   /* Base address of the tract */
@} TractStruct;
@end example

@anchor{design/arena design mps arena tract field pool}@anchor{cbe}@ref{cbe,,.tract.field.pool;} The pool field indicates to which pool the tract
has been allocated (@ref{c98,,.req.fun.trans.pool}). Tracts are only valid
when they are allocated to pools. When tracts are not allocated to
pools, arena classes are free to reuse tract objects in undefined
ways. A standard technique is for arena class implementations to
internally describe the objects as a union type of @code{TractStruct} and
some private representation, and to set the pool field to @code{NULL}
when the tract is not allocated. The pool field must come first so
that the private representation can share a common prefix with
@code{TractStruct}. This permits arena classes to determine from their
private representation whether such an object is allocated or not,
without requiring an extra field.

@anchor{design/arena design mps arena tract field seg}@anchor{cbf}@ref{cbf,,.tract.field.seg;} The seg field is a pointer to the segment
containing the tract, or @code{NULL} if the tract is not contained in any
segment.

@anchor{design/arena design mps arena tract field base}@anchor{cc0}@ref{cc0,,.tract.field.base;} The base field contains the base address of the
memory represented by the tract.

@anchor{design/arena design mps arena tract limit}@anchor{cc1}@ref{cc1,,.tract.limit;} The limit of the tract’s memory may be determined by
adding the arena grain size to the base address.

@anchor{design/arena design mps arena tract iteration}@anchor{cc2}@ref{cc2,,.tract.iteration;} Iteration over tracts is described in
design.mps.arena.tract-iter(0).

@geindex TractOfAddr (C function)
@anchor{design/arena c TractOfAddr}@anchor{4c4}
@deffn {C Function} @ref{3a9,,Bool} TractOfAddr (Tract *tractReturn, Arena arena, Addr addr)
@end deffn

@anchor{design/arena design mps arena tract if tractofaddr}@anchor{cc3}@ref{cc3,,.tract.if.tractofaddr;} The function @ref{4c4,,TractOfAddr()} finds the
tract corresponding to an address in memory. (See @ref{c96,,.req.fun.trans}.)
If @code{addr} is an address which has been allocated to some pool, then
@ref{4c4,,TractOfAddr()} returns @code{TRUE}, and sets @code{*tractReturn} to the
tract corresponding to that address. Otherwise, it returns @code{FALSE}.
This function is similar to @code{TractOfBaseAddr()} (see
design.mps.arena.tract-iter.if.contig-base) but serves a more general
purpose and is less efficient.

@node Control pool,Polling,Tracts,Architecture<4>
@anchor{design/arena control-pool}@anchor{cc4}
@subsubsection Control pool


@anchor{design/arena design mps arena pool}@anchor{cc5}@ref{cc5,,.pool;} Each arena has a “control pool”,
@code{arena->controlPoolStruct}, which is used for allocating MPS control
data structures by calling @code{ControlAlloc()}.

@node Polling,Commit limit,Control pool,Architecture<4>
@anchor{design/arena polling}@anchor{cc6}
@subsubsection Polling


@anchor{design/arena design mps arena poll}@anchor{cc7}@ref{cc7,,.poll;} @code{ArenaPoll()} is called “often” by other code (for instance,
on buffer fill or allocation). It is the entry point for doing tracing
work. If the polling clock exceeds a set threshold, and we’re not
already doing some tracing work (that is, @code{insidePoll} is not set),
it calls @code{TracePoll()} on all busy traces.

@anchor{design/arena design mps arena poll size}@anchor{cc8}@ref{cc8,,.poll.size;} The actual clock is @code{arena->fillMutatorSize}. This is
because internal allocation is only significant when copy segments are
being allocated, and we don’t want to have the pause times to shrink
because of that. There is no current requirement for the trace rate to
guard against running out of memory.

@cartouche
@quotation Note 
Clearly it really ought to: we have a requirement to not run out
of memory (see req.dylan.prot.fail-alloc, req.dylan.prot.consult),
and emergency tracing should not be our only story. David Jones,
1999-06-22.
@end quotation
@end cartouche

@code{BufferEmpty()} is not taken into account, because the splinter will
rarely be useable for allocation and we are wary of the clock running
backward.

@anchor{design/arena design mps arena poll clamp}@anchor{cc9}@ref{cc9,,.poll.clamp;} Polling is disabled when the arena is “clamped”, in
which case @code{arena->clamped} is @code{TRUE}. Clamping the arena prevents
background tracing work, and further new garbage collections from
starting. Clamping and releasing are implemented by the @code{ArenaClamp()}
and @code{ArenaRelease()} methods.

@anchor{design/arena design mps arena poll park}@anchor{cca}@ref{cca,,.poll.park;} The arena is “parked” by clamping it, then polling until
there are no active traces. This finishes all the active collections
and prevents further collection. Parking is implemented by the
@code{ArenaPark()} method.

@node Commit limit,Spare committed aka “hysteresis”,Polling,Architecture<4>
@anchor{design/arena commit-limit}@anchor{ccb}
@subsubsection Commit limit


@anchor{design/arena design mps arena commit-limit}@anchor{cae}@ref{cae,,.commit-limit;} The arena supports a client configurable “commit
limit” which is a limit on the total amount of committed memory. The
generic arena structure contains a field to hold the value of the
commit limit and the implementation provides two functions for
manipulating it: @code{ArenaCommitLimit()} to read it, and
@code{ArenaSetCommitLimit()} to set it. Actually abiding by the contract of
not committing more memory than the commit limit is left up to the
individual arena classes.

@anchor{design/arena design mps arena commit-limit err}@anchor{ccc}@ref{ccc,,.commit-limit.err;} When allocation from the arena would otherwise
succeed but cause the MPS to use more committed memory than specified
by the commit limit @code{ArenaAlloc()} should refuse the request and
return @code{ResCOMMIT_LIMIT}.

@anchor{design/arena design mps arena commit-limit err multi}@anchor{ccd}@ref{ccd,,.commit-limit.err.multi;} In the case where an @code{ArenaAlloc()} request
cannot be fulfilled for more than one reason including exceeding the
commit limit then class implementations should strive to return a
result code other than @code{ResCOMMIT_LIMIT}. That is,
@code{ResCOMMIT_LIMIT} should only be returned if the `only' reason for
failing the @code{ArenaAlloc()} request is that the commit limit would be
exceeded. The client documentation allows implementations to be
ambiguous with respect to which result code in returned in such a
situation however.

@node Spare committed aka “hysteresis”,Pause time control,Commit limit,Architecture<4>
@anchor{design/arena spare-committed-aka-hysteresis}@anchor{cce}
@subsubsection Spare committed (aka “hysteresis”)


@anchor{design/arena design mps arena spare-committed}@anchor{caf}@ref{caf,,.spare-committed;} See @ref{191,,mps_arena_spare_committed()}. The generic
arena structure contains two fields for the spare committed memory
fund: @code{spareCommitted} records the total number of spare committed
bytes; @code{spareCommitLimit} records the limit (set by the user) on the
amount of spare committed memory. @code{spareCommitted} is modified by
the arena class but its value is used by the generic arena code. There
are two uses: a getter function for this value is provided through the
MPS interface (@ref{320,,mps_arena_spare_commit_limit()}), and by the
@code{ArenaSetSpareCommitLimit()} function to determine whether the
amount of spare committed memory needs to be reduced.
@code{spareCommitLimit} is manipulated by generic arena code, however the
associated semantics are the responsibility of the class. It is the
class’s responsibility to ensure that it doesn’t use more spare
committed bytes than the value in @code{spareCommitLimit}.

@anchor{design/arena design mps arena spare-commit-limit}@anchor{ccf}@ref{ccf,,.spare-commit-limit;} The function @code{ArenaSetSpareCommitLimit()} sets
the @code{spareCommitLimit} field. If the limit is set to a value lower
than the amount of spare committed memory (stored in
@code{spareCommitted}) then the class specific function
@code{spareCommitExceeded} is called.

@node Pause time control,Locks,Spare committed aka “hysteresis”,Architecture<4>
@anchor{design/arena pause-time-control}@anchor{cd0}
@subsubsection Pause time control


@anchor{design/arena design mps arena pause-time}@anchor{cd1}@ref{cd1,,.pause-time;} The generic arena structure contains the field
@code{pauseTime} for the maximum time any operation in the arena may take
before returning to the mutator. This value is used by
@ref{cd2,,PolicyPollAgain()} to decide whether to do another unit of tracing
work. The MPS interface provides getter (@ref{193,,mps_arena_pause_time()})
and setter (@ref{180,,mps_arena_pause_time_set()}) functions.

@node Locks,Location dependencies,Pause time control,Architecture<4>
@anchor{design/arena locks}@anchor{cd3}
@subsubsection Locks


@anchor{design/arena design mps arena lock ring}@anchor{cd4}@ref{cd4,,.lock.ring;} @code{ArenaAccess()} is called when we fault on a barrier.
The first thing it does is claim the non-recursive global lock to
protect the arena ring (see design.mps.lock(0)).

@anchor{design/arena design mps arena lock arena}@anchor{cd5}@ref{cd5,,.lock.arena;} After the arena ring lock is claimed, @code{ArenaEnter()} is
called on one or more arenas. This claims the lock for that arena.
When the correct arena is identified or we run out of arenas, the lock
on the ring is released.

@anchor{design/arena design mps arena lock avoid}@anchor{cd6}@ref{cd6,,.lock.avoid;} Deadlocking is avoided as described below:

@anchor{design/arena design mps arena lock avoid mps}@anchor{cd7}@ref{cd7,,.lock.avoid.mps;} Firstly we require the MPS not to fault (that is,
when any of these locks are held by a thread, that thread does not
fault).

@anchor{design/arena design mps arena lock avoid thread}@anchor{cd8}@ref{cd8,,.lock.avoid.thread;} Secondly, we require that in a multi-threaded
system, memory fault handlers do not suspend threads (although the
faulting thread will, of course, wait for the fault handler to
finish).

@anchor{design/arena design mps arena lock avoid conflict}@anchor{cd9}@ref{cd9,,.lock.avoid.conflict;} Thirdly, we avoid conflicting deadlock between
the arena and global locks by ensuring we never claim the arena lock
when the recursive global lock is already held, and we never claim the
binary global lock when the arena lock is held.

@node Location dependencies,Finalization<4>,Locks,Architecture<4>
@anchor{design/arena location-dependencies}@anchor{cda}
@subsubsection Location dependencies


@anchor{design/arena design mps arena ld}@anchor{cdb}@ref{cdb,,.ld;} Location dependencies use fields in the arena to maintain a
history of summaries of moved objects, and to keep a notion of time,
so that the staleness of location dependency can be determined.

@node Finalization<4>,,Location dependencies,Architecture<4>
@anchor{design/arena finalization}@anchor{cdc}
@subsubsection Finalization


@anchor{design/arena design mps arena final}@anchor{cdd}@ref{cdd,,.final;} There is a pool which is optionally (and dynamically)
instantiated to implement finalization. The fields @code{finalPool} and
@code{isFinalPool} are used.

@node Implementation<16>,,Architecture<4>,Arena
@anchor{design/arena implementation}@anchor{cde}
@subsection Implementation


@menu
* Tract cache:: 
* Control pool: Control pool<2>. 
* Traces:: 
* Polling: Polling<2>. 
* Location dependencies: Location dependencies<2>. 
* Roots: Roots<3>. 

@end menu

@node Tract cache,Control pool<2>,,Implementation<16>
@anchor{design/arena tract-cache}@anchor{cdf}
@subsubsection Tract cache


@anchor{design/arena design mps arena impl tract cache}@anchor{ce0}@ref{ce0,,.impl.tract.cache;} When tracts are allocated to pools by @code{ArenaAlloc()},
the first tract of the block and it’s base address are cached in arena
fields @code{lastTract} and @code{lastTractBase}. The function
@code{TractOfBaseAddr()} (see design.mps.arena.tract-iter.if.block-base(0))
checks against these cached values and only calls the class method on
a cache miss. This optimizes for the common case where a pool
allocates a block and then iterates over all its tracts (for example,
to attach them to a segment).

@anchor{design/arena design mps arena impl tract uncache}@anchor{ce1}@ref{ce1,,.impl.tract.uncache;} When blocks of memory are freed by pools,
@code{ArenaFree()} checks to see if the cached value for the most
recently allocated tract (see @ref{ce0,,.impl.tract.cache}) is being freed. If
so, the cache is invalid, and must be reset. The @code{lastTract} and
@code{lastTractBase} fields are set to @code{NULL}.

@node Control pool<2>,Traces,Tract cache,Implementation<16>
@anchor{design/arena id1}@anchor{ce2}
@subsubsection Control pool


@anchor{design/arena design mps arena impl pool init}@anchor{ce3}@ref{ce3,,.impl.pool.init;} The control pool is initialized by a call to
@code{PoolInit()} during @code{ArenaCreate()}.

@anchor{design/arena design mps arena impl pool ready}@anchor{ce4}@ref{ce4,,.impl.pool.ready;} All the other fields in the arena are made
checkable before calling @code{PoolInit()}, so @code{PoolInit()} can call
@code{ArenaCheck(arena)}. The pool itself is, of course, not checkable,
so we have a field @code{arena->poolReady}, which is false until after
the return from @code{PoolInit()}. @code{ArenaCheck()} only checks the pool
if @code{poolReady}.

@node Traces,Polling<2>,Control pool<2>,Implementation<16>
@anchor{design/arena traces}@anchor{ce5}
@subsubsection Traces


@anchor{design/arena design mps arena impl trace}@anchor{ce6}@ref{ce6,,.impl.trace;} @code{arena->trace[ti]} is valid if and only if
@code{TraceSetIsMember(arena->busyTraces, ti)}.

@anchor{design/arena design mps arena impl trace create}@anchor{ce7}@ref{ce7,,.impl.trace.create;} Since the arena created by @code{ArenaCreate()}
has @code{arena->busyTraces = TraceSetEMPTY}, none of the traces are
meaningful.

@anchor{design/arena design mps arena impl trace invalid}@anchor{ce8}@ref{ce8,,.impl.trace.invalid;} Invalid traces have signature @code{SigInvalid},
which can be checked.

@node Polling<2>,Location dependencies<2>,Traces,Implementation<16>
@anchor{design/arena id2}@anchor{ce9}
@subsubsection Polling


@anchor{design/arena design mps arena impl poll fields}@anchor{cea}@ref{cea,,.impl.poll.fields;} There are three fields of a arena used for
polling: @code{pollThreshold}, @code{insidePoll}, and @code{clamped} (see
above). @code{pollThreshold} is the threshold for the next poll: it is
set at the end of @code{ArenaPoll()} to the current polling time plus
@code{ARENA_POLL_MAX}.

@node Location dependencies<2>,Roots<3>,Polling<2>,Implementation<16>
@anchor{design/arena id3}@anchor{ceb}
@subsubsection Location dependencies


@anchor{design/arena design mps arena impl ld}@anchor{cec}@ref{cec,,.impl.ld;} The @code{historyStruct} contains fields used to maintain a
history of garbage collection and in particular object motion in order
to implement location dependency.

@anchor{design/arena design mps arena impl ld epoch}@anchor{ced}@ref{ced,,.impl.ld.epoch;} The @code{epoch} is the “current epoch”. This is the number
of “flips” of traces, in which objects might have moved, in the arena
since it was created. From the mutator’s point of view, locations
change atomically at flip.

@anchor{design/arena design mps arena impl ld history}@anchor{cee}@ref{cee,,.impl.ld.history;} The @code{history} is a circular buffer of
@code{LDHistoryLENGTH} elements of type @ref{b26,,RefSet}. These are the
summaries of moved objects since the last @code{LDHistoryLENGTH} epochs.
If @code{e} is one of these recent epochs, then

@example
history->history[e % LDHistoryLENGTH]
@end example

is a summary of (the original locations of) objects moved since epoch
@code{e}.

@anchor{design/arena design mps arena impl ld prehistory}@anchor{cef}@ref{cef,,.impl.ld.prehistory;} The @code{prehistory} is a @ref{b26,,RefSet} summarizing
the original locations of all objects ever moved. When considering
whether a really old location dependency is stale, it is compared with
this summary.

@node Roots<3>,,Location dependencies<2>,Implementation<16>
@anchor{design/arena roots}@anchor{cf0}
@subsubsection Roots


@anchor{design/arena design mps arena impl root-ring}@anchor{cf1}@ref{cf1,,.impl.root-ring;} The arena holds a member of a ring of roots in the
arena. It holds an incremental serial which is the serial of the next
root.

@geindex virtual memory arena; design
@geindex VM arena; design

@node Virtual Memory Arena,Bit tables,Arena,Old design
@anchor{design/arenavm doc}@anchor{cf2}@anchor{design/arenavm design-arenavm}@anchor{cf3}@anchor{design/arenavm virtual-memory-arena}@anchor{cf4}
@section Virtual Memory Arena


@menu
* Introduction: Introduction<49>. 
* Overview: Overview<14>. 
* Notes: Notes<3>. 
* Requirements: Requirements<30>. 
* Architecture: Architecture<5>. 
* Solution ideas:: 
* Data structures: Data structures<2>. 
* Notes: Notes<4>. 

@end menu

@node Introduction<49>,Overview<14>,,Virtual Memory Arena
@anchor{design/arenavm design mps arena vm}@anchor{cf5}@anchor{design/arenavm introduction}@anchor{cf6}
@subsection Introduction


@anchor{design/arenavm design mps arena vm intro}@anchor{cf7}@ref{cf7,,.intro;} This is the design of the Virtual Memory Arena Class of the
Memory Pool System. The VM Arena Class is just one class available in
the MPS. The generic arena part is described in design.mps.arena@footnote{arena.html}.

@node Overview<14>,Notes<3>,Introduction<49>,Virtual Memory Arena
@anchor{design/arenavm design-mps-arena}@anchor{cf8}@anchor{design/arenavm overview}@anchor{cf9}
@subsection Overview


@anchor{design/arenavm design mps arena vm overview}@anchor{cfa}@ref{cfa,,.overview;} VM arenas provide blocks of memory to all other parts of
the MPS in the form of “tracts” using the virtual mapping interface
(design.mps.vm@footnote{vm.html}) to the operating system. The VM Arena Class is not
expected to be provided on platforms that do not have virtual memory
(for example, Macintosh System 7).

@anchor{design/arenavm design mps arena vm overview gc}@anchor{cfb}@ref{cfb,,.overview.gc;} The VM Arena Class provides some special services on
these blocks in order to facilitate garbage collection:

@anchor{design/arenavm design mps arena vm overview gc zone}@anchor{cfc}@ref{cfc,,.overview.gc.zone;} Allocation of blocks with specific zones. This
means that the generic fix function (design.mps.fix@footnote{fix.html}) can use a fast
refset test to eliminate references to addresses that are not in the
condemned set. This assumes that a pool class that uses this placement
appropriately is being used (such as the generation placement policy
used by AMC: see design.mps.poolamc@footnote{poolamc.html}) and that the pool selects the
condemned sets to coincide with zone stripes.

@anchor{design/arenavm design mps arena vm overview gc tract}@anchor{cfd}@ref{cfd,,.overview.gc.tract;} A fast translation from addresses to tract.
(See design.mps.arena.req.fun.trans@footnote{arena.html#design.mps.arena.req.fun.trans}.)

@node Notes<3>,Requirements<30>,Overview<14>,Virtual Memory Arena
@anchor{design/arenavm design-mps-arena-req-fun-trans}@anchor{cfe}@anchor{design/arenavm notes}@anchor{cff}
@subsection Notes


@anchor{design/arenavm design mps arena vm note refset}@anchor{d00}@ref{d00,,.note.refset;} Some of this document simply assumes that RefSets
(see design.mps.collections.refsets@footnote{collections.html#design.mps.collections.refsets}) have been chosen as the solution for
design.mps.arena.req.fun.set@footnote{arena.html#design.mps.arena.req.fun.set}. It’s a lot simpler that way. Both to
write and understand.

@node Requirements<30>,Architecture<5>,Notes<3>,Virtual Memory Arena
@anchor{design/arenavm design-mps-arena-req-fun-set}@anchor{d01}@anchor{design/arenavm requirements}@anchor{d02}
@subsection Requirements


Most of the requirements are in fact on the generic arena (see
design.mps.arena.req@footnote{arena.html#design.mps.arena.req}). However, many of those requirements can only
be met by a suitable arena class design.

Requirements particular to this arena class:

@menu
* Placement:: 
* Arena partition: Arena partition<2>. 

@end menu

@node Placement,Arena partition<2>,,Requirements<30>
@anchor{design/arenavm placement}@anchor{d03}
@subsubsection Placement


@anchor{design/arenavm design mps arena vm req fun place}@anchor{d04}@ref{d04,,.req.fun.place;} It must be possible for pools to obtain tracts at
particular addresses. Such addresses shall be declared by the pool
specifying what refset zones the tracts should lie in and what refset
zones the tracts should not lie in. It is acceptable for the arena to
not always honour the request in terms of placement if it has run out
of suitable addresses.

@node Arena partition<2>,,Placement,Requirements<30>
@anchor{design/arenavm arena-partition}@anchor{d05}
@subsubsection Arena partition


@anchor{design/arenavm design mps arena vm req fun set}@anchor{d06}@ref{d06,,.req.fun.set;} See design.mps.arena.req.fun.set@footnote{arena.html#design.mps.arena.req.fun.set}. The
approximation to sets of address must cooperate with the placement
mechanism in the way required by @ref{d04,,.req.fun.place} (above).

@node Architecture<5>,Solution ideas,Requirements<30>,Virtual Memory Arena
@anchor{design/arenavm architecture}@anchor{d07}
@subsection Architecture


@anchor{design/arenavm design mps arena vm arch memory}@anchor{d08}@ref{d08,,.arch.memory;} The underlying memory is obtained from whatever
Virtual Memory interface (see design.mps.vm@footnote{vm.html}). @@@@@@@@ Explain why this
is used.

@node Solution ideas,Data structures<2>,Architecture<5>,Virtual Memory Arena
@anchor{design/arenavm solution-ideas}@anchor{d09}
@subsection Solution ideas


@anchor{design/arenavm design mps arena vm idea grain}@anchor{d0a}@ref{d0a,,.idea.grain;} Set the arena granularity to the grain provided by the
virtual mapping module.

@anchor{design/arenavm design mps arena vm idea mem}@anchor{d0b}@ref{d0b,,.idea.mem;} Get a single large contiguous address area from the
virtual mapping interface and divide that up.

@anchor{design/arenavm design mps arena vm idea table}@anchor{d0c}@ref{d0c,,.idea.table;} Maintain a table with one entry per grain in order to
provide fast mapping (shift and add) between addresses and table
entries.

@anchor{design/arenavm design mps arena vm idea table figure}@anchor{d0d}@ref{d0d,,.idea.table.figure;} [missing figure]

@anchor{design/arenavm design mps arena vm idea map}@anchor{d0e}@ref{d0e,,.idea.map;} Store the pointers (design.arena.req.fun.trans) in the
table directly for every grain.

@anchor{design/arenavm design mps arena vm idea zones}@anchor{d0f}@ref{d0f,,.idea.zones;} Partition the managed address space into zones (see
idea.zones) and provide the set approximation as a reference
signature.

@anchor{design/arenavm design mps arena vm idea first-fit}@anchor{d10}@ref{d10,,.idea.first-fit;} Use a simple first-fit allocation policy for
tracts within each zone (@ref{d0f,,.idea.zones}). Store the freelist in the
table (@ref{d0c,,.idea.table}).

@anchor{design/arenavm design mps arena vm idea base}@anchor{d11}@ref{d11,,.idea.base;} Store information about each contiguous area (allocated
of free) in the table entry (@ref{d0c,,.idea.table}) corresponding to the base
address of the area.

@anchor{design/arenavm design mps arena vm idea shadow}@anchor{d12}@ref{d12,,.idea.shadow;} Use the table (@ref{d0c,,.idea.table}) as a “shadow” of the
operating system’s page table. Keep information such as last access,
protection, etc. in this table, since we can’t get at this information
otherwise.

@anchor{design/arenavm design mps arena vm idea barrier}@anchor{d13}@ref{d13,,.idea.barrier;} Use the table (@ref{d0c,,.idea.table}) to implement the
software barrier. Each segment can have a read and/or write barrier
placed on it by each process. (@anchor{design/arenavm design mps arena vm idea barrier bits}@anchor{d14}@ref{d14,,.idea.barrier.bits;} Store a
bit-pattern which remembers which process protected what.) This will
give a fast translation from a barrier-protected address to the
barrier handler via the process table.

@anchor{design/arenavm design mps arena vm idea demand-table}@anchor{d15}@ref{d15,,.idea.demand-table;} For a 1 GiB managed address space with a 4 KiB
page size, the table will have 256K-entries. At, say, four words per
entry, this is 4 MiB of table. Although this is only an 0.4%, the
table shouldn’t be preallocated or initially it is an infinite
overhead, and with 1 MiB active, it is a 300% overhead! The address
space for the table should be reserved, but the pages for it mapped
and unmapped on demand. By storing the table in a tract, the status of
the table’s pages can be determined by looking at it’s own entries in
itself, and thus the translation lookup (design.arena.req.fun.trans)
is slowed to two lookups rather than one.

@anchor{design/arenavm design mps arena vm idea pool}@anchor{d16}@ref{d16,,.idea.pool;} Make the Arena Manager a pool class. Arena
initialization becomes pool creation. Tract allocation becomes
@code{PoolAlloc()}. Other operations become class-specific operations on
the “arena pool”.

@node Data structures<2>,Notes<4>,Solution ideas,Virtual Memory Arena
@anchor{design/arenavm data-structures}@anchor{d17}
@subsection Data structures


@anchor{design/arenavm design mps arena vm tables}@anchor{d18}@ref{d18,,.tables;} There are two table data structures: a page table, and an
alloc table.

@anchor{design/arenavm design mps arena vm table page map}@anchor{d19}@ref{d19,,.table.page.map;} Each page in the VM has a corresponding page table
entry.

@anchor{design/arenavm design mps arena vm table page linear}@anchor{d1a}@ref{d1a,,.table.page.linear;} The table is a linear array of PageStruct
entries; there is a simple mapping between the index in the table and
the base address in the VM. Namely:


@itemize -

@item 
index to base address: @code{base-address = arena-base + (index * page-size)}

@item 
base address to index: @code{index = (base-address - arena-base) / page-size}
@end itemize

@anchor{design/arenavm design mps arena vm table page partial}@anchor{d1b}@ref{d1b,,.table.page.partial;} The table is partially mapped on an
“as-needed” basis using the SparseArray abstract type.

@anchor{design/arenavm design mps arena vm table page tract}@anchor{d1c}@ref{d1c,,.table.page.tract;} Each page table entry contains a tract, which is
only valid if it is allocated to a pool. If it is not allocated to a
pool, the fields of the tract are used for other purposes. (See
design.mps.arena.tract.field.pool@footnote{arena.html#design.mps.arena.tract.field.pool})

@anchor{design/arenavm design mps arena vm table alloc}@anchor{d1d}@ref{d1d,,.table.alloc;} The alloc table is a simple bit table (implemented
using the BT module, design.mps.bt@footnote{bt.html}).

@anchor{design/arenavm design mps arena vm table alloc map}@anchor{d1e}@ref{d1e,,.table.alloc.map;} Each page in the VM has a corresponding alloc
table entry.

@anchor{design/arenavm design mps arena vm table alloc semantics}@anchor{d1f}@ref{d1f,,.table.alloc.semantics;} The bit in the alloc table is set iff the
corresponding page is allocated (to a pool).

@node Notes<4>,,Data structures<2>,Virtual Memory Arena
@anchor{design/arenavm id1}@anchor{d20}
@subsection Notes


@anchor{design/arenavm design mps arena vm fig page}@anchor{d21}@ref{d21,,.fig.page;} How the pages in the arena area are represented in the
tables.

[missing figure]

@anchor{design/arenavm design mps arena vm fig count}@anchor{d22}@ref{d22,,.fig.count;} How a count table can be used to partially map the page
table, as proposed in request.dylan.170049.sol.map@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/dylan/170049}.

[missing figure]

@geindex bit tables; design

@node Bit tables,Allocation buffers and allocation points,Virtual Memory Arena,Old design
@anchor{design/bt doc}@anchor{d23}@anchor{design/bt bit-tables}@anchor{d24}@anchor{design/bt design-bt}@anchor{d25}
@section Bit tables


@menu
* Introduction: Introduction<50>. 
* Definitions: Definitions<8>. 
* Requirements: Requirements<31>. 
* Non requirements:: 
* Background: Background<3>. 
* Clients:: 
* Overview: Overview<15>. 
* Interface: Interface<21>. 
* Detailed design:: 
* Testing: Testing<6>. 
* References: References<21>. 

@end menu

@node Introduction<50>,Definitions<8>,,Bit tables
@anchor{design/bt design mps bt}@anchor{d26}@anchor{design/bt introduction}@anchor{d27}
@subsection Introduction


@anchor{design/bt design mps bt intro}@anchor{d28}@ref{d28,,.intro;} This is the design of the Bit Tables module. A Bit Table is
a linear array of bits. A Bit Table of length `n' is indexed using an
integer from 0 up to (but not including) `n'. Each bit in a Bit Table
can hold either the value 0 (@code{FALSE}) or 1 (@code{TRUE}). A variety of
operations are provided including: get, set, and reset individual
bits; set and reset a contiguous range of bits; search for a
contiguous range of reset bits; making a “negative image” copy of a
range.

@anchor{design/bt design mps bt readership}@anchor{d29}@ref{d29,,.readership;} MPS developers.

@node Definitions<8>,Requirements<31>,Introduction<50>,Bit tables
@anchor{design/bt definitions}@anchor{d2a}
@subsection Definitions


@anchor{design/bt design mps bt def set}@anchor{d2b}@ref{d2b,,.def.set;} `Set'

@quotation

Used as a verb meaning to assign the value 1 or @code{TRUE} to a bit.
Used descriptively to denote a bit containing the value 1. Note 1
and @code{TRUE} are synonyms in MPS C code (see @ref{3a9,,Bool}).
@end quotation

@anchor{design/bt design mps bt def reset}@anchor{d2c}@ref{d2c,,.def.reset;} `Reset'

@quotation

Used as a verb meaning to assign the value 0 or @code{FALSE} to a
bit. Used descriptively to denote a bit containing the value 0.
Note 0 and @code{FALSE} are synonyms in MPS C code (see @ref{3a9,,Bool}).
@end quotation

@cartouche
@quotation Note 
Consider using “fill/empty” or “mark/clear” instead of
“set/reset”, set/reset is probably a hangover from drj’s z80
hacking days – drj 1999-04-26
@end quotation
@end cartouche

@anchor{design/bt design mps bt def bt}@anchor{d2d}@ref{d2d,,.def.bt;} `Bit Table'

@quotation

A Bit Table is a mapping from [0, `n') to @{0,1@} for some `n',
represented as a linear array of bits.

@anchor{design/bt design mps bt def bt justify}@anchor{d2e}@ref{d2e,,.def.bt.justify;} They are called `Bit Tables' because a single
bit is used to encode whether the image of a particular integer
under the map is 0 or 1.
@end quotation

@anchor{design/bt design mps bt def range}@anchor{d2f}@ref{d2f,,.def.range;} `Range'

@quotation

A contiguous sequence of bits in a Bit Table. Ranges are typically
specified as a `base'–`limit' pair where the range includes the
position specified by the base, but excludes that specified by the
limit. The mathematical interval notation for half-open intervals,
[`base', `limit'), is used.
@end quotation

@node Requirements<31>,Non requirements,Definitions<8>,Bit tables
@anchor{design/bt requirements}@anchor{d30}
@subsection Requirements


@anchor{design/bt design mps bt req bit}@anchor{d31}@ref{d31,,.req.bit;} The storage for a Bit Table of `n' bits shall take no
more than a small constant addition to the storage required for `n'
bits. @anchor{design/bt design mps bt req bit why}@anchor{d32}@ref{d32,,.req.bit.why;} This is so that clients can make some
predictions about how much storage their algorithms use. A small
constant is allowed over the minimal for two reasons: inevitable
implementation overheads (such as only being able to allocate storage
in multiples of 32 bits), extra storage for robustness or speed (such
as signature and length fields).

@anchor{design/bt design mps bt req create}@anchor{d33}@ref{d33,,.req.create;} A means to create Bit Tables. @anchor{design/bt design mps bt req create why}@anchor{d34}@ref{d34,,.req.create.why;}
Obvious.

@anchor{design/bt design mps bt req destroy}@anchor{d35}@ref{d35,,.req.destroy;} A means to destroy Bit Tables. @anchor{design/bt design mps bt req destroy why}@anchor{d36}@ref{d36,,.req.destroy.why;}
Obvious.

@anchor{design/bt design mps bt req ops}@anchor{d37}@ref{d37,,.req.ops;} The following operations shall be supported:


@itemize *

@item 
@anchor{design/bt design mps bt req ops get}@anchor{d38}@ref{d38,,.req.ops.get;} `Get'.  Get the value of a bit at a specified
index.

@item 
@anchor{design/bt design mps bt req ops set}@anchor{d39}@ref{d39,,.req.ops.set;} `Set'.  Set a bit at a specified index.

@item 
@anchor{design/bt design mps bt req ops reset}@anchor{d3a}@ref{d3a,,.req.ops.reset;} `Reset'.  Reset a bit at a specified index.
@end itemize

@anchor{design/bt design mps bt req ops minimal why}@anchor{d3b}@ref{d3b,,.req.ops.minimal.why;} Get, Set, Reset, are the minimal operations.
All possible mappings can be created and inspected using these
operations.


@itemize *

@item 
@anchor{design/bt design mps bt req ops set range}@anchor{d3c}@ref{d3c,,.req.ops.set.range;} `SetRange'. Set a range of bits.
@anchor{design/bt design mps bt req ops set range why}@anchor{d3d}@ref{d3d,,.req.ops.set.range.why;} It’s expected that clients will often want
to set a range of bits; providing this operation allows the
implementation of the BT module to make the operation efficient.

@item 
@anchor{design/bt design mps bt req ops reset range}@anchor{d3e}@ref{d3e,,.req.ops.reset.range;} `ResetRange'. Reset a range of
bits. @anchor{design/bt design mps bt req ops reset range why}@anchor{d3f}@ref{d3f,,.req.ops.reset.range.why;} as for SetRange, see
@ref{d3d,,.req.ops.set.range.why}.

@item 
@anchor{design/bt design mps bt req ops test range set}@anchor{d40}@ref{d40,,.req.ops.test.range.set;} `IsSetRange'. Test whether a range
of bits are all set. @anchor{design/bt design mps bt req ops test range set why}@anchor{d41}@ref{d41,,.req.ops.test.range.set.why;} Mostly
for checking. For example, often clients will know that a range they
are about to reset is currently all set, they can use this operation
to assert that fact.

@item 
@anchor{design/bt design mps bt req ops test range reset}@anchor{d42}@ref{d42,,.req.ops.test.range.reset;} `IsResetRange'. Test whether a
range of bits are all reset. @anchor{design/bt req-ops-test-range-reset-why}@anchor{d43}.req.ops.test.range.reset.why
As for IsSetRange, see @ref{d41,,.req.ops.test.range.set.why}.

@item 
@anchor{design/bt design mps bt req ops find}@anchor{d44}@ref{d44,,.req.ops.find;} Find a range, which we’ll denote [`i', `j'), of at
least `L' reset bits that lies in a specified subrange of the entire
Bit Table. Various find operations are required according to the
(additional) properties of the required range:


@itemize *

@item 
@anchor{design/bt design mps bt req ops find short low}@anchor{d45}@ref{d45,,.req.ops.find.short.low;} `FindShortResetRange'. Of all
candidate ranges, find the range with least `j' (find the leftmost
range that has at least `L' reset bits and return just enough of
that). @anchor{design/bt design mps bt req ops find short low why}@anchor{d46}@ref{d46,,.req.ops.find.short.low.why;} Required by client and VM
arenas to allocate segments. The arenas implement definite
placement policies (such as lowest addressed segment first) so
they need the lowest (or highest) range that will do. It’s not
currently useful to allocate segments larger than the requested
size, so finding a short range is sufficient.

@item 
@anchor{design/bt design mps bt req ops find short high}@anchor{d47}@ref{d47,,.req.ops.find.short.high;} `FindShortResetRangeHigh'. Of all
candidate ranges, find the range with greatest `i' (find the
rightmost range that has at least `L' reset bits and return just
enough of that). @anchor{design/bt design mps bt req ops find short high why}@anchor{d48}@ref{d48,,.req.ops.find.short.high.why;} Required by arenas
to implement a specific segment placement policy (highest
addressed segment first).

@item 
@anchor{design/bt design mps bt req ops find long low}@anchor{d49}@ref{d49,,.req.ops.find.long.low;} `FindLongResetRange'. Of all candidate
ranges, identify the ranges with least `i' and of those find the
one with greatest `j' (find the leftmost range that has at least
`L' reset bits and return all of it). @anchor{design/bt req-ops-find-long-low-why}@anchor{d4a}.req.ops.find.long.low.why
Required by the mark and sweep Pool Classes (AMS, AWL, LO) for
allocating objects (filling a buffer). It’s more efficient to fill
a buffer with as much memory as is conveniently possible. There’s
no strong reason to find the lowest range but it’s bound to have
some beneficial (small) cache effect and makes the algorithm more
predictable.

@item 
@anchor{design/bt design mps bt req ops find long high}@anchor{d4b}@ref{d4b,,.req.ops.find.long.high;} `FindLongResetRangeHigh'. Provided,
but not required, see @ref{d4c,,.non-req.ops.find.long.high}.
@end itemize

@item 
@anchor{design/bt design mps bt req ops copy}@anchor{d4d}@ref{d4d,,.req.ops.copy;} Copy a range of bits from one Bit Table to another
Bit Table. Various copy operations are required:


@itemize *

@item 
@anchor{design/bt design mps bt req ops copy simple}@anchor{d4e}@ref{d4e,,.req.ops.copy.simple;} Copy a range of bits from one Bit Table to
the same position in another Bit Table.
@anchor{design/bt design mps bt req ops copy simple why}@anchor{d4f}@ref{d4f,,.req.ops.copy.simple.why;} Required to support copying of the
tables for the “low” segment during segment merging and splitting,
for pools using tables (for example, @code{PoolClassAMS}).

@item 
@anchor{design/bt design mps bt req ops copy offset}@anchor{d50}@ref{d50,,.req.ops.copy.offset;} Copy a range of bits from one Bit Table to
an offset position in another Bit Table.
@anchor{design/bt design mps bt req ops copy offset why}@anchor{d51}@ref{d51,,.req.ops.copy.offset.why;} Required to support copying of the
tables for the “high” segment during segment merging and
splitting, for pools which support this (currently none, as of
2000-01-17).

@item 
@anchor{design/bt design mps bt req ops copy invert}@anchor{d52}@ref{d52,,.req.ops.copy.invert;} Copy a range of bits from one Bit Table to
the same position in another Bit Table inverting all the bits in
the target copy. @anchor{design/bt design mps bt req ops copy invert why}@anchor{d53}@ref{d53,,.req.ops.copy.invert.why;} Required by colour
manipulation code in @code{PoolClassAMS} and @code{PoolClassLO}.
@end itemize
@end itemize

@anchor{design/bt design mps bt req speed}@anchor{d54}@ref{d54,,.req.speed;} Operations shall take no more than a few memory
operations per bit manipulated. @anchor{design/bt design mps bt req speed why}@anchor{d55}@ref{d55,,.req.speed.why;} Any slower would be
gratuitous.

@anchor{design/bt design mps bt req speed fast}@anchor{d56}@ref{d56,,.req.speed.fast;} The following operations shall be very fast:


@itemize *

@item 
@anchor{design/bt design mps bt req speed fast find short}@anchor{d57}@ref{d57,,.req.speed.fast.find.short;} FindShortResRange (the
operation used to meet @ref{d45,,.req.ops.find.short.low})
FindShortResRangeHigh (the operation used to meet
@ref{d47,,.req.ops.find.short.high}).

@anchor{design/bt design mps bt req speed fast find short why}@anchor{d58}@ref{d58,,.req.speed.fast.find.short.why;} These two are used by the client
arena (design.mps.arena.client) and the VM arena
(design.mps.arena.vm@footnote{arenavm.html}) for finding segments in page tables. The
operation will be used sufficiently often that its speed will
noticeably affect the overall speed of the MPS. They will be called
with a length equal to the number of pages in a segment. Typical
values of this length depend on the pool classes used and their
configuration, but we can expect length to be small (1 to 16)
usually. We can expect the Bit Table to be populated densely where
it is populated at all, that is set bits will tend to be clustered
together in subranges.

@item 
@anchor{design/bt design mps bt req speed fast find long}@anchor{d59}@ref{d59,,.req.speed.fast.find.long;} FindLongResRange (the operation
used to meet @ref{d49,,.req.ops.find.long.low})

@anchor{design/bt design mps bt req speed fast find long why}@anchor{d5a}@ref{d5a,,.req.speed.fast.find.long.why;} Used in the allocator for
@code{PoolClassAWL} (design.mps.poolawl@footnote{poolawl.html}), @code{PoolClassAMS}
(design.mps.poolams@footnote{poolams.html}), @code{PoolClassEPVM} (design.mps.poolepvm(0)).
Of these AWL and EPVM have speed requirements. For AWL the length of
range to be found will be the length of a Dylan table in words.
According to mail.tony.1999-05-05.11-36@footnote{https://info.ravenbrook.com/project/mps/mail/1999/05/05/11-36/0.txt}, only @code{<entry-vector>}
objects are allocated in AWL (though not all @code{<entry-vector>}
objects are allocated in AWL), and the mean length of an
@code{<entry-vector>} object is 486 Words. No data for EPVM alas.
@end itemize

@anchor{design/bt design mps bt req speed fast other why}@anchor{d5b}@ref{d5b,,.req.speed.fast.other.why;} We might expect mark and sweep pools to
make use of Bit Tables, the MPS has general requirements to support
efficient mark and sweep pools, so that imposes general speed
requirements on Bit Tables.

@node Non requirements,Background<3>,Requirements<31>,Bit tables
@anchor{design/bt non-requirements}@anchor{d5c}
@subsection Non requirements


The following are not requirements but the current design could
support them with little modification or does support them. Often they
used to be requirements, but are no longer, or were added
speculatively or experimentally but aren’t currently used.


@itemize *

@item 
@anchor{design/bt design mps bt non-req ops test range same}@anchor{d5d}@ref{d5d,,.non-req.ops.test.range.same;} `RangesSame'. Test whether two
ranges that occupy the same positions in different Bit Tables are
the same. This used to be required by @code{PoolClassAMS}, but is no
longer. Currently (1999-05-04) the functionality still exists.

@item 
@anchor{design/bt design mps bt non-req ops find long high}@anchor{d4c}@ref{d4c,,.non-req.ops.find.long.high;} `FindLongResetRangeHigh'. (see
@ref{d44,,.req.ops.find}) Of all candidate ranges, identify the ranges with
greatest `j' and of those find the one with least `i' (find the
rightmost range that has at least `L' reset bits and return all of
it). Provided for symmetry but only currently used by the BT tests
and @code{cbstest.c}.
@end itemize

@node Background<3>,Clients,Non requirements,Bit tables
@anchor{design/bt background}@anchor{d5e}
@subsection Background


@anchor{design/bt design mps bt background}@anchor{d5f}@ref{d5f,,.background;} Originally Bit Tables were used and implemented
by @code{PoolClassLO} (design.mps.poollo@footnote{poollo.html}). It was
decided to lift them out into a separate module when designing the
Pool to manage Dylan Weak Tables which is also a mark and sweep pool
and will make use of Bit Tables (see design.mps.poolawl@footnote{poolawl.html}).

@anchor{design/bt design mps bt background analysis}@anchor{d60}@ref{d60,,.background.analysis;} analysis.mps.bt(0) contains
some of the analysis of the design decisions that were and were not
made in this document.

@node Clients,Overview<15>,Background<3>,Bit tables
@anchor{design/bt clients}@anchor{d61}
@subsection Clients


@anchor{design/bt design mps bt clients}@anchor{d62}@ref{d62,,.clients;} Bit Tables are used throughout the MPS but the important
uses are in the client and VM arenas (design.mps.arena.client(0) and
design.mps.arena.vm@footnote{arenavm.html}) a bit table is used to record whether each
page is free or not; several pool classes (@code{PoolClassLO},
@code{PoolClassEPVM}, @code{PoolClassAMS}) use bit tables to record which
locations are free and also to store colour.

@node Overview<15>,Interface<21>,Clients,Bit tables
@anchor{design/bt overview}@anchor{d63}
@subsection Overview


@anchor{design/bt design mps bt over}@anchor{d64}@ref{d64,,.over;} Mostly, the design is as simple as possible. The significant
complications are iteration (see @ref{d65,,.iteration} below) and searching
(see @ref{d66,,.fun.find-res-range} below) because both of these are required
to be fast.

@node Interface<21>,Detailed design,Overview<15>,Bit tables
@anchor{design/bt interface}@anchor{d67}
@subsection Interface


@geindex BT (C type)
@anchor{design/bt c BT}@anchor{6b4}
@deffn {C Type} typedef @ref{653,,Word} *BT
@end deffn

@anchor{design/bt design mps bt if representation abstract}@anchor{d68}@ref{d68,,.if.representation.abstract;} A Bit Table is represented by the type
@ref{6b4,,BT}.

@anchor{design/bt design mps bt if declare}@anchor{d69}@ref{d69,,.if.declare;} The module declares a type @ref{6b4,,BT} and a prototype for
each of the functions below. The type is declared in impl.h.mpmtypes,
the prototypes are declared in impl.h.mpm. Some of the functions are
in fact implemented as macros in the usual way
(doc.mps.ref-man.if-conv(0).macro.std).

@anchor{design/bt design mps bt if general index}@anchor{d6a}@ref{d6a,,.if.general.index;} Many of the functions specified below take
indexes. If otherwise unspecified an index must be in the interval [0,
`n') (note, up to, but not including, `n') where `n' is the number of
bits in the relevant Bit Table (as passed to the @ref{d6b,,BTCreate()}
function).

@anchor{design/bt design mps bt if general range}@anchor{d6c}@ref{d6c,,.if.general.range;} Where a range is specified by two indexes (`base'
and `limit'), the index `base', which specifies the beginning of the
range, must be in the interval [0, `n'), and the index `limit', which
specifies the end of the range, must be in the interval [1, `n'] (note
can be `n'), and `base' must be strictly less than `limit' (empty
ranges are not allowed). Sometimes `i' and `j' are used instead of
`base' and `limit'.

@geindex BTCreate (C function)
@anchor{design/bt c BTCreate}@anchor{d6b}
@deffn {C Function} @ref{55f,,Res} BTCreate (BT *btReturn, Arena arena, Count n)
@end deffn

@anchor{design/bt design mps bt if create}@anchor{d6d}@ref{d6d,,.if.create;} Attempts to create a table of length @code{n} in the arena
control pool, putting the table in @code{*btReturn}. Returns @code{ResOK} if
and only if the table is created OK. The initial values of the bits in
the table are undefined (so the client should probably call
@ref{d6e,,BTResRange()} on the entire range before using the @ref{6b4,,BT}). Meets
@ref{d33,,.req.create}.

@geindex BTDestroy (C function)
@anchor{design/bt c BTDestroy}@anchor{d6f}
@deffn {C Function} void BTDestroy (BT t, Arena arena, Count n)
@end deffn

@anchor{design/bt design mps bt if destroy}@anchor{d70}@ref{d70,,.if.destroy;} Destroys the table @code{t}, which must have been created
with @ref{d6b,,BTCreate()}. The value of argument @code{n} must be same as the
value of the argument passed to @ref{d6b,,BTCreate()}. Meets
@ref{d35,,.req.destroy}.

@geindex BTSize (C function)
@anchor{design/bt c BTSize}@anchor{d71}
@deffn {C Function} size_t BTSize (Count n)
@end deffn

@anchor{design/bt design mps bt if size}@anchor{d72}@ref{d72,,.if.size;} @code{BTSize(n)} returns the number of bytes needed for a Bit
Table of @code{n} bits. @ref{d71,,BTSize()} is a macro, but @code{(BTSize)(n)} will
assert if @code{n} exceeds @code{COUNT_MAX - MPS_WORD_WIDTH + 1}. This is
used by clients that allocate storage for the @ref{6b4,,BT} themselves.
Before @ref{d6b,,BTCreate()} and @ref{d6f,,BTDestroy()} were implemented that was the
only way to allocate a Bit Table, but is now deprecated.

@geindex BTGet (C function)
@anchor{design/bt c BTGet}@anchor{d73}
@deffn {C Function} int BTGet (BT t, Index i)
@end deffn

@anchor{design/bt design mps bt if get}@anchor{d74}@ref{d74,,.if.get;} @code{BTGet(t, i)} returns the @code{i}-th bit of the table @code{t}
(that is, the image of @code{i} under the mapping). Meets
@ref{d38,,.req.ops.get}.

@geindex BTSet (C function)
@anchor{design/bt c BTSet}@anchor{d75}
@deffn {C Function} void BTSet (BT t, Index i)
@end deffn

@anchor{design/bt design mps bt if set}@anchor{d76}@ref{d76,,.if.set;} @code{BTSet(t, i)} sets the @code{i}-th bit of the table @code{t} (to
1). @code{BTGet(t, i)} will now return 1. Meets @ref{d39,,.req.ops.set}.

@geindex BTRes (C function)
@anchor{design/bt c BTRes}@anchor{d77}
@deffn {C Function} void BTRes (BT t, Index i)
@end deffn

@anchor{design/bt design mps bt if res}@anchor{d78}@ref{d78,,.if.res;} @code{BTRes(t, i)} resets the @code{i}-th bit of the table @code{t}
(to 0). @code{BTGet(t, i)} will now return 0. Meets @ref{d3a,,.req.ops.reset}.

@geindex BTSetRange (C function)
@anchor{design/bt c BTSetRange}@anchor{d79}
@deffn {C Function} void BTSetRange (BT t, Index base, Index limit)
@end deffn

@anchor{design/bt design mps bt if set-range}@anchor{d7a}@ref{d7a,,.if.set-range;} @code{BTSetRange(t, base, limit)} sets the range of bits
[@code{base}, @code{limit}) in the table @code{t}. @code{BTGet(t, x)} will now
return 1 for @code{base} ≤ @code{x} < @code{limit}. Meets
@ref{d40,,.req.ops.test.range.set}.

@geindex BTResRange (C function)
@anchor{design/bt c BTResRange}@anchor{d6e}
@deffn {C Function} void BTResRange (BT t, Index base, Index limit)
@end deffn

@anchor{design/bt design mps bt if res-range}@anchor{d7b}@ref{d7b,,.if.res-range;} @code{BTResRange(t, base, limit)} resets the range of
bits [@code{base}, @code{limit}) in the table @code{t}. @code{BTGet(t, x)} will
now return 0 for @code{base} ≤ @code{x} < @code{limit}. Meets
@ref{d42,,.req.ops.test.range.reset}.

@geindex BTIsSetRange (C function)
@anchor{design/bt c BTIsSetRange}@anchor{d7c}
@deffn {C Function} @ref{3a9,,Bool} BTIsSetRange (BT bt, Index base, Index limit)
@end deffn

@anchor{design/bt design mps bt if test range set}@anchor{d7d}@ref{d7d,,.if.test.range.set;} Returns @code{TRUE} if all the bits in the range
[@code{base}, @code{limit}) are set, @code{FALSE} otherwise. Meets
@ref{d40,,.req.ops.test.range.set}.

@geindex BTIsResRange (C function)
@anchor{design/bt c BTIsResRange}@anchor{771}
@deffn {C Function} @ref{3a9,,Bool} BTIsResRange (BT bt, Index base, Index limit)
@end deffn

@anchor{design/bt design mps bt if test range reset}@anchor{d7e}@ref{d7e,,.if.test.range.reset;} Returns @code{TRUE} if all the bits in the range
[@code{base}, @code{limit}) are reset, @code{FALSE} otherwise. Meets
@ref{d42,,.req.ops.test.range.reset}.

@geindex BTRangesSame (C function)
@anchor{design/bt c BTRangesSame}@anchor{d7f}
@deffn {C Function} @ref{3a9,,Bool} BTRangesSame (BT BTx, BT BTy, Index base, Index limit)
@end deffn

@anchor{design/bt design mps bt if test range same}@anchor{d80}@ref{d80,,.if.test.range.same;} returns @code{TRUE} if @code{BTGet(BTx,i)} equals
@code{BTGet(BTy,i)} for @code{i} in [@code{base}, @code{limit}), and @code{FALSE}
otherwise. Meets @ref{d5d,,.non-req.ops.test.range.same}.

@anchor{design/bt design mps bt if find general}@anchor{d81}@ref{d81,,.if.find.general;} There are four functions (below) to find reset
ranges. All the functions have the same prototype (for symmetry):

@example
Bool find(Index *baseReturn, Index *limitReturn,
          BT bt,
          Index searchBase, Index searchLimit,
          Count length);
@end example

where @code{bt} is the Bit Table in which to search. @code{searchBase} and
@code{searchLimit} specify a subset of the Bit Table to use, the
functions will only find ranges that are subsets of [@code{searchBase},
@code{searchLimit}) (when set, @code{*baseReturn} will never be less than
@code{searchBase} and @code{*limitReturn} will never be greater than
@code{searchLimit}). @code{searchBase} and @code{searchLimit} specify a range
that must conform to the general range requirements for a range [`i',
`j'), as per @ref{d6c,,.if.general.range} modified appropriately. @code{length}
is the number of contiguous reset bits to find; it must not be bigger
than @code{searchLimit - searchBase} (that would be silly). If a suitable
range cannot be found the function returns @code{FALSE} (0) and leaves
@code{*baseReturn} and @code{*limitReturn} untouched. If a suitable range is
found then the function returns the range’s base in @code{*baseReturn}
and its limit in @code{*limitReturn} and returns @code{TRUE} (1).

@geindex BTFindShortResRange (C function)
@anchor{design/bt c BTFindShortResRange}@anchor{d82}
@deffn {C Function} @ref{3a9,,Bool} BTFindShortResRange (Index *baseReturn, Index *limitReturn, BT bt, Index searchBase, Index searchLimit, Count length)
@end deffn

@anchor{design/bt design mps bt if find-short-res-range}@anchor{d83}@ref{d83,,.if.find-short-res-range;} Finds a range of reset bits in the table,
starting at @code{searchBase} and working upwards. This function is
intended to meet @ref{d45,,.req.ops.find.short.low} so it will find the
leftmost range that will do, and never finds a range longer than the
requested length (the intention is that it will not waste time
looking).

@geindex BTFindShortResRangeHigh (C function)
@anchor{design/bt c BTFindShortResRangeHigh}@anchor{d84}
@deffn {C Function} @ref{3a9,,Bool} BTFindShortResRangeHigh (Index *baseReturn, Index *limitReturn, BT bt, Index searchBase, Index searchLimit, Count length)
@end deffn

@anchor{design/bt design mps bt if find-short-res-range-high}@anchor{d85}@ref{d85,,.if.find-short-res-range-high;} Finds a range of reset bits in the
table, starting at @code{searchLimit} and working downwards. This
function is intended to meet @ref{d47,,.req.ops.find.short.high} so it will
find the rightmost range that will do, and never finds a range longer
than the requested length.

@geindex BTFindLongResRange (C function)
@anchor{design/bt c BTFindLongResRange}@anchor{d86}
@deffn {C Function} @ref{3a9,,Bool} BTFindLongResRange (Index *baseReturn, Index *limitReturn, BT bt, Index searchBase, Index searchLimit, Count length)
@end deffn

@anchor{design/bt design mps bt if find-long-res-range}@anchor{d87}@ref{d87,,.if.find-long-res-range;} Finds a range of reset bits in the table,
starting at @code{searchBase} and working upwards. This function is
intended to meet @ref{d49,,.req.ops.find.long.low} so it will find the
leftmost range that will do and returns all of that range (which can
be longer than the requested length).

@geindex BTFindLongResRangeHigh (C function)
@anchor{design/bt c BTFindLongResRangeHigh}@anchor{d88}
@deffn {C Function} @ref{3a9,,Bool} BTFindLongResRangeHigh (Index *baseReturn, Index *limitReturn, BT bt, Index searchBase, Index searchLimit, Count length)
@end deffn

@anchor{design/bt design mps bt if find-long-res-range-high}@anchor{d89}@ref{d89,,.if.find-long-res-range-high;} Finds a range of reset bits in the
table, starting at @code{searchLimit} and working downwards. This
function is intended to meet @ref{d4b,,.req.ops.find.long.high} so it will
find the rightmost range that will do and returns all that range
(which can be longer than the requested length).

@geindex BTCopyRange (C function)
@anchor{design/bt c BTCopyRange}@anchor{d8a}
@deffn {C Function} void BTCopyRange (BT fromBT, BT toBT, Index base, Index limit)
@end deffn

@anchor{design/bt design mps bt if copy-range}@anchor{d8b}@ref{d8b,,.if.copy-range;} Overwrites the @code{i}-th bit of @code{toBT} with the
@code{i}-th bit of @code{fromBT}, for all @code{i} in [@code{base}, @code{limit}).
Meets @ref{d4e,,.req.ops.copy.simple}.

@geindex BTCopyOffsetRange (C function)
@anchor{design/bt c BTCopyOffsetRange}@anchor{d8c}
@deffn {C Function} void BTCopyOffsetRange (BT fromBT, BT toBT, Index fromBase, Index fromLimit, Index toBase, Index toLimit)
@end deffn

@anchor{design/bt design mps bt if copy-offset-range}@anchor{d8d}@ref{d8d,,.if.copy-offset-range;} Overwrites the @code{i}-th bit of @code{toBT} with
the @code{j}-th bit of @code{fromBT}, for all @code{i} in [@code{toBase},
@code{toLimit}) and corresponding @code{j} in [@code{fromBase}, @code{fromLimit}).
Each of these ranges must be the same size. This might be
significantly less efficient than @ref{d8a,,BTCopyRange()}. Meets
@ref{d50,,.req.ops.copy.offset}.

@geindex BTCopyInvertRange (C function)
@anchor{design/bt c BTCopyInvertRange}@anchor{d8e}
@deffn {C Function} void BTCopyInvertRange (BT fromBT, BT toBT, Index base, Index limit)
@end deffn

@anchor{design/bt design mps bt if copy-invert-range}@anchor{d8f}@ref{d8f,,.if.copy-invert-range;} Overwrites the @code{i}-th bit of @code{toBT} with
the inverse of the @code{i}-th bit of @code{fromBT}, for all @code{i} in
[@code{base}, @code{limit}). Meets @ref{d52,,.req.ops.copy.invert}.

@node Detailed design,Testing<6>,Interface<21>,Bit tables
@anchor{design/bt detailed-design}@anchor{d90}
@subsection Detailed design


@menu
* Data structures: Data structures<3>. 
* Functions: Functions<7>. 

@end menu

@node Data structures<3>,Functions<7>,,Detailed design
@anchor{design/bt data-structures}@anchor{d91}
@subsubsection Data structures


@anchor{design/bt design mps bt datastructure}@anchor{d92}@ref{d92,,.datastructure;} Bit Tables will be represented as (a pointer to) an
array of @ref{653,,Word}. A plain array is used instead of the more usual
design convention of implementing an abstract data type as a structure
with a signature (see guide.impl.c.adt(0)).
@anchor{design/bt design mps bt datastructure words justify}@anchor{d93}@ref{d93,,.datastructure.words.justify;} The type @ref{653,,Word} is used as it will
probably map to the object that can be most efficiently accessed on
any particular platform. @anchor{design/bt design mps bt datastructure non-adt justify}@anchor{d94}@ref{d94,,.datastructure.non-adt.justify;} The usual
abstract data type convention was not followed because (i) The initial
design (drj) was lazy, (ii) Bit Tables are more likely to come in
convenient powers of two with the extra one or two words overhead.
However, the loss of checking is severe. Perhaps it would be better to
use the usual abstract data type style.

@node Functions<7>,,Data structures<3>,Detailed design
@anchor{design/bt functions}@anchor{d95}
@subsubsection Functions


@anchor{design/bt design mps bt fun size}@anchor{d96}@ref{d96,,.fun.size;} @ref{d71,,BTSize()}. Since a Bit Table is an array of @ref{653,,Word}, the
size of a Bit Table of `n' bits is simply the number of words that it
takes to store `n' bits times the number of bytes in a word. This is
@code{ceiling(n/MPS_WORD_WIDTH)*sizeof(Word).} @anchor{design/bt design mps bt fun size justify}@anchor{d97}@ref{d97,,.fun.size.justify;} Since
there can be at most @code{MPS_WORD_WIDTH - 1} unused bits in the entire
table, this satisfies @ref{d31,,.req.bit}.

@anchor{design/bt design mps bt index}@anchor{d98}@ref{d98,,.index;} The designs for the following functions use a decomposition
of a bit-index, @code{i}, into two parts, @code{iw}, @code{ib}.


@itemize *

@item 
@anchor{design/bt design mps bt index word}@anchor{d99}@ref{d99,,.index.word;} @code{iw} is the “word-index” which is the index into the
word array of the word that contains the bit referred to by the
bit-index. @code{iw = i / MPS_WORD_WIDTH}. Since @ref{187,,MPS_WORD_WIDTH} is
a power of two, this is the same as @code{iw = i >> MPS_WORD_SHIFT}.
The latter expression is used in the code. @anchor{design/bt design mps bt index word justify}@anchor{d9a}@ref{d9a,,.index.word.justify;} The
compiler is more likely to generate good code without the divide.

@item 
@anchor{design/bt design mps bt index sub-word}@anchor{d9b}@ref{d9b,,.index.sub-word;} @code{ib} is the “sub-word-index” which is the index
of the bit referred to by the bit-index in the above word. @code{ib = i
% MPS_WORD_WIDTH}. Since @ref{187,,MPS_WORD_WIDTH} is a power of two, this
is the same as @code{ib = i & ~((Word)-1<<MPS_WORD_SHIFT)}. The latter
expression is used in the code. @anchor{design/bt design mps bt index sub-word justify}@anchor{d9c}@ref{d9c,,.index.sub-word.justify;} The
compiler is more likely to generate good code without the modulus.
@end itemize

@anchor{design/bt design mps bt index justify dubious}@anchor{d9d}@ref{d9d,,.index.justify.dubious;} The above justifications are dubious; gcc
2.7.2 (with -O2) running on a sparc (zaphod) produces identical code
for the following two functions:

@example
unsigned long f(unsigned long i) @{
    return i/32 + i%32;
@}

unsigned long g(unsigned long i) @{
   return (i>>5) + (i&31);
@}
@end example

@geindex ACT_ON_RANGE (C macro)
@anchor{design/bt c ACT_ON_RANGE}@anchor{d9e}
@deffn {C Macro} ACT_ON_RANGE (base, limit, single_action, bits_action, word_action)
@end deffn

@geindex ACT_ON_RANGE_HIGH (C macro)
@anchor{design/bt c ACT_ON_RANGE_HIGH}@anchor{d9f}
@deffn {C Macro} ACT_ON_RANGE_HIGH (base, limit, single_action, bits_action, word_action)
@end deffn

@anchor{design/bt design mps bt iteration}@anchor{d65}@ref{d65,,.iteration;} Many of the following functions involve iteration over
ranges in a Bit Table. This is performed on whole words rather than
individual bits, whenever possible (to improve speed). This is
implemented internally by the macros @ref{d9e,,ACT_ON_RANGE()} and
@ref{d9f,,ACT_ON_RANGE_HIGH()} for iterating over the range forwards and
backwards respectively. These macros do not form part of the interface
of the module, but are used extensively in the implementation. The
macros are often used even when speed is not an issue because it
simplifies the implementation and makes it more uniform. The iteration
macros take the parameters @code{base}, @code{limit}, @code{single_action},
@code{bits_action}, and @code{word_action}:


@itemize *

@item 
@code{base} and @code{limit} are of type @ref{b19,,Index} and define the range of
the iteration.

@item 
@code{single_action} is the name of a macro which will be used for
iterating over bits in the table individually. This macro must take
a single @ref{b19,,Index} parameter corresponding to the index for the bit.
The expansion of the macro must not contain @code{break} or
@code{continue} because it will be called from within a loop from the
expansion of @ref{d9e,,ACT_ON_RANGE()}.

@item 
@code{bits_action} is the name of a macro which will be used for
iterating over part-words. This macro must take parameters
@code{wordIndex}, @code{base}, @code{limit} where @code{wordIndex} is the index
into the array of words, and @code{base} and @code{limit} define a range
of bits within the indexed word.

@item 
@code{word_action} is the name of a macro which will be used for
iterating over whole-words. This macro must take the single
parameter @code{wordIndex} which is the index of the whole-word in the
array. The expansion of the macro must not contain @code{break} or
@code{continue} because it will be called from within a loop from the
expansion of @ref{d9e,,ACT_ON_RANGE()}.
@end itemize

@anchor{design/bt design mps bt iteration exit}@anchor{da0}@ref{da0,,.iteration.exit;} The expansion of the @code{single_action},
@code{bits_action}, and @code{word_action} macros is allowed to contain
@code{return} or @code{goto} to terminate the iteration early. This is used
by the test (@ref{da1,,.fun.test.range.set}) and find (@ref{da2,,.fun.find})
operations.

@anchor{design/bt design mps bt iteration small}@anchor{da3}@ref{da3,,.iteration.small;} If the range is sufficiently small only the
@code{single_action} macro will be used, as this is more efficient in
practice. The choice of what constitutes a small range is made
entirely on the basis of experimental performance results (and
currently, 1999-04-27, a “small range” is 6 bits or fewer. See
change.mps.epcore.brisling.160181 for some justification). Otherwise
(for a bigger range) @code{bits_action} is used on the part words at
either end of the range (or the whole of the range it if it fits in a
single word), and @code{word_action} is used on the words that comprise
the inner portion of the range.

The implementation of @ref{d9e,,ACT_ON_RANGE()} (and @ref{d9f,,ACT_ON_RANGE_HIGH()}) is
simple enough. It decides which macros it should invoke and invokes
them. @code{single_action} and @code{word_action} are invoked inside loops.

@anchor{design/bt design mps bt fun get}@anchor{da4}@ref{da4,,.fun.get;} @ref{d73,,BTGet()}. The bit-index will be converted in the usual
way, see @ref{d98,,.index}. The relevant @ref{653,,Word} will be read out of the Bit
Table and shifted right by the sub-@ref{653,,Word} index (this brings the
relevant bit down to the least significant bit of the @ref{653,,Word}), the
@ref{653,,Word} will then be masked with 1, producing the answer.

@anchor{design/bt design mps bt fun set}@anchor{da5}@ref{da5,,.fun.set;} @ref{d75,,BTSet()}.

@anchor{design/bt design mps bt fun res}@anchor{da6}@ref{da6,,.fun.res;} @ref{d77,,BTRes()}.

In both @ref{d75,,BTSet()} and @ref{d77,,BTRes()} a mask is constructed by shifting 1
left by the sub-word-index (see @ref{d98,,.index}). For @ref{d75,,BTSet()} the mask is
or-ed into the relevant word (thereby setting a single bit). For
@ref{d77,,BTRes()} the mask is inverted and and-ed into the relevant word
(thereby resetting a single bit).

@anchor{design/bt design mps bt fun set-range}@anchor{da7}@ref{da7,,.fun.set-range;} @ref{d79,,BTSetRange()}. @ref{d9e,,ACT_ON_RANGE()} (see @ref{d65,,.iteration}
above) is used with macros that set a single bit (using @ref{d75,,BTSet()}),
set a range of bits in a word, and set a whole word.

@anchor{design/bt design mps bt fun res-range}@anchor{da8}@ref{da8,,.fun.res-range;} @ref{d6e,,BTResRange()} This is implemented similarly to
@ref{d79,,BTSetRange()} (@ref{da7,,.fun.set-range}) except using @ref{d77,,BTRes()} and reverse
bit-masking logic.

@anchor{design/bt design mps bt fun test range set}@anchor{da1}@ref{da1,,.fun.test.range.set;} @ref{d7c,,BTIsSetRange()}. @ref{d9e,,ACT_ON_RANGE()} (see
@ref{d65,,.iteration} above) is used with macros that test whether all the
relevant bits are set; if some of the relevant bits are not set then
@code{return FALSE} is used to terminate the iteration early and return
from the @ref{d7c,,BTIsSetRange()} function. If the iteration completes then
@code{TRUE} is returned.

@anchor{design/bt design mps bt fun test range reset}@anchor{da9}@ref{da9,,.fun.test.range.reset;} @ref{771,,BTIsResRange()}. As for @ref{d7c,,BTIsSetRange()}
(@ref{da1,,.fun.test.range.set} above) but testing whether the bits are reset.

@anchor{design/bt design mps bt fun test range same}@anchor{daa}@ref{daa,,.fun.test.range.same;} @ref{d7f,,BTRangesSame()}. As for @ref{d7c,,BTIsSetRange()}
(@ref{da1,,.fun.test.range.set} above) but testing whether corresponding
ranges in the two Bit Tables are the same. Note there are no speed
requirements, but @ref{d9e,,ACT_ON_RANGE()} is used for simplicity and
uniformity.

@anchor{design/bt design mps bt fun find}@anchor{da2}@ref{da2,,.fun.find;} The four external find functions (@ref{d82,,BTFindShortResRange()},
@ref{d84,,BTFindShortResRangeHigh()}, @ref{d86,,BTFindLongResRange()},
@ref{d88,,BTFindLongResRangeHigh()}) simply call through to one of the two
internal functions: @ref{dab,,BTFindResRange()} and @ref{dac,,BTFindResRangeHigh()}.

@geindex BTFindResRange (C function)
@anchor{design/bt c BTFindResRange}@anchor{dab}
@deffn {C Function} @ref{3a9,,Bool} BTFindResRange (Index *baseReturn, Index *limitReturn, BT bt, Index searchBase, Index searchLimit, Count minLength, Count maxLength)
@end deffn

@geindex BTFindResRangeHigh (C function)
@anchor{design/bt c BTFindResRangeHigh}@anchor{dac}
@deffn {C Function} @ref{3a9,,Bool} BTFindResRangeHigh (Index *baseReturn, Index *limitReturn, BT bt, Index searchBase, Index searchLimit, Count minLength, Count maxLength)
@end deffn

There are two length parameters, one specifying the minimum length of
the range to be found, the other the maximum length. For
@code{BTFindShort()} and @code{BTFindShortHigh()}, @code{maxLength} is equal to
@code{minLength} when passed; for @code{BTFindLong()} and @code{BTFindLongHigh()},
@code{maxLength` is equal to the maximum possible range, namely
`@w{`}searchLimit - searchBase}.

@anchor{design/bt design mps bt fun find-res-range}@anchor{d66}@ref{d66,,.fun.find-res-range;} @ref{dab,,BTFindResRange()}. Iterate within the search
boundaries, identifying candidate ranges by searching for a reset bit.
The Boyer–Moore algorithm @ref{dad,,[Boyer_Moore_1977]} is used (it’s particularly
easy to implement when there are only two symbols, 0 and 1, in the
alphabet). For each candidate range, iterate backwards over the bits
from the end of the range towards the beginning. If a set bit is
found, this candidate has failed and a new candidate range is
selected. If when scanning for the set bit a range of reset bits was
found before finding the set bit, then this (small) range of reset
bits is used as the start of the next candidate. Additionally the end
of this small range of reset bits (the end of the failed candidate
range) is remembered so that we don’t have to iterate over this range
again. But if no reset bits were found in the candidate range, then
iterate again (starting from the end of the failed candidate) to look
for one. If during the backwards search no set bit is found, then we
have found a sufficiently large range of reset bits; now extend the
valid range as far as possible up to the maximum length by iterating
forwards up to the maximum limit looking for a set bit. The iterations
make use of the @ref{d9e,,ACT_ON_RANGE()} and @ref{d9f,,ACT_ON_RANGE_HIGH()} macros,
which can use @code{goto} to effect an early termination of the iteration
when a set/reset (as appropriate) bit is found. The macro
@code{ACTION_FIND_SET_BIT()} is used in the iterations. It efficiently
finds the first (that is, with lowest index or weight) set bit in a
word or subword.

@anchor{design/bt design mps bt fun find-res-range improve}@anchor{dae}@ref{dae,,.fun.find-res-range.improve;} Various other performance improvements
have been suggested in the past, including some from
request.epcore.170534@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/epcore/170534}. Here is a list of potential improvements which
all sound plausible, but which have not led to performance improvements
in practice:


@itemize *

@item 
@anchor{design/bt design mps bt fun find-res-range improve step partial}@anchor{daf}@ref{daf,,.fun.find-res-range.improve.step.partial;} When the top index in a
candidate range fails, skip partial words as well as whole words,
using, for example, lookup tables.

@item 
@anchor{design/bt design mps bt fun find-res-range improve lookup}@anchor{db0}@ref{db0,,.fun.find-res-range.improve.lookup;} When testing a candidate run,
examine multiple bits at once (for example, 8), using lookup tables
for (for example) index of first set bit, index of last set bit,
number of reset bits, length of maximum run of reset bits.
@end itemize

@anchor{design/bt design mps bt fun find-res-range-high}@anchor{db1}@ref{db1,,.fun.find-res-range-high;} @ref{dac,,BTFindResRangeHigh()}. Exactly the same
algorithm as in @ref{dab,,BTFindResRange()} (see @ref{d66,,.fun.find-res-range} above),
but moving over the table in the opposite direction.

@anchor{design/bt design mps bt fun copy-simple-range}@anchor{db2}@ref{db2,,.fun.copy-simple-range;} @ref{d8a,,BTCopyRange()}. Uses @ref{d9e,,ACT_ON_RANGE()} (see
@ref{d65,,.iteration} above) with the obvious implementation. Should be fast.

@anchor{design/bt design mps bt fun copy-offset-range}@anchor{db3}@ref{db3,,.fun.copy-offset-range;} @ref{d8c,,BTCopyOffsetRange()}. Uses a simple
iteration loop, reading bits with @ref{d73,,BTGet()} and setting them with
@ref{d75,,BTSet()}. Doesn’t use @ref{d9e,,ACT_ON_RANGE()} because the two ranges will
not, in general, be similarly word-aligned.

@anchor{design/bt design mps bt fun copy-invert-range}@anchor{db4}@ref{db4,,.fun.copy-invert-range;} @ref{d8e,,BTCopyInvertRange()}. Uses @ref{d9e,,ACT_ON_RANGE()}
(see @ref{d65,,.iteration} above) with the obvious implementation. Should be
fast—although there are no speed requirements.

@node Testing<6>,References<21>,Detailed design,Bit tables
@anchor{design/bt testing}@anchor{db5}
@subsection Testing


@anchor{design/bt design mps bt test}@anchor{db6}@ref{db6,,.test;} The following tests are available or have been used during
development.

@anchor{design/bt design mps bt test btcv}@anchor{db7}@ref{db7,,.test.btcv;} @code{btcv.c}. This is supposed to be a coverage test,
intended to execute all of the module’s code in at least some minimal
way.

@anchor{design/bt design mps bt test landtest}@anchor{db8}@ref{db8,,.test.landtest;} @code{landtest.c}. This is a test of the @ref{53c,,Land}
module (design.mps.land@footnote{land.html}) and its concrete implementations. It
compares the functional operation of a @ref{53c,,Land} with that of a @ref{6b4,,BT}
so is a good functional test of either module.

@anchor{design/bt design mps bt test mmqa 120}@anchor{db9}@ref{db9,,.test.mmqa.120;} MMQA_test_function!210.c. This is used because it has
a fair amount of segment allocation and freeing so exercises the arena
code that uses Bit Tables.

@anchor{design/bt design mps bt test bttest}@anchor{dba}@ref{dba,,.test.bttest;} @code{bttest.c}. This is an interactive test that can be
used to exercise some of the @ref{6b4,,BT} functionality by hand.

@anchor{design/bt design mps bt test dylan}@anchor{dbb}@ref{dbb,,.test.dylan;} It is possible to modify Dylan so that it uses Bit
Tables more extensively. See change.mps.epcore.brisling.160181 TEST1
and TEST2.

@node References<21>,,Testing<6>,Bit tables
@anchor{design/bt references}@anchor{dbc}
@subsection References


@anchor{design/bt boyer-moore-1977}@anchor{dad}@w{(Boyer_Moore_1977)} 
Robert S. Boyer and J. Strother Moore. Communications of the ACM 20(10):762–772. 1977. “A Fast String Searching Algorithm@footnote{http://www.cs.utexas.edu/~moore/publications/fstrpos.pdf}”.

@geindex buffers; design

@node Allocation buffers and allocation points,Checking<4>,Bit tables,Old design
@anchor{design/buffer doc}@anchor{dbd}@anchor{design/buffer allocation-buffers-and-allocation-points}@anchor{dbe}@anchor{design/buffer design-buffer}@anchor{dbf}
@section Allocation buffers and allocation points


@menu
* Introduction: Introduction<51>. 
* Glossary:: 
* Source: Source<2>. 
* Requirements: Requirements<32>. 
* Classes: Classes<3>. 
* Logging:: 
* Measurement:: 
* Notes from the whiteboard:: 
* Synchronization: Synchronization<2>. 
* Interface: Interface<22>. 
* Diagrams:: 

@end menu

@node Introduction<51>,Glossary,,Allocation buffers and allocation points
@anchor{design/buffer design mps buffer}@anchor{dc0}@anchor{design/buffer introduction}@anchor{dc1}
@subsection Introduction


@anchor{design/buffer design mps buffer scope}@anchor{dc2}@ref{dc2,,.scope;} This is the design of allocation buffers and allocation
points.

@anchor{design/buffer design mps buffer purpose}@anchor{dc3}@ref{dc3,,.purpose;} The purpose of this document is to record design
decisions made concerning allocation buffers and allocation points and
justify those decisions in terms of requirements.

@anchor{design/buffer design mps buffer readership}@anchor{dc4}@ref{dc4,,.readership;} The document is intended for reading by any MPS
developer.

@node Glossary,Source<2>,Introduction<51>,Allocation buffers and allocation points
@anchor{design/buffer glossary}@anchor{dc5}
@subsection Glossary


trapped

@quotation

@anchor{design/buffer design mps buffer def trapped}@anchor{dc6}@ref{dc6,,.def.trapped;} The buffer is in a state such that the MPS gets
to know about the next use of that buffer.
@end quotation

@node Source<2>,Requirements<32>,Glossary,Allocation buffers and allocation points
@anchor{design/buffer source}@anchor{dc7}
@subsection Source


@anchor{design/buffer design mps buffer source mail}@anchor{dc8}@ref{dc8,,.source.mail;} Much of the juicy stuff about buffers is only
floating around in mail discussions. You might like to try searching
the archives if you can’t find what you want here.

@cartouche
@quotation Note 
Mail archives are only accessible to Ravenbrook staff. RHSK
2006-06-09.
@end quotation
@end cartouche

@anchor{design/buffer design mps buffer source synchronize}@anchor{dc9}@ref{dc9,,.source.synchronize;} For a discussion of the synchronization
issues, see mail.richard.1995-05-19.17-10@footnote{https://info.ravenbrook.com/project/mps/mail/1995/05/19/17-10/0.txt},
mail.ptw.1995-05-19.19-15@footnote{https://info.ravenbrook.com/project/mps/mail/1995/05/19/19-15/0.txt}, and mail.richard.1995-05-24.10-18@footnote{https://info.ravenbrook.com/project/mps/mail/1995/05/24/10-18/0.txt}.

@cartouche
@quotation Note 
I believe that the sequence for flip in PTW’s message is
incorrect. The operations should be in the other order. DRJ.
@end quotation
@end cartouche

@anchor{design/buffer design mps buffer source interface}@anchor{dca}@ref{dca,,.source.interface;} For a description of the buffer interface in C
prototypes, see mail.richard.1997-04-28.09-25@footnote{https://info.ravenbrook.com/project/mps/mail/1997/04/28/09-25/0.txt}.

@anchor{design/buffer design mps buffer source qa}@anchor{dcb}@ref{dcb,,.source.qa;} Discussions with QA were useful in pinning down the
semantics and understanding of some obscure but important boundary
cases. See the thread with subject “notes on our allocation points
discussion” and messages mail.richard.tucker.1997-05-12.09-45@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/12/09-45/0.txt},
mail.ptw.1997-05-12.12-46@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/12/12-46/1.txt}, mail.richard.1997-05-12.13-15@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/12/13-15/0.txt},
mail.richard.1997-05-12.13-28@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/12/13-28/0.txt}, mail.ptw.1997-05-13.15-15@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/13/15-15/0.txt},
mail.sheep.1997-05-14.11-52@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/14/11-52/0.txt}, mail.rit.1997-05-15.09-19@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/15/09-19/0.txt},
mail.ptw.1997-05-15.21-22@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/15/21-22/0.txt}, mail.ptw.1997-05-15.21-35@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/15/21-35/0.txt},
mail.rit.1997-05-16.08-02@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/16/08-02/0.txt}, mail.rit.1997-05-16.08-42@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/16/08-42/0.txt},
mail.ptw.1997-05-16.12-36@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/16/12-36/0.txt}, mail.ptw.1997-05-16.12-47@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/16/12-47/0.txt},
mail.richard.1997-05-19.15-46@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/19/15-46/0.txt}, mail.richard.1997-05-19.15-56@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/19/15-56/0.txt},
and mail.ptw.1997-05-20.20-47@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/20/20-47/0.txt}.

@node Requirements<32>,Classes<3>,Source<2>,Allocation buffers and allocation points
@anchor{design/buffer mail-ptw-1997-05-20-20-47}@anchor{dcc}@anchor{design/buffer requirements}@anchor{dcd}
@subsection Requirements


@anchor{design/buffer design mps buffer req fast}@anchor{dce}@ref{dce,,.req.fast;} Allocation must be very fast.

@anchor{design/buffer design mps buffer req thread-safe}@anchor{dcf}@ref{dcf,,.req.thread-safe;} Must run safely in a multi-threaded environment.

@anchor{design/buffer design mps buffer req no-synch}@anchor{dd0}@ref{dd0,,.req.no-synch;} Must avoid the use of thread-synchronization.
(@ref{dce,,.req.fast})

@anchor{design/buffer design mps buffer req manual}@anchor{dd1}@ref{dd1,,.req.manual;} Support manual memory management.

@anchor{design/buffer design mps buffer req exact}@anchor{dd2}@ref{dd2,,.req.exact;} Support exact collectors.

@anchor{design/buffer design mps buffer req ambig}@anchor{dd3}@ref{dd3,,.req.ambig;} Support ambiguous collectors.

@anchor{design/buffer design mps buffer req count}@anchor{dd4}@ref{dd4,,.req.count;} Must record (approximately) the amount of allocation (in bytes).

@cartouche
@quotation Note 
Actually not a requirement any more, but once was put forward as a
Dylan requirement. Bits of the code still reflect this
requirement. See request.dylan.170554@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/dylan/170554}.
@end quotation
@end cartouche

@node Classes<3>,Logging,Requirements<32>,Allocation buffers and allocation points
@anchor{design/buffer classes}@anchor{dd5}@anchor{design/buffer request-dylan-170554}@anchor{dd6}
@subsection Classes


@anchor{design/buffer design mps buffer class hierarchy}@anchor{dd7}@ref{dd7,,.class.hierarchy;} The @code{Buffer} data structure is designed to be
subclassable (see design.mps.protocol@footnote{protocol.html}).

@anchor{design/buffer design mps buffer class hierarchy buffer}@anchor{dd8}@ref{dd8,,.class.hierarchy.buffer;} The basic buffer class (@code{BufferClass})
supports basic allocation-point buffering, and is appropriate for
those manual pools which don’t use segments (@ref{dd1,,.req.manual}). The
@code{Buffer} class doesn’t support reference ranks (that is, the buffers
have @code{RankSetEMPTY}). Clients may use @code{BufferClass} directly, or
create their own subclasses (see @ref{dd9,,.subclassing}).

@anchor{design/buffer design mps buffer class hierarchy segbuf}@anchor{dda}@ref{dda,,.class.hierarchy.segbuf;} Class @code{SegBufClass} is also provided for
the use of pools which additionally need to associate buffers with
segments. @code{SegBufClass} is a subclass of @code{BufferClass}. Manual
pools may find it convenient to use @code{SegBufClass}, but it is
primarily intended for automatic pools (@ref{dd2,,.req.exact}, @ref{dd3,,.req.ambig}).
An instance of @code{SegBufClass} may be attached to a region of memory
that lies within a single segment. The segment is associated with the
buffer, and may be accessed with the @code{BufferSeg()} function.
@code{SegBufClass} also supports references at any rank set. Hence this
class or one of its subclasses should be used by all automatic pools
(with the possible exception of leaf pools). The rank sets of buffers
and the segments they are attached to must match. Clients may use
@code{SegBufClass} directly, or create their own subclasses (see
@ref{dd9,,.subclassing}).

@anchor{design/buffer design mps buffer class hierarchy rankbuf}@anchor{ddb}@ref{ddb,,.class.hierarchy.rankbuf;} Class @code{RankBufClass} is also provided
as a subclass of @code{SegBufClass}. The only way in which this differs
from its superclass is that the rankset of a @code{RankBufClass} is set
during initialization to the singleton rank passed as an additional
parameter to @ref{ddc,,BufferCreate()}. Instances of @code{RankBufClass} are of
the same type as instances of @code{SegBufClass}, that is, @code{SegBuf}.
Clients may use @code{RankBufClass} directly, or create their own
subclasses (see @ref{dd9,,.subclassing}).

@anchor{design/buffer design mps buffer class create}@anchor{ddd}@ref{ddd,,.class.create;} The buffer creation functions (@ref{ddc,,BufferCreate()}
and @code{BufferCreateV()}) take a @code{class} parameter, which determines
the class of buffer to be created.

@anchor{design/buffer design mps buffer class choice}@anchor{dde}@ref{dde,,.class.choice;} Pools which support buffered allocation should
specify a default class for buffers. This class will be used when a
buffer is created in the normal fashion by MPS clients (for example by
a call to @ref{339,,mps_ap_create()}). Pools specify the default class by
means of the @code{bufferClass} field in the pool class object. This
should be a pointer to a function of type @ref{79e,,PoolBufferClassMethod}.
The normal class “Ensure” function (for example
@code{EnsureBufferClass()}) has the appropriate type.

@anchor{design/buffer design mps buffer subclassing}@anchor{dd9}@ref{dd9,,.subclassing;} Pools may create their own subclasses of the standard
buffer classes. This is sometimes useful if the pool needs to add an
extra field to the buffer. The convenience macro
@code{DEFINE_BUFFER_CLASS()} may be used to define subclasses of buffer
classes. See design.mps.protocol.int.define-special@footnote{protocol.html#design.mps.protocol.int.define-special}.

@anchor{design/buffer design mps buffer replay}@anchor{ddf}@ref{ddf,,.replay;} To work with the allocation replayer (see
design.mps.telemetry.replayer@footnote{telemetry.html#design.mps.telemetry.replayer}), the buffer class has to emit an event
for each call to an external interface, containing all the parameters
passed by the user. If a new event type is required to carry this
information, the replayer (impl.c.eventrep) must then be extended to
recreate the call.

@anchor{design/buffer design mps buffer replay pool-buffer}@anchor{de0}@ref{de0,,.replay.pool-buffer;} The replayer must also be updated if the
association of buffer class to pool or the buffer class hierarchy is
changed.

@anchor{design/buffer design mps buffer class method}@anchor{de1}@ref{de1,,.class.method;} Buffer classes provide the following methods (these
should not be confused with the pool class methods related to the
buffer protocol, described in @ref{de2,,.method.create} and following
sections):

@geindex BufferInitMethod (C type)
@anchor{design/buffer c BufferInitMethod}@anchor{de3}
@deffn {C Type} typedef @ref{55f,,Res} (*BufferInitMethod)(Buffer buffer, Pool pool, ArgList args)
@end deffn

@anchor{design/buffer design mps buffer class method init}@anchor{de4}@ref{de4,,.class.method.init;} @code{init()} is a class-specific initialization
method called from @code{BufferInit()}. It receives the keyword arguments
passed to to @code{BufferInit()}. Client-defined methods must call their
superclass method (via a next-method call) before performing any
class-specific behaviour. @anchor{design/buffer design mps buffer replay init}@anchor{de5}@ref{de5,,.replay.init;} The @code{init()} method
should emit a @code{BufferInit<foo>} event (if there aren’t any extra
parameters, @code{<foo> = ""}).

@geindex BufferAttachMethod (C type)
@anchor{design/buffer c BufferAttachMethod}@anchor{de6}
@deffn {C Type} typedef void (*BufferAttachMethod)(Buffer buffer, @ref{632,,Addr} base, @ref{632,,Addr} limit, @ref{632,,Addr} init, @ref{40e,,Size} size)
@end deffn

@anchor{design/buffer design mps buffer class method attach}@anchor{de7}@ref{de7,,.class.method.attach;} @code{attach()} is a class-specific method
called whenever a buffer is attached to memory, via
@ref{de8,,BufferAttach()}. Client-defined methods must call their superclass
method (via a next-method call) before performing any class-specific
behaviour.

@geindex BufferDetachMethod (C type)
@anchor{design/buffer c BufferDetachMethod}@anchor{de9}
@deffn {C Type} typedef void (*BufferDetachMethod)(Buffer buffer)
@end deffn

@anchor{design/buffer design mps buffer class method detach}@anchor{dea}@ref{dea,,.class.method.detach;} @code{detach()} is a class-specific method
called whenever a buffer is detached from memory, via
@ref{7a5,,BufferDetach()}. Client-defined methods must call their superclass
method (via a next-method call) after performing any class-specific
behaviour.

@geindex BufferSegMethod (C type)
@anchor{design/buffer c BufferSegMethod}@anchor{deb}
@deffn {C Type} typedef @ref{b53,,Seg} (*BufferSegMethod)(Buffer buffer)
@end deffn

@anchor{design/buffer design mps buffer class method seg}@anchor{dec}@ref{dec,,.class.method.seg;} @code{seg()} is a class-specific accessor method
which returns the segment attached to a buffer (or @code{NULL} if there
isn’t one). It is called from @code{BufferSeg()}. Clients should not need
to define their own methods for this.

@geindex BufferRankSetMethod (C type)
@anchor{design/buffer c BufferRankSetMethod}@anchor{ded}
@deffn {C Type} typedef @ref{b21,,RankSet} (*BufferRankSetMethod)(Buffer buffer)
@end deffn

@anchor{design/buffer design mps buffer class method rankSet}@anchor{dee}@ref{dee,,.class.method.rankSet;} @code{rankSet()} is a class-specific accessor
method which returns the rank set of a buffer. It is called from
@code{BufferRankSet()}. Clients should not need to define their own
methods for this.

@geindex BufferSetRankSetMethod (C type)
@anchor{design/buffer c BufferSetRankSetMethod}@anchor{def}
@deffn {C Type} typedef void (*BufferSetRankSetMethod)(Buffer buffer, @ref{b21,,RankSet} rankSet)
@end deffn

@anchor{design/buffer design mps buffer class method setRankSet}@anchor{df0}@ref{df0,,.class.method.setRankSet;} @code{setRankSet()} is a class-specific
setter method which sets the rank set of a buffer. It is called from
@code{BufferSetRankSet()}. Clients should not need to define their own
methods for this.

@node Logging,Measurement,Classes<3>,Allocation buffers and allocation points
@anchor{design/buffer logging}@anchor{df1}
@subsection Logging


@anchor{design/buffer design mps buffer logging control}@anchor{df2}@ref{df2,,.logging.control;} Buffers have a separate control for whether they
are logged or not, this is because they are particularly high volume.
This is a Boolean flag (@code{bufferLogging}) in the @code{ArenaStruct}.

@node Measurement,Notes from the whiteboard,Logging,Allocation buffers and allocation points
@anchor{design/buffer measurement}@anchor{df3}
@subsection Measurement


@anchor{design/buffer design mps buffer count}@anchor{df4}@ref{df4,,.count;} Counting the allocation volume is done by maintaining two
fields in the buffer struct:

@anchor{design/buffer design mps buffer count fields}@anchor{df5}@ref{df5,,.count.fields;} @code{fillSize}, @code{emptySize}.

@anchor{design/buffer design mps buffer count monotonic}@anchor{df6}@ref{df6,,.count.monotonic;} both of these fields are monotonically
increasing.

@anchor{design/buffer design mps buffer count fillsize}@anchor{df7}@ref{df7,,.count.fillsize;} @code{fillSize} is an accumulated total of the size
of all the fills (as a result of calling the @code{PoolClass}
@ref{7a2,,BufferFill()} method) that happen on the buffer.

@anchor{design/buffer design mps buffer count emptysize}@anchor{df8}@ref{df8,,.count.emptysize;} @code{emptySize} is an accumulated total of the size of
all the empties than happen on the buffer (which are notified to the
pool using the @code{PoolClass} @code{BufferEmpty()} method).

@anchor{design/buffer design mps buffer count generic}@anchor{df9}@ref{df9,,.count.generic;} These fields are maintained by the generic buffer
code in @ref{de8,,BufferAttach()} and @ref{7a5,,BufferDetach()}.

@anchor{design/buffer design mps buffer count other}@anchor{dfa}@ref{dfa,,.count.other;} Similar count fields are maintained in the arena.
They are maintained on an internal (buffers used internally by the
MPS) and external (buffers used for mutator allocation points) basis.
The fields are also updated by the buffer code. The fields are:


@itemize -

@item 
in the arena, @code{fillMutatorSize}, @code{fillInternalSize},
@code{emptyMutatorSize}, @code{emptyInternalSize}, and
@code{allocMutatorSize} (5 fields).
@end itemize

@anchor{design/buffer design mps buffer count alloc how}@anchor{dfb}@ref{dfb,,.count.alloc.how;} The amount of allocation in the buffer just
after an empty is @code{fillSize - emptySize}. At other times this
computation will include space that the buffer has the use of (between
base and init) but which may not get allocated in (because the
remaining space may be too large for the next reserve so some or all
of it may get emptied). The arena field @code{allocMutatorSize} is
incremented by the allocated size (between base and init)
whenever a buffer is detached. Symmetrically this field is decremented
by by the pre-allocated size (between base and init) whenever
a buffer is attached. The overall count is asymptotically correct.

@anchor{design/buffer design mps buffer count type}@anchor{dfc}@ref{dfc,,.count.type;} All the count fields are type double.

@anchor{design/buffer design mps buffer count type justify}@anchor{dfd}@ref{dfd,,.count.type.justify;} This is because double is the type most likely
to give us enough precision. Because of the lack of genuine
requirements the type isn’t so important. It’s nice to have it more
precise than long. Which double usually is.

@node Notes from the whiteboard,Synchronization<2>,Measurement,Allocation buffers and allocation points
@anchor{design/buffer notes-from-the-whiteboard}@anchor{dfe}
@subsection Notes from the whiteboard


Requirements


@itemize -

@item 
atomic update of words

@item 
guarantee order of reads and write to certain memory locations.
@end itemize

Flip


@itemize -

@item 
limit:=0

@item 
record init for scanner
@end itemize

Commit


@itemize -

@item 
init:=alloc

@item 
if(limit = 0) …

@item 
L written only by MM

@item 
A written only by client (except during synchronized MM op)

@item 
I ditto

@item 
I read by MM during flip
@end itemize

States


@itemize -

@item 
busy

@item 
ready

@item 
trapped

@item 
reset
@end itemize

@cartouche
@quotation Note 
There are many more states. DRJ.
@end quotation
@end cartouche

Misc


@itemize -

@item 
During buffer ops all field values can change. Might trash perfectly
good (“valid”?) object if pool isn’t careful.
@end itemize

@node Synchronization<2>,Interface<22>,Notes from the whiteboard,Allocation buffers and allocation points
@anchor{design/buffer synchronization}@anchor{dff}
@subsection Synchronization


Buffers provide a loose form of synchronization between the mutator
and the collector.

The crucial synchronization issues are between the operation the pool
performs on flip and the mutator’s commit operation.

Commit


@itemize -

@item 
read init

@item 
write init

@item 
Memory Barrier

@item 
read @code{limit}
@end itemize

Flip


@itemize -

@item 
write @code{limit}

@item 
Memory Barrier

@item 
read init
@end itemize

Commit consists of two parts. The first is the update to init.
This is a declaration that the new object just before init is now
correctly formatted and can be scanned. The second is a check to see
if the buffer has been “tripped”. The ordering of the two parts is
crucial.

Note that the declaration that the object is correctly formatted is
independent of whether the buffer has been tripped or not. In
particular a pool can scan up to the init pointer (including the newly
declared object) whether or not the pool will cause the commit to
fail. In the case where the pool scans the object, but then causes the
commit to fail (and presumably the allocation to occur somewhere
else), the pool will have scanned a “dead” object, but this is just
another example of conservatism in the general sense.

Not that the read of init in the Flip sequence can in fact be
arbitrarily delayed (as long as it is read before a buffered segment
is scanned).

On processors with Relaxed Memory Order (such as the DEC Alpha),
Memory Barriers will need to be placed at the points indicated.

@example
* DESIGN
*
* An allocation buffer is an interface to a pool which provides
* very fast allocation, and defers the need for synchronization in
* a multi-threaded environment.
*
* Pools which contain formatted objects must be synchronized so
* that the pool can know when an object is valid.  Allocation from
* such pools is done in two stages: reserve and commit.  The client
* first reserves memory, then initializes it, then commits.
* Committing the memory declares that it contains a valid formatted
* object.  Under certain conditions, some pools may cause the
* commit operation to fail.  (See the documentation for the pool.)
* Failure to commit indicates that the whole allocation failed and
* must be restarted.  When using a pool which introduces the
* possibility of commit failing, the allocation sequence could look
* something like this:
*
* do @{
*   res = BufferReserve(&p, buffer, size);
*   if(res != ResOK) return res;       // allocation fails, reason res
*   initialize(p);                     // p now points at valid object
* @} while(!BufferCommit(buffer, p, size));
*
* Pools which do not contain formatted objects can use a one-step
* allocation as usual.  Effectively any random rubbish counts as a
* "valid object" to such pools.
*
* An allocation buffer is an area of memory which is pre-allocated
* from a pool, plus a buffer descriptor, which contains, inter
* alia, four pointers: base, init, alloc, and limit.  Base points
* to the base address of the area, limit to the last address plus
* one.  Init points to the first uninitialized address in the
* buffer, and alloc points to the first unallocated address.
*
*    L . - - - - - .         ^
*      |           |     Higher addresses -'
*      |   junk    |
*      |           |       the "busy" state, after Reserve
*    A |-----------|
*      |  uninit   |
*    I |-----------|
*      |   init    |
*      |           |     Lower addresses  -.
*    B `-----------'         v
*
*    L . - - - - - .         ^
*      |           |     Higher addresses -'
*      |   junk    |
*      |           |       the "ready" state, after Commit
*  A=I |-----------|
*      |           |
*      |           |
*      |   init    |
*      |           |     Lower addresses  -.
*    B `-----------'         v
*
* Access to these pointers is restricted in order to allow
* synchronization between the pool and the client.  The client may
* only write to init and alloc, but in a restricted and atomic way
* detailed below.  The pool may read the contents of the buffer
* descriptor at _any_ time.  During calls to the fill and trip
* methods, the pool may update any or all of the fields
* in the buffer descriptor.  The pool may update the limit at _any_
* time.
*
* Access to buffers by these methods is not synchronized.  If a buffer
* is to be used by more than one thread then it is the client's
* responsibility to ensure exclusive access.  It is recommended that
* a buffer be used by only a single thread.
*
* [Only one thread may use a buffer at once, unless the client
* places a mutual exclusion around the buffer access in the usual
* way.  In such cases it is usually better to create one buffer for
* each thread.]
*
* Here are pseudo-code descriptions of the reserve and commit
* operations.  These may be implemented in-line by the client.
* Note that the client is responsible for ensuring that the size
* (and therefore the alloc and init pointers) are aligned according
* to the buffer's alignment.
*
* Reserve(buf, size)                   ; size must be aligned to pool
*   if buf->limit - buf->alloc >= size then
*     buf->alloc +=size                ; must be atomic update
*     p = buf->init
*   else
*     res = BufferFill(&p, buf, size)  ; buf contents may change
*
* Commit(buf, p, size)
*   buf->init = buf->alloc             ; must be atomic update
*   if buf->limit == 0 then
*     res = BufferTrip(buf, p, size)   ; buf contents may change
*   else
*     res = True
* (returns True on successful commit)
*
* The pool must allocate the buffer descriptor and initialize it by
* calling BufferInit.  The descriptor this creates will fall
* through to the fill method on the first allocation.  In general,
* pools should not assign resources to the buffer until the first
* allocation, since the buffer may never be used.
*
* The pool may update the base, init, alloc, and limit fields when
* the fallback methods are called.  In addition, the pool may set
* the limit to zero at any time.  The effect of this is either:
*
*   1. cause the _next_ allocation in the buffer to fall through to
*      the buffer fill method, and allow the buffer to be flushed
*      and relocated;
*
*   2. cause the buffer trip method to be called if the client was
*      between reserve and commit.
*
* A buffer may not be relocated under other circumstances because
* there is a race between updating the descriptor and the client
* allocation sequence.
@end example

@node Interface<22>,Diagrams,Synchronization<2>,Allocation buffers and allocation points
@anchor{design/buffer interface}@anchor{e00}
@subsection Interface


@geindex BufferCreate (C function)
@anchor{design/buffer c BufferCreate}@anchor{ddc}
@deffn {C Function} @ref{55f,,Res} BufferCreate (Buffer *bufferReturn, BufferClass class, Pool pool, Bool isMutator, ArgList args)
@end deffn

@anchor{design/buffer design mps buffer method create}@anchor{de2}@ref{de2,,.method.create;} Create an allocation buffer in a pool. The buffer
is created in the “ready” state.

A buffer structure is allocated from the space control pool and
partially initialized (in particularly neither the signature nor the
serial field are initialized). The pool class’s @code{bufferCreate()}
method is then called. This method can update (some undefined subset
of) the fields of the structure; it should return with the buffer in
the “ready” state (or fail). The remainder of the initialization then
occurs.

If and only if successful then a valid buffer is returned.

@geindex BufferDestroy (C function)
@anchor{design/buffer c BufferDestroy}@anchor{e01}
@deffn {C Function} void BufferDestroy (Buffer buffer)
@end deffn

@anchor{design/buffer design mps buffer method destroy}@anchor{e02}@ref{e02,,.method.destroy;} Free a buffer descriptor. The buffer must be in
the “ready” state, that is, not between a Reserve and Commit.
Allocation in the area of memory to which the descriptor refers must
cease after @ref{e01,,BufferDestroy()} is called.

Destroying an allocation buffer does not affect objects which have
been allocated, it just frees resources associated with the buffer
itself.

The pool class’s @code{bufferDestroy()} method is called and then the
buffer structure is uninitialized and freed.

@geindex BufferCheck (C function)
@anchor{design/buffer c BufferCheck}@anchor{e03}
@deffn {C Function} @ref{3a9,,Bool} BufferCheck (Buffer buffer)
@end deffn

@anchor{design/buffer design mps buffer method check}@anchor{e04}@ref{e04,,.method.check;} The check method is straightforward, the non-trivial dependencies checked are:


@itemize -

@item 
The ordering constraints between base, init, alloc, and limit.

@item 
The alignment constraints on base, init, alloc, and limit.

@item 
That the buffer’s rank is identical to the segment’s rank.
@end itemize

@geindex BufferAttach (C function)
@anchor{design/buffer c BufferAttach}@anchor{de8}
@deffn {C Function} void BufferAttach (Buffer buffer, Addr base, Addr limit, Addr init, Size size)
@end deffn

@anchor{design/buffer design mps buffer method attach}@anchor{e05}@ref{e05,,.method.attach;} Set the base, init, alloc, and limit fields so that
the buffer is ready to start allocating in area of memory. The alloc
field is set to @code{init + size}.

@anchor{design/buffer design mps buffer method attach unbusy}@anchor{e06}@ref{e06,,.method.attach.unbusy;} @ref{de8,,BufferAttach()} must only be applied to
buffers that are not busy.

@geindex BufferDetach (C function)
@anchor{design/buffer c BufferDetach}@anchor{7a5}
@deffn {C Function} void BufferDetach (Buffer buffer, Pool pool)
@end deffn

@anchor{design/buffer design mps buffer method detach}@anchor{e07}@ref{e07,,.method.detach;} Set the seg, base, init, alloc, and limit fields to
zero, so that the next reserve request will call the fill method.

@anchor{design/buffer design mps buffer method detach unbusy}@anchor{e08}@ref{e08,,.method.detach.unbusy;} @ref{7a5,,BufferDetach()} must only be applied to
buffers that are not busy.

@geindex BufferIsReset (C function)
@anchor{design/buffer c BufferIsReset}@anchor{e09}
@deffn {C Function} @ref{3a9,,Bool} BufferIsReset (Buffer buffer)
@end deffn

@anchor{design/buffer design mps buffer method isreset}@anchor{e0a}@ref{e0a,,.method.isreset;} Returns @code{TRUE} if and only if the buffer is in the
reset state, that is, with base, init, alloc, and limit all set to
zero.

@geindex BufferIsReady (C function)
@anchor{design/buffer c BufferIsReady}@anchor{e0b}
@deffn {C Function} @ref{3a9,,Bool} BufferIsReady (Buffer buffer)
@end deffn

@anchor{design/buffer design mps buffer method isready}@anchor{e0c}@ref{e0c,,.method.isready;} Returns @code{TRUE} if and only if the buffer is not
between a reserve and commit. The result is only reliable if the
client is not currently using the buffer, since it may update the
alloc and init pointers asynchronously.

@geindex BufferAP (C function)
@anchor{design/buffer c BufferAP}@anchor{e0d}
@deffn {C Function} @ref{1c0,,mps_ap_t} BufferAP (Buffer buffer)
@end deffn

Returns the @code{APStruct} substructure of a buffer.

@geindex BufferOfAP (C function)
@anchor{design/buffer c BufferOfAP}@anchor{e0e}
@deffn {C Function} Buffer BufferOfAP (mps_ap_t ap)
@end deffn

@anchor{design/buffer design mps buffer method ofap}@anchor{e0f}@ref{e0f,,.method.ofap;} Return the buffer which owns an @code{APStruct}.

@anchor{design/buffer design mps buffer method ofap thread-safe}@anchor{e10}@ref{e10,,.method.ofap.thread-safe;} @ref{e0e,,BufferOfAP()} must be thread safe (see
impl.c.mpsi.thread-safety). This is achieved simply because the
underlying operation involved is simply a subtraction.

@geindex BufferArena (C function)
@anchor{design/buffer c BufferArena}@anchor{e11}
@deffn {C Function} @ref{796,,Arena} BufferArena (Buffer buffer)
@end deffn

@anchor{design/buffer design mps buffer method arena}@anchor{e12}@ref{e12,,.method.arena;} Returns the arena which owns a buffer.

@anchor{design/buffer design mps buffer method arena thread-safe}@anchor{e13}@ref{e13,,.method.arena.thread-safe;} @ref{e11,,BufferArena()} must be thread safe
(see impl.c.mpsi.thread-safety). This is achieved simple because the
underlying operation is a read of shared-non-mutable data (see
design.mps.thread-safety@footnote{thread-safety.html}).

@geindex BufferPool (C function)
@anchor{design/buffer c BufferPool}@anchor{e14}
@deffn {C Function} Pool BufferPool (Buffer buffer)
@end deffn

Returns the pool to which a buffer is attached.

@geindex BufferReserve (C function)
@anchor{design/buffer c BufferReserve}@anchor{e15}
@deffn {C Function} @ref{55f,,Res} BufferReserve (Addr *pReturn, Buffer buffer, Size size)
@end deffn

@anchor{design/buffer design mps buffer method reserve}@anchor{e16}@ref{e16,,.method.reserve;} Reserves memory from an allocation buffer.

This is a provided version of the reserve procedure described above.
The size must be aligned according to the buffer alignment. If
successful, @code{ResOK} is returned and @code{*pReturn} is updated with a
pointer to the reserved memory. Otherwise @code{*pReturn} is not touched.
The reserved memory is not guaranteed to have any particular contents.
The memory must be initialized with a valid object (according to the
pool to which the buffer belongs) and then passed to the
@ref{e17,,BufferCommit()} method (see below). @code{BufferReserve(0} may not be
applied twice to a buffer without a @ref{e17,,BufferCommit()} in-between. In
other words, Reserve/Commit pairs do not nest.

@geindex BufferFill (C function)
@anchor{design/buffer c BufferFill}@anchor{7a2}
@deffn {C Function} @ref{55f,,Res} BufferFill (Addr *pReturn, Buffer buffer, Size size)
@end deffn

@anchor{design/buffer design mps buffer method fill}@anchor{e18}@ref{e18,,.method.fill;} Refills an empty buffer. If there is not enough space
in a buffer to allocate in-line, @ref{7a2,,BufferFill()} must be called to
“refill” the buffer.

@geindex BufferCommit (C function)
@anchor{design/buffer c BufferCommit}@anchor{e17}
@deffn {C Function} @ref{3a9,,Bool} BufferCommit (Buffer buffer, Addr p, Size size)
@end deffn

@anchor{design/buffer design mps buffer method commit}@anchor{e19}@ref{e19,,.method.commit;} Commit memory previously reserved.

@ref{e17,,BufferCommit()} notifies the pool that memory which has been
previously reserved (see above) has been initialized with a valid
object (according to the pool to which the buffer belongs). The
pointer @code{p} must be the same as that returned by
@ref{e15,,BufferReserve()}, and the size must match the size passed to
@ref{e15,,BufferReserve()}.

@ref{e17,,BufferCommit()} may not be applied twice to a buffer without a
reserve in between. In other words, objects must be reserved,
initialized, then committed only once.

Commit returns @code{TRUE} if successful, @code{FALSE} otherwise. If commit
fails and returns @code{FALSE}, the client may try to allocate again by
going back to the reserve stage, and may not use the memory at @code{p}
again for any purpose.

Some classes of pool may cause commit to fail under rare
circumstances.

@geindex BufferTrip (C function)
@anchor{design/buffer c BufferTrip}@anchor{e1a}
@deffn {C Function} void BufferTrip (Buffer buffer, Addr p, Size size)
@end deffn

@anchor{design/buffer design mps buffer method trip}@anchor{e1b}@ref{e1b,,.method.trip;} Act on a tripped buffer. The pool which owns a buffer
may asynchronously set the buffer limit to zero in order to get
control over the buffer. If this occurs after a @ref{e15,,BufferReserve()}
(but before the corresponding commit), then the @ref{e17,,BufferCommit()}
method calls @ref{e1a,,BufferTrip()} and the @ref{e17,,BufferCommit()} method
returns with the return value of @ref{e1a,,BufferTrip()}.

@anchor{design/buffer design mps buffer method trip precondition}@anchor{e1c}@ref{e1c,,.method.trip.precondition;} At the time trip is called, from
@ref{e17,,BufferCommit()}, the following are true:


@itemize -

@item 
@anchor{design/buffer design mps buffer method trip precondition limit}@anchor{e1d}@ref{e1d,,.method.trip.precondition.limit;} @code{limit == 0}

@item 
@anchor{design/buffer design mps buffer method trip precondition init}@anchor{e1e}@ref{e1e,,.method.trip.precondition.init;} @code{init == alloc}

@item 
@anchor{design/buffer design mps buffer method trip precondition p}@anchor{e1f}@ref{e1f,,.method.trip.precondition.p;} @code{p + size == alloc}
@end itemize

@node Diagrams,,Interface<22>,Allocation buffers and allocation points
@anchor{design/buffer diagrams}@anchor{e20}
@subsection Diagrams


Here are a number of diagrams showing how buffers behave. In general,
the horizontal axis corresponds to mutator action (reserve, commit)
and the vertical axis corresponds to collector action. I’m not sure
which of the diagrams are the same as each other, and which are best
or most complete when they are different, but they all attempt to show
essentially the same information. It’s very difficult to get all the
details in. These diagrams were drawn by Richard Brooksby, Richard
Tucker, Gavin Matthews, and others in April 1997. In general, the
later diagrams are, I suspect, more correct, complete and useful than
the earlier ones. I have put them all here for the record. Richard
Tucker, 1998-02-09.

Buffer Diagram:
Buffer States

Buffer States (3-column)
Buffer States (4-column)
Buffer States (gavinised)
Buffer States (interleaved)
Buffer States (richardized)

[missing diagrams]

@geindex checking; design

@node Checking<4>,Collection framework,Allocation buffers and allocation points,Old design
@anchor{design/check doc}@anchor{e21}@anchor{design/check checking}@anchor{e22}@anchor{design/check design-check}@anchor{e23}
@section Checking


@menu
* Introduction: Introduction<52>. 
* Implementation: Implementation<17>. 
* Common assertions:: 

@end menu

@node Introduction<52>,Implementation<17>,,Checking<4>
@anchor{design/check design mps check}@anchor{e24}@anchor{design/check introduction}@anchor{e25}
@subsection Introduction


@anchor{design/check design mps check intro}@anchor{e26}@ref{e26,,.intro;} This documents the design of structure checking within the
MPS.

@anchor{design/check design mps check readership}@anchor{e27}@ref{e27,,.readership;} MPS developers.

@node Implementation<17>,Common assertions,Introduction<52>,Checking<4>
@anchor{design/check implementation}@anchor{e28}
@subsection Implementation


@anchor{design/check design mps check level}@anchor{e29}@ref{e29,,.level;} There are three levels of checking:


@enumerate 

@item 
@anchor{design/check design mps check level sig}@anchor{e2a}@ref{e2a,,.level.sig;} The lowest level checks only that the structure has
a valid @code{Signature} (see design.mps.sig@footnote{sig.html}).

@item 
@anchor{design/check design mps check level shallow}@anchor{e2b}@ref{e2b,,.level.shallow;} Shallow checking checks all local fields
(including signature) and also checks the signatures of any parent
or child structures.

@item 
@anchor{design/check design mps check level deep}@anchor{e2c}@ref{e2c,,.level.deep;} Deep checking checks all local fields
(including signatures), the signatures of any parent structures,
and does full recursive checking on any child structures.
@end enumerate

@anchor{design/check design mps check level control}@anchor{e2d}@ref{e2d,,.level.control;} Control over the levels of checking is via the
definition of at most one of the macros @code{TARGET_CHECK_SHALLOW}
(which if defined gives @ref{e2b,,.level.shallow}), @code{TARGET_CHECK_DEEP}
(which if defined gives @ref{e2c,,.level.deep}). If neither macro is defined
then @ref{e2a,,.level.sig} is used. These macros are not intended to be
manipulated directly by developers, they should use the interface in
impl.h.target.

@anchor{design/check design mps check order}@anchor{e2e}@ref{e2e,,.order;} Because deep checking (@ref{e2c,,.level.deep}) uses unchecked
recursion, it is important that child relationships are acyclic
(@ref{e2f,,.macro.down}).

@anchor{design/check design mps check fun}@anchor{e30}@ref{e30,,.fun;} Every abstract data type which is a structure pointer should
have a function @code{<type>Check} which takes a pointer of type
@code{<type>} and returns a @ref{3a9,,Bool}. It should check all fields in
order, using one of the macros in @ref{e31,,.macro}, or document why not.

@anchor{design/check design mps check fun omit}@anchor{e32}@ref{e32,,.fun.omit;} The only fields which should be omitted from a check
function are those for which there is no meaningful check (for
example, an unlimited unsigned integer with no relation to other
fields).

@anchor{design/check design mps check fun return}@anchor{e33}@ref{e33,,.fun.return;} Although the function returns a @ref{3a9,,Bool}, if the assert
handler returns (or there is no assert handler), then this is taken to
mean “ignore and continue”, and the check function hence returns
@code{TRUE}.

@anchor{design/check design mps check macro}@anchor{e31}@ref{e31,,.macro;} Checking is implemented by invoking four macros in
impl.h.assert:

@geindex CHECKS (C macro)
@anchor{design/check c CHECKS}@anchor{8ee}
@deffn {C Macro} CHECKS (type, val)
@end deffn

@anchor{design/check design mps check macro sig}@anchor{e34}@ref{e34,,.macro.sig;} @code{CHECKS(type, val)} checks the signature only, and
should be called precisely on @code{type} and the received object
pointer.

@geindex CHECKL (C macro)
@anchor{design/check c CHECKL}@anchor{e35}
@deffn {C Macro} CHECKL (cond)
@end deffn

@anchor{design/check design mps check macro local}@anchor{e36}@ref{e36,,.macro.local;} @code{CHECKL(cond)} checks a local field (depending on
level; see @ref{e29,,.level}), and should be called on each local field that
is not an abstract data type structure pointer itself (apart from
the signature), with an appropriate normally-true test condition.

@geindex CHECKU (C macro)
@anchor{design/check c CHECKU}@anchor{e37}
@deffn {C Macro} CHECKU (type, val)
@end deffn

@anchor{design/check design mps check macro up}@anchor{e38}@ref{e38,,.macro.up;} @code{CHECKU(type, val)} checks a parent abstract data
type structure pointer, performing at most signature checks
(depending on level; see @ref{e29,,.level}). It should be called with the
parent type and pointer.

@geindex CHECKD (C macro)
@anchor{design/check c CHECKD}@anchor{e39}
@deffn {C Macro} CHECKD (type, val)
@end deffn

@anchor{design/check design mps check macro down}@anchor{e2f}@ref{e2f,,.macro.down;} @code{CHECKD(type, val)} checks a child abstract data
type structure pointer, possibly invoking @code{<type>Check} (depending
on level; see @ref{e29,,.level}). It should be called with the child type
and pointer.

@anchor{design/check design mps check full-type}@anchor{e3a}@ref{e3a,,.full-type;} Use @ref{8ee,,CHECKS()}, @ref{e39,,CHECKD()} or @ref{e37,,CHECKU()} on all
types that satisfy these three requirements:

@anchor{design/check design mps check full-type pointer}@anchor{e3b}@ref{e3b,,.full-type.pointer;} The type is a pointer type.

@anchor{design/check design mps check full-type check}@anchor{e3c}@ref{e3c,,.full-type.check;} The type provides a function @code{Bool TypeCheck(Type
type)} where @code{Type} is substituted for the name of the type (for
example, @code{PoolCheck()}).

@anchor{design/check design mps check full-type sig}@anchor{e3d}@ref{e3d,,.full-type.sig;} The expression @code{obj->sig} is a valid value of
type @ref{8dc,,Sig} whenever @code{obj} is a valid value of type @code{Type}.

@anchor{design/check design mps check partial-type}@anchor{e3e}@ref{e3e,,.partial-type;} Where the type satisfies @ref{e3b,,.full-type.pointer} and
@ref{e3c,,.full-type.check} but not @ref{e3d,,.full-type.sig} because the type lacks a
signature in order to save space (this applies to small structures
that are embedded many times in other structures, for example
@ref{85c,,Ring}), use @code{CHECKD_NOSIG()}.

@anchor{design/check design mps check hidden-type}@anchor{e3f}@ref{e3f,,.hidden-type;} Where the type satisfies @ref{e3b,,.full-type.pointer} and
@ref{e3c,,.full-type.check} but not @ref{e3d,,.full-type.sig} because the structure
has a signature but the structure definition is not visible at point
of checking (for example @code{Root}), use @code{CHECKD_NOSIG()} and
reference this tag. The structure could be considered for addition to
@code{mpmst.h}.

@node Common assertions,,Implementation<17>,Checking<4>
@anchor{design/check common-assertions}@anchor{e40}
@subsection Common assertions


@anchor{design/check design mps check common}@anchor{e41}@ref{e41,,.common;} Some assertions are commonly triggered by mistakes in the
client program. These are listed in the section “Common assertions and
their causes” in the MPS Reference, together with an explanation of
their likely cause, and advice for fixing the problem. To assist with
keeping the MPS Reference up to date, these assertions are marked with
a cross-reference to this tag. When you update the assertion, you must
also update the MPS Reference.

@geindex collection framework; design

@node Collection framework,Diagnostic feedback,Checking<4>,Old design
@anchor{design/collection doc}@anchor{e42}@anchor{design/collection collection-framework}@anchor{e43}@anchor{design/collection design-collection}@anchor{e44}
@section Collection framework


@menu
* Introduction: Introduction<53>. 
* Overview: Overview<16>. 
* Collection abstractions:: 
* The tracer:: 
* Barriers:: 

@end menu

@node Introduction<53>,Overview<16>,,Collection framework
@anchor{design/collection design mps collection}@anchor{e45}@anchor{design/collection introduction}@anchor{e46}
@subsection Introduction


@anchor{design/collection design mps collection intro}@anchor{e47}@ref{e47,,.intro;} This document describes the Collection Framework. It’s a
framework for implementing garbage collection techniques and
integrating them into a system of collectors that all cooperate in
recycling garbage.

@node Overview<16>,Collection abstractions,Introduction<53>,Collection framework
@anchor{design/collection overview}@anchor{e48}
@subsection Overview


@anchor{design/collection design mps collection framework}@anchor{e49}@ref{e49,,.framework;} MPS provides a framework that allows the integration of
many different types of GC strategies and provides many of the basic
services that those strategies use.

@anchor{design/collection design mps collection framework cover}@anchor{e4a}@ref{e4a,,.framework.cover;} The framework subsumes most major GC strategies
and allows many efficient techniques, like in-line allocation or
software barriers.

@anchor{design/collection design mps collection framework overhead}@anchor{e4b}@ref{e4b,,.framework.overhead;} The overhead due to cooperation is low.

@cartouche
@quotation Note 
But not non-existent. Can we say something useful about it?
@end quotation
@end cartouche

@anchor{design/collection design mps collection framework benefits}@anchor{e4c}@ref{e4c,,.framework.benefits;} The ability to combine collectors contributes
significantly to the flexibility of the system. The reduction in code
duplication contributes to reliability and integrity. The services of
the framework make it easier to write new MM strategies and
collectors.

@anchor{design/collection design mps collection framework mpm}@anchor{e4d}@ref{e4d,,.framework.mpm;} The Collection Framework is merely a part of the
structure of the MPM. See design.mps.architecture and design.mps.arch
for the big picture.

@cartouche
@quotation Note 
Those two documents should be combined into one. Pekka P. Pirinen,
1998-01-15.
@end quotation
@end cartouche

Other notable components that the MPM manages to integrate into a
single framework are manually-managed memory and finalization services
(see design.mps.finalize@footnote{finalize.html}).

@cartouche
@quotation Note 
A document describing the design of manually-managed memory is
missing. Pekka P. Pirinen, 1998-01-15.
@end quotation
@end cartouche

@anchor{design/collection design mps collection see-also}@anchor{e4e}@ref{e4e,,.see-also;} This document assumes basic familiarity with the ideas
of pool (see design.mps.arch.pools) and segment (see
design.mps.seg.over).

@node Collection abstractions,The tracer,Overview<16>,Collection framework
@anchor{design/collection collection-abstractions}@anchor{e4f}
@subsection Collection abstractions


@menu
* Colours@comma{} scanning and fixing: Colours scanning and fixing. 
* Reference sets:: 

@end menu

@node Colours scanning and fixing,Reference sets,,Collection abstractions
@anchor{design/collection colours-scanning-and-fixing}@anchor{e50}
@subsubsection Colours, scanning and fixing


@anchor{design/collection design mps collection state}@anchor{e51}@ref{e51,,.state;} The framework knows about the three colours of the
tri-state abstraction and free blocks. Recording the state of each
object is the responsibility of the pool, but the framework gets told
about changes in the states and keeps track of colours in each
segment. Specifically, it records whether a segment might contain
white, grey and black objects with respect to each active trace (see
@ref{e52,,.tracer})

@cartouche
@quotation Note 
Black not currently implemented. Pekka P. Pirinen, 1998-01-04.
@end quotation
@end cartouche

(A segment might contain objects of all colours at once, or none.)
This information is approximate, because when an object changes
colour, or dies, it usually is too expensive to determine if it was
the last object of its former colour.

@anchor{design/collection design mps collection state transitions}@anchor{e53}@ref{e53,,.state.transitions;} The possible state transitions are as follows:

@example
free   ---alloc--> black (or grey) or white or none
none   --condemn-> white
none   --refine--> grey
grey   ---scan---> black
white  ----fix---> grey (or black)
black  --revert--> grey
white  --reclaim-> free
black  --reclaim-> none
@end example

@anchor{design/collection design mps collection none-is-black}@anchor{e54}@ref{e54,,.none-is-black;} Outside of a trace, objects don’t really have
colour, but technically, the colour is black. Objects are only
allocated grey or white during a trace, and by the time the trace has
finished, they are either dead or black, like the other surviving
objects. We might then reuse the colour field for another trace, so
it’s convenient to set the colour to black when allocating outside a
trace. This means that refining the foundation
(analysis.tracer.phase.condemn.refine), actually turns black segments
grey, rather than vice versa, but the principle is the same.

@anchor{design/collection design mps collection scan-fix}@anchor{e55}@ref{e55,,.scan-fix;} “Scanning” an object means applying the “fix” function
to all references in that object. Fixing is the generic name for the
operation that takes a reference to a white object and makes it
non-white (usually grey, but black is a possibility, and so is
changing the reference as we do for weak references). Typical examples
of fix methods are copying the object into to-space or setting its
mark bit.

@anchor{design/collection design mps collection cooperation}@anchor{e56}@ref{e56,,.cooperation;} The separation of scanning and fixing is what allows
different GC techniques to cooperate. The scanning is done by a method
on the pool that the scanned object resides in, and the fixing is done
by a method on the pool that the reference points to.

@anchor{design/collection design mps collection scan-all}@anchor{e57}@ref{e57,,.scan-all;} Pools provide a method to scan all the grey objects in a
segment.

@node Reference sets,,Colours scanning and fixing,Collection abstractions
@anchor{design/collection reference-sets}@anchor{e58}
@subsubsection Reference sets


@anchor{design/collection design mps collection refsets}@anchor{e59}@ref{e59,,.refsets;} The cost of scanning can be significantly reduced by
storing remembered sets. We have chosen a very compact and efficient
implementation, called reference sets, or refsets for short (see
idea.remember).

@cartouche
@quotation Note 
design.mps.refset is empty! Perhaps some of this should go there.
Pekka P. Pirinen, 1998-02-19.
@end quotation
@end cartouche

This makes the cost of maintaining them low, so we maintain them for
all references out of all scannable segments.

@anchor{design/collection design mps collection refsets approx}@anchor{e5a}@ref{e5a,,.refsets.approx;} You might describe refsets as summaries of all
references out of an area of memory, so they are only approximations
of remembered sets. When a refset indicates that an interesting
reference might be present in a segment, we still have to scan the
segment to find it.

@anchor{design/collection design mps collection refsets scan}@anchor{e5b}@ref{e5b,,.refsets.scan;} The refset information is collected during scanning.
The scan state protocol provides a way for the pool and the format
scan methods to cooperate in this, and to pass this information to the
tracer module which checks it and updates the segment (see
design.mps.scan@footnote{scan.html}).

@cartouche
@quotation Note 
Actually, there’s very little doc there. Pekka P. Pirinen,
1998-02-17.
@end quotation
@end cartouche

@anchor{design/collection design mps collection refsets maintain}@anchor{e5c}@ref{e5c,,.refsets.maintain;} The MPS tries to maintain the refset information
when it moves or changes object.

@anchor{design/collection design mps collection refsets pollution}@anchor{e5d}@ref{e5d,,.refsets.pollution;} Ambiguous references and pointers outside the
arena will introduce spurious zones into the refsets. We put up with
this to keep the scanning costs down. Consistency checks on refsets
have to take this into account.

@anchor{design/collection design mps collection refsets write-barrier}@anchor{e5e}@ref{e5e,,.refsets.write-barrier;} A write-barrier are needed to keep the
mutator from invalidating the refsets when writing to a segment. We
need one on any scannable segment whose refset is not a superset of
the mutator’s (and that the mutator can see). If we know what the
mutator is writing and whether it’s a reference, we can just add that
reference to the refset (figuring out whether anything can be removed
from the refset is too expensive). If we don’t know or if we cannot
afford to keep the barrier up, the framework can union the mutator’s
refset to the segment’s refset.

@anchor{design/collection design mps collection refset mutator}@anchor{e5f}@ref{e5f,,.refset.mutator;} The mutator’s refset could be computed during root
scanning in the usual way, and then kept up to date by using a
read-barrier. It’s not a problem that the mutator can create new
pointers out of nothing behind the read-barrier, as they won’t be real
references. However, this is probably not cost-effective, since it
would cause lots of barrier hits. We’d need a read-barrier on every
scannable segment whose refset is not a subset of the mutator’s (and
that the mutator can see). So instead we approximate the mutator’s
refset with the universal refset.

@node The tracer,Barriers,Collection abstractions,Collection framework
@anchor{design/collection the-tracer}@anchor{e60}
@subsection The tracer


@anchor{design/collection design mps collection tracer}@anchor{e52}@ref{e52,,.tracer;} The tracer is an engine for implementing multiple garbage
collection processes. Each process (called a “trace”) proceeds
independently of the others through five phases as described in
analysis.tracer. The following sections describe how the action of
each phase fits into the framework. See design.mps.trace@footnote{trace.html} for details

@cartouche
@quotation Note 
No, there’s not much there, either. Possibly some of this section
should go there. Pekka P. Pirinen, 1998-02-18.
@end quotation
@end cartouche

@anchor{design/collection design mps collection combine}@anchor{e61}@ref{e61,,.combine;} The tracer can also combine several traces for some
actions, like scanning a segment or a root. The methods the tracer
calls to do the work get an argument that tells them which traces they
are expected to act for.

@cartouche
@quotation Note 
Extend this.
@end quotation
@end cartouche

@anchor{design/collection design mps collection trace begin}@anchor{e62}@ref{e62,,.trace.begin;} Traces are started by external request, usually from
a client function or an action (see design.mps.action).

@anchor{design/collection design mps collection trace progress}@anchor{e63}@ref{e63,,.trace.progress;} The tracer gets time slices from the arena to work
on a given trace.

@cartouche
@quotation Note 
This is just a provisional arrangement, in lieu of real progress
control. Pekka P. Pirinen, 1998-02-18.
@end quotation
@end cartouche

In each slice, it selects a small amount of work to do, based on the
state of the trace, and does it, using facilities provided by the
pools.

@anchor{design/collection design mps collection trace scan}@anchor{e64}@ref{e64,,.trace.scan;} A typical unit of work is to scan a single segment.
The tracer can choose to do this for multiple traces at once, provided
the segment is grey for more than one trace.

@anchor{design/collection design mps collection trace barrier}@anchor{e65}@ref{e65,,.trace.barrier;} Barrier hits might also cause a need to scan :mps:a
segment (see @ref{e66,,.hw-barriers.hit}). Again, the tracer can
:mps:choose to combine traces, when it does this.

@anchor{design/collection design mps collection mutator-colour}@anchor{e67}@ref{e67,,.mutator-colour;} The framework keeps track of the colour of the
mutator separately for each trace.

@menu
* The condemn phase:: 
* The grey mutator phase:: 
* The flip phase:: 
* The black mutator phase:: 
* The reclaim phase:: 

@end menu

@node The condemn phase,The grey mutator phase,,The tracer
@anchor{design/collection the-condemn-phase}@anchor{e68}
@subsubsection The condemn phase


@anchor{design/collection design mps collection phase condemn}@anchor{e69}@ref{e69,,.phase.condemn;} The agent that creates the trace (see
@ref{e62,,.trace.begin}) determines the condemned set and colours it white.
The tracer then examines the refsets on all scannable segments, and if
it can deduce some segment cannot refer to the white set, it’s
immediately coloured black, otherwise the pool is asked to grey any
objects in the segment that might need to be scanned (in copying
pools, this is typically the whole segment).

@anchor{design/collection design mps collection phase condemn zones}@anchor{e6a}@ref{e6a,,.phase.condemn.zones;} To get the maximum benefit from the refsets,
we try to arrange that the zones are a minimal superset (for example,
generations uniquely occupy zones) and a maximal subset (there’s
nothing else in the zone) of the condemned set. This needs to be
arranged at allocation time (or when copying during collection, which
is much like allocation)

@cartouche
@quotation Note 
Soon, this will be handled by segment loci, see design.mps.locus@footnote{locus.html}.
@end quotation
@end cartouche

@anchor{design/collection design mps collection phase condemn mutator}@anchor{e6b}@ref{e6b,,.phase.condemn.mutator;} At this point, the mutator might reference
any objects, that is, it is grey. Allocation can be in any colour,
most commonly white.

@cartouche
@quotation Note 
More could be said about this.
@end quotation
@end cartouche

@node The grey mutator phase,The flip phase,The condemn phase,The tracer
@anchor{design/collection the-grey-mutator-phase}@anchor{e6c}
@subsubsection The grey mutator phase


@anchor{design/collection design mps collection phase grey-mutator}@anchor{e6d}@ref{e6d,,.phase.grey-mutator;} Grey segments are chosen according to some
sort of progress control and scanned by the pool to make them black.
Eventually, the tracer will decide to flip or it runs out of grey
segments, and proceeds to the next phase.

@cartouche
@quotation Note 
Currently, this phase has not been implemented; all traces flip
immediately after condemn. Pekka P. Pirinen, 1998-02-18.
@end quotation
@end cartouche

@anchor{design/collection design mps collection phase grey-mutator copy}@anchor{e6e}@ref{e6e,,.phase.grey-mutator.copy;} At this stage, we don’t want to copy
condemned objects, because we would need an additional barrier to keep
the mutator’s view of the heap consistent (see
analysis.async-gc.copied.pointers-and-new-copy).

@anchor{design/collection design mps collection phase grey-mutator ambig}@anchor{e6f}@ref{e6f,,.phase.grey-mutator.ambig;} This is a good time to get all ambiguous
scanning out of the way, because we usually can’t do any after the
flip and because it doesn’t cause any copying.

@cartouche
@quotation Note 
Write a detailed explanation of this some day.
@end quotation
@end cartouche

@node The flip phase,The black mutator phase,The grey mutator phase,The tracer
@anchor{design/collection the-flip-phase}@anchor{e70}
@subsubsection The flip phase


@anchor{design/collection design mps collection phase flip}@anchor{e71}@ref{e71,,.phase.flip;} The roots (see design.mps.root@footnote{root.html}) are scanned. This has
to be an atomic action as far as the mutator is concerned, so all
threads are suspended for the duration.

@anchor{design/collection design mps collection phase flip mutator}@anchor{e72}@ref{e72,,.phase.flip.mutator;} After this, the mutator is black: if we use a
strong barrier (analysis.async-gc.strong), this means it cannot refer
to white objects. Allocation will be in black (could be grey as well,
but there’s no point to it).

@node The black mutator phase,The reclaim phase,The flip phase,The tracer
@anchor{design/collection the-black-mutator-phase}@anchor{e73}
@subsubsection The black mutator phase


@anchor{design/collection design mps collection phase black-mutator}@anchor{e74}@ref{e74,,.phase.black-mutator;} Grey segments are chosen according to some
sort of progress control and scanned by the pool to make them black.
Eventually, the tracer runs out of segments that are grey for this
trace, and proceeds to the next phase.

@anchor{design/collection design mps collection phase black-mutator copy}@anchor{e75}@ref{e75,,.phase.black-mutator.copy;} At this stage white objects can be
relocated, because the mutator cannot see them (as long as a strong
barrier is used, as we must do for a copying collection, see
analysis.async-gc.copied.pointers).

@node The reclaim phase,,The black mutator phase,The tracer
@anchor{design/collection the-reclaim-phase}@anchor{e76}
@subsubsection The reclaim phase


@anchor{design/collection design mps collection phase reclaim}@anchor{e77}@ref{e77,,.phase.reclaim;} The tracer finds the remaining white segments and
asks the pool to reclaim any white objects in them.

@anchor{design/collection design mps collection phase reclaim barrier}@anchor{e78}@ref{e78,,.phase.reclaim.barrier;} Once a trace has started reclaiming
objects, the others shouldn’t try to scan any objects that are white
for it, because they might have dangling pointers in them.

@cartouche
@quotation Note 
Needs cross-reference to document that is yet to be written.

Currently, we reclaim atomically, but it could be incremental, or
even overlapped with a new trace on the same condemned set.
Pekka P. Pirinen, 1997-12-31.
@end quotation
@end cartouche

@node Barriers,,The tracer,Collection framework
@anchor{design/collection barriers}@anchor{e79}
@subsection Barriers


@cartouche
@quotation Note 
An introduction and a discussion of general principles should go
here. This is a completely undesigned area.
@end quotation
@end cartouche

@menu
* Hardware barriers:: 
* Software barriers:: 

@end menu

@node Hardware barriers,Software barriers,,Barriers
@anchor{design/collection hardware-barriers}@anchor{e7a}
@subsubsection Hardware barriers


@anchor{design/collection design mps collection hw-barriers}@anchor{e7b}@ref{e7b,,.hw-barriers;} Hardware barrier services cannot, by their very
nature, be independently provided to each trace. A segment is either
protected or not, and we have to set the protection on a segment if
any trace needs a hardware barrier on it.

@anchor{design/collection design mps collection hw-barriers supported}@anchor{e7c}@ref{e7c,,.hw-barriers.supported;} The framework currently supports
segment-oriented Appel-Ellis-Li barriers
(analysis.async-gc.barrier.appel-ellis-li), and write-barriers for
keeping the refsets up-to-date. It would not be hard to add Steele
barriers (analysis.async-gc.barrier.steele.scalable).

@anchor{design/collection design mps collection hw-barriers hit}@anchor{e66}@ref{e66,,.hw-barriers.hit;} When a barrier hit happens, the arena determines
which segment it was on. The segment colour info is used to determine
whether it had trace barriers on it, and if so, the appropriate
barrier action is performed, using the methods of the owning pool. If
the segment was write-protected, its refset is unioned with the refset
of the mutator.

@cartouche
@quotation Note 
In practice this is @code{RefSetUNIV}.
@end quotation
@end cartouche

@anchor{design/collection design mps collection hw-barriers hit multiple}@anchor{e7d}@ref{e7d,,.hw-barriers.hit.multiple;} Fortunately, if we get a barrier hit on
a segment with multiple trace barriers on it, we can scan it for all
the traces that it had a barrier for.

@cartouche
@quotation Note 
Needs link to unwritten section under @ref{e61,,.combine}.
@end quotation
@end cartouche

@node Software barriers,,Hardware barriers,Barriers
@anchor{design/collection software-barriers}@anchor{e7e}
@subsubsection Software barriers


@cartouche
@quotation Note 
Write something about software barriers.
@end quotation
@end cartouche

@geindex diagnostic feedback; design

@node Diagnostic feedback,The generic fix function,Collection framework,Old design
@anchor{design/diag doc}@anchor{e7f}@anchor{design/diag design-diag}@anchor{e80}@anchor{design/diag diagnostic-feedback}@anchor{e81}
@section Diagnostic feedback


@menu
* Introduction: Introduction<54>. 
* Overview: Overview<17>. 
* Requirements: Requirements<33>. 
* Usage: Usage<2>. 
* How to write a diagnostic:: 
* How the MPS diagnostic system works:: 
* References: References<22>. 

@end menu

@node Introduction<54>,Overview<17>,,Diagnostic feedback
@anchor{design/diag design mps diag}@anchor{e82}@anchor{design/diag introduction}@anchor{e83}
@subsection Introduction


@anchor{design/diag design mps diag intro}@anchor{e84}@ref{e84,,.intro;} This document describes how to use the diagnostic feedback
mechanism in the Memory Pool System.

@anchor{design/diag design mps diag sources}@anchor{e85}@ref{e85,,.sources;} Initially abased on @ref{e86,,[RHSK_2007-04-13]} and @ref{e87,,[RHSK_2007-04-18]}.

@node Overview<17>,Requirements<33>,Introduction<54>,Diagnostic feedback
@anchor{design/diag overview}@anchor{e88}
@subsection Overview


Diagnostic feedback is information created by the MPS diagnostic
system for the purpose of helping MPS programmers and client
programmers.

Such a piece of information is called “a diagnostic”. (See also
@ref{e89,,.parts}.)

A diagnostic is not intended to be visible to end users, or readable
by them.

A diagnostic is not intended to be stable from one release to the
next: it may be modified or removed at any time.

@node Requirements<33>,Usage<2>,Overview<17>,Diagnostic feedback
@anchor{design/diag requirements}@anchor{e8a}
@subsection Requirements


MPS diagnostic feedback code must do these things:


@itemize -

@item 
calculate, store, and propagate data;

@item 
collate, synthesise, and format it into a human-useful diagnostic;

@item 
control (for example, filter) output of diagnostics;

@item 
use a channel to get the diagnostic out.
@end itemize

@node Usage<2>,How to write a diagnostic,Requirements<33>,Diagnostic feedback
@anchor{design/diag usage}@anchor{e8b}
@subsection Usage


To get diagnostic output from the MPS, you must use a variety with
diagnostics compiled-in. Currently, that means variety.cool. See
@code{config.h}.

There are two mechanism for getting diagnostic output:


@enumerate 

@item 
Automatically via the telemetry system. See design.mps.telemetry@footnote{telemetry.html},
and the “Telemetry” chapter in the manual.

@item 
Manually via the debugger. In the debugger, set break points at the
places where you want to inspect data structures (or wait for the
debugger to be entered via an @code{abort()} call or unhandled
segmentation fault). Then at the debugger command prompt, run
@code{Describe()} commands of your choice. For example:

@example
(gdb) run
Starting program: mv2test
Reading symbols for shared libraries +............................. done
cbs.c:94: MPS ASSERTION FAILED: !cbs->inCBS

Program received signal SIGABRT, Aborted.
0x00007fff83e42d46 in __kill ()
(gdb) frame 12
#12 0x000000010000b1fc in MVTFree (pool=0x103ffe160, base=0x101dfd000, size=5024) at poolmv2.c:711
711         Res res = CBSInsert(MVTCBS(mvt), base, limit);
(gdb) p MVTDescribe(mvt, mps_lib_get_stdout(), 0)
MVT 0000000103FFE160 @{
  minSize: 8
  meanSize: 42
  maxSize: 8192
  fragLimit: 30
  reuseSize: 16384
  fillSize: 8192
  availLimit: 90931
  abqOverflow: FALSE
  splinter: TRUE
  splinterBase: 0000000106192FF0
  splinterLimit: 0000000106193000
  size: 303104
  allocated: 262928
  available: 40176
  unavailable: 0
  # ... etc ...
@}
@end example
@end enumerate

@node How to write a diagnostic,How the MPS diagnostic system works,Usage<2>,Diagnostic feedback
@anchor{design/diag how-to-write-a-diagnostic}@anchor{e8c}
@subsection How to write a diagnostic


@menu
* Compile away in non-diag varieties; no side effects:: 
* Writing good paragraph text:: 

@end menu

@node Compile away in non-diag varieties; no side effects,Writing good paragraph text,,How to write a diagnostic
@anchor{design/diag compile-away-in-non-diag-varieties-no-side-effects}@anchor{e8d}
@subsubsection Compile away in non-diag varieties; no side effects


Wrap code with the @ref{e8e,,STATISTIC} and @code{METER} macros, to make sure
that non-diagnostic varieties do not execute diagnostic-generating
code.

Diagnostic-generating code must have no side effects.

@node Writing good paragraph text,,Compile away in non-diag varieties; no side effects,How to write a diagnostic
@anchor{design/diag writing-good-paragraph-text}@anchor{e8f}
@subsubsection Writing good paragraph text


Make your diagnostics easy to understand! Other people will read your
diagnostics! Make them clear and helpful. Do not make them terse and
cryptic. If you use symbols, print a key in the diagnostic.

@node How the MPS diagnostic system works,References<22>,How to write a diagnostic,Diagnostic feedback
@anchor{design/diag how-the-mps-diagnostic-system-works}@anchor{e90}
@subsection How the MPS diagnostic system works


@menu
* Parts of the MPS diagnostic system:: 
* Statistics:: 
* Related systems:: 

@end menu

@node Parts of the MPS diagnostic system,Statistics,,How the MPS diagnostic system works
@anchor{design/diag parts-of-the-mps-diagnostic-system}@anchor{e91}
@subsubsection Parts of the MPS diagnostic system


@anchor{design/diag design mps diag parts}@anchor{e89}@ref{e89,,.parts;} The following facilities are considered part of the MPS
diagnostic system:


@itemize -

@item 
the @code{Describe()} methods.

@item 
the @ref{e8e,,STATISTIC} macros (see @code{mpm.h});

@item 
the @code{METER} macros and meter subsystem.
@end itemize

@node Statistics,Related systems,Parts of the MPS diagnostic system,How the MPS diagnostic system works
@anchor{design/diag statistics}@anchor{e92}
@subsubsection Statistics


@anchor{design/diag design mps diag stat}@anchor{e93}@ref{e93,,.stat;} The statistic system collects information about the
behaviour and performance of the MPS that may be useful for MPS
developers and customers, but which is not needed by the MPS itself
for internal decision-making.

@anchor{design/diag design mps diag stat remove}@anchor{e94}@ref{e94,,.stat.remove;} The space needed for these statistics, and the code
for maintaining them, can therefore be removed (compiled out) in some
varieties.

@anchor{design/diag design mps diag stat config}@anchor{e95}@ref{e95,,.stat.config;} Statistics are compiled in if @code{CONFIG_STATS} is
defined (in the cool variety) and compiled out if
@code{CONFIG_STATS_NONE} is defined (in the hot and rash varieties).

@geindex STATISTIC_DECL (C macro)
@anchor{design/diag c STATISTIC_DECL}@anchor{e96}
@deffn {C Macro} STATISTIC_DECL (decl)
@end deffn

@anchor{design/diag design mps diag stat decl}@anchor{e97}@ref{e97,,.stat.decl;} The @ref{e96,,STATISTIC_DECL} macro is used to wrap the
declaration of storage for a statistic. Note that the expansion
supplies a terminating semi-colon and so it must not be followed by a
semi-colon in use. This is so that it can be used in structure
declarations.

@geindex STATISTIC (C macro)
@anchor{design/diag c STATISTIC}@anchor{e8e}
@deffn {C Macro} STATISTIC (gather)
@end deffn

@anchor{design/diag design mps diag stat gather}@anchor{e98}@ref{e98,,.stat.gather;} The @ref{e8e,,STATISTIC} macro is used to gather statistics.
The argument is a statement and the expansion followed by a semicolon
is syntactically a statement. The macro expends to @code{NOOP} in
non-statistical varieties. (Note that it can’t use @code{DISCARD_STAT} to
check the syntax of the statement because it is expected to use fields
that have been compiled away by @ref{e96,,STATISTIC_DECL}, and these will
cause compilation errors.)

@anchor{design/diag design mps diag stat gather effect}@anchor{e99}@ref{e99,,.stat.gather.effect;} The argument to the @ref{e8e,,STATISTIC} macro is not
executed in non-statistical varieties and must have no side effects,
except for updates to fields that are declared in @ref{e96,,STATISTIC_DECL},
and telemetry output containing the values of such fields.

@geindex STATISTIC_WRITE (C macro)
@anchor{design/diag c STATISTIC_WRITE}@anchor{e9a}
@deffn {C Macro} STATISTIC_WRITE (format, arg)
@end deffn

@anchor{design/diag design mps diag stat write}@anchor{e9b}@ref{e9b,,.stat.write;} The @ref{e9a,,STATISTIC_WRITE} macro is used in @ref{446,,WriteF()}
argument lists to output the values of statistics.

@node Related systems,,Statistics,How the MPS diagnostic system works
@anchor{design/diag related-systems}@anchor{e9c}
@subsubsection Related systems


The MPS diagnostic system is separate from the following other MPS
systems:


@itemize -

@item 
The telemetry-log-events system. This emits much more data, in a
less human-readable form, requires MPS-aware external tools, and is
more stable from release to release). In non-diagnostic telemetry
varieties, the telemetry-log-events system emits events that log all
normal MPS actions. In diagnostic telemetry varieties, it may emit
additional events containing diagnostic information. Additionally,
the telemetry-log-events stream might in future be available as a
channel for emitting human-readable text diagnostics. See also
design.mps.telemetry@footnote{telemetry.html}.

@item 
The MPS message system. This is present in all varieties, and
manages asynchronous communication from the MPS to the client
program). However, the MPS message system might in future also be
available as a channel for emitting diagnostics. See also
design.mps.message@footnote{message.html}.
@end itemize

@node References<22>,,How the MPS diagnostic system works,Diagnostic feedback
@anchor{design/diag references}@anchor{e9d}
@subsection References


@anchor{design/diag rhsk-2007-04-13}@anchor{e86}@w{(RHSK_2007-04-13)} 
Richard Kistruck. 2007-04-13. “diagnostic feedback from the MPS@footnote{https://info.ravenbrook.com/mail/2007/04/13/13-07-45/0.txt}”.

@anchor{design/diag rhsk-2007-04-18}@anchor{e87}@w{(RHSK_2007-04-18)} 
Richard Kistruck. 2007-04-18. “Diverse types of diagnostic feedback@footnote{https://info.ravenbrook.com/mail/2007/04/18/10-58-49/0.txt}”.

@geindex fix function; design

@node The generic fix function,I/O subsystem,Diagnostic feedback,Old design
@anchor{design/fix doc}@anchor{e9e}@anchor{design/fix design-fix}@anchor{e9f}@anchor{design/fix the-generic-fix-function}@anchor{ea0}
@section The generic fix function


@menu
* Introduction: Introduction<55>. 
* Was-marked protocol:: 
* Implementation: Implementation<18>. 

@end menu

@node Introduction<55>,Was-marked protocol,,The generic fix function
@anchor{design/fix design mps fix}@anchor{ea1}@anchor{design/fix introduction}@anchor{ea2}
@subsection Introduction


@anchor{design/fix design mps fix intro}@anchor{ea3}@ref{ea3,,.intro;} Fix is the interface through which the existence of
references are communicated from the MPS client to the MPS. The
interface also allows the value of such references to be changed (this
is necessary in order to implement a moving memory manager).

@node Was-marked protocol,Implementation<18>,Introduction<55>,The generic fix function
@anchor{design/fix was-marked-protocol}@anchor{ea4}
@subsection Was-marked protocol


@anchor{design/fix design mps fix was-marked}@anchor{ea5}@ref{ea5,,.was-marked;} The @code{ScanState} has a @code{Bool wasMarked}
field. This is used for finalization.

@anchor{design/fix design mps fix was-marked not}@anchor{ea6}@ref{ea6,,.was-marked.not;} If a segment’s fix method discovers that the
object referred to by the ref (the one that it is supposed to be
fixing) has not previously been marked (that is, this is the first
reference to this object that has been fixed), and that the object was
white (that is, in condemned space), it should (but need not) set the
@code{wasMarked} field to @code{FALSE} in the passed @code{ScanState}.

@anchor{design/fix design mps fix was-marked otherwise}@anchor{ea7}@ref{ea7,,.was-marked.otherwise;} Otherwise, the fix method must
leave the @code{wasMarked} field unchanged.

@anchor{design/fix design mps fix was-marked finalizable}@anchor{ea8}@ref{ea8,,.was-marked.finalizable;} The MRG pool (design.mps.poolmrg@footnote{poolmrg.html})
uses the value of the @code{wasMarked} field to determine whether an
object is finalizable.

@node Implementation<18>,,Was-marked protocol,The generic fix function
@anchor{design/fix design-mps-poolmrg}@anchor{ea9}@anchor{design/fix implementation}@anchor{eaa}
@subsection Implementation


@anchor{design/fix design mps fix fix nailed}@anchor{eab}@ref{eab,,.fix.nailed;} In a copying collection, a non-ambiguous fix to a
broken heart should be snapped out `even if' there is a @code{RankAMBIG}
ref to same object (that is, if the broken heart is nailed); the
@code{RankAMBIG} reference must either be stale (no longer in existence)
or bogus.

@geindex I/O subsystem; design

@node I/O subsystem,Library interface,The generic fix function,Old design
@anchor{design/io doc}@anchor{eac}@anchor{design/io design-io}@anchor{ead}@anchor{design/io i-o-subsystem}@anchor{eae}
@section I/O subsystem


@menu
* Introduction: Introduction<56>. 
* Background: Background<4>. 
* Purpose: Purpose<2>. 
* Requirements: Requirements<34>. 
* Architecture: Architecture<6>. 
* Interface: Interface<23>. 
* I/O module implementations:: 
* Notes: Notes<5>. 
* Attachments:: 

@end menu

@node Introduction<56>,Background<4>,,I/O subsystem
@anchor{design/io design mps io}@anchor{eaf}@anchor{design/io introduction}@anchor{eb0}
@subsection Introduction


@anchor{design/io design mps io intro}@anchor{eb1}@ref{eb1,,.intro;} This document is the design of the MPS I/O Subsystem, a
part of the plinth.

@anchor{design/io design mps io readership}@anchor{eb2}@ref{eb2,,.readership;} This document is intended for MPS developers.

@node Background<4>,Purpose<2>,Introduction<56>,I/O subsystem
@anchor{design/io background}@anchor{eb3}
@subsection Background


@anchor{design/io design mps io bg}@anchor{eb4}@ref{eb4,,.bg;} This design is partly based on the design of the Internet User
Datagram Protocol (UDP). Mainly I used this to make sure I hadn’t left
out anything which we might need.

@node Purpose<2>,Requirements<34>,Background<4>,I/O subsystem
@anchor{design/io purpose}@anchor{eb5}
@subsection Purpose


@anchor{design/io design mps io purpose}@anchor{eb6}@ref{eb6,,.purpose;} The purpose of the MPS I/O Subsystem is to provide a
means to measure, debug, control, and test a memory manager build
using the MPS.

@anchor{design/io design mps io purpose measure}@anchor{eb7}@ref{eb7,,.purpose.measure;} Measurement consists of emitting data which can
be collected and analysed in order to improve the attributes of
application program, quite possibly by adjusting parameters of the
memory manager (see overview.mps.usage).

@anchor{design/io design mps io purpose control}@anchor{eb8}@ref{eb8,,.purpose.control;} Control means adjusting the behaviour of the MM
dynamically. For example, one might want to adjust a parameter in
order to observe the effect, then transfer that adjustment to the
client application later.

@anchor{design/io design mps io purpose test}@anchor{eb9}@ref{eb9,,.purpose.test;} Test output can be used to ensure that the memory
manager is behaving as expected in response to certain inputs.

@node Requirements<34>,Architecture<6>,Purpose<2>,I/O subsystem
@anchor{design/io requirements}@anchor{eba}
@subsection Requirements


@menu
* General:: 
* Functional:: 

@end menu

@node General,Functional,,Requirements<34>
@anchor{design/io general}@anchor{ebb}
@subsubsection General


@anchor{design/io design mps io req fun non-hosted}@anchor{ebc}@ref{ebc,,.req.fun.non-hosted;} The MPM must be a host-independent system.

@anchor{design/io design mps io req attr host}@anchor{ebd}@ref{ebd,,.req.attr.host;} It should be easy for the client to set up the MPM
for a particular host (such as a washing machine).

@node Functional,,General,Requirements<34>
@anchor{design/io functional}@anchor{ebe}
@subsubsection Functional


@anchor{design/io design mps io req fun measure}@anchor{ebf}@ref{ebf,,.req.fun.measure;} The subsystem must allow the MPS to transmit
quantitative measurement data to an external tool so that the system
can be tuned.

@anchor{design/io design mps io req fun debug}@anchor{ec0}@ref{ec0,,.req.fun.debug;} The subsystem must allow the MPS to transmit
qualitative information about its operation to an external tool so
that the system can be debugged.

@anchor{design/io design mps io req fun control}@anchor{ec1}@ref{ec1,,.req.fun.control;} The subsystem must allow the MPS to receive
control information from an external tool so that the system can be
adjusted while it is running.

@anchor{design/io design mps io req dc env no-net}@anchor{ec2}@ref{ec2,,.req.dc.env.no-net;} The subsystem should operate in environments
where there is no networking available.

@anchor{design/io design mps io req dc env no-fs}@anchor{ec3}@ref{ec3,,.req.dc.env.no-fs;} The subsystem should operate in environments
where there is no filesystem available.

@node Architecture<6>,Interface<23>,Requirements<34>,I/O subsystem
@anchor{design/io architecture}@anchor{ec4}
@subsection Architecture


@anchor{design/io design mps io arch diagram}@anchor{ec5}@ref{ec5,,.arch.diagram;} I/O Architecture Diagram

[missing diagram]

@anchor{design/io design mps io arch int}@anchor{ec6}@ref{ec6,,.arch.int;} The I/O Interface is a C function call interface by
which the MPM sends and receives “messages” to and from the hosted I/O
module.

@anchor{design/io design mps io arch module}@anchor{ec7}@ref{ec7,,.arch.module;} The modules are part of the MPS but not part of the
freestanding core system (see design.mps.exec-env@footnote{exec-env.html}). The I/O module is
responsible for transmitting those messages to the external tools, and
for receiving messages from external tools and passing them to the
MPM.

@anchor{design/io design mps io arch module example}@anchor{ec8}@ref{ec8,,.arch.module.example;} For example, the “file implementation” might
just send/write telemetry messages into a file so that they can be
received/read later by an off-line measurement tool.

@anchor{design/io design mps io arch external}@anchor{ec9}@ref{ec9,,.arch.external;} The I/O Interface is part of interface to the
freestanding core system (see design.mps.exec-env@footnote{exec-env.html}). This is so that
the MPS can be deployed in a freestanding environment, with a special
I/O module. For example, if the MPS is used in a washing machine the
I/O module could communicate by writing output to the seven-segment
display.

@menu
* Example configurations:: 

@end menu

@node Example configurations,,,Architecture<6>
@anchor{design/io example-configurations}@anchor{eca}
@subsubsection Example configurations


@anchor{design/io design mps io example telnet}@anchor{ecb}@ref{ecb,,.example.telnet;} This shows the I/O subsystem communicating with a
telnet client over a TCP/IP connection. In this case, the I/O
subsystem is translating the I/O Interface into an interactive text
protocol so that the user of the telnet client can talk to the MM.

[missing diagram]

@anchor{design/io design mps io example file}@anchor{ecc}@ref{ecc,,.example.file;} This shows the I/O subsystem dumping measurement
data into a file which is later read and analysed. In this case the
I/O subsystem is simply writing out binary in a format which can be
decoded.

[missing diagram]

@anchor{design/io design mps io example serial}@anchor{ecd}@ref{ecd,,.example.serial;} This shows the I/O subsystem communicating with a
graphical analysis tool over a serial link. This could be useful for a
developer who has two machines in close proximity and no networking
support.

@anchor{design/io design mps io example local}@anchor{ece}@ref{ece,,.example.local;} In this example the application is talking directly
to the I/O subsystem. This is useful when the application is a
reflective development environment (such as MLWorks) which wants to
observe its own behaviour.

[missing diagram]

@node Interface<23>,I/O module implementations,Architecture<6>,I/O subsystem
@anchor{design/io interface}@anchor{ecf}
@subsection Interface


@anchor{design/io design mps io if msg}@anchor{ed0}@ref{ed0,,.if.msg;} The I/O interface is oriented around opaque binary
“messages” which the I/O module must pass between the MPM and external
tools. The I/O module need not understand or interpret the contents of
those messages.

@anchor{design/io design mps io if msg opaque}@anchor{ed1}@ref{ed1,,.if.msg.opaque;} The messages are opaque in order to minimize the
dependency of the I/O module on the message internals. It should be
possible for clients to implement their own I/O modules for unusual
environments. We do not want to reveal the internal structure of our
data to the clients. Nor do we want to burden them with the details of
our protocols. We’d also like their code to be independent of ours, so
that we can expand or change the protocols without requiring them to
modify their modules.

@anchor{design/io design mps io if msg dgram}@anchor{ed2}@ref{ed2,,.if.msg.dgram;} Neither the MPM nor the external tools should assume
that the messages will be delivered in finite time, exactly once, or
in order. This will allow the I/O modules to be implemented using
unreliable transport layers such as the Internet User Datagram Protocol
(UDP). It will also give the I/O module the freedom to drop
information rather than block on a congested network, or stop the
memory manager when the disk is full, or similar events which really
shouldn’t cause the memory manager to stop working. The protocols we
need to implement at the high level can be design to be robust against
lossage without much difficulty.

@menu
* I/O module state:: 
* Message types: Message types<2>. 
* Limits:: 
* Interface set-up and tear-down:: 
* Message send and receive:: 

@end menu

@node I/O module state,Message types<2>,,Interface<23>
@anchor{design/io i-o-module-state}@anchor{ed3}
@subsubsection I/O module state


@anchor{design/io design mps io if state}@anchor{ed4}@ref{ed4,,.if.state;} The I/O module may have some internal state to preserve.
The I/O Interface defines a type for this state, @ref{2ce,,mps_io_t}, a
pointer to an incomplete structure @code{mps_io_s}. The I/O module is at
liberty to define this structure.

@node Message types<2>,Limits,I/O module state,Interface<23>
@anchor{design/io message-types}@anchor{ed5}
@subsubsection Message types


@anchor{design/io design mps io if type}@anchor{ed6}@ref{ed6,,.if.type;} The I/O module must be able to deliver messages of
several different types. It will probably choose to send them to
different destinations based on their type: telemetry to the
measurement tool, debugging output to the debugger, etc.

@example
typedef int mps_io_type_t;
enum @{
  MPS_IO_TYPE_TELEMETRY,
  MPS_IO_TYPE_DEBUG
@};
@end example

@node Limits,Interface set-up and tear-down,Message types<2>,Interface<23>
@anchor{design/io limits}@anchor{ed7}
@subsubsection Limits


@anchor{design/io design mps io if message-max}@anchor{ed8}@ref{ed8,,.if.message-max;} The interface will define an unsigned integral
constant @code{MPS_IO_MESSAGE_MAX} which will be the maximum size of
messages that the MPM will pass to @ref{ed9,,mps_io_send()} (@ref{eda,,.if.send}) and
the maximum size it will expect to receive from @ref{edb,,mps_io_receive()}.

@node Interface set-up and tear-down,Message send and receive,Limits,Interface<23>
@anchor{design/io interface-set-up-and-tear-down}@anchor{edc}
@subsubsection Interface set-up and tear-down


@anchor{design/io design mps io if create}@anchor{edd}@ref{edd,,.if.create;} The MPM will call @ref{2b9,,mps_io_create()} to set up the I/O
module. On success, this function should return @ref{5a,,MPS_RES_OK}. It may
also initialize a “state” value which will be passed to subsequent
calls through the interface.

@anchor{design/io design mps io if destroy}@anchor{ede}@ref{ede,,.if.destroy;} The MPM will call @ref{2cf,,mps_io_destroy()} to tear down
the I/O module, after which it guarantees that the state value will
not be used again. The @code{state} parameter is the state previously
returned by @ref{2b9,,mps_io_create()} (@ref{edd,,.if.create}).

@node Message send and receive,,Interface set-up and tear-down,Interface<23>
@anchor{design/io message-send-and-receive}@anchor{edf}
@subsubsection Message send and receive


@geindex mps_io_send (C function)
@anchor{design/io c mps_io_send}@anchor{ed9}
@deffn {C Function} extern @ref{14d,,mps_res_t} mps_io_send (mps_io_t state, mps_io_type_t type, void *message, size_t size)
@end deffn

@anchor{design/io design mps io if send}@anchor{eda}@ref{eda,,.if.send;} The MPM will call @ref{ed9,,mps_io_send()} when it wishes to
send a message to a destination. The @code{state} parameter is the state
previously returned by @ref{2b9,,mps_io_create()} (@ref{edd,,.if.create}). The
@code{type} parameter is the type (@ref{ed6,,.if.type}) of the message. The
@code{message} parameter is a pointer to a buffer containing the message,
and @code{size} is the length of that message, in bytes. The I/O module
must make an effort to deliver the message to the destination, but is
not expected to guarantee delivery. The function should return
@ref{150,,MPS_RES_IO} only if a serious error occurs that should cause the
MPM to return with an error to the client application. Failure to
deliver the message does not count.

@cartouche
@quotation Note 
Should there be a timeout parameter? What are the timing
constraints? @ref{ed9,,mps_io_send()} shouldn’t block.
@end quotation
@end cartouche

@geindex mps_io_receive (C function)
@anchor{design/io c mps_io_receive}@anchor{edb}
@deffn {C Function} extern @ref{14d,,mps_res_t} mps_io_receive (mps_io_t state, void **buffer_o, size_t *size_o)
@end deffn

@anchor{design/io design mps io if receive}@anchor{ee0}@ref{ee0,,.if.receive;} The MPM will call @ref{edb,,mps_io_receive()} when it wants
to see if a message has been sent to it. The @code{state} parameter is
the state previously returned by @ref{2b9,,mps_io_create()} (@ref{edd,,.if.create}).
The @code{buffer_o} parameter is a pointer to a value which should be
updated with a pointer to a buffer containing the message received.
The @code{size_o} parameter is a pointer to a value which should be
updated with the length of the message received. If there is no
message ready for receipt, the length returned should be zero.

@cartouche
@quotation Note 
Should we be able to receive truncated messages? How can this be
done neatly?
@end quotation
@end cartouche

@node I/O module implementations,Notes<5>,Interface<23>,I/O subsystem
@anchor{design/io i-o-module-implementations}@anchor{ee1}
@subsection I/O module implementations


@menu
* Routeing:: 

@end menu

@node Routeing,,,I/O module implementations
@anchor{design/io routeing}@anchor{ee2}
@subsubsection Routeing


The I/O module must decide where to send the various messages. A
file-based implementation could put them in different files based on
their types. A network-based implementation must decide how to address
the messages. In either case, any configuration must either be
statically compiled into the module, or else read from some external
source such as a configuration file.

@node Notes<5>,Attachments,I/O module implementations,I/O subsystem
@anchor{design/io notes}@anchor{ee3}
@subsection Notes


The external tools should be able to reconstruct stuff from partial
info. For example, you come across a fragment of an old log containing
just a few old messages. What can you do with it?

Here’s some completely untested code which might do the job for UDP.

@example
#include "mpsio.h"

#include <sys/types.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <arpa/inet.h>
#include <fcntl.h>
#include <errno.h>

typedef struct mps_io_s @{
  int sock;
  struct sockaddr_in mine;
  struct sockaddr_in telemetry;
  struct sockaddr_in debugging;
@} mps_io_s;

static mps_bool_t inited = 0;
static mps_io_s state;


mps_res_t mps_io_create(mps_io_t *mps_io_o)
@{
  int sock, r;

  if(inited)
    return MPS_RES_LIMIT;

  state.mine = /* setup somehow from config */;
  state.telemetry = /* setup something from config */;
  state.debugging = /* setup something from config */;

  /* Make a socket through which to communicate. */
  sock = socket(AF_INET, SOCK_DGRAM, 0);
  if(sock == -1) return MPS_RES_IO;

  /* Set socket to non-blocking mode. */
  r = fcntl(sock, F_SETFL, O_NDELAY);
  if(r == -1) return MPS_RES_IO;

  /* Bind the socket to some UDP port so that we can receive messages. */
  r = bind(sock, (struct sockaddr *)&state.mine, sizeof(state.mine));
  if(r == -1) return MPS_RES_IO;

  state.sock = sock;

  inited = 1;

  *mps_io_o = &state;
  return MPS_RES_OK;
@}


void mps_io_destroy(mps_io_t mps_io)
@{
  assert(mps_io == &state);
  assert(inited);

  (void)close(state.sock);

  inited = 0;
@}


mps_res_t mps_io_send(mps_io_t mps_io, mps_type_t type,
                      void *message, size_t size)
@{
  struct sockaddr *toaddr;

  assert(mps_io == &state);
  assert(inited);

  switch(type) @{
    MPS_IO_TYPE_TELEMETRY:
    toaddr = (struct sockaddr *)&state.telemetry;
    break;

    MPS_IO_TYPE_DEBUGGING:
    toaddr = (struct sockaddr *)&state.debugging;
    break;

    default:
    assert(0);
    return MPS_RES_UNIMPL;
  @}

  (void)sendto(state.sock, message, size, 0, toaddr, sizeof(*toaddr));

  return MPS_RES_OK;
@}


mps_res_t mps_io_receive(mps_io_t mps_io,
                         void **message_o, size_t **size_o)
@{
  int r;
  static char buffer[MPS_IO_MESSAGE_MAX];

  assert(mps_io == &state);
  assert(inited);

  r = recvfrom(state.sock, buffer, sizeof(buffer), 0, NULL, NULL);
  if(r == -1)
    switch(errno) @{
      /* Ignore interrupted system calls, and failures due to lack */
      /* of resources (they might go away.) */
      case EINTR: case ENOMEM: case ENOSR:
      r = 0;
      break;

      default:
      return MPS_RES_IO;
    @}

  *message_o = buffer;
  *size_o = r;
  return MPS_RES_OK;
@}
@end example

@node Attachments,,Notes<5>,I/O subsystem
@anchor{design/io attachments}@anchor{ee4}
@subsection Attachments


“O Architecture Diagram”
“O Configuration Diagrams”

@geindex library interface; design

@node Library interface,Locus manager,I/O subsystem,Old design
@anchor{design/lib doc}@anchor{ee5}@anchor{design/lib design-lib}@anchor{ee6}@anchor{design/lib library-interface}@anchor{ee7}
@section Library interface


@menu
* Introduction: Introduction<57>. 
* Goals: Goals<2>. 
* Description: Description<2>. 
* Implementation: Implementation<19>. 

@end menu

@node Introduction<57>,Goals<2>,,Library interface
@anchor{design/lib design mps lib}@anchor{ee8}@anchor{design/lib introduction}@anchor{ee9}
@subsection Introduction


@anchor{design/lib design mps lib intro}@anchor{eea}@ref{eea,,.intro;} This document is the design of the MPS Library Interface, a
part of the plinth.

@anchor{design/lib design mps lib readership}@anchor{eeb}@ref{eeb,,.readership;} Any MPS developer. Any clients that are prepared to
read this in order to get documentation.

@node Goals<2>,Description<2>,Introduction<57>,Library interface
@anchor{design/lib goals}@anchor{eec}
@subsection Goals


@anchor{design/lib design mps lib goal}@anchor{eed}@ref{eed,,.goal;} The goals of the MPS library interface are:

@anchor{design/lib design mps lib goal host}@anchor{eee}@ref{eee,,.goal.host;} To control the dependency of the MPS on the hosted ISO
C library so that the core MPS remains freestanding (see
design.mps.exec-env@footnote{exec-env.html}).

@anchor{design/lib design mps lib goal free}@anchor{eef}@ref{eef,,.goal.free;} To allow the core MPS convenient access to ISO C
functionality that is provided on freestanding platforms (see
design.mps.exec-env@footnote{exec-env.html}).

@node Description<2>,Implementation<19>,Goals<2>,Library interface
@anchor{design/lib description}@anchor{ef0}
@subsection Description


@menu
* Overview: Overview<18>. 

@end menu

@node Overview<18>,,,Description<2>
@anchor{design/lib overview}@anchor{ef1}
@subsubsection Overview


@anchor{design/lib design mps lib overview access}@anchor{ef2}@ref{ef2,,.overview.access;} The core MPS needs to access functionality that
could be provided by an ISO C hosted environment.

@anchor{design/lib design mps lib overview hosted}@anchor{ef3}@ref{ef3,,.overview.hosted;} The core MPS must not make direct use of any
facilities in the hosted environment (design.mps.exec-env@footnote{exec-env.html}). However,
it is sensible to make use of them when the MPS is deployed in a
hosted environment.

@anchor{design/lib design mps lib overview hosted indirect}@anchor{ef4}@ref{ef4,,.overview.hosted.indirect;} The core MPS does not make any direct
use of hosted ISO C library facilities. Instead, it indirects through
the MPS Library Interface, impl.h.mpslib.

@anchor{design/lib design mps lib overview provision client}@anchor{ef5}@ref{ef5,,.overview.provision.client;} In a freestanding environment the
client is expected to provide functions meeting this interface to the
MPS.

@anchor{design/lib design mps lib overview provision hosted}@anchor{ef6}@ref{ef6,,.overview.provision.hosted;} In a hosted environment,
impl.c.mpsliban may be used. It just maps impl.h.mpslib directly onto
the ISO C library equivalents.

@node Implementation<19>,,Description<2>,Library interface
@anchor{design/lib implementation}@anchor{ef7}
@subsection Implementation


@anchor{design/lib design mps lib impl}@anchor{ef8}@ref{ef8,,.impl;} The MPS Library Interface comprises a header file
impl.h.mpslib and some documentation.

@anchor{design/lib design mps lib impl decl}@anchor{ef9}@ref{ef9,,.impl.decl;} The header file defines the interface to definitions
which parallel those parts of the non-freestanding ISO headers which
are used by the MPS.

@anchor{design/lib design mps lib impl include}@anchor{efa}@ref{efa,,.impl.include;} The header file also includes the freestanding
header @code{<stddef.h>}.

@geindex locus manager; design

@node Locus manager,GC messages,Library interface,Old design
@anchor{design/locus doc}@anchor{efb}@anchor{design/locus design-locus}@anchor{efc}@anchor{design/locus locus-manager}@anchor{efd}
@section Locus manager


@menu
* Introduction: Introduction<58>. 
* Overview: Overview<19>. 
* Definitions: Definitions<9>. 
* Requirements: Requirements<35>. 
* Analysis: Analysis<4>. 
* Interface: Interface<24>. 
* Architecture: Architecture<7>. 
* Implementation: Implementation<20>. 
* Notes: Notes<6>. 

@end menu

@node Introduction<58>,Overview<19>,,Locus manager
@anchor{design/locus design mps locus}@anchor{efe}@anchor{design/locus introduction}@anchor{eff}
@subsection Introduction


@anchor{design/locus design mps locus intro}@anchor{f00}@ref{f00,,.intro;} The locus manager coordinates between the pools and takes
the burden of having to be clever about tract/group placement away
from the pools, preserving trace differentiability and contiguity
where appropriate.

@anchor{design/locus design mps locus source}@anchor{f01}@ref{f01,,.source;} mail.gavinm.1998-02-05.17-52@footnote{https://info.ravenbrook.com/project/mps/mail/1998/02/05/17-52/0.txt},
mail.ptw.1998-02-05.19-53@footnote{https://info.ravenbrook.com/project/mps/mail/1998/02/05/19-53/0.txt}, mail.pekka.1998-02-09.13-58@footnote{https://info.ravenbrook.com/project/mps/mail/1998/02/09/13-58/0.txt}, and
mail.gavinm.1998-02-09.14-05@footnote{https://info.ravenbrook.com/project/mps/mail/1998/02/09/14-05/0.txt}.

@anchor{design/locus design mps locus readership}@anchor{f02}@ref{f02,,.readership;} Any MPS developer.

@node Overview<19>,Definitions<9>,Introduction<58>,Locus manager
@anchor{design/locus overview}@anchor{f03}
@subsection Overview


The MPS manages three main resources:


@enumerate 

@item 
storage;

@item 
address space;

@item 
time.
@end enumerate

The locus manager manages address space at the arena level.

@cartouche
@quotation Note 
Tucker was right: see mail.ptw.1998-11-02.14-25@footnote{https://info.ravenbrook.com/project/mps/mail/1998/11/02/14-25/0.txt}. Richard
Kistruck, 2007-04-24.
@end quotation
@end cartouche

When a pool wants some address space, it expresses some preferences to
the locus manager. The locus manager and the arena (working together)
try to honour these preferences, and decide what address space the
pool gets.

Preferences are expressed by the @code{LocusPref} argument to
@code{SegAlloc()}. Note that, when they call @code{SegAlloc()}, pools are
asking for address space and writeable storage simultaneously, in a
single call. There is currently no way for pools to reserve address
space without requesting storage.

@menu
* Why is it important to manage address space?:: 
* Discovering the layout:: 

@end menu

@node Why is it important to manage address space?,Discovering the layout,,Overview<19>
@anchor{design/locus why-is-it-important-to-manage-address-space}@anchor{f04}
@subsubsection Why is it important to manage address space?



@enumerate 

@item 
Trace differentiability

Carefully chosen addresses are used by reference tracing systems
(ie. automatic pools), to categorise objects into clumps; and to
summarise and cheaply find references between clumps.

Different clumps will become worth collecting at different times
(the classic example, of course, is generations in a generational
collector). For these partial collections to be efficient, it must
be cheap to keep these clumps differentiable, cheap to condemn
(Whiten) a particular clump, and cheap to find a good conservative
approximation to all inward references to a clump (both initially
to construct the Grey set, and to make scanning the Grey set
efficient).

This is what the MPS zone mechanism is all about.

The locus manager manages the mapping from clumps to zones.

To specify a clump, pools can pass @code{LocusPrefZONESET} and a set
of zones to @code{LocusPrefExpress()}.

@item 
Prevent address space fragmentation (within the arena)

Address space is not infinite.

In some use cases, the MPS is required to remain efficient when
using very nearly all available address space and storage. For
example, with the client-arena class, where the only address space
available is that of the storage available.

Even with the VM arena class, typical storage sizes (as of 2007)
can make 32-bit address space constrained: the client may need
several gigabytes, which leaves little spare address space.

Address space fragmentation incurs failure when there is no way to
allocate a big block of address space. The big block may be
requested via the MPS (by the client), or by something else in the
same process, such as a third-party graphics library, image
library, etc.

Address space fragmentation incurs cost when:


@itemize -

@item 
desired large-block requests (such as for buffering) are denied,
causing them to be re-requested as a smaller block, or as several
smaller blocks;

@item 
possible operating-system costs in maintaining a fragmented
mapping?
@end itemize

@item 
Prevent storage fragmentation (within tracts and segments)

@quotation

Storage is not infinite: it is allocated in multiples of a
fixed-size tract. Small lonely objects, each retaining a whole
tract, cause storage fragmentation.

Non-moving pools manage this fragmentation with placement
strategies that use:


@itemize -

@item 
co-located death (in space and time);

@item 
segment merging and splitting.
@end itemize

These pool-level strategies always care about contiguity of object
storage. They also often care about the `ordering' of addresses,
because pool code uses an address-ordered search when choosing
where to place a new object. For these two reasons, the address
chosen (by the locus manager and arena) for new tracts is
important.

Certain specialised pools, and/or some client programs that use
them, have carefully tuned segment sizes, positioning, and search
order. Be careful: seemingly inconsequential changes can
catastrophically break this tuning.

Pools can specify a preference for High and Low ends of address
space, which implies a search-order. Pools could also specify
clumping, using @code{LocusPrefZONESET}.
@end quotation
@end enumerate

@node Discovering the layout,,Why is it important to manage address space?,Overview<19>
@anchor{design/locus discovering-the-layout}@anchor{f05}
@subsubsection Discovering the layout


The locus manager is not given advance notice of how much address
space will be required with what preferences. Instead, the locus
manager starts with an empty layout, and adapts it as more requests
come in over time. It is attempting to discover a suitable layout by
successive refinement. This is ambitious.

@node Definitions<9>,Requirements<35>,Overview<19>,Locus manager
@anchor{design/locus definitions}@anchor{f06}
@subsection Definitions


@anchor{design/locus design mps locus note cohort}@anchor{f07}@ref{f07,,.note.cohort;} We use the word “cohort” in its usual sense here, but
we’re particularly interested in cohorts that have properties relevant
to tract placement. It is such cohorts that the pools will try to
organize using the services of the locus manager. Typical properties
would be trace differentiability or (en masse) death-time
predictability. Typical cohorts would be instances of a
non-generational pool, or generations of a collection strategy.

@anchor{design/locus design mps locus def trace differentiability}@anchor{f08}@ref{f08,,.def.trace.differentiability;} Objects (and hence tracts) that are
collected, may or may not have “trace differentiability” from each
other, depending on their placement in the different zones. Objects
(or pointers to them) can also have trace differentiability (or not)
from non-pointers in ambiguous references; in practice, we will be
worried about low integers, that may appear to be in zones 0 or -1.

@node Requirements<35>,Analysis<4>,Definitions<9>,Locus manager
@anchor{design/locus requirements}@anchor{f09}
@subsection Requirements


@anchor{design/locus design mps locus req cohort}@anchor{f0a}@ref{f0a,,.req.cohort;} Tract allocations must specify the cohort they
allocate in. These kind of cohorts will be called loci, and they will
have such attributes as are implied by the other requirements.
Critical.

@anchor{design/locus design mps locus req counter objects}@anchor{f0b}@ref{f0b,,.req.counter.objects;} As a counter-requirement, pools are expected
to manage objects. Objects the size of a tract allocation request
(segment-sized) are exceptional. Critical.
@anchor{design/locus design mps locus req counter objects just}@anchor{f0c}@ref{f0c,,.req.counter.objects.just;} This means the locus manager is not
meant to solve the problems of allocating large objects, and it isn’t
required to know what goes on in pools.

@anchor{design/locus design mps locus req contiguity}@anchor{f0d}@ref{f0d,,.req.contiguity;} Must support a high level of contiguity within
cohorts when requested. This means minimizing the number of times a
cohort is made aware of discontiguity. Essential (as we’ve effectively
renegotiated this in SW, down to a vague hope that certain critical
cohorts are not too badly fragmented). @anchor{design/locus design mps locus req contiguity just}@anchor{f0e}@ref{f0e,,.req.contiguity.just;} TSBA.

@anchor{design/locus design mps locus req contiguity specific}@anchor{f0f}@ref{f0f,,.req.contiguity.specific;} It should be possible to request another
allocation next to a specific tract on either side (or an extension in
that direction, as the case may be). Such a request can fail, if
there’s no space there. Nice. It would also be nice to have one for
“next to the largest free block”.

@anchor{design/locus design mps locus req differentiable}@anchor{f10}@ref{f10,,.req.differentiable;} Must support the trace differentiability of
segments that may be condemned separately. Due to the limited number
of zones, it must be possible to place several cohorts into the same
zone. Essential.

@anchor{design/locus design mps locus req differentiable integer}@anchor{f11}@ref{f11,,.req.differentiable.integer;} It must be possible to place
collectable allocations so that they are trace-differentiable from
small integers. Essential.

@anchor{design/locus design mps locus req disjoint}@anchor{f12}@ref{f12,,.req.disjoint;} Must support the disjointness of pages that have
different VM properties (such as mutable/immutable,
read-only/read-write, and different lifetimes). Optional.

@cartouche
@quotation Note 
I expect the implementation will simply work at page or larger
granularity, so the problem will not arise, but Tucker insisted on
stating this as a requirement. Pekka P. Pirinen, 1998-10-28.
@end quotation
@end cartouche

@anchor{design/locus design mps locus req low-memory}@anchor{f13}@ref{f13,,.req.low-memory;} The architecture of the locus manager must not
prevent the design of efficient applications that often use all
available memory. Critical. @anchor{design/locus design mps locus req low-memory expl}@anchor{f14}@ref{f14,,.req.low-memory.expl;} This basically
says it must be designed to perform well in low-memory conditions, but
that there can be configurations where it doesn’t do as well, as long
as this is documented for the application programmer. Note that it
doesn’t say all applications are efficient, only that if you manage to
design an otherwise efficient application, the locus manager will not
sink it.

@anchor{design/locus design mps locus req address}@anchor{f15}@ref{f15,,.req.address;} Must conserve address space in VM arenas to a
reasonable extent. Critical.

@anchor{design/locus design mps locus req inter-pool}@anchor{f16}@ref{f16,,.req.inter-pool;} Must support the association of sets of tracts in
different pools into one cohort. Nice.

@anchor{design/locus design mps locus req ep-style}@anchor{f17}@ref{f17,,.req.ep-style;} Must support the existing EP-style of allocation
whereby allocation is from one end of address space either upwards or
downwards (or a close approximation thereto with the same behavior).
@anchor{design/locus design mps locus req ep-style just}@anchor{f18}@ref{f18,,.req.ep-style.just;} We cannot risk disrupting a policy with
well-known properties when this technology is introduced.

@anchor{design/locus design mps locus req attributes}@anchor{f19}@ref{f19,,.req.attributes;} There should be a way to inform the locus manager
about various attributes of cohorts that might be useful for
placement: deathtime, expected total size, and so on. Optional. It’s a
given that the cohorts must then have these attributes, within the
limits set in the contract of the appropriate interface.
@anchor{design/locus design mps locus req attributes action}@anchor{f1a}@ref{f1a,,.req.attributes.action;} The locus manager should use the attributes
to guide its placement decisions. Nice.

@anchor{design/locus design mps locus req blacklisting}@anchor{f1b}@ref{f1b,,.req.blacklisting;} There should be a way of maintaining at least
one blacklist for pages (or some other small unit), that can
not/should not be allocated to collectable pools. Optional.

@cartouche
@quotation Note 
How to do blacklist breaking for ambiguous refs?
@end quotation
@end cartouche

@anchor{design/locus design mps locus req hysteresis}@anchor{f1c}@ref{f1c,,.req.hysteresis;} There should be a way to indicate which cohorts
fluctuate in size and by how much, to guide the arena hysteresis to
hold on to suitable pages. Optional.

@node Analysis<4>,Interface<24>,Requirements<35>,Locus manager
@anchor{design/locus analysis}@anchor{f1d}
@subsection Analysis


@anchor{design/locus design mps locus analysis sw}@anchor{f1e}@ref{f1e,,.analysis.sw;} Almost any placement policy would be an improvement on
the current SW one.

@anchor{design/locus design mps locus analysis cause-and-effect}@anchor{f1f}@ref{f1f,,.analysis.cause-and-effect;} The locus manager doesn’t usually need to
know `why' things need to be differentiable, disjoint, contiguous, and
so on. Abstracting the reason away from the interface makes it more
generic, more likely to have serendipitous new uses. Attributes
described by a quantity (deathtime, size, etc.) are an exception to
this, because we can’t devise a common measure.

@anchor{design/locus design mps locus analysis stable}@anchor{f20}@ref{f20,,.analysis.stable;} The strategy must be stable: it must avoid repeated
recomputation, especially the kind that switches between alternatives
with a short period (repeated “bites” out the same region or
flip-flopping between two regions).

@anchor{design/locus design mps locus analysis fragmentation}@anchor{f21}@ref{f21,,.analysis.fragmentation;} There’s some call to avoid fragmentation in
cohorts that don’t need strict contiguity, but this is not a separate
requirement, since fragmentation is a global condition, and can only
be ameliorated if there’s a global strategy that clumps allocations
together.

@anchor{design/locus design mps locus analysis deathtime}@anchor{f22}@ref{f22,,.analysis.deathtime;} Cohorts with good death-time clumping of their
objects could use some locality of tract allocation, because it
increases the chances of creating large holes in the address space
(for other allocation to use). OTOH. many cohorts will not do multiple
frees in short succession, or at least cannot reasonably be predicted
to do so. This locality is not contiguity, nor is it low
fragmentation, it’s just the requirement to place the new tracts next
to the tract where the last object was allocated in the cohort. Note
that the placement of objects is under the control of the pool, and
the locus manager will not know it, therefore this requirement should
be pursued by requesting allocation next to a particular tract (which
we already have a requirement for).

@anchor{design/locus design mps locus analysis asymmetrical}@anchor{f23}@ref{f23,,.analysis.asymmetrical;} The strategy has to be asymmetrical with
respect to cohorts growing and shrinking. The reason of this asymmetry
is that it can choose where to grow, but it cannot choose where to
shrink (except in a small way by growing with good locality).

@node Interface<24>,Architecture<7>,Analysis<4>,Locus manager
@anchor{design/locus interface}@anchor{f24}
@subsection Interface


@anchor{design/locus design mps locus interface locus}@anchor{f25}@ref{f25,,.interface.locus;} A cohort will typically reside on multiple tracts
(and the pools will avoid putting objects of other cohorts on them),
so there should be an interface to describe the properties of the
cohort, and associate each allocation request with the cohort. We
shall call such an object, created to represent a cohort, a locus (pl.
loci).

@anchor{design/locus design mps locus interface locus pool}@anchor{f26}@ref{f26,,.interface.locus.pool;} Loci will usually be created by the pool
that uses it. Some of the locus attributes will be inherited from
client-specified pool attributes [this means there will be additional
pool attributes].

@anchor{design/locus design mps locus interface detail}@anchor{f27}@ref{f27,,.interface.detail;} This describes interface in overview; for
details, see implementation section and code, or user doc.

@menu
* Loci:: 
* Peaks:: 

@end menu

@node Loci,Peaks,,Interface<24>
@anchor{design/locus loci}@anchor{f28}
@subsubsection Loci


@geindex LocusCreate (C function)
@anchor{design/locus c LocusCreate}@anchor{f29}
@deffn {C Function} @ref{55f,,Res} LocusCreate (Locus *locusReturn, LocusAttrs attrs, ZoneGroup zg, LocusAllocDesc adesc)
@end deffn

@anchor{design/locus design mps locus function create}@anchor{f2a}@ref{f2a,,.function.create;} A function to create a locus: @code{adesc} contains
the information about the allocation sequences in the locus, @code{zg} is
used for zone differentiability, and @code{attrs} encodes the following:


@itemize -

@item 
@anchor{design/locus design mps locus locus contiguity}@anchor{f2b}@ref{f2b,,.locus.contiguity;} A locus can be contiguous. This means
performing as required in @ref{f0d,,.req.contiguity}, non-contiguous
allocations can be freely placed anywhere (but efficiency dictates
that similar allocations are placed close together and apart from
others).

@item 
@anchor{design/locus design mps locus locus blacklist}@anchor{f2c}@ref{f2c,,.locus.blacklist;} Allocations in the locus will avoid blacklisted
pages (for collectable segments).

@item 
@anchor{design/locus design mps locus locus zero}@anchor{f2d}@ref{f2d,,.locus.zero;} Allocations in the locus are zero-filled.
@end itemize

@cartouche
@quotation Note 
Other attributes will be added, I’m sure.
@end quotation
@end cartouche

@anchor{design/locus design mps locus interface zone-group}@anchor{f2e}@ref{f2e,,.interface.zone-group;} The locus can be made a member of a zone
group. Passing @code{ZoneGroupNONE} means it’s not a member of any group
(allocations will be placed without regard to zone, except to keep
them out of stripes likely to be needed for some group).

@cartouche
@quotation Note 
I propose no mechanism for managing zone groups at this time,
since it’s only used internally for one purpose. Pekka P. Pirinen,
2000-01-17.
@end quotation
@end cartouche

@anchor{design/locus design mps locus interface size}@anchor{f2f}@ref{f2f,,.interface.size;} An allocation descriptor (@code{LocusAllocDesc})
contains various descriptions of how the locus will develop over time
(inconsistent specifications are forbidden, of course):


@itemize -

@item 
@anchor{design/locus design mps locus interface size typical-alloc}@anchor{f30}@ref{f30,,.interface.size.typical-alloc;} Size of a typical allocation in
this locus, in bytes. This will mainly affect the grouping of
non-contiguous loci.

@item 
@anchor{design/locus design mps locus interface size large-alloc}@anchor{f31}@ref{f31,,.interface.size.large-alloc;} Typical large allocation that the
manager should try to allow for (this allows some relief from
@ref{f0b,,.req.counter.objects}), in bytes. This will mainly affect the size
of gaps that will be allotted adjoining this locus.

@item 

@table @asis
@anchor{design/locus design mps locus interface size direction}@anchor{f32}
@item @ref{f32,,.interface.size.direction;} Direction of growth: up/down/none.

Only useful if the locus is contiguous.
@end table

@item 
@anchor{design/locus design mps locus interface size lifetime}@anchor{f33}@ref{f33,,.interface.size.lifetime;} Some measure of the lifetime of tracts
(not objects) in the cohort.

@cartouche
@quotation Note 
Don’t know the details yet, probably only useful for placing
similar cohorts next to each other, so the details don’t
actually matter. Pekka P. Pirinen, 2000-01-17.
@end quotation
@end cartouche

@item 
@anchor{design/locus design mps locus interface size deathtime}@anchor{f34}@ref{f34,,.interface.size.deathtime;} Some measure of the deathtime of
tracts (not objects) in the cohort.

@cartouche
@quotation Note 
Ditto. Pekka P. Pirinen, 2000-01-17.
@end quotation
@end cartouche
@end itemize

@anchor{design/locus design mps locus function init}@anchor{f35}@ref{f35,,.function.init;} @code{LocusInit()} is like @ref{f29,,LocusCreate()}, but
without the allocation. This is the usual interface, since most loci
are embedded in a pool or something.

@anchor{design/locus design mps locus function alloc}@anchor{f36}@ref{f36,,.function.alloc;} @code{ArenaAlloc()} to take a locus argument.
@code{ArenaAllocHere()} is like it, plus it takes a tract and a
specification to place the new allocation immediately above/below a
given tract; if that is not possible, it returns @code{ResFAIL} (this
will make it useful for reallocation functionality).

@geindex ArenaSetTotalLoci (C function)
@anchor{design/locus c ArenaSetTotalLoci}@anchor{f37}
@deffn {C Function} void ArenaSetTotalLoci (Arena arena, Size nLoci, Size nZoneGroups)
@end deffn

@anchor{design/locus design mps locus function set-total}@anchor{f38}@ref{f38,,.function.set-total;} A function to tell the arena the expected
number of (non-miscible client) loci, and of zone groups.

@node Peaks,,Loci,Interface<24>
@anchor{design/locus peaks}@anchor{f39}
@subsubsection Peaks


@geindex mps_peak_create (C function)
@anchor{design/locus c mps_peak_create}@anchor{f3a}
@deffn {C Function} @ref{14d,,mps_res_t} mps_peak_create (mps_peak_t*, mps_arena_t)
@end deffn

@anchor{design/locus design mps locus function peak create}@anchor{f3b}@ref{f3b,,.function.peak.create;} A function to create a peak. A newly-created
peak is open, and will not be used to guide the strategy of the locus
manager.

@geindex mps_peak_describe_pool (C function)
@anchor{design/locus c mps_peak_describe_pool}@anchor{f3c}
@deffn {C Function} @ref{14d,,mps_res_t} mps_peak_describe_pool (mps_peak_t, mps_pool_t, mps_size_desc_t)
@end deffn

@anchor{design/locus design mps locus function peak add}@anchor{f3d}@ref{f3d,,.function.peak.add;} A function to add a description of the state of
one pool into the peak. Calling this function again for the same peak and pool instance will replace
the earlier description.

@anchor{design/locus design mps locus function peak add size}@anchor{f3e}@ref{f3e,,.function.peak.add.size;} The size descriptor contains a total size
in bytes or percent of arena size.

@cartouche
@quotation Note 
Is this right? Pekka P. Pirinen, 2000-01-17.
@end quotation
@end cartouche

@anchor{design/locus design mps locus function peak add remove}@anchor{f3f}@ref{f3f,,.function.peak.add.remove;} Specifying a @code{NULL} size will remove
the pool from the peak. The client is not allowed to destroy a pool
that is mentioned in any peak; it must be first removed from the peak,
or the peak must be destroyed. This is to ensure that the client
adjusts the peaks in a manner that makes sense to the application; the
locus manager can’t know how to do that.

@geindex mps_peak_close (C function)
@anchor{design/locus c mps_peak_close}@anchor{f40}
@deffn {C Function} @ref{14d,,mps_res_t} mps_peak_close (mps_peak_t)
@end deffn

@anchor{design/locus design mps locus function peak close}@anchor{f41}@ref{f41,,.function.peak.close;} A function to indicate that all the
significant pools have been added to the peak, and it can now be used
to guide the locus manager. For any pool not described in the peak,
the locus manager will take its current size at any given moment as
the best prediction of its size at the peak.

@anchor{design/locus design mps locus function peak close after}@anchor{f42}@ref{f42,,.function.peak.close.after;} It is legal to add more descriptions to
the peak after closing, but this will reopen the peak, and it will
have to be closed before the locus manager will use it again. The
locus manager uses the previous closed state of the peak, while this
is going on.

@geindex mps_peak_destroy (C function)
@anchor{design/locus c mps_peak_destroy}@anchor{f43}
@deffn {C Function} void mps_peak_destroy (mps_peak_t)
@end deffn

@anchor{design/locus design mps locus function peak destroy}@anchor{f44}@ref{f44,,.function.peak.destroy;} A function to destroy a peak.

@anchor{design/locus design mps locus interface ep-style}@anchor{f45}@ref{f45,,.interface.ep-style;} This satisfies @ref{f17,,.req.ep-style} by allowing SW
to specify zero size for most pools (which will cause them to be place
next to other loci with the same growth direction).

@cartouche
@quotation Note 
Not sure this is good enough, but we’ll try it first. Pekka P.
Pirinen, 2000-01-17.
@end quotation
@end cartouche

@node Architecture<7>,Implementation<20>,Interface<24>,Locus manager
@anchor{design/locus architecture}@anchor{f46}
@subsection Architecture


@menu
* Data objects:: 
* Overview of strategy:: 
* Allocation: Allocation<3>. 
* Deallocation:: 
* Region placement recomputation:: 

@end menu

@node Data objects,Overview of strategy,,Architecture<7>
@anchor{design/locus data-objects}@anchor{f47}
@subsubsection Data objects


@anchor{design/locus design mps locus arch locus}@anchor{f48}@ref{f48,,.arch.locus;} To represent the cohorts, we have locus objects.
Usually a locus is embedded in a pool instance, but generations are
separate loci.

@anchor{design/locus design mps locus arch locus attr}@anchor{f49}@ref{f49,,.arch.locus.attr;} contiguity, blacklist, zg, current region, @@@@@@@@

@anchor{design/locus design mps locus arch locus attr exceptional}@anchor{f4a}@ref{f4a,,.arch.locus.attr.exceptional;} The client can define a typical large
allocation for the locus. Requests substantially larger than that are
deemed exceptional.

@anchor{design/locus design mps locus arch zone-group}@anchor{f4b}@ref{f4b,,.arch.zone-group;} To satisfy @ref{f10,,.req.differentiable}, we offer zone
groups. Each locus can be a member of a zone group, and the locus
manager will attempt to place allocations in this locus in different
zones from all the other zone groups. A zone-group is represented as
@@@@@@@@.

@anchor{design/locus design mps locus arch page-table}@anchor{f4c}@ref{f4c,,.arch.page-table;} A page table is maintained by the arena, as usual
to track association between tracts, pools and segments, and mapping
status for VM arenas.

@anchor{design/locus design mps locus arch region}@anchor{f4d}@ref{f4d,,.arch.region;} All of the address space is divided into disjoint
regions, represented by region objects. These objects store their
current limits, and high and low watermarks of currently allocated
tracts (we hope there’s usually a gap of empty space between regions).
The limits are actually quite porous and flexible.

@anchor{design/locus design mps locus arch region assoc}@anchor{f4e}@ref{f4e,,.arch.region.assoc;} Each region is associated with one contiguous
locus or any number of non-contiguous loci (or none). We call the
first kind of region “contiguous”. @anchor{design/locus design mps locus arch locus assoc}@anchor{f4f}@ref{f4f,,.arch.locus.assoc;} Each locus
remembers all regions where it has tracts currently, excepting the
badly-placed allocations (see below). It is not our intention that any
locus would have very many, or that loci that share regions would have
any reason to stop doing do.

@anchor{design/locus design mps locus arch region more}@anchor{f50}@ref{f50,,.arch.region.more;} Various quantities used by the placement
computation are also stored in the regions and the loci. Regions are
created (and destroyed) by the placement recomputation. Regions are
located in stripes (if it’s a zoned region), but they can extend into
neighboring stripes if an exceptionally large tract allocation is
requested (to allow for large objects).

@anchor{design/locus design mps locus arch chunk}@anchor{f51}@ref{f51,,.arch.chunk;} Arenas may allocate more address space in additional
chunks, which may be disjoint from the existing chunks. Inter-chunk
space will be represented by dummy regions. There are also sentinel
regions at both ends of the address space. See
design.mps.arena.chunk@footnote{arena.html#design.mps.arena.chunk}.

@node Overview of strategy,Allocation<3>,Data objects,Architecture<7>
@anchor{design/locus design-mps-arena-chunk}@anchor{f52}@anchor{design/locus overview-of-strategy}@anchor{f53}
@subsubsection Overview of strategy


@anchor{design/locus design mps locus arch strategy delay}@anchor{f54}@ref{f54,,.arch.strategy.delay;} The general strategy is to delay placement
decisions until they have to be made, but no later.

@anchor{design/locus design mps locus arch strategy delay until}@anchor{f55}@ref{f55,,.arch.strategy.delay.until;} Hence, the locus manager only makes
placement decisions when an allocation is requested (frees and other
operations might set a flag to cause the next allocation to redecide).
This also allows the client to change the peak and pool configuration
in complicated ways without causing a lot of recomputation, by doing
all the changes without allocating in the middle (unless the control
pool needs more space because of the changes).

@anchor{design/locus design mps locus arch strategy normal}@anchor{f56}@ref{f56,,.arch.strategy.normal;} While we want the placement to be
sophisticated, we do not believe it is worth the effort to consider
all the data at each allocation. Hence, allocations are usually just
placed in one of the regions used previously (see @ref{f57,,.arch.alloc})
without reconsidering the issues.

@anchor{design/locus design mps locus arch strategy normal limit}@anchor{f58}@ref{f58,,.arch.strategy.normal.limit;} However, the manager sets
precautionary limits on the regions to ensure that the placement
decisions are revisited when an irrevocable placement is about to be
made.

@anchor{design/locus design mps locus arch strategy create}@anchor{f59}@ref{f59,,.arch.strategy.create;} The manager doesn’t create new regions until
they are needed for allocation (but it might compute where they could
be placed to accommodate a peak).

@node Allocation<3>,Deallocation,Overview of strategy,Architecture<7>
@anchor{design/locus allocation}@anchor{f5a}
@subsubsection Allocation


@anchor{design/locus design mps locus arch alloc}@anchor{f57}@ref{f57,,.arch.alloc;} Normally, each allocation to a locus is placed in its
current region. New regions are only sought when necessary to fulfill
an allocation request or when there is reason to think the situation
has changed significantly (see @ref{f5b,,.arch.significant}).

@anchor{design/locus design mps locus arch alloc same}@anchor{f5c}@ref{f5c,,.arch.alloc.same;} An allocation is first attempted next to the
previous allocation in the same locus, respecting growth direction. If
that is not possible, a good place in the current region is sought.
@anchor{design/locus design mps locus arch alloc same hole}@anchor{f5d}@ref{f5d,,.arch.alloc.same.hole;} At the moment, for finding a good place
within a region, we just use the current algorithm, limited to the
region. In future, the placement within regions will be more clever.

@anchor{design/locus design mps locus arch alloc extend}@anchor{f5e}@ref{f5e,,.arch.alloc.extend;} If there’s no adequate hole in the current
region and the request is not exceptional, the neighboring regions are
examined to see if the region could be extended at one border. (This
will basically only be done if the neighbor has shrunk since the last
placement recomputation, because the limit was set on sophisticated
criteria, and should not be changed without justification.)
@anchor{design/locus design mps locus arch alloc extend here}@anchor{f5f}@ref{f5f,,.arch.alloc.extend.here;} When an allocation is requested next to a
specific tract (@code{ArenaAllocHere()}), we try to extend a little
harder (at least for @code{change_size}, perhaps not for locality).

@anchor{design/locus design mps locus arch alloc other}@anchor{f60}@ref{f60,,.arch.alloc.other;} If no way can be found to allocate in the
current region, other regions used for this locus are considered in
the same way, to see if space can be found there. [Or probably look at
other regions before trying to extend anything?]

@anchor{design/locus design mps locus arch alloc recompute}@anchor{f61}@ref{f61,,.arch.alloc.recompute;} When no region of this locus has enough
space for the request, or when otherwise required, region placement is
recomputed to find a new region for the request (which might be the
same region, after extension).

@anchor{design/locus design mps locus arch alloc current}@anchor{f62}@ref{f62,,.arch.alloc.current;} This region where the allocation was placed
then becomes the current region for this locus, except when the
request was exceptional, or when the region chosen was “bad” (see
@@@@@@@@).

@anchor{design/locus design mps locus arch significant}@anchor{f5b}@ref{f5b,,.arch.significant;} Significant changes to the parameters affecting
placement are deemed to have happened at certain client calls and when
the total allocation has changed substantially since the last
recomputation. Such conditions set a flag that causes the next
allocation to recompute even if its current region is not full
(possibly second-guess the decision to recompute after some
investigation of the current state?).

@node Deallocation,Region placement recomputation,Allocation<3>,Architecture<7>
@anchor{design/locus deallocation}@anchor{f63}
@subsubsection Deallocation


@anchor{design/locus design mps locus arch free}@anchor{f64}@ref{f64,,.arch.free;} Deallocation simply updates the counters in the region
and the locus. For some loci, it will make the region of the
deallocation the current region. @anchor{design/locus design mps locus arch free remove}@anchor{f65}@ref{f65,,.arch.free.remove;} If a region
becomes entirely empty, it is deleted (and the neighbors limits might
be adjusted).

@cartouche
@quotation Note 
This is quite tricky to get right.
@end quotation
@end cartouche

@node Region placement recomputation,,Deallocation,Architecture<7>
@anchor{design/locus region-placement-recomputation}@anchor{f66}
@subsubsection Region placement recomputation


@anchor{design/locus design mps locus arch gap}@anchor{f67}@ref{f67,,.arch.gap;} When doing placement computations, we view the arena as
a sequence of alternating region cores and gaps (which can be small,
even zero-sized). Initially, we’ll take the core of a region to be the
area between the high and low watermark, but in the future we might be
more flexible about that.

@cartouche
@quotation Note 
Edge determination is actually a worthwhile direction to explore.
@end quotation
@end cartouche

@anchor{design/locus design mps locus arch reach}@anchor{f68}@ref{f68,,.arch.reach;} The gap between two cores could potentially end up
being allocated to either region, if they grow in that direction, or
one or neither, if they don’t. The set of states that the region
assignment could reach by assigning the gaps to their neighbors is
called the reach of the current configuration.

@anchor{design/locus design mps locus arch placement object}@anchor{f69}@ref{f69,,.arch.placement.object;} The object of the recomputation is to find
a configuration of regions that is not too far from the current
configuration and that keeps all the peaks inside its reach; if that
is not possible, keep the nearest ones in the reach and then minimize
the total distance from the rest.

@anchor{design/locus design mps locus arch placement hypothetical}@anchor{f6a}@ref{f6a,,.arch.placement.hypothetical;} The configurations that are
considered will include hypothetical placements for new regions for
loci that cannot fit in their existing regions at the peak. This is
necessary to avoid choosing a bad alternative.

@anchor{design/locus design mps locus arch placement interesting}@anchor{f6b}@ref{f6b,,.arch.placement.interesting;} The computation will only consider new
regions of loci that are deemed interesting, that is, far from their
peak state. This will reduce the computational burden and avoid
jittering near a peak.

@cartouche
@quotation Note 
Details missing.
@end quotation
@end cartouche

@node Implementation<20>,Notes<6>,Architecture<7>,Locus manager
@anchor{design/locus implementation}@anchor{f6c}
@subsection Implementation


[missing]

@node Notes<6>,,Implementation<20>,Locus manager
@anchor{design/locus notes}@anchor{f6d}
@subsection Notes


@anchor{design/locus design mps locus idea change}@anchor{f6e}@ref{f6e,,.idea.change;} Even after the first segment, be prepared to change
your mind, if by the second segment a lot of new loci have been
created.

@anchor{design/locus design mps locus distance}@anchor{f6f}@ref{f6f,,.distance;} If the current state is far from a peak, there’s time to
reassign regions and for free space to appear (in fact, under the
steady arena assumption, enough free space `will' appear).

@anchor{design/locus design mps locus clear-pool}@anchor{f70}@ref{f70,,.clear-pool;} Need to have a function to deallocate all objects in a
pool, so that @code{PoolDestroy()} won’t have to be used for that
purpose.

@geindex garbage collection messages; design

@node GC messages,Debugging features for client objects,Locus manager,Old design
@anchor{design/message-gc doc}@anchor{f71}@anchor{design/message-gc design-message-gc}@anchor{f72}@anchor{design/message-gc gc-messages}@anchor{f73}
@section GC messages


@menu
* Introduction: Introduction<59>. 
* Overview: Overview<20>. 
* Introduction: Introduction<60>. 
* Purpose: Purpose<3>. 
* Names and parts:: 
* Lifecycle:: 
* Testing: Testing<7>. 

@end menu

@node Introduction<59>,Overview<20>,,GC messages
@anchor{design/message-gc design mps config}@anchor{f74}@anchor{design/message-gc introduction}@anchor{f75}
@subsection Introduction


@anchor{design/message-gc design mps config intro}@anchor{f76}@ref{f76,,.intro;} This document describes the design of the MPS garbage
collection messages. For a guide to the MPS message system in general,
see design.mps.message.

@anchor{design/message-gc design mps config readership}@anchor{f77}@ref{f77,,.readership;} Any MPS developer.

@node Overview<20>,Introduction<60>,Introduction<59>,GC messages
@anchor{design/message-gc overview}@anchor{f78}
@subsection Overview


The MPS provides two types of GC messages:


@itemize -

@item 
@ref{22a,,mps_message_type_gc_start()};

@item 
@ref{18d,,mps_message_type_gc()}.
@end itemize

They are called “trace start” and “trace end” messages in this
document and in most MPS source code.

@node Introduction<60>,Purpose<3>,Overview<20>,GC messages
@anchor{design/message-gc id1}@anchor{f79}
@subsection Introduction


The MPS posts a trace start message (@ref{22a,,mps_message_type_gc_start()})
near the start of every trace (but after calculating the condemned
set, so we can report how large it is).

The MPS posts a trace end message (@ref{18d,,mps_message_type_gc()}) near the
end of every trace.

These messages are extremely flexible: they can hold arbitrary
additional data simply by writing new accessor functions. If there is
more data to report at either of these two events, then there is a
good argument for adding it into these existing messages.

@cartouche
@quotation Note 
In previous versions of this design document, there was a partial
unimplemented design for an @code{mps_message_type_gc_generation()}
message. This would not have been a good design, because managing
and collating multiple messages is much more complex for both MPS
and client than using a single message. Richard Kistruck,
2008-12-19.
@end quotation
@end cartouche

@node Purpose<3>,Names and parts,Introduction<60>,GC messages
@anchor{design/message-gc purpose}@anchor{f7a}
@subsection Purpose


@anchor{design/message-gc design mps config purpose}@anchor{f7b}@ref{f7b,,.purpose;} The purpose of these messages is to allow the client
program to be aware of GC activity, in order to:


@itemize -

@item 
adjust its own behaviour programmatically;

@item 
show or report GC activity in a custom way, such as an in-client
display, in a log file, etc.
@end itemize

The main message content should be intelligible and helpful to
client-developers (with help from MPS staff if necessary). There may
be extra content that is only meaningful to MPS staff, to help us
diagnose client problems.

While there is some overlap with the Diagnostic Feedback system
(design.mps.diag@footnote{diag.html}) and the Telemetry system (design.mps.telemetry@footnote{telemetry.html}), the
main contrasts are that these GC messages are present in release
builds, are stable from release to release, and are designed to be
parsed by the client program.

@node Names and parts,Lifecycle,Purpose<3>,GC messages
@anchor{design/message-gc design-mps-diag}@anchor{f7c}@anchor{design/message-gc names-and-parts}@anchor{f7d}
@subsection Names and parts


Here’s a helpful list of the names used in the GC message system:

Implementation is mostly in the source file @code{traceanc.c} (trace
ancillary).


@multitable {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxx} 
@item

Internal name

@tab

“trace start”

@tab

“trace end”

@item

Internal type

@tab

@code{TraceStartMessage}

@tab

@code{TraceMessage}

@item

@code{ArenaStruct} member

@tab

@code{tsMessage[]}

@tab

@code{tMessage}

@item

Message type

@tab

@code{MessageTypeGCSTART}

@tab

@code{MessageTypeGC}

@item

External name

@tab

@code{mps_message_type_gc_start}

@tab

@code{mps_message_type_gc}

@end multitable


@cartouche
@quotation Note 
The names of these messages are unconventional; they should
properly be called “gc (or trace) `begin'” and “gc (or trace)
`end'”. But it’s much too late to change them now. Richard
Kistruck, 2008-12-15.
@end quotation
@end cartouche

Collectively, the trace-start and trace-end messages are called the
“trace id messages”, and they are managed by the functions
@code{TraceIdMessagesCheck()}, @code{TraceIdMessagesCreate()}, and @code{TraceIdMessagesDestroy()}.

The currently supported message-field accessor methods are:
@ref{22d,,mps_message_gc_start_why()}, @ref{22f,,mps_message_gc_live_size()},
@ref{230,,mps_message_gc_condemned_size()}, and
@ref{231,,mps_message_gc_not_condemned_size()}. These are documented in the
Reference Manual.

@node Lifecycle,Testing<7>,Names and parts,GC messages
@anchor{design/message-gc lifecycle}@anchor{f7e}
@subsection Lifecycle


@anchor{design/message-gc design mps config lifecycle}@anchor{f7f}@ref{f7f,,.lifecycle;} for each trace id, pre-allocate a pair of start/end
messages by calling @code{ControlAlloc()}. Then, when a trace runs using
that trace id, fill in and post these messages. As soon as the trace
has posted both messages, immediately pre-allocate a new pair of
messages, which wait in readiness for the next trace to use that
trace id.

@menu
* Requirements: Requirements<36>. 
* Storage:: 
* Creating and Posting:: 
* Getting and discarding:: 
* Final clearup:: 

@end menu

@node Requirements<36>,Storage,,Lifecycle
@anchor{design/message-gc requirements}@anchor{f80}
@subsubsection Requirements


@anchor{design/message-gc design mps config req no-start-alloc}@anchor{f81}@ref{f81,,.req.no-start-alloc;} Should avoid attempting to allocate memory at
trace start time. @anchor{design/message-gc design mps config req no-start-alloc why}@anchor{f82}@ref{f82,,.req.no-start-alloc.why;} There may be no free
memory at trace start time. Client would still like to hear about
collections in those circumstances.

@anchor{design/message-gc design mps config req queue}@anchor{f83}@ref{f83,,.req.queue;} Must support a client that enables, but does not
promptly retrieve, GC messages. Messages that have not yet been
retrieved must remain queued, and the client must be able to retrieve
them later without loss. It is not acceptable to stop issuing GC
messages for subsequent collections merely because messages from
previous collections have not yet been retrieved. @anchor{design/message-gc design mps config req queue why}@anchor{f84}@ref{f84,,.req.queue.why;}
This is because there is simply no reasonable way for a client to
guarantee that it always promptly collects GC messages.

@anchor{design/message-gc design mps config req match}@anchor{f85}@ref{f85,,.req.match;} Start and end messages should always match up: never
post one of the messages but fail to post the matching one.

@anchor{design/message-gc design mps config req match why}@anchor{f86}@ref{f86,,.req.match.why;} This makes client code much simpler – it does not
have to handle mismatching messages.

@anchor{design/message-gc design mps config req errors-not-direct}@anchor{f87}@ref{f87,,.req.errors-not-direct;} Errors (such as a @code{ControlAlloc()}
failure) cannot be reported directly to the client, because
collections often happen automatically, without an explicit client
call to the MPS interface.

@anchor{design/message-gc design mps config req multi-trace}@anchor{f88}@ref{f88,,.req.multi-trace;} Up to @code{TraceLIMIT} traces may be running, and
emitting start/end messages, simultaneously.

@anchor{design/message-gc design mps config req early}@anchor{f89}@ref{f89,,.req.early;} Nice to tell client as much as possible about the
collection in the start message, if we can.

@anchor{design/message-gc design mps config req similar}@anchor{f8a}@ref{f8a,,.req.similar;} Start and end messages are conceptually similar – it
is quite okay, and may be helpful to the client, for the same datum
(for example: the reason why the collection occurred) to be present in
both the start and end message.

@node Storage,Creating and Posting,Requirements<36>,Lifecycle
@anchor{design/message-gc storage}@anchor{f8b}
@subsubsection Storage


For each trace-id (@ref{f88,,.req.multi-trace}) a pair (@ref{f85,,.req.match}) of
start/end messages is dynamically allocated (@ref{f83,,.req.queue}) in advance
(@ref{f81,,.req.no-start-alloc}). Messages are allocated in the control pool
using @code{ControlAlloc()}.

@cartouche
@quotation Note 
Previous implementations of the trace start message used static
allocation. This does not satisfy @ref{f83,,.req.queue}. See also
job001570@footnote{https://www.ravenbrook.com/project/mps/issue/job001570/}. Richard Kistruck, 2008-12-15.
@end quotation
@end cartouche

Pointers to these messages are stored in @code{tsMessage[ti]} and
@code{tMessage[ti]} arrays in the @code{ArenaStruct}.

@cartouche
@quotation Note 
We must not> keep the pre-allocated messages, or pointers to them,
in @code{TraceStruct}: the memory for these structures is statically
allocated, but the values in them are re-initialised by
@code{TraceCreate()} each time the trace id is used, so the
@code{TraceStruct()} is invalid (that is: to be treated as random
uninitialised memory) when not being used by a trace. See also
job001989@footnote{https://www.ravenbrook.com/project/mps/issue/job001989/}. Richard Kistruck, 2008-12-15.
@end quotation
@end cartouche

@node Creating and Posting,Getting and discarding,Storage,Lifecycle
@anchor{design/message-gc creating-and-posting}@anchor{f8c}
@subsubsection Creating and Posting


In @code{ArenaCreate()} we use @code{TRACE_SET_ITER} to initialise the
@code{tsMessage[ti]} and @code{tMessage[ti]} pointers to @code{NULL}, and then
(when the control pool is ready) @code{TRACE_SET_ITER} calling
@code{TraceIdMessagesCreate()}. This performs the initial pre-allocation
of the trace start/end messages for each trace id. Allocation failure
is not tolerated here: it makes @code{ArenaCreate()} fail with an error
code, because the arena is deemed to be unreasonably small.

When a trace is running using trace id @code{ti}, it finds a
pre-allocated message via @code{tsMessage[ti]} or @code{tMessage[ti]} in the
@code{ArenaStruct()}, fills in and posts the message, and nulls-out the
pointer. (If the pointer was null, no message is sent; see below.) The
message is now reachable only from the arena message queue (but the
control pool also knows about it).

When the trace completes, it calls @code{TraceIdMessagesCreate()} for its
trace id. This performs the ongoing pre-allocation of the trace
start/end messages for the next use of this trace id. The expectation
is that, after a trace has completed, some memory will have been
reclaimed, and the @code{ControlAlloc()} will succeed.

But allocation failure here is permitted: if it happens, both the
start and the end messages are freed (if present). This means that,
for the next collection using this trace id, neither a start nor an
end message will be sent (@ref{f85,,.req.match}). There is no direct way to
report this failure to the client (@ref{f87,,.req.errors-not-direct}), so we
just increment the @code{droppedMessages} counter in the @code{ArenaStruct}.
This counter is available via the @code{MessagesDropped} telemetry event.

@node Getting and discarding,Final clearup,Creating and Posting,Lifecycle
@anchor{design/message-gc getting-and-discarding}@anchor{f8d}
@subsubsection Getting and discarding


If the client has not enabled that message type, the message is
discarded immediately when posted, calling @code{ControlFree()} and
reclaiming the memory.

If the client has enabled but never gets the message, it remains on
the message queue until @code{ArenaDestroy()}. Theoretically these
messages could accumulate forever until they exhaust memory. This is
intentional: the client should not enable a message type and then
never get it!

Otherwise, when the client gets a message, it is dropped from the
arena message queue: now only the client (and the control pool) hold
references to it. The client must call @ref{ee,,mps_message_discard()} once
it has finished using the message. This calls @code{ControlFree()} and
reclaims the memory.

If the client simply drops its reference, the memory will not be
reclaimed until @code{ArenaDestroy()}. This is intentional: the control
pool is not garbage-collected.

@node Final clearup,,Getting and discarding,Lifecycle
@anchor{design/message-gc final-clearup}@anchor{f8e}
@subsubsection Final clearup


Final clearup is performed at @code{ArenaDestroy()}, as follows:


@itemize -

@item 
Unused and unsent pre-allocated messages (one per trace id) are
freed with @code{TRACE_SET_ITER} calling @code{TraceIdMessagesDestroy()}
which calls the message Delete functions (and thereby
@code{ControlFree()}) on anything left in @code{tsMessage[ti]} and
@code{tMessage[ti]}.

@item 
Unretrieved messages are freed by emptying the arena message queue
with @ref{554,,MessageEmpty()}.

@item 
Retrieved but undiscarded messages are freed by destroying the
control pool.
@end itemize

@node Testing<7>,,Lifecycle,GC messages
@anchor{design/message-gc testing}@anchor{f8f}
@subsection Testing


The main test is “@code{zmess.c}”. See notes there.

Various other tests, including @code{amcss.c}, also collect and report
@ref{18d,,mps_message_type_gc()} and @ref{22a,,mps_message_type_gc_start()}.

@menu
* Coverage:: 

@end menu

@node Coverage,,,Testing<7>
@anchor{design/message-gc coverage}@anchor{f90}
@subsubsection Coverage


Current tests do not check:


@itemize -

@item 
The less common why-codes (reasons why a trace starts). These should
be added to @code{zmess.c}.
@end itemize

@geindex debugging; design

@node Debugging features for client objects,AMC pool class,GC messages,Old design
@anchor{design/object-debug doc}@anchor{f91}@anchor{design/object-debug debugging-features-for-client-objects}@anchor{f92}@anchor{design/object-debug design-object-debug}@anchor{f93}
@section Debugging features for client objects


@menu
* Introduction: Introduction<61>. 
* Overview: Overview<21>. 
* Requirements: Requirements<37>. 
* Solution ideas: Solution ideas<2>. 
* Architecture: Architecture<8>. 
* Client interface:: 
* Examples:: 
* Implementation: Implementation<21>. 

@end menu

@node Introduction<61>,Overview<21>,,Debugging features for client objects
@anchor{design/object-debug design mps object-debug}@anchor{f94}@anchor{design/object-debug introduction}@anchor{f95}
@subsection Introduction


@anchor{design/object-debug design mps object-debug intro}@anchor{f96}@ref{f96,,.intro;} This is the design for all the various debugging features
that MPS clients (and sometimes MPS developers) can use to discover
what is happening to their objects and the memory space.

@anchor{design/object-debug design mps object-debug readership}@anchor{f97}@ref{f97,,.readership;} MPS developers.

@node Overview<21>,Requirements<37>,Introduction<61>,Debugging features for client objects
@anchor{design/object-debug overview}@anchor{f98}
@subsection Overview


@anchor{design/object-debug design mps object-debug over fenceposts}@anchor{f99}@ref{f99,,.over.fenceposts;} In its current state, this document mostly talks
about fenceposts, straying a little into tagging where theses features
have an effect on each other.

@cartouche
@quotation Note 
There exist other documents that list other required features, and
propose interfaces and implementations. These will eventually be
folded into this one. Pekka P. Pirinen, 1998-09-10.
@end quotation
@end cartouche

@node Requirements<37>,Solution ideas<2>,Overview<21>,Debugging features for client objects
@anchor{design/object-debug requirements}@anchor{f9a}
@subsection Requirements


@anchor{design/object-debug design mps object-debug req fencepost}@anchor{f9b}@ref{f9b,,.req.fencepost;} Try to detect overwrites and underwrites of
allocated blocks by adding fenceposts (source req.product.??? VC++,
req.epcore.fun.debug.support).  [TODO: Locate the relevant product
requirement.  RB 2023-02-23]

@anchor{design/object-debug design mps object-debug req fencepost size}@anchor{f9c}@ref{f9c,,.req.fencepost.size;} The fenceposts should be at least 4 bytes on
either side or 8 bytes if on one side only, with an adjustable content
(although VC++ only has 4 bytes with pattern 0xFDFDFDFD, having
unwisely combined the implementation with other debug features).

@anchor{design/object-debug design mps object-debug req fencepost check}@anchor{f9d}@ref{f9d,,.req.fencepost.check;} There should be a function to check all the
fenceposts (source req.epcore.fun.debug.support).

@anchor{design/object-debug design mps object-debug req free-block}@anchor{f9e}@ref{f9e,,.req.free-block;} Try to detect attempts to write and read free
blocks.

@anchor{design/object-debug design mps object-debug req walk}@anchor{f9f}@ref{f9f,,.req.walk;} There should be a way to map (“walk”) a user function
over all allocated objects (except PS VM objects), possibly only in a
separate debugging variety/mode (source req.epcore.fun.debug.support).

@anchor{design/object-debug design mps object-debug req tag}@anchor{fa0}@ref{fa0,,.req.tag;} There should be a way to store at least a word of user
data (a “tag”, borrowing the SW term) with every object in debugging
mode, to be used in memory dumps (source req.product.??? VC++).
[TODO: Locate the relevant product requirement.  RB 2023-02-23]

@anchor{design/object-debug design mps object-debug req tag walk}@anchor{fa1}@ref{fa1,,.req.tag.walk;} The walking function (as required by @ref{f9f,,.req.walk})
should have access to this data (source req.epcore.fun.debug.support).

@anchor{design/object-debug design mps object-debug req dump aver}@anchor{fa2}@ref{fa2,,.req.dump.aver;} It must be possible to perform a memory dump after
an @code{AVER()} has fired. Naturally, if the information required for
the dump has been corrupted, it will fail, as softly as possible
(source @@@@@@@@).

@anchor{design/object-debug design mps object-debug req portable}@anchor{fa3}@ref{fa3,,.req.portable;} Client code that uses these features must be easily
portable to all the supported platforms. (Source: job003749@footnote{https://www.ravenbrook.com/project/mps/issue/job003749/}.)

@cartouche
@quotation Note 
There are more requirements, especially about memory dumps and
allocation locations. Pekka P. Pirinen, 1998-09-10.
@end quotation
@end cartouche

@node Solution ideas<2>,Architecture<8>,Requirements<37>,Debugging features for client objects
@anchor{design/object-debug solution-ideas}@anchor{fa4}
@subsection Solution ideas


@anchor{design/object-debug design mps object-debug note assumptions}@anchor{fa5}@ref{fa5,,.note.assumptions;} I’ve tried not to assume anything about the
coincidence of manual/automatic, formatted/unformatted, and
ap/mps_alloc. I think those questions deserve to be decided on their
own merits. instead of being constrained by a debug feature.

@anchor{design/object-debug design mps object-debug fence content repeat}@anchor{fa6}@ref{fa6,,.fence.content.repeat;} The content of a fencepost could be
specified as a byte/word which used repeatedly to fill the fencepost.

@anchor{design/object-debug design mps object-debug fence content template}@anchor{fa7}@ref{fa7,,.fence.content.template;} The content could be given as a template
which is of the right size and is simply copied onto the fencepost.

@anchor{design/object-debug design mps object-debug fence content template repeat}@anchor{fa8}@ref{fa8,,.fence.content.template.repeat;} The content could be given as a
template which is copied repeatedly until the fencepost is full. (This
would avoid the need to specify different templates on different
architectures, and so help meet @ref{fa3,,.req.portable}.)

@anchor{design/object-debug design mps object-debug fence walk}@anchor{fa9}@ref{fa9,,.fence.walk;} @ref{f9d,,.req.fencepost.check} requires the ability to find
all the allocated objects. In formatted pools, this is not a problem.
In unformatted pools, we could use the walker. It’s a feasible
strategy to bet that any pool that might have to support fenceposting
will also have a walking requirement.

@anchor{design/object-debug design mps object-debug fence tag}@anchor{faa}@ref{faa,,.fence.tag;} Fenceposting also needs to keep track which objects
have fenceposts. unless we manage to do them all. It would be easiest
to put this in the tags.

@anchor{design/object-debug design mps object-debug fence check object}@anchor{fab}@ref{fab,,.fence.check.object;} A function to check the fenceposts on a given
object would be nice.

@anchor{design/object-debug design mps object-debug fence ap}@anchor{fac}@ref{fac,,.fence.ap;} AP’s could support fenceposting transparently by having
a mode where @ref{b0,,mps_reserve()} always goes out-of-line and fills in the
fenceposts (the pool’s @ref{7a2,,BufferFill()} method isn’t involved). This
would leave the MPS with more freedom of implementation, especially
when combined with some of the other ideas. We think doing a function
call for every allocation is not too bad for debugging.

@anchor{design/object-debug design mps object-debug fence outside-ap}@anchor{fad}@ref{fad,,.fence.outside-ap;} We could also let the client insert their own
fenceposts outside the MPS allocation mechanism. Even if fenceposting
were done like this, we’d still want it to be an MPS feature, so we’d
offer sample C macros for adding the size of the fencepost and filling
in the fencepost pattern. Possibly something like this (while we could
still store the parameters in the pool or allocation point, there
seems little point in doing so in this case, and having them as
explicit parameters to the macros allows the client to specify
constants to gain efficiency):

@example
#define mps_add_fencepost(size, fp_size)
#define mps_fill_fenceposts(obj, size, fp_size, fp_pattern)
@end example

The client would need to supply their own fencepost checking function,
obviously, but again we could offer one that matches the sample
macros.

@anchor{design/object-debug design mps object-debug fence tail-only}@anchor{fae}@ref{fae,,.fence.tail-only;} In automatic pools, the presence of a fencepost
at the head of the allocated block results in the object reference
being an internal pointer. This means that the format or the pool
would need to know about fenceposting and convert between references
and pointers. This would slow down the critical path when fenceposting
is used. This can be ameliorated by putting a fencepost at the tail of
the block only: this obviates the internal pointer problem and could
provide almost the same degree of checking (provided the size was
twice as large), especially in copying pools, where there are normally
no gaps between allocated blocks. In addition to the inescapable
effects on allocation and freeing (including copying and reclaim
thereunder), only scanning would have to know about fenceposts.

@anchor{design/object-debug design mps object-debug fence tail-only under}@anchor{faf}@ref{faf,,.fence.tail-only.under;} Walking over all the objects in the pool
would be necessary to detect underwrites, as one couldn’t be sure that
there is a fencepost before any given object (or where it’s located
exactly). If the pool were doing the checking, it could be sure: it
would know about alignments and it could put fenceposts in padding
objects (free blocks will have them because they were once allocated)
so there’d be one on either side of any object (except at the head of
a segment, which is not a major problem, and could be fixed by adding
a padding object at the beginning of every segment). This requires
some cleverness to avoid splinters smaller than the fencepost size,
but it can be done.

@anchor{design/object-debug design mps object-debug fence wrapper}@anchor{fb0}@ref{fb0,,.fence.wrapper;} On formatted pools, fenceposting could be
implemented by “wrapping” the client-supplied format at creation time.
The wrapper can handle the conversion from the fenceposted object and
back. This will be invisible to the client and gives the added benefit
that the wrapper can validate fenceposts on every format operation,
should it desire. That is, the pool would see the fenceposts as part
of the client object, but the client would only see its object; the
format wrapper would translate between the two. Note that hiding the
fenceposts from scan methods, which are required to take a contiguous
range of objects, is a bit complicated.

@anchor{design/object-debug design mps object-debug fence client-format}@anchor{fb1}@ref{fb1,,.fence.client-format;} The MPS would supply such a wrapper, but
clients could also be allowed to write their own fenceposted formats
(provided they coordinate with allocation, see below). This would make
scanning fenceposted segments more efficient.

@anchor{design/object-debug design mps object-debug fence wrapper variable}@anchor{fb2}@ref{fb2,,.fence.wrapper.variable;} Furthermore, you could create different
classes of fencepost within a pool, because the fencepost itself could
have a variable format. For instance, you might choose to have the
fencepost be minimal (one to two words) for small objects, and more
detailed/complex for large objects (imagining that large objects are
likely vector-ish and subject to overruns). You could get really fancy
and have the fencepost class keyed to the object class (for example,
different allocation points create different classes of fenceposting).

@anchor{design/object-debug design mps object-debug fence wrapper alloc}@anchor{fb3}@ref{fb3,,.fence.wrapper.alloc;} Even with a wrapped format, allocation and
freeing would still have know about the fenceposts. If allocation
points are used, either MPS-side (@ref{fac,,.fence.ap}) or client-side
(@ref{fad,,.fence.outside-ap}) fenceposting could be used, with the obvious
modifications.

@anchor{design/object-debug design mps object-debug fence wrapper alloc format}@anchor{fb4}@ref{fb4,,.fence.wrapper.alloc.format;} We could add three format methods, to
adjust the pointer and the size for alloc and free, to put down the
fenceposts during alloc, and to check them; to avoid slowing down all
allocation, this would require some MOPping to make the format class
affect the choice of the alloc and free methods (see
mail.pekka.1998-06-11.18-18@footnote{https://info.ravenbrook.com/project/mps/mail/1998/06/11/18-18/0.txt}).

@anchor{design/object-debug design mps object-debug fence wrapper alloc size}@anchor{fb5}@ref{fb5,,.fence.wrapper.alloc.size;} We could just communicate the size of
the fenceposts between the format and the allocation routines, but
then you couldn’t use variable fenceposts
(@ref{fb2,,.fence.wrapper.variable}).

@cartouche
@quotation Note 
All this applies to copying and reclaim in a straight-forward
manner, I think.
@end quotation
@end cartouche

@anchor{design/object-debug design mps object-debug fence pool wrapper}@anchor{fb6}@ref{fb6,,.fence.pool.wrapper;} Pools can be wrapped as well. This could be a
natural way to represent/implement the fenceposting changes to the
Alloc and Free methods. [@@@@@@@@alignment]

@anchor{design/object-debug design mps object-debug fence pool new-class}@anchor{fb7}@ref{fb7,,.fence.pool.new-class;} We could simply offer a debugging version of
each pool class (e.g., @code{mps_pool_class_mv_debug()}). As we have seen,
debugging features have synergies which make it advantageous to have a
coordinated implementation, so splitting them up would not just
complicate the client interface, it would also be an implementation
problem; we can turn features on or off with pool init parameters.

@anchor{design/object-debug design mps object-debug fence pool abstract}@anchor{fb8}@ref{fb8,,.fence.pool.abstract;} We could simply use pool init parameters only
to control all debugging features (optargs would be useful here).
While there might be subclasses and wrappers internally, the client
would only see a single pool class; in the internal view, this would
be an abstract class, and the parameters would determine which
concrete class actually gets instantiated.

@anchor{design/object-debug design mps object-debug tag out-of-line}@anchor{fb9}@ref{fb9,,.tag.out-of-line;} It would be nice if tags were stored out-of-line,
so they can be used to study allocation patterns and fragmentation
behaviours. Such an implementation of tagging could also easily be
shared among several pools.

@node Architecture<8>,Client interface,Solution ideas<2>,Debugging features for client objects
@anchor{design/object-debug architecture}@anchor{fba}
@subsection Architecture


@anchor{design/object-debug design mps object-debug pool}@anchor{fbb}@ref{fbb,,.pool;} The implementation is at the pool level, because pools
manage allocated objects. A lot of the code will be generic,
naturally, but the data structures and the control interfaces attach
to pools. In particular, clients will be able to use tagging and
fenceposting separately on each pool.

@anchor{design/object-debug design mps object-debug fence size}@anchor{fbc}@ref{fbc,,.fence.size;} Having fenceposts of adjustable size and pattern is
useful. Restricting the size to an integral multiple of the [pool or
format?] alignment would simplify the implementation but breaks
@ref{fa3,,.req.portable}.

@anchor{design/object-debug design mps object-debug fence template}@anchor{fbd}@ref{fbd,,.fence.template;} We use templates (@ref{fa7,,.fence.content.template}) to
fill in the fenceposts, but we do not give any guarantees about the
location of the fenceposts. This leaves us the opportunity to do
tail-only fenceposting, if we choose.

@anchor{design/object-debug design mps object-debug fence slop}@anchor{fbe}@ref{fbe,,.fence.slop;} [see impl.c.dbgpool.FenceAlloc @@@@@@@@]

@anchor{design/object-debug design mps object-debug fence check free}@anchor{fbf}@ref{fbf,,.fence.check.free;} We check the fenceposts when freeing an object.

@anchor{design/object-debug design mps object-debug unified-walk}@anchor{fc0}@ref{fc0,,.unified-walk;} Combine the walking and tagging requirements
(@ref{fa1,,.req.tag.walk} and @@@@@@@@) into a generic facility for walking and
tagging objects with just one interface and one name: tagging. Also
combine the existing formatted object walker into this metaphor, but
allowing the format and tag parameters of the step function be
optional.

@cartouche
@quotation Note 
This part has not been implemented yet Pekka P. Pirinen,
1998-09-10.
@end quotation
@end cartouche

@anchor{design/object-debug design mps object-debug init}@anchor{fc1}@ref{fc1,,.init;} It simplifies the implementation of both tagging and
fenceposting if they are always on, so that we don’t have to keep
track of which objects have been fenceposted and which have not, and
don’t have to have three kinds of tags: for user data, for
fenceposting, and for both. So we determine this at pool init time
(and let fenceposting turn on tagging, if necessary).

@anchor{design/object-debug design mps object-debug pool-parameters}@anchor{fc2}@ref{fc2,,.pool-parameters;} Fencepost templates and tag formats are passed in
as pool parameters.

@anchor{design/object-debug design mps object-debug modularity}@anchor{fc3}@ref{fc3,,.modularity;} While a combined generic implementation of tags and
fenceposts is provided, it is structured so that each part of it could
be implemented by a pool-specific mechanism with a minimum of new
protocol.

@cartouche
@quotation Note 
This will be improved, when we figure out formatted pools – they
don’t need tags for fenceposting.
@end quotation
@end cartouche

@anchor{design/object-debug design mps object-debug out-of-space}@anchor{fc4}@ref{fc4,,.out-of-space;} If there’s no room for tags, we just fail to
allocate the tag. We free the block allocated for the object and fail
the allocation, so that the client gets a chance to do whatever
low-memory actions they might want to do.

This breaks the one-to-one relationship between tags and objects, so
some checks cannot be made, but we do count the “lost” tags.

@cartouche
@quotation Note 
Need to hash out how to do fenceposting in formatted pools.
@end quotation
@end cartouche

@node Client interface,Examples,Architecture<8>,Debugging features for client objects
@anchor{design/object-debug client-interface}@anchor{fc5}
@subsection Client interface


@anchor{design/object-debug design mps object-debug interface fenceposting check}@anchor{fc6}@ref{fc6,,.interface.fenceposting.check;}
@ref{280,,mps_pool_check_fenceposts()} is a function to check all
fenceposts in a pool (@code{AVER()} if a problem is found)

@cartouche
@quotation Note 
From here on, these are tentative and incomplete.
@end quotation
@end cartouche

@geindex mps_fmt_fencepost_wrap (C function)
@anchor{design/object-debug c mps_fmt_fencepost_wrap}@anchor{fc7}
@deffn {C Function} @ref{14d,,mps_res_t} mps_fmt_fencepost_wrap (mps_fmt_t *format_return, mps_arena_t arena, mps_fmt_t format, ...)
@end deffn

@anchor{design/object-debug design mps object-debug interface fenceposting format}@anchor{fc8}@ref{fc8,,.interface.fenceposting.format;} A function to wrap a format
(class) to provide fenceposting.

@geindex mps_fmt_adjust_fencepost_t (C type)
@anchor{design/object-debug c mps_fmt_adjust_fencepost_t}@anchor{fc9}
@deffn {C Type} typedef void (*mps_fmt_adjust_fencepost_t)(size_t *size_io)
@end deffn

@anchor{design/object-debug design mps object-debug interface fenceposting adjust}@anchor{fca}@ref{fca,,.interface.fenceposting.adjust;} A format method to adjust size of a
block about to be allocated to allow for fenceposts.

@geindex mps_fmt_put_fencepost_t (C type)
@anchor{design/object-debug c mps_fmt_put_fencepost_t}@anchor{fcb}
@deffn {C Type} typedef void (*mps_fmt_put_fencepost_t)(@ref{11d,,mps_addr_t} *addr_io, size_t size)
@end deffn

@anchor{design/object-debug design mps object-debug interface fenceposting add}@anchor{fcc}@ref{fcc,,.interface.fenceposting.add;} A format method to add a fencepost
around a block about to be allocated. The @code{NULL} method adds a tail
fencepost.

@geindex mps_fmt_check_fenceposts_t (C type)
@anchor{design/object-debug c mps_fmt_check_fenceposts_t}@anchor{fcd}
@deffn {C Type} typedef @ref{129,,mps_bool_t} (*mps_fmt_check_fenceposts_t)(@ref{11d,,mps_addr_t})
@end deffn

@anchor{design/object-debug design mps object-debug interface fenceposting checker}@anchor{fce}@ref{fce,,.interface.fenceposting.checker;} A format method to check the
fenceposts around an object. The @code{NULL} method checks tails.

@geindex mps_alloc_dbg (C function)
@anchor{design/object-debug c mps_alloc_dbg}@anchor{fcf}
@deffn {C Function} @ref{14d,,mps_res_t} mps_alloc_dbg (mps_addr_t*, mps_pool_t, size_t, ...)
@end deffn

@geindex mps_alloc_dbg_v (C function)
@anchor{design/object-debug c mps_alloc_dbg_v}@anchor{fd0}
@deffn {C Function} @ref{14d,,mps_res_t} mps_alloc_dbg_v (mps_addr_t*, mps_pool_t, size_t, va_list)
@end deffn

@anchor{design/object-debug design mps object-debug interface tags alloc}@anchor{fd1}@ref{fd1,,.interface.tags.alloc;} Two functions to extend the existing
@ref{ad,,mps_alloc()} (request.???.??? proposes to remove the varargs)
[TODO: Locate the relevant Harlequin request.  RB 2023-02-23]

@geindex mps_objects_step_t (C type)
@anchor{design/object-debug c mps_objects_step_t}@anchor{fd2}
@deffn {C Type} typedef void (*mps_objects_step_t)(@ref{11d,,mps_addr_t} addr, size_t size, @ref{141,,mps_fmt_t} format, @ref{1b1,,mps_pool_t} pool, void *tag_data, void *p)
@end deffn

@anchor{design/object-debug design mps object-debug interface tags walker type}@anchor{fd3}@ref{fd3,,.interface.tags.walker.type;} Type of walker function for
@ref{1a6,,mps_pool_walk()} and @code{mps_arena_walk()}.

@anchor{design/object-debug design mps object-debug interface tags walker}@anchor{fd4}@ref{fd4,,.interface.tags.walker;} Functions to walk all the allocated
objects in an arena (only client pools in this case),
@code{format} and @code{tag_data} can be @code{NULL} (@code{tag_data} really wants
to be @code{void *}, not @ref{11d,,mps_addr_t}, because it’s stored
together with the internal tag data in an MPS internal pool)

@node Examples,Implementation<21>,Client interface,Debugging features for client objects
@anchor{design/object-debug examples}@anchor{fd5}
@subsection Examples


@anchor{design/object-debug design mps object-debug example debug-alloc}@anchor{fd6}@ref{fd6,,.example.debug-alloc;}

@example
#define MPS_ALLOC_DBG(res_io, addr_io, pool, size)
  MPS_BEGIN
    static mps_tag_A_s _ts = @{ __FILE__, __LINE__ @};

    *res_io = mps_alloc(addr_io, pool, size, _ts_)
  MPS_END
@end example

@node Implementation<21>,,Examples,Debugging features for client objects
@anchor{design/object-debug implementation}@anchor{fd7}
@subsection Implementation


@anchor{design/object-debug design mps object-debug new-pool}@anchor{fd8}@ref{fd8,,.new-pool;} The client interface to control fenceposting
consists of the new classes @code{mps_pool_class_mv_debug()},
@code{mps_pool_class_epdl_debug()}, and
@code{mps_pool_class_epdr_debug()}, and their new init parameter of
type @ref{143,,mps_pool_debug_option_s}.

@cartouche
@quotation Note 
This is a temporary solution, to get it out without writing lots
of new interface. Pekka P. Pirinen, 1998-09-10.
@end quotation
@end cartouche

@anchor{design/object-debug design mps object-debug new-pool impl}@anchor{fd9}@ref{fd9,,.new-pool.impl;} The debug pools are implemented using the “class
wrapper” @code{EnsureDebugClass()}, which produces a subclass with
modified @code{init}, @code{finish}, @code{alloc}, and @code{free} methods. These
methods are implemented in the generic debug class code
(@code{impl.c.dbgpool}), and are basically wrappers around the superclass
methods (invoked through the @code{pool->class->super} field). To find
the data stored in the class for the debugging features, they use the
@code{debugMixin} method provided by the subclass. So to make a debug
subclass, three things should be provided: a structure definition of
the instance containing a @code{PoolDebugMixinStruct}, a pool class
function that uses @code{EnsureDebugClass()}, and a @code{debugMixin} method
that locates the @code{PoolDebugMixinStruct} within an instance.

@anchor{design/object-debug design mps object-debug tags splay}@anchor{fda}@ref{fda,,.tags.splay;} The tags are stored in a splay tree of tags
allocated from a subsidiary MFS pool. The client needs to specify the
(maximum) size of the client data in a tag, so that the pool can be
created.

@cartouche
@quotation Note 
Lots more should be said, eventually. Pekka P. Pirinen,
1998-09-10.
@end quotation
@end cartouche

@geindex AMC pool class; design
@geindex pool class; AMC design

@node AMC pool class,AMS pool class,Debugging features for client objects,Old design
@anchor{design/poolamc doc}@anchor{fdb}@anchor{design/poolamc amc-pool-class}@anchor{fdc}@anchor{design/poolamc design-poolamc}@anchor{fdd}
@section AMC pool class


@menu
* Guide Introduction:: 
* Guide: Guide<2>. 
* Initial design:: 

@end menu

@node Guide Introduction,Guide<2>,,AMC pool class
@anchor{design/poolamc design mps poolamc}@anchor{fde}@anchor{design/poolamc guide-introduction}@anchor{fdf}
@subsection Guide Introduction


@c The intro and readership tags were found to be duplicated by
@c changelist 182116 / commit e9841d23a but not referenced.  But that
@c was just a consequence of two documents being smushed together by
@c RHSK in changelist 168424 / commit b0433b3e9: a guide and a design.
@c It would be good to sort that out.  See also
@c <https://github.com/Ravenbrook/mps/issues/128>.  RB 2023-01-14

@anchor{design/poolamc design mps poolamc guide intro}@anchor{fe0}@ref{fe0,,.guide.intro;} This document contains a guide (@ref{fe1,,.guide}) to the MPS AMC
pool class, followed by the historical initial design
(@ref{fe2,,.initial-design}).

@anchor{design/poolamc design mps poolamc guide readership}@anchor{fe3}@ref{fe3,,.guide.readership;} Any MPS developer.

@node Guide<2>,Initial design,Guide Introduction,AMC pool class
@anchor{design/poolamc guide}@anchor{fe4}
@subsection Guide


@anchor{design/poolamc design mps poolamc guide}@anchor{fe1}@ref{fe1,,.guide;} The AMC pool class is a general-purpose automatic
(collecting) pool class. It is intended for most client objects. AMC
is “Automatic, Mostly Copying”: it preserves objects by copying,
except when an ambiguous reference ‘nails’ the object in place. It is
generational. Chain: specify capacity and mortality of generations 0
to `N' − 1. Survivors from generation `N' − 1 get promoted into an
arena-wide “top” generation (often anachronistically called the
“dynamic” generation, which was the term on the Lisp Machine).

@menu
* Segment states:: 
* Pads:: 
* Placement pads are okay:: 
* Retained pads could be a problem:: 
* Small@comma{} medium@comma{} and large segments: Small medium and large segments. 
* The LSP payoff calculation:: 
* Retained pages:: 
* Feedback about retained pages:: 

@end menu

@node Segment states,Pads,,Guide<2>
@anchor{design/poolamc segment-states}@anchor{fe5}
@subsubsection Segment states


@anchor{design/poolamc design mps poolamc seg state}@anchor{fe6}@ref{fe6,,.seg.state;} AMC segments are in one of three states: “mobile”,
“boarded”, or “stuck”.

@anchor{design/poolamc design mps poolamc seg state mobile}@anchor{fe7}@ref{fe7,,.seg.state.mobile;} Segments are normally `mobile': all objects on
the seg are un-nailed, and thus may be preserved by copying.

@anchor{design/poolamc design mps poolamc seg state boarded}@anchor{fe8}@ref{fe8,,.seg.state.boarded;} An ambiguous reference to any address within an
segment makes that segment `boarded': a nailboard is allocated to
record ambiguous references (“nails”), but un-nailed objects on the
segment are still preserved by copying.

@anchor{design/poolamc design mps poolamc seg state stuck}@anchor{fe9}@ref{fe9,,.seg.state.stuck;} Stuck segments only occur in emergency tracing: a
discovery fix to an object in a mobile segment is recorded in the only
non-allocating way available: by making the entire segment `stuck'.

@node Pads,Placement pads are okay,Segment states,Guide<2>
@anchor{design/poolamc pads}@anchor{fea}
@subsubsection Pads


(See job001809@footnote{https://www.ravenbrook.com/project/mps/issue/job001809/} and job001811@footnote{https://www.ravenbrook.com/project/mps/issue/job001811/}, and mps/branch/2009-03-31/padding.)

@anchor{design/poolamc design mps poolamc pad}@anchor{feb}@ref{feb,,.pad;} A pad is logically a trivial client object. Pads are created
by the MPS asking the client’s format code to create them, to fill up
a space in a segment. Thereafter, the pad appears to the MPS as a
normal client object (that is: the MPS cannot distinguish a pad from a
client object).

@anchor{design/poolamc design mps poolamc pad reason}@anchor{fec}@ref{fec,,.pad.reason;} AMC creates pads for three reasons: buffer empty
fragment (BEF), large segment padding (LSP), and non-mobile reclaim
(NMR). (Large segment pads were new with job001811@footnote{https://www.ravenbrook.com/project/mps/issue/job001811/}.)

@anchor{design/poolamc design mps poolamc pad reason bef}@anchor{fed}@ref{fed,,.pad.reason.bef;} Buffer empty fragment (BEF) pads are made by
@ref{fee,,amcSegBufferEmpty()} whenever it detaches a non-empty buffer from
an AMC segment. Buffer detachment is most often caused because the
buffer is too small for the current buffer reserve request (which may
be either a client requested or a forwarding allocation). Detachment
may happen for other reasons, such as trace flip.

@anchor{design/poolamc design mps poolamc pad reason lsp}@anchor{fef}@ref{fef,,.pad.reason.lsp;} Large segment padding (LSP) pads are made by
@ref{903,,AMCBufferFill()} when the requested fill size is “large” (see @ref{ff0,,The LSP payoff calculation} below). @ref{903,,AMCBufferFill()} fills the buffer
to exactly the size requested by the current buffer reserve operation;
that is: it does not round up to the whole segment size. This prevents
subsequent small objects being placed in the same segment as a single
very large object. If the buffer fill size is less than the segment
size, @ref{903,,AMCBufferFill()} fills any remainder with a large segment
pad.

@anchor{design/poolamc design mps poolamc pad reason nmr}@anchor{ff1}@ref{ff1,,.pad.reason.nmr;} Non-mobile reclaim (NMR) pads are made by
@code{amcSegReclaimNailed()}, when performing reclaim on a non-mobile (that
is, either boarded or stuck) segment:

The more common NMR scenario is reclaim of a boarded segment after a
non-emergency trace. Ambiguous references into the segment are
recorded as nails. Subsequent exact references to a nailed object do
nothing further, but exact refs that do not match a nail cause
preserve-by-copy and leave a forwarding object. Unreachable objects
are not touched during the scan+fix part of the trace. On reclaim,
only nailed objects need to be preserved; others (namely forwarding
pointers and unreachable objects) are replaced by an NMR pad. (Note
that a BEF or LSP pad appears to be an unreachable object, and is
therefore overwritten by an NMR pad).

The less common NMR scenario is after emergency tracing. Boarded
segments still occur; they may have nailed objects from ambiguous
references, forwarding objects from pre-emergency exact fixes, nailed
objects from mid-emergency exact fixes, and unpreserved objects;
reclaim is as in the non-emergency case. Stuck segments may have
forwarding objects from pre-emergency exact fixes, objects from
mid-emergency fixes, and unreachable objects – but the latter two are
not distinguishable because there is no nailboard. On reclaim, all
objects except forwarding pointers are preserved; each forwarding
object is replaced by an NMR pad.

If @code{amcSegReclaimNailed()} finds no objects to be preserved then it
calls @code{SegFree()} (new with job001809@footnote{https://www.ravenbrook.com/project/mps/issue/job001809/}).

@node Placement pads are okay,Retained pads could be a problem,Pads,Guide<2>
@anchor{design/poolamc placement-pads-are-okay}@anchor{ff2}
@subsubsection Placement pads are okay


Placement pads are the BEF and LSP pads created in “to-space” when
placing objects into segments. This wasted space is an expected
space-cost of AMC’s naive (but time-efficient) approach to placement
of objects into segments. This is normally not a severe problem. (The
worst case is a client that always requests @code{amc->extendBy + 1} byte
objects: this has an overhead of nearly @code{ArenaGrainSize() / amc->extendBy}).

@node Retained pads could be a problem,Small medium and large segments,Placement pads are okay,Guide<2>
@anchor{design/poolamc retained-pads-could-be-a-problem}@anchor{ff3}
@subsubsection Retained pads could be a problem


Retained pads are the NMR pads stuck in “from-space”: non-mobile
segments that were condemned but have preserved-in-place objects
cannot be freed by @code{amcSegReclaimNailed()}. The space around the
preserved objects is filled with NMR pads.

In the worst case, retained pads could waste an enormous amount of
space! A small (one-byte) object could retain a multi-page segment for
as long as the ambiguous reference persists; that is: indefinitely.
Imagine a 256-page (1 MiB) segment containing a very large object
followed by a handful of small objects. An ambiguous reference to one
of the small objects will unfortunately cause the entire 256-page
segment to be retained, mostly as an NMR pad; this is a massive
overhead of wasted space.

AMC mitigates this worst-case behaviour, by treating large segments
specially.

@node Small medium and large segments,The LSP payoff calculation,Retained pads could be a problem,Guide<2>
@anchor{design/poolamc small-medium-and-large-segments}@anchor{ff4}
@subsubsection Small, medium, and large segments


AMC categorises segments as `small' (up to @code{amc->extendBy}), `medium'
(larger than small but smaller than large), or `large' (@code{amc->largeSize} or
more):

@example
size = SegSize(seg);
if(size < amc->extendBy) @{
  /* small */
@} else if(size < amc->largeSize) @{
  /* medium */
@} else @{
  /* large */
@}</code></pre></blockquote>
@end example

@code{amc->extendBy} defaults to 4096 (rounded up to the arena
alignment), and is settable by using @code{MPS_KEY_EXTEND_BY} keyword
argument. @code{amc->largeSize} is currently 32768 – see @ref{ff0,,The LSP payoff calculation} below.

AMC might treat “Large” segments specially, in two ways:


@itemize -

@item 
@anchor{design/poolamc design mps poolamc large single-reserve}@anchor{ff5}@ref{ff5,,.large.single-reserve;} A large segment is only used for a single
(large) buffer reserve request; the remainder of the segment (if
any) is immediately padded with an LSP pad.

@item 
@anchor{design/poolamc design mps poolamc large lsp-no-retain}@anchor{ff6}@ref{ff6,,.large.lsp-no-retain;} Nails to such an LSP pad do not cause
@code{amcSegReclaimNailed()} to retain the segment.
@end itemize

@ref{ff5,,.large.single-reserve} is implemented. See job001811@footnote{https://www.ravenbrook.com/project/mps/issue/job001811/}.

@ref{ff6,,.large.lsp-no-retain} is `not' currently implemented.

The point of @ref{ff6,,.large.lsp-no-retain} would be to avoid retention of
the (large) segment when there is a spurious ambiguous reference to
the LSP pad at the end of the segment. Such an ambiguous reference
might happen naturally and repeatably if the preceding large object is
an array, the array is accessed by an ambiguous element pointer (for
example, on the stack), and the element pointer ends up pointing just
off the end of the large object (as is normal for sequential element
access in C) and remains with that value for a while. (Such an
ambiguous reference could also occur by chance, for example, by
coincidence with an @code{int} or @code{float}, or when the stack grows to
include old unerased values).

Implementing @ref{ff6,,.large.lsp-no-retain} is a little tricky. A pad is
indistinguishable from a client object, so AMC has no direct way to
detect, and safely ignore, the final LSP object in the seg. If AMC
could `guarantee' that the single buffer reserve
(@ref{ff5,,.large.single-reserve}) is only used for a single `object', then
@code{amcSegReclaimNailed()} could honour a nail at the start of a large
seg and ignore all others; this would be extremely simple to
implement. But AMC cannot guarantee this, because in the MPS
Allocation Point Protocol the client is permitted to make a large
buffer reserve and then fill it with many small objects. In such a
case, AMC must honour all nails (if the buffer reserve request was an
exact multiple of the arena grain size), or all nails except to the
last object (if there was a remainder filled with an LSP pad). Because
an LSP pad cannot be distinguished from a client object, and the
requested allocation size is not recorded, AMC cannot distinguish
these two conditions at reclaim time. Therefore AMC must record
whether or not the last object in the seg is a pad, in order to ignore
nails to it. This could be done by adding a flag to @code{AMCSegStruct}.
(This can be done without increasing the structure size, by making the
@code{Bool new} field smaller than its current 32 bits.)

@node The LSP payoff calculation,Retained pages,Small medium and large segments,Guide<2>
@anchor{design/poolamc the-lsp-payoff-calculation}@anchor{ff0}
@subsubsection The LSP payoff calculation


The LSP fix for job001811@footnote{https://www.ravenbrook.com/project/mps/issue/job001811/} treats large segments differently. Without
it, after allocating a very large object (in a new very large
multi-page segment), MPS would happily place subsequent small objects
in any remaining space at the end of the segment. This would risk
pathological fragmentation: if these small objects were systematically
preserved by ambiguous refs, enormous NMR pads would be retained along
with them.

The payoff calculation is a bit like deciding whether or not to
purchase insurance. For single-page and medium-sized segments, we go
ahead and use the remaining space for subsequent small objects. This
is equivalent to choosing `not' to purchase insurance. If the small
objects were to be preserved by ambiguous refs, the retained NMR pads
would be big, but not massive. We expect such ambiguous refs to be
uncommon, so we choose to live with this slight risk of bad
fragmentation. The benefit is that the remaining space is used.

For large segments, we decide that the risk of using the remainder is
just too great, and the benefit too small, so we throw it away as an
LSP pad. This is equivalent to purchasing insurance: we choose to pay
a known small cost every time, to avoid risking an occasional
disaster.

To decide what size of segment counts as “large”, we must decide how
much uninsured risk we can tolerate, versus how much insurance cost we
can tolerate. The likelihood of ambiguous references retaining objects
is entirely dependent on client behaviour. However, as a sufficient
“one size fits all” policy, I (RHSK 2009-09-14) have judged that
segments smaller than eight pages long do not need to be treated as
large: the insurance cost to “play safe” would be considerable
(wasting up to one page of remainder per seven pages of allocation),
and the fragmentation overhead risk is not that great (at most eight
times worse than the unavoidable minimum). So @code{AMC_LARGE_SIZE_DEFAULT} is
defined as 32768 in config.h. As long as the assumption that most segments
are not ambiguously referenced remains correct, I expect this policy
will be satisfactory.

To verify that this threshold is acceptable for a given client,
poolamc.c calculates metrics; see @ref{ff7,,Feedback about retained pages}
below. If this one-size-fits-all approach is not satisfactory,
@code{amc->largeSize} is a client-tunable parameter which defaults to
@code{AMC_LARGE_SIZE_DEFAULT}. It can be tuned by passing an
@code{MPS_KEY_LARGE_SIZE} keyword argument to @ref{166,,mps_pool_create_k()}.

@node Retained pages,Feedback about retained pages,The LSP payoff calculation,Guide<2>
@anchor{design/poolamc retained-pages}@anchor{ff8}
@subsubsection Retained pages


The reasons why a segment and its pages might be retained are:


@enumerate 

@item 
ambiguous reference to first-obj: unavoidable page retention (only
the mutator can reduce this, if they so wish, by nulling out ambig
references);

@item 
ambiguous reference to rest-obj: tuning MPS LSP policy could
mitigate this, reducing the likelihood of rest-objs being
co-located with large first-objs;

@item 
ambiguous reference to final pad: implementing
@ref{ff6,,.large.lsp-no-retain} could mitigate this;

@item 
ambiguous reference to other (NMR) pad: hard to mitigate, as pads
are indistinguishable from client objects;

@item 
emergency trace;

@item 
non-object-aligned ambiguous ref: fixed by job001809@footnote{https://www.ravenbrook.com/project/mps/issue/job001809/};

@item 
other reason (for example, buffered at flip): not expected to be a
problem.
@end enumerate

This list puts the reasons that are more “obvious” to the client
programmer first, and the more obscure reasons last.

@node Feedback about retained pages,,Retained pages,Guide<2>
@anchor{design/poolamc feedback-about-retained-pages}@anchor{ff7}
@subsubsection Feedback about retained pages


(New with job001811@footnote{https://www.ravenbrook.com/project/mps/issue/job001811/}). AMC now accumulates counts of pages condemned
and retained during a trace, in categories according to size and
reason for retention, and emits this via the @code{AMCTraceEnd} telemetry
event. See comments on the @code{PageRetStruct} in @code{poolamc.c}. These
page-based metrics are not as precise as actually counting the size of
objects, but they require much less intrusive code to implement, and
should be sufficient to assess whether AMC’s page retention policies
and behaviour are acceptable.

@node Initial design,,Guide<2>,AMC pool class
@anchor{design/poolamc initial-design}@anchor{ff9}
@subsection Initial design


@anchor{design/poolamc design mps poolamc initial-design}@anchor{fe2}@ref{fe2,,.initial-design;} This section contains the original design for the
AMC Pool Class.

@menu
* Introduction: Introduction<62>. 
* Overview: Overview<22>. 
* Definitions: Definitions<10>. 
* Segments:: 
* Fixing and nailing:: 
* Emergency tracing:: 
* Buffers:: 
* Types: Types<9>. 
* Generations:: 
* Ramps:: 
* Headers: Headers<2>. 
* Old and aging notes below here:: 

@end menu

@node Introduction<62>,Overview<22>,,Initial design
@anchor{design/poolamc introduction}@anchor{ffa}
@subsubsection Introduction


@anchor{design/poolamc design mps poolamc intro}@anchor{ffb}@ref{ffb,,.intro;} This is the design of the AMC Pool Class. AMC stands for
Automatic Mostly-Copying. This design is highly fragmentory and some
may even be sufficiently old to be misleading.

@anchor{design/poolamc design mps poolamc readership}@anchor{ffc}@ref{ffc,,.readership;} The intended readership is any MPS developer.

@node Overview<22>,Definitions<10>,Introduction<62>,Initial design
@anchor{design/poolamc overview}@anchor{ffd}
@subsubsection Overview


@anchor{design/poolamc design mps poolamc overview}@anchor{ffe}@ref{ffe,,.overview;} This class is intended to be the main pool class used by
Harlequin Dylan. It provides garbage collection of objects (hence
“automatic”). It uses generational copying algorithms, but with some
facility for handling small numbers of ambiguous references. Ambiguous
references prevent the pool from copying objects (hence “mostly
copying”). It provides incremental collection.

@cartouche
@quotation Note 
A lot of this design is awesomely old. David Jones, 1998-02-04.
@end quotation
@end cartouche

@node Definitions<10>,Segments,Overview<22>,Initial design
@anchor{design/poolamc definitions}@anchor{fff}
@subsubsection Definitions


@anchor{design/poolamc design mps poolamc def grain}@anchor{1000}@ref{1000,,.def.grain;} Grain. An quantity of memory which is both aligned to
the pool’s alignment and equal to the pool’s alignment in size. That
is, the smallest amount of memory worth talking about.

@node Segments,Fixing and nailing,Definitions<10>,Initial design
@anchor{design/poolamc segments}@anchor{1001}
@subsubsection Segments


@anchor{design/poolamc design mps poolamc seg class}@anchor{1002}@ref{1002,,.seg.class;} AMC allocates segments of class @code{AMCSegClass}, which
is a subclass of @code{MutatorSegClass} (see
design.mps.seg.over.hierarchy.mutatorseg@footnote{seg.html#design.mps.seg.over.hierarchy.mutatorseg}).

@anchor{design/poolamc design mps poolamc seg gen}@anchor{1003}@ref{1003,,.seg.gen;} AMC organizes the segments it manages into generations.

@anchor{design/poolamc design mps poolamc seg gen map}@anchor{1004}@ref{1004,,.seg.gen.map;} Every segment is in exactly one generation.

@anchor{design/poolamc design mps poolamc seg gen ind}@anchor{1005}@ref{1005,,.seg.gen.ind;} The segment’s @code{gen} field indicates which
generation (that the segment is in) (an @code{AMCGenStruct} see blah
below).

@anchor{design/poolamc design mps poolamc seg gen get}@anchor{1006}@ref{1006,,.seg.gen.get;} The map from segment to generation is implemented by
@code{amcSegGen()} which deals with all this.

@node Fixing and nailing,Emergency tracing,Segments,Initial design
@anchor{design/poolamc fixing-and-nailing}@anchor{1007}
@subsubsection Fixing and nailing


@cartouche
@quotation Note 
This section contains placeholders for design rather than design
really. David Jones, 1998-02-04.
@end quotation
@end cartouche

@anchor{design/poolamc design mps poolamc nailboard}@anchor{1008}@ref{1008,,.nailboard;} AMC uses a nailboard structure for recording ambiguous
references to segments. See design.mps.nailboard@footnote{nailboard.html}.

@anchor{design/poolamc design mps poolamc nailboard create}@anchor{1009}@ref{1009,,.nailboard.create;} A nailboard is allocated dynamically whenever a
segment becomes newly ambiguously referenced. This table is used by
subsequent scans and reclaims in order to work out which objects were
ambiguously referenced.

@anchor{design/poolamc design mps poolamc nailboard destroy}@anchor{100a}@ref{100a,,.nailboard.destroy;} The nailboatrd is deallocated during reclaim.

@anchor{design/poolamc design mps poolamc nailboard emergency}@anchor{100b}@ref{100b,,.nailboard.emergency;} During emergency tracing two things relating
to nailboards happen that don’t normally:


@enumerate 

@item 
@anchor{design/poolamc design mps poolamc nailboard emergency nonew}@anchor{100c}@ref{100c,,.nailboard.emergency.nonew;} Nailboards aren’t allocated when we
have new ambiguous references to segments.

@anchor{design/poolamc design mps poolamc nailboard emergency nonew justify}@anchor{100d}@ref{100d,,.nailboard.emergency.nonew.justify;} We could try and allocate a
nailboard, but we’re in emergency mode so short of memory so it’s
unlikely to succeed, and there would be additional code for yet
another error path which complicates things.

@item 
@anchor{design/poolamc design mps poolamc nailboard emergency exact}@anchor{100e}@ref{100e,,.nailboard.emergency.exact;} nailboards are used to record exact
references in order to avoid copying the objects.

@anchor{design/poolamc design mps poolamc nailboard hyper-conservative}@anchor{100f}@ref{100f,,.nailboard.hyper-conservative;} Not creating new nailboards
(@ref{100c,,.nailboard.emergency.nonew} above) means that when we have a new
reference to a segment during emergency tracing then we nail the
entire segment and preserve everything in place.
@end enumerate

@anchor{design/poolamc design mps poolamc fix nail states}@anchor{1010}@ref{1010,,.fix.nail.states;} Partition the segment states into four sets:


@enumerate 

@item 
white segment and not nailed (and has no nailboard);

@item 
white segment and nailed and has no nailboard;

@item 
white segment and nailed and has nailboard;

@item 
the rest.
@end enumerate

@anchor{design/poolamc design mps poolamc fix nail why}@anchor{1011}@ref{1011,,.fix.nail.why;} A segment is recorded as being nailed when either
there is an ambiguous reference to it, or there is an exact reference
to it and the object couldn’t be copied off the segment (because there
wasn’t enough memory to allocate the copy). In either of these cases
reclaim cannot simply destroy the segment (usually the segment will
not be destroyed because it will have live objects on it, though see
@ref{1012,,.nailboard.limitations.middle} below). If the segment is nailed then
we might be using a nailboard to mark objects on the segment.
However, we cannot guarantee that being nailed implies a nailboard,
because we might not be able to allocate the nailboard. Hence all
these states actually occur in practice.

@anchor{design/poolamc design mps poolamc fix nail distinguish}@anchor{1013}@ref{1013,,.fix.nail.distinguish;} The nailed bits in the segment descriptor
(@code{SegStruct}) are used to record the set of traces for which a
segment has nailed objects.

@anchor{design/poolamc design mps poolamc nailboard limitations single}@anchor{1014}@ref{1014,,.nailboard.limitations.single;} Just having a single nailboard per
segment prevents traces from improving on the findings of each other:
a later trace could find that a nailed object is no longer nailed or
even dead. Until the nailboard is discarded, that is.

@anchor{design/poolamc design mps poolamc nailboard limitations middle}@anchor{1012}@ref{1012,,.nailboard.limitations.middle;} An ambiguous reference to a segment
that does not point into any object in that segment will cause that
segment to survive even though there are no surviving objects on it.

@node Emergency tracing,Buffers,Fixing and nailing,Initial design
@anchor{design/poolamc emergency-tracing}@anchor{1015}
@subsubsection Emergency tracing


@anchor{design/poolamc design mps poolamc emergency fix}@anchor{1016}@ref{1016,,.emergency.fix;} @code{amcSegFixEmergency()} is at the core of AMC’s
emergency tracing policy (unsurprisingly). @code{amcSegFixEmergency()}
chooses exactly one of three options:


@enumerate 

@item 
use the existing nailboard structure to record the fix;

@item 
preserve and nail the segment in its entirety;

@item 
snapout an exact (or high rank) pointer to a broken heart to the
broken heart’s forwarding pointer.
@end enumerate

If the rank of the reference is @code{RankAMBIG} then it either does (1)
or (2) depending on whether there is an existing nailboard or not.
Otherwise (the rank is exact or higher) if there is a broken heart it
is used to snapout the pointer. Otherwise it is as for an
@code{RankAMBIG} reference: we either do (1) or (2).

@anchor{design/poolamc design mps poolamc emergency scan}@anchor{1017}@ref{1017,,.emergency.scan;} This is basically as before, the only complication
is that when scanning a nailed segment we may need to do multiple
passes, as @code{amcSegFixEmergency()} may introduce new marks into the
nail board.

@node Buffers,Types<9>,Emergency tracing,Initial design
@anchor{design/poolamc buffers}@anchor{1018}
@subsubsection Buffers


@anchor{design/poolamc design mps poolamc buffer class}@anchor{1019}@ref{1019,,.buffer.class;} AMC uses buffer of class @code{AMCBufClass} (a subclass
of SegBufClass).

@anchor{design/poolamc design mps poolamc buffer gen}@anchor{101a}@ref{101a,,.buffer.gen;} Each buffer allocates into exactly one generation.

@anchor{design/poolamc design mps poolamc buffer field gen}@anchor{101b}@ref{101b,,.buffer.field.gen;} @code{AMCBuf} buffer contain a gen field which
points to the generation that the buffer allocates into.

@anchor{design/poolamc design mps poolamc buffer fill gen}@anchor{101c}@ref{101c,,.buffer.fill.gen;} @ref{903,,AMCBufferFill()} uses the generation (obtained
from the @code{gen} field) to initialise the segment’s @code{segTypeP} field
which is how segments get allocated in that generation.

@anchor{design/poolamc design mps poolamc buffer condemn}@anchor{101d}@ref{101d,,.buffer.condemn;} We condemn buffered segments, but not the contents
of the buffers themselves, because we can’t reclaim uncommitted
buffers (see design.mps.buffer@footnote{buffer.html} for details). If the segment has a
forwarding buffer on it, we detach it.

@cartouche
@quotation Note 
Why? Forwarding buffers are detached because they used to cause
objects on the same segment to not get condemned, hence caused
retention of garbage. Now that we condemn the non-buffered portion
of buffered segments this is probably unnecessary. David Jones,
1998-06-01.

But it’s probably more efficient than keeping the buffer on the
segment, because then the other stuff gets nailed – Pekka P.
Pirinen, 1998-07-10.
@end quotation
@end cartouche

If the segment has a mutator buffer on it, we nail the buffer. If the
buffer cannot be nailed, we give up condemning, since nailing the
whole segment would make it survive anyway. The scan methods skip over
buffers and fix methods don’t do anything to things that have already
been nailed, so the buffer is effectively black.

@node Types<9>,Generations,Buffers,Initial design
@anchor{design/poolamc types}@anchor{101e}
@subsubsection Types


@anchor{design/poolamc design mps poolamc struct}@anchor{101f}@ref{101f,,.struct;} @code{AMCStruct} is the pool class AMC instance structure.

@anchor{design/poolamc design mps poolamc struct pool}@anchor{1020}@ref{1020,,.struct.pool;} Like other pool class instances, it contains a
@code{PoolStruct} containing the generic pool fields.

@anchor{design/poolamc design mps poolamc struct format}@anchor{1021}@ref{1021,,.struct.format;} The @code{format} field points to a @code{Format}
structure describing the object format of objects allocated in the
pool. The field is initialized by @code{AMCInit()} from a parameter, and
thereafter it is not changed until the pool is destroyed.

@cartouche
@quotation Note 
Actually the format field is in the generic @code{PoolStruct} these
days. David Jones, 1998-09-21.
@end quotation
@end cartouche

@cartouche
@quotation Note 
There are lots more fields here.
@end quotation
@end cartouche

@node Generations,Ramps,Types<9>,Initial design
@anchor{design/poolamc generations}@anchor{1022}
@subsubsection Generations


@anchor{design/poolamc design mps poolamc gen}@anchor{1023}@ref{1023,,.gen;} Generations partition the segments that a pool manages (see
@ref{1004,,.seg.gen.map} above).

@anchor{design/poolamc design mps poolamc gen collect}@anchor{1024}@ref{1024,,.gen.collect;} Generations are more or less the units of
condemnation in AMC. And also the granularity for forwarding (when
copying objects during a collection): all the objects which are copied
out of a generation use the same forwarding buffer for allocating the
new copies, and a forwarding buffer results in allocation in exactly
one generation.

@anchor{design/poolamc design mps poolamc gen rep}@anchor{1025}@ref{1025,,.gen.rep;} Generations are represented using an @code{AMCGenStruct}
structure.

@anchor{design/poolamc design mps poolamc gen create}@anchor{1026}@ref{1026,,.gen.create;} All the generations are created when the pool is
created (during @code{AMCInitComm()}).

@anchor{design/poolamc design mps poolamc gen manage ring}@anchor{1027}@ref{1027,,.gen.manage.ring;} An AMC’s generations are kept on a ring attached
to the @code{AMCStruct} (the @code{genRing} field).

@anchor{design/poolamc design mps poolamc gen manage array}@anchor{1028}@ref{1028,,.gen.manage.array;} They are also kept in an array which is
allocated when the pool is created and attached to the @code{AMCStruct}
(the gens field holds the number of generations, the @code{gen} field
points to an array of @code{AMCGen}).

@cartouche
@quotation Note 
it seems to me that we could probably get rid of the ring. David
Jones, 1998-09-22.
@end quotation
@end cartouche

@anchor{design/poolamc design mps poolamc gen number}@anchor{1029}@ref{1029,,.gen.number;} There are @code{AMCTopGen + 2} generations in total.
“normal” generations numbered from 0 to @code{AMCTopGen} inclusive and an
extra “ramp” generation (see @ref{102a,,.gen.ramp} below).

@anchor{design/poolamc design mps poolamc gen forward}@anchor{102b}@ref{102b,,.gen.forward;} Each generation has an associated forwarding buffer
(stored in the @code{forward} field of @code{AMCGen}). This is the buffer
that is used to forward objects out of this generation. When a
generation is created in @code{AMCGenCreate()}, its forwarding buffer has
a null @code{p} field, indicating that the forwarding buffer has no
generation to allocate in. The collector will assert out (in
@ref{903,,AMCBufferFill()} where it checks that @code{buffer->p} is an
@code{AMCGen}) if you try to forward an object out of such a generation.

@anchor{design/poolamc design mps poolamc gen forward setup}@anchor{102c}@ref{102c,,.gen.forward.setup;} All the generation’s forwarding buffer’s are
associated with generations when the pool is created (just after the
generations are created in @code{AMCInitComm()}).

@node Ramps,Headers<2>,Generations,Initial design
@anchor{design/poolamc ramps}@anchor{102d}
@subsubsection Ramps


@anchor{design/poolamc design mps poolamc ramp}@anchor{102e}@ref{102e,,.ramp;} Ramps usefully implement the begin/end
@ref{26f,,mps_alloc_pattern_ramp()} interface.

@anchor{design/poolamc design mps poolamc gen ramp}@anchor{102a}@ref{102a,,.gen.ramp;} To implement ramping (request.dylan.170423@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/dylan/170423}), AMC uses a
special “ramping mode”, where promotions are redirected. One
generation is designated the “ramp generation” (@code{amc->rampGen} in
the code).

@anchor{design/poolamc design mps poolamc gen ramp ordinary}@anchor{102f}@ref{102f,,.gen.ramp.ordinary;} Ordinarily, that is whilst not ramping, objects
are promoted into the ramp generation from younger generations and are
promoted out to older generations. The generation that the ramp
generation ordinarily promotes into is designated the “after-ramp
generation” (@code{amc->afterRampGen}).

@anchor{design/poolamc design mps poolamc gen ramp particular}@anchor{1030}@ref{1030,,.gen.ramp.particular;} the ramp generation is the second oldest
generation and the after-ramp generation is the oldest generation.

@anchor{design/poolamc design mps poolamc gen ramp possible}@anchor{1031}@ref{1031,,.gen.ramp.possible;} In alternative designs it might be possible to
make the ramp generation a special generation that is only promoted
into during ramping, however, this is not done.

@anchor{design/poolamc design mps poolamc gen ramp ramping}@anchor{1032}@ref{1032,,.gen.ramp.ramping;} The ramp generation is promoted into itself
during ramping mode;

@anchor{design/poolamc design mps poolamc gen ramp after}@anchor{1033}@ref{1033,,.gen.ramp.after;} after this mode ends, the ramp generation is
promoted into the after-ramp generation as usual.

@anchor{design/poolamc design mps poolamc gen ramp after once}@anchor{1034}@ref{1034,,.gen.ramp.after.once;} Care is taken to
ensure that there is at least one collection where stuff is promoted
from the ramp generation to the after-ramp generation even if ramping
mode is immediately re-entered.

@anchor{design/poolamc design mps poolamc ramp mode}@anchor{1035}@ref{1035,,.ramp.mode;} This behaviour is controlled in a slightly convoluted
manner by a state machine. The rampMode field of the pool forms an
important part of the state of the machine.

There are five states: OUTSIDE, BEGIN, RAMPING, FINISH, and
COLLECTING. These appear in the code as @code{RampOUTSIDE} and so on.

@anchor{design/poolamc design mps poolamc ramp state cycle usual}@anchor{1036}@ref{1036,,.ramp.state.cycle.usual;} The usual progression of states is a
cycle: OUTSIDE → BEGIN → RAMPING → FINISH → COLLECTING → OUTSIDE.

@anchor{design/poolamc design mps poolamc ramp count}@anchor{1037}@ref{1037,,.ramp.count;} The pool just counts the number of APs that have begun
ramp mode (and not ended). No state changes occur unless this count
goes from 0 to 1 (starting the first ramp) or from 1 to 0 (leaving the
last ramp). In other words, all nested ramps are ignored (see code in
@code{AMCRampBegin()} and @code{AMCRampEnd()}).

@anchor{design/poolamc design mps poolamc ramp state invariant count}@anchor{1038}@ref{1038,,.ramp.state.invariant.count;} In the OUTSIDE state the count must be
zero. In the BEGIN and RAMPING states the count must be greater than
zero. In the FINISH and COLLECTING states the count is not
constrained.

@anchor{design/poolamc design mps poolamc ramp state invariant forward}@anchor{1039}@ref{1039,,.ramp.state.invariant.forward;} When in OUTSIDE, BEGIN, or
COLLECTING, the ramp generation forwards to the after-ramp generation.
When in RAMPING or FINISH, the ramp generation forwards to itself.

@anchor{design/poolamc design mps poolamc ramp outside}@anchor{103a}@ref{103a,,.ramp.outside;} The pool is initially in the OUTSIDE state. The only
transition away from the OUTSIDE state is to the BEGIN state, when a
ramp is entered.

@anchor{design/poolamc design mps poolamc ramp begin}@anchor{103b}@ref{103b,,.ramp.begin;} When the count goes up from zero, the state moves from
COLLECTING or OUTSIDE to BEGIN.

@anchor{design/poolamc design mps poolamc ramp begin leave}@anchor{103c}@ref{103c,,.ramp.begin.leave;} We can leave the BEGIN state to either the
OUTSIDE or the RAMPING state.

@anchor{design/poolamc design mps poolamc ramp begin leave outside}@anchor{103d}@ref{103d,,.ramp.begin.leave.outside;} We go to OUTSIDE if the count drops to 0
before a collection starts. This shortcuts the usual cycle of states
for small enough ramps.

@anchor{design/poolamc design mps poolamc ramp begin leave ramping}@anchor{103e}@ref{103e,,.ramp.begin.leave.ramping;} We enter the RAMPING state if a
collection starts that condemns the ramp generation (pedantically when
a new GC begins, and a segment in the ramp generation is condemned, we
leave the BEGIN state, see @code{amcSegWhiten()}). At this point we
switch the ramp generation to forward to itself
(@ref{1032,,.gen.ramp.ramping}).

@anchor{design/poolamc design mps poolamc ramp ramping leave}@anchor{103f}@ref{103f,,.ramp.ramping.leave;} We leave the RAMPING state and go to the
FINISH state when the ramp count goes back to zero. Thus, the FINISH
state indicates that we have started collecting the ramp generation
while inside a ramp which we have subsequently finished.

@anchor{design/poolamc design mps poolamc ramp finish remain}@anchor{1040}@ref{1040,,.ramp.finish.remain;} We remain in the FINISH state until we next
start to collect the ramp generation (condemn it), regardless of
entering or leaving any ramps. This ensures that the ramp generation
will be collected to the after-ramp generation at least once.

@anchor{design/poolamc design mps poolamc ramp finish leave}@anchor{1041}@ref{1041,,.ramp.finish.leave;} When we next condemn the ramp generation, we
move to the COLLECTING state. At this point the forwarding generations
are switched back so that the ramp generation promotes into the
after-ramp generation on this collection.

@anchor{design/poolamc design mps poolamc ramp collecting leave}@anchor{1042}@ref{1042,,.ramp.collecting.leave;} We leave the COLLECTING state when the GC
enters reclaim (specifically, when a segment in the ramp generation is
reclaimed), or when we begin another ramp. Ordinarily we enter the
OUTSIDE state, but if the client has started a ramp then we go
directly to the BEGIN state.

@anchor{design/poolamc ramp-collect-all}@anchor{1043}.ramp.collect-all There used to be two flavours of ramps: the
normal one and the collect-all flavour that triggered a full GC after
the ramp end. This was a hack for producing certain Dylan statistics,
and no longer has any effect (the flag is passed to
@code{AMCRampBegin()}, but ignored there).

@node Headers<2>,Old and aging notes below here,Ramps,Initial design
@anchor{design/poolamc headers}@anchor{1044}
@subsubsection Headers


@anchor{design/poolamc design mps poolamc header}@anchor{1045}@ref{1045,,.header;} AMC supports a fixed-size header on objects, with the
client pointers pointing after the header, rather than the base of the
memory block. See format documentation for details of the interface.

@anchor{design/poolamc design mps poolamc header client}@anchor{1046}@ref{1046,,.header.client;} The code mostly deals in client pointers, only
computing the base and limit of a block when these are needed (such as
when an object is copied). In several places, the code gets a block of
some sort (a segment or a buffer) and creates a client pointer by
adding the header size (@code{pool->format->headerSize}).

@node Old and aging notes below here,,Headers<2>,Initial design
@anchor{design/poolamc old-and-aging-notes-below-here}@anchor{1047}
@subsubsection Old and aging notes below here


@geindex AMCFinish (C function)
@anchor{design/poolamc c AMCFinish}@anchor{1048}
@deffn {C Function} void AMCFinish (Pool pool)
@end deffn

@anchor{design/poolamc design mps poolamc finish forward}@anchor{1049}@ref{1049,,.finish.forward;} If the pool is being destroyed it is OK to destroy
the forwarding buffers, as the condemned set is about to disappear.

@geindex amcSegBufferEmpty (C function)
@anchor{design/poolamc c amcSegBufferEmpty}@anchor{fee}
@deffn {C Function} void amcSegBufferEmpty (Seg seg, Buffer buffer)
@end deffn

@anchor{design/poolamc design mps poolamc flush}@anchor{104a}@ref{104a,,.flush;} Free the unused part of the buffer to the segment.

@anchor{design/poolamc design mps poolamc flush pad}@anchor{104b}@ref{104b,,.flush.pad;} The segment is padded out with a dummy object so that
it appears full.

@anchor{design/poolamc design mps poolamc flush expose}@anchor{104c}@ref{104c,,.flush.expose;} The segment needs exposing before writing the
padding object onto it. If the segment is being used for forwarding it
might already be exposed, in this case the segment attached to it must
be covered when it leaves the buffer. See @ref{104d,,.fill.expose}.

@anchor{design/poolamc design mps poolamc flush cover}@anchor{104e}@ref{104e,,.flush.cover;} The segment needs covering whether it was being used
for forwarding or not. See @ref{104c,,.flush.expose}.

@geindex AMCBufferFill (C function)
@anchor{design/poolamc c AMCBufferFill}@anchor{903}
@deffn {C Function} @ref{55f,,Res} AMCBufferFill (Addr *baseReturn, Addr *limitReturn, Pool pool, Buffer buffer, Size size)
@end deffn

@anchor{design/poolamc design mps poolamc fill}@anchor{104f}@ref{104f,,.fill;} Reserve was called on an allocation buffer which was reset,
or there wasn’t enough room left in the buffer. Allocate a group for
the new object and attach it to the buffer.

@anchor{design/poolamc design mps poolamc fill expose}@anchor{104d}@ref{104d,,.fill.expose;} If the buffer is being used for forwarding it may be
exposed, in which case the group attached to it should be exposed. See
@ref{104e,,.flush.cover}.

@geindex amcSegFix (C function)
@anchor{design/poolamc c amcSegFix}@anchor{4bf}
@deffn {C Function} @ref{55f,,Res} amcSegFix (Seg seg, ScanState ss, Ref *refIO)
@end deffn

@anchor{design/poolamc design mps poolamc fix}@anchor{1050}@ref{1050,,.fix;} Fix a reference to an AMC segment.

Ambiguous references lock down an entire segment by removing it
from old-space and also marking it grey for future scanning.

Exact, final, and weak references are merged because the action for an
already forwarded object is the same in each case. After that
situation is checked for, the code diverges.

Weak references are either snapped out or replaced with
@code{ss->weakSplat} as appropriate.

Exact and final references cause the referenced object to be copied to
new-space and the old copy to be forwarded (broken-heart installed) so
that future references are fixed up to point at the new copy.

@anchor{design/poolamc design mps poolamc fix exact expose}@anchor{1051}@ref{1051,,.fix.exact.expose;} In order to allocate the new copy the forwarding
buffer must be exposed. This might be done more efficiently outside
the entire scan, since it’s likely to happen a lot.

@anchor{design/poolamc design mps poolamc fix exact grey}@anchor{1052}@ref{1052,,.fix.exact.grey;} The new copy must be at least as grey as the old
as it may have been grey for some other collection.

@geindex amcSegScan (C function)
@anchor{design/poolamc c amcSegScan}@anchor{902}
@deffn {C Function} @ref{55f,,Res} amcSegScan (Bool *totalReturn, Seg seg, ScanState ss1)
@end deffn

@anchor{design/poolamc design mps poolamc scan}@anchor{1053}@ref{1053,,.scan;} Searches for a group which is grey for the trace and scans
it. If there aren’t any, it sets the finished flag to true.

@geindex amcSegReclaim (C function)
@anchor{design/poolamc c amcSegReclaim}@anchor{1054}
@deffn {C Function} void amcSegReclaim (Seg seg, Trace trace)
@end deffn

@anchor{design/poolamc design mps poolamc reclaim}@anchor{1055}@ref{1055,,.reclaim;} After a trace, destroy any groups which are still
condemned for the trace, because they must be dead.

@anchor{design/poolamc design mps poolamc reclaim grey}@anchor{1056}@ref{1056,,.reclaim.grey;} Note that this might delete things which are grey
for other collections. This is OK, because we have conclusively proved
that they are dead – the other collection must have assumed they were
alive. There might be a problem with the accounting of grey groups,
however.

@anchor{design/poolamc design mps poolamc reclaim buf}@anchor{1057}@ref{1057,,.reclaim.buf;} If a condemned group still has a buffer attached, we
can’t destroy it, even though we know that there are no live objects
there. Even the object the mutator is allocating is dead, because the
buffer is tripped.

@geindex AMS pool class; design
@geindex pool class; AMS design

@node AMS pool class,AWL pool class,AMC pool class,Old design
@anchor{design/poolams doc}@anchor{1058}@anchor{design/poolams ams-pool-class}@anchor{1059}@anchor{design/poolams design-poolams}@anchor{105a}
@section AMS pool class


@menu
* Introduction: Introduction<63>. 
* Overview: Overview<23>. 
* Requirements: Requirements<38>. 
* Architecture: Architecture<9>. 
* Implementation: Implementation<22>. 
* Testing: Testing<8>. 
* Notes: Notes<7>. 

@end menu

@node Introduction<63>,Overview<23>,,AMS pool class
@anchor{design/poolams design mps poolams}@anchor{105b}@anchor{design/poolams introduction}@anchor{105c}
@subsection Introduction


@anchor{design/poolams design mps poolams intro}@anchor{105d}@ref{105d,,.intro;} This is the design of the AMS pool class.

@anchor{design/poolams design mps poolams readership}@anchor{105e}@ref{105e,,.readership;} MM developers.

@anchor{design/poolams design mps poolams source}@anchor{105f}@ref{105f,,.source;} design.mps.buffer@footnote{buffer.html}, design.mps.trace@footnote{trace.html}, design.mps.scan@footnote{scan.html},
design.mps.action and design.mps.pool@footnote{pool.html} [none of these were
actually used – pekka 1998-04-21]. No requirements doc [we need a
req.mps that captures the commonalities between the products – pekka
1998-01-27].

@node Overview<23>,Requirements<38>,Introduction<63>,AMS pool class
@anchor{design/poolams design-mps-buffer}@anchor{1060}@anchor{design/poolams overview}@anchor{1061}
@subsection Overview


@anchor{design/poolams design mps poolams overview}@anchor{1062}@ref{1062,,.overview;} This is the design of the AMS (Automatic Mark-and-Sweep)
pool class. The AMS pool is a proof-of-concept design for a mark-sweep
pool in the MPS. It’s not meant to be efficient, but it could serve as
a model for an implementation of a more advanced pool (such as EPVM).

@node Requirements<38>,Architecture<9>,Overview<23>,AMS pool class
@anchor{design/poolams requirements}@anchor{1063}
@subsection Requirements


@anchor{design/poolams design mps poolams req mark-sweep}@anchor{1064}@ref{1064,,.req.mark-sweep;} The pool must use a mark-and-sweep GC algorithm.

@anchor{design/poolams design mps poolams req colour}@anchor{1065}@ref{1065,,.req.colour;} The colour representation should be as efficient as
possible.

@anchor{design/poolams design mps poolams req incremental}@anchor{1066}@ref{1066,,.req.incremental;} The pool must support incremental GC.

@anchor{design/poolams design mps poolams req ambiguous}@anchor{1067}@ref{1067,,.req.ambiguous;} The pool must support ambiguous references to
objects in it (but ambiguous references into the middle of an object
do not preserve the object).

@anchor{design/poolams design mps poolams req format}@anchor{1068}@ref{1068,,.req.format;} The pool must be formatted, for generality.

@anchor{design/poolams design mps poolams req correct}@anchor{1069}@ref{1069,,.req.correct;} The design and the implementation should be simple
enough to be seen to be correct.

@anchor{design/poolams design mps poolams req simple}@anchor{106a}@ref{106a,,.req.simple;} Features not related to mark-and-sweep GC should
initially be implemented as simply as possible, in order to save
development effort.

@anchor{design/poolams design mps poolams not-req grey}@anchor{106b}@ref{106b,,.not-req.grey;} We haven’t figured out how buffers ought to work
with a grey mutator, so we use @ref{1069,,.req.correct} to allow us to design a
pool that doesn’t work in that phase. This is acceptable as long as we
haven’t actually implemented grey mutator collection.

@node Architecture<9>,Implementation<22>,Requirements<38>,AMS pool class
@anchor{design/poolams architecture}@anchor{106c}
@subsection Architecture


@menu
* Subclassing:: 
* Allocation: Allocation<4>. 
* Colours:: 
* Scanning: Scanning<2>. 

@end menu

@node Subclassing,Allocation<4>,,Architecture<9>
@anchor{design/poolams subclassing}@anchor{106d}
@subsubsection Subclassing


@anchor{design/poolams design mps poolams subclass}@anchor{106e}@ref{106e,,.subclass;} Since we expect to have many mark-and-sweep pools, we
build in some protocol for subclasses to modify various aspects of the
behaviour. Notably there’s a subclassable segment class, and a
protocol for performing iteration.

@node Allocation<4>,Colours,Subclassing,Architecture<9>
@anchor{design/poolams allocation}@anchor{106f}
@subsubsection Allocation


@anchor{design/poolams design mps poolams align}@anchor{1070}@ref{1070,,.align;} We divide the segments in grains, each the size of the
format alignment. @anchor{design/poolams design mps poolams alloc-bit-table}@anchor{1071}@ref{1071,,.alloc-bit-table;} We keep track of allocated
grains using a bit table. This allows a simple implementation of
allocation and freeing using the bit table operators, satisfying
@ref{106a,,.req.simple}, and can simplify the GC routines. Eventually, this
should use some sophisticated allocation technique suitable for
non-moving automatic pools.

@anchor{design/poolams design mps poolams buffer}@anchor{1072}@ref{1072,,.buffer;} We use buffered allocation, satisfying
@ref{1066,,.req.incremental}. The AMC buffer technique is reused, although it
is not suitable for non-moving pools, but req.simple allows us to do
that for now.

@anchor{design/poolams design mps poolams extend}@anchor{1073}@ref{1073,,.extend;} If there’s no space in any existing segment, a new segment
is allocated. The actual class is allowed to decide the size of the
new segment.

@anchor{design/poolams design mps poolams no-alloc}@anchor{1074}@ref{1074,,.no-alloc;} Do not support @code{PoolAlloc()}, because we can’t support
one-phase allocation for a scannable pool (unless we disallow
incremental collection). For exact details, see design.mps.buffer@footnote{buffer.html}.

@anchor{design/poolams design mps poolams no-free}@anchor{1075}@ref{1075,,.no-free;} Do not support @code{PoolFree()}, because automatic pools
don’t need explicit free and having it encourages clients to use it
(and therefore to have dangling pointers, double frees, and other
memory management errors.)

@node Colours,Scanning<2>,Allocation<4>,Architecture<9>
@anchor{design/poolams colours}@anchor{1076}
@subsubsection Colours


@anchor{design/poolams design mps poolams colour}@anchor{1077}@ref{1077,,.colour;} Objects in a segment which is `not' condemned (for some
trace) take their colour (for this trace) from the segment.

@anchor{design/poolams design mps poolams colour object}@anchor{1078}@ref{1078,,.colour.object;} Since we need to implement a non-copying GC, we
keep track of the colour of each object in a condemned segment
separately. For this, we use bit tables with a bit for each grain.
This format is fast to access, has better locality than mark bits in
the objects themselves, and allows cheap interoperation with the
allocation bit table.

@anchor{design/poolams design mps poolams colour encoding}@anchor{1079}@ref{1079,,.colour.encoding;} As to the details, we follow
analysis.non-moving-colour(3), implementing both the alloc-white
sharing option described in
analysis.non-moving-colour.constraint.reclaim.white-free-bit and the
vanilla three-table option, because the former cannot work with
interior pointers. However, the colour encoding in both is the same.

@anchor{design/poolams design mps poolams ambiguous middle}@anchor{107a}@ref{107a,,.ambiguous.middle;} We will allow ambiguous references into the
middle of an object (as required by @ref{1067,,.req.ambiguous}), using the
trick in analysis.non-moving-colour.interior.ambiguous-only to speed
up scanning.

@anchor{design/poolams design mps poolams interior-pointer}@anchor{107b}@ref{107b,,.interior-pointer;} Note that non-ambiguous interior pointers are
outlawed.

@anchor{design/poolams design mps poolams colour alloc}@anchor{107c}@ref{107c,,.colour.alloc;} Objects are allocated black. This is the most
efficient alternative for traces in the black mutator phase, and
@ref{106b,,.not-req.grey} means that’s sufficient.

@cartouche
@quotation Note 
Some day, we need to think about allocating grey or white during
the grey mutator phase.
@end quotation
@end cartouche

@node Scanning<2>,,Colours,Architecture<9>
@anchor{design/poolams scanning}@anchor{107d}
@subsubsection Scanning


@anchor{design/poolams design mps poolams scan segment}@anchor{107e}@ref{107e,,.scan.segment;} The tracer protocol requires (for segment barrier
hits) that there is a method for scanning a segment and turning all
grey objects on it black. This cannot be achieved with a single
sequential sweep over the segment, since objects that the sweep has
already passed may become grey as later objects are scanned.

@anchor{design/poolams design mps poolams scan graph}@anchor{107f}@ref{107f,,.scan.graph;} For a non-moving GC, it is more efficient to trace
along the reference graph than segment by segment. It also allows
passing type information from fix to scan. Currently, the tracer
doesn’t offer this option when it’s polling for work.

@anchor{design/poolams design mps poolams scan stack}@anchor{1080}@ref{1080,,.scan.stack;} Tracing along the reference graph cannot be done by
recursive descent, because we can’t guarantee that the stack won’t
overflow. We can, however, maintain an explicit stack of things to
trace, and fall back on iterative methods (@ref{1081,,.scan.iter}) when it
overflows and can’t be extended.

@anchor{design/poolams design mps poolams scan iter}@anchor{1081}@ref{1081,,.scan.iter;} As discussed in @ref{107e,,.scan.segment}, when scanning a
segment, we need to ensure that there are no grey objects in the
segment when the scan method returns. We can do this by iterating a
sequential scan over the segment until nothing is grey (see
@ref{1082,,.marked.scan} for details).

@anchor{design/poolams design mps poolams scan iter only}@anchor{1083}@ref{1083,,.scan.iter.only;} Some iterative method is needed as a fallback for
the more advanced methods, and as this is the simplest way of
implementing the current tracer protocol, we will start by
implementing it as the only scanning method.

@anchor{design/poolams design mps poolams scan buffer}@anchor{1084}@ref{1084,,.scan.buffer;} We do not scan between ScanLimit and Limit of a
buffer (see @ref{1085,,.iteration.buffer}), as usual.

@cartouche
@quotation Note 
design.mps.buffer@footnote{buffer.html} should explain why this works, but doesn’t.
Pekka P. Pirinen, 1998-02-11.
@end quotation
@end cartouche

@anchor{design/poolams design mps poolams fix to-black}@anchor{1086}@ref{1086,,.fix.to-black;} When fixing a reference to a white object, if the
segment does not refer to the white set, the object cannot refer to
the white set, and can therefore be marked as black immediately
(rather than grey).

@node Implementation<22>,Testing<8>,Architecture<9>,AMS pool class
@anchor{design/poolams implementation}@anchor{1087}
@subsection Implementation


@menu
* Colour:: 
* Iteration: Iteration<2>. 
* Scanning Algorithm:: 
* Allocation: Allocation<5>. 
* Initialization:: 
* Condemnation:: 
* Reclaim:: 
* Segment merging and splitting:: 

@end menu

@node Colour,Iteration<2>,,Implementation<22>
@anchor{design/poolams colour}@anchor{1088}
@subsubsection Colour


@anchor{design/poolams design mps poolams colour determine}@anchor{1089}@ref{1089,,.colour.determine;} Following the plan in @ref{1077,,.colour}, if
@code{SegWhite(seg)} includes the trace, the colour of an object is given
by the bit tables. Otherwise if @code{SegGrey(seg)} includes the trace,
all the objects are grey. Otherwise all the objects are black.

@anchor{design/poolams design mps poolams colour bits}@anchor{108a}@ref{108a,,.colour.bits;} As we only have searches for runs of zero bits, we use
two bit tables, the non-grey and non-white tables, but this is hidden
beneath a layer of macros talking about grey and white in positive
terms.

@anchor{design/poolams design mps poolams colour single}@anchor{108b}@ref{108b,,.colour.single;} We have only implemented a single set of mark and
scan tables, so we can only condemn a segment for one trace at a time.
This is checked for in condemnation. If we want to do overlapping
white sets, each trace needs its own set of tables.

@anchor{design/poolams design mps poolams colour check}@anchor{108c}@ref{108c,,.colour.check;} The grey-and-non-white state is illegal, and free
objects must be white as explained in
analysis.non-moving-colour.constraint.reclaim.

@node Iteration<2>,Scanning Algorithm,Colour,Implementation<22>
@anchor{design/poolams iteration}@anchor{108d}
@subsubsection Iteration


@anchor{design/poolams design mps poolams iteration}@anchor{108e}@ref{108e,,.iteration;} Scan, reclaim and other operations need to iterate over
all objects in a segment. We abstract this into a single iteration
function, even though we no longer use it for reclaiming and rarely
for scanning.

@anchor{design/poolams design mps poolams iteration buffer}@anchor{1085}@ref{1085,,.iteration.buffer;} Iteration skips directly from ScanLimit to Limit
of a buffer. This is because this area may contain
partially-initialized and uninitialized data, which cannot be
processed. Since the iteration skips the buffer, callers need to take
the appropriate action, if any, on it.

@cartouche
@quotation Note 
ScanLimit is used for reasons which are not documented in
design.mps.buffer@footnote{buffer.html}.
@end quotation
@end cartouche

@node Scanning Algorithm,Allocation<5>,Iteration<2>,Implementation<22>
@anchor{design/poolams scanning-algorithm}@anchor{108f}
@subsubsection Scanning Algorithm


@anchor{design/poolams design mps poolams marked}@anchor{1090}@ref{1090,,.marked;} Each segment has a @code{marksChanged} flag, indicating
whether anything in it has been made grey since the last scan
iteration (@ref{1081,,.scan.iter}) started. This flag only concerns the colour
of objects with respect to the trace for which the segment is
condemned, as this is the only trace for which objects in the segment
are being made grey by fixing. Note that this flag doesn’t imply that
there are grey objects in the segment, because the grey objects might
have been subsequently scanned and blackened.

@anchor{design/poolams design mps poolams marked fix}@anchor{1091}@ref{1091,,.marked.fix;} The @code{marksChanged} flag is set @code{TRUE} by
@code{amsSegFix()} when an object is made grey.

@anchor{design/poolams design mps poolams marked scan}@anchor{1082}@ref{1082,,.marked.scan;} @code{amsSegScan()} must blacken all grey objects on the
segment, so it must iterate over the segment until all grey objects
have been seen. Scanning an object in the segment might grey another
one (@ref{1091,,.marked.fix}), so the scanner iterates until this flag is
@code{FALSE}, setting it to @code{FALSE} before each scan. It is safe to
scan the segment even if it contains nothing grey.

@anchor{design/poolams design mps poolams marked scan fail}@anchor{1092}@ref{1092,,.marked.scan.fail;} If the format scanner returns failure (see
protocol.mps.scanning), we abort the scan in the middle of a segment.
So in this case the marksChanged flag is set back to TRUE, because we
may not have blackened all grey objects.

@cartouche
@quotation Note 
Is that the best reference for the format scanner?
@end quotation
@end cartouche

@anchor{design/poolams design mps poolams marked unused}@anchor{1093}@ref{1093,,.marked.unused;} The @code{marksChanged} flag is meaningless unless the
segment is condemned. We make it @code{FALSE} in these circumstances.

@anchor{design/poolams design mps poolams marked condemn}@anchor{1094}@ref{1094,,.marked.condemn;} Condemnation makes all objects in a segment either
black or white, leaving nothing grey, so it doesn’t need to set the
@code{marksChanged} flag which must already be @code{FALSE}.

@anchor{design/poolams design mps poolams marked reclaim}@anchor{1095}@ref{1095,,.marked.reclaim;} When a segment is reclaimed, it can contain
nothing marked as grey, so the @code{marksChanged} flag must already be
@code{FALSE}.

@anchor{design/poolams design mps poolams marked blacken}@anchor{1096}@ref{1096,,.marked.blacken;} When the tracer decides not to scan, but to call
@code{SegBlacken()}, we know that any greyness can be removed.
@code{amsSegBlacken()} does this and resets the @code{marksChanged} flag, if
it finds that the segment has been condemned.

@anchor{design/poolams design mps poolams marked clever}@anchor{1097}@ref{1097,,.marked.clever;} AMS could be clever about not setting the
@code{marksChanged} flag, if the fixed object is ahead of the current
scan pointer. It could also keep low- and high-water marks of grey
objects, but we don’t need to implement these improvements at first.

@node Allocation<5>,Initialization,Scanning Algorithm,Implementation<22>
@anchor{design/poolams id1}@anchor{1098}
@subsubsection Allocation


@anchor{design/poolams design mps poolams buffer-init}@anchor{1099}@ref{1099,,.buffer-init;} We take one init arg to set the Rank on the buffer,
just to see how it’s done.

@anchor{design/poolams design mps poolams no-bit}@anchor{109a}@ref{109a,,.no-bit;} As an optimization, we won’t use the alloc bit table until
the first reclaim on the segment. Before that, we just keep a
high-water mark.

@anchor{design/poolams design mps poolams fill}@anchor{109b}@ref{109b,,.fill;} @code{AMSBufferFill()} takes the simplest approach: it iterates
over the segments in the pool, looking for one which can be used to
refill the buffer.

@anchor{design/poolams design mps poolams fill colour}@anchor{109c}@ref{109c,,.fill.colour;} The objects allocated from the new buffer must be
black for all traces (@ref{107c,,.colour.alloc}), so putting it on a black
segment (meaning one where neither @code{SegWhite(seg)} nor
@code{SegGrey(seg)} include the trace, see @ref{1089,,.colour.determine}) is
obviously OK. White segments (where @code{SegWhite(seg)} includes the
trace) are also fine, as we can use the colour tables to make it
black. At first glance, it seems we can’t put it on a segment that is
grey but not white for some trace (one where @code{SegWhite(seg)} doesn’t
include the trace, but @code{SegGrey(seg)} does), because the new objects
would become grey as the buffer’s ScanLimit advanced. However, in many
configurations, the mutator would hit a barrier as soon as it started
initializing the object, which would flip the buffer. In fact, the
current (2002-01) implementation of buffers assumes buffers are black,
so they’d better.

@anchor{design/poolams design mps poolams fill colour reclaim}@anchor{109d}@ref{109d,,.fill.colour.reclaim;} In fact, putting a buffer on a condemned
segment will screw up the accounting in @code{amsSegReclaim()}, so it’s
disallowed.

@anchor{design/poolams design mps poolams fill slow}@anchor{109e}@ref{109e,,.fill.slow;} @code{AMSBufferFill()} gets progressively slower as more
segments fill up, as it laboriously checks whether the buffer can be
refilled from each segment, by inspecting the allocation bit map. This
is helped a bit by keeping count of free grains in each segment, but
it still spends a lot of time iterating over all the full segments
checking the free size. Obviously, this can be much improved (we could
keep track of the largest free block in the segment and in the pool,
or we could keep the segments in some more efficient structure, or we
could have a real free list structure).

@anchor{design/poolams design mps poolams fill extend}@anchor{109f}@ref{109f,,.fill.extend;} If there’s no space in any existing segment, the
@code{segSize} method is called to decide the size of the new segment to
allocate. If that fails, the code tries to allocate a segment that’s
just large enough to satisfy the request.

@anchor{design/poolams design mps poolams empty}@anchor{10a0}@ref{10a0,,.empty;} @code{amsSegBufferEmpty()} makes the unused space free, since
there’s no reason not to. We have to adjust the colour tables as well,
since these grains were black and now they need to be white (or at
least encoded -G and W).

@anchor{design/poolams design mps poolams reclaim empty buffer}@anchor{10a1}@ref{10a1,,.reclaim.empty.buffer;} Segments which after reclaim only contain a
buffer could be destroyed by trapping the buffer, but there’s no point
to this.

@node Initialization,Condemnation,Allocation<5>,Implementation<22>
@anchor{design/poolams initialization}@anchor{10a2}
@subsubsection Initialization


@anchor{design/poolams design mps poolams init}@anchor{10a3}@ref{10a3,,.init;} The initialization method @code{AMSInit()} takes three
additional arguments: the format of objects allocated in the pool, the
chain that controls GC timing, and a flag for supporting ambiguous
references.

@anchor{design/poolams design mps poolams init share}@anchor{10a4}@ref{10a4,,.init.share;} If support for ambiguity is required, the
@code{shareAllocTable} flag is reset to indicate the pool uses three
separate bit tables, otherwise it is set and the pool shares a table
for non-white and alloc (see @ref{1079,,.colour.encoding}).

@anchor{design/poolams design mps poolams init align}@anchor{10a5}@ref{10a5,,.init.align;} The pool alignment is set equal to the format
alignment (see design.mps.align).

@anchor{design/poolams design mps poolams init internal}@anchor{10a6}@ref{10a6,,.init.internal;} Subclasses call @code{AMSInitInternal()} to avoid the
problems of sharing @code{va_list} and emitting a superfluous
@code{PoolInitAMS} event.

@node Condemnation,Reclaim,Initialization,Implementation<22>
@anchor{design/poolams condemnation}@anchor{10a7}
@subsubsection Condemnation


@anchor{design/poolams design mps poolams condemn buffer}@anchor{10a8}@ref{10a8,,.condemn.buffer;} Buffers are not condemned, instead they are
coloured black, to make sure that the objects allocated will be black,
following @ref{107c,,.colour.alloc} (or, if you wish, because buffers are
ignored like free space, so need the same encoding).

@node Reclaim,Segment merging and splitting,Condemnation,Implementation<22>
@anchor{design/poolams reclaim}@anchor{10a9}
@subsubsection Reclaim


@anchor{design/poolams design mps poolams reclaim}@anchor{10aa}@ref{10aa,,.reclaim;} Reclaim uses either of
analysis.non-moving-colour.constraint.reclaim.white-free-bit (just
reuse the non-white table as the alloc table) or
analysis.non-moving-colour.constraint.reclaim.free-bit (copy it),
depending on the @code{shareAllocTable} flag (as set by @ref{10a4,,.init.share}).
However, bit table still has to be iterated over to count the free
grains. Also, in a debug pool, each white block has to be splatted.

@node Segment merging and splitting,,Reclaim,Implementation<22>
@anchor{design/poolams segment-merging-and-splitting}@anchor{10ab}
@subsubsection Segment merging and splitting


@anchor{design/poolams design mps poolams split-merge}@anchor{10ac}@ref{10ac,,.split-merge;} We provide methods for splitting and merging AMS
segments. The pool implementation doesn’t cause segments to be split
or merged – but a subclass might want to do this (see
@ref{10ad,,.stress.split-merge}). The methods serve as an example of how to
implement this facility.

@anchor{design/poolams design mps poolams split-merge constrain}@anchor{10ae}@ref{10ae,,.split-merge.constrain;} There are some additional constraints on
what segments may be split or merged:


@itemize -

@item 
@anchor{design/poolams design mps poolams split-merge constrain align}@anchor{10af}@ref{10af,,.split-merge.constrain.align;} Segments may only be split or
merged at an address which is aligned to the pool alignment as well
as to the arena grain size.

@anchor{design/poolams design mps poolams split-merge constrain align justify}@anchor{10b0}@ref{10b0,,.split-merge.constrain.align.justify;} This constraint is implied
by the design of allocation and colour tables, which cannot
represent segments starting at unaligned addresses. The constraint
only arises if the pool alignment is larger than the arena
alignment. There’s no requirement to split segments at unaligned
addresses.

@item 
@anchor{design/poolams design mps poolams split-merge constrain empty}@anchor{10b1}@ref{10b1,,.split-merge.constrain.empty;} The higher segment must be empty.
That is, the higher segment passed to @ref{10b2,,SegMerge()} must be empty,
and the higher segment returned by @ref{10b3,,SegSplit()} must be empty.

@anchor{design/poolams design mps poolams split-merge constrain empty justify}@anchor{10b4}@ref{10b4,,.split-merge.constrain.empty.justify;} This constraint makes the
code significantly simpler. There’s no requirement for a more
complex solution at the moment (as the purpose is primarily
pedagogic).
@end itemize

@anchor{design/poolams design mps poolams split-merge fail}@anchor{10b5}@ref{10b5,,.split-merge.fail;} The split and merge methods are not proper
anti-methods for each other (see
design.mps.seg.split-merge.fail.anti.no@footnote{seg.html#design.mps.seg.split-merge.fail.anti.no}). Methods will not reverse the
side-effects of their counterparts if the allocation of the colour and
allocation bit tables should fail. Client methods which over-ride
split and merge should not be written in such a way that they might
detect failure after calling the next method, unless they have reason
to know that the bit table allocations will not fail.

@node Testing<8>,Notes<7>,Implementation<22>,AMS pool class
@anchor{design/poolams design-mps-seg-split-merge-fail-anti-no}@anchor{10b6}@anchor{design/poolams testing}@anchor{10b7}
@subsection Testing


@anchor{design/poolams design mps poolams stress}@anchor{10b8}@ref{10b8,,.stress;} There’s a stress test, MMsrc!amsss.c, that does 800 kB of
allocation, enough for about three GCs. It uses a modified Dylan
format, and checks for corruption by the GC. Both ambiguous and exact
roots are tested.

@anchor{design/poolams design mps poolams stress split-merge}@anchor{10ad}@ref{10ad,,.stress.split-merge;} There’s also a stress test for segment
splitting and merging, MMsrc!segsmss.c. This is similar to amsss.c –
but it defines a subclass of AMS, and causes segments to be split and
merged. Both buffered and non-buffered segments are split / merged.

@node Notes<7>,,Testing<8>,AMS pool class
@anchor{design/poolams notes}@anchor{10b9}
@subsection Notes


@anchor{design/poolams design mps poolams addr-index slow}@anchor{10ba}@ref{10ba,,.addr-index.slow;} Translating from an address to and from a grain
index in a segment uses macros such as @code{AMS_INDEX} and
@code{AMS_INDEX_ADDR}. These are slow because they call @code{SegBase()} on
every translation – we could cache that.

@anchor{design/poolams design mps poolams grey-mutator}@anchor{10bb}@ref{10bb,,.grey-mutator;} To enforce the restriction set in @ref{106b,,.not-req.grey}
we check that all the traces are flipped in @code{amsSegScan()}. It would
be good to check in @code{amsSegFix()} as well, but we can’t do that,
because it’s called during the flip, and we can’t tell the difference
between the flip and the grey mutator phases with the current tracer
interface.

@geindex AWL pool class; design
@geindex pool class; AWL design

@node AWL pool class,LO pool class,AMS pool class,Old design
@anchor{design/poolawl doc}@anchor{10bc}@anchor{design/poolawl awl-pool-class}@anchor{10bd}@anchor{design/poolawl design-poolawl}@anchor{10be}
@section AWL pool class


@menu
* Introduction: Introduction<64>. 
* Requirements: Requirements<39>. 
* Definitions: Definitions<11>. 
* Overview: Overview<24>. 
* Interface: Interface<25>. 
* Data structures: Data structures<4>. 
* Functions: Functions<8>. 
* Test:: 

@end menu

@node Introduction<64>,Requirements<39>,,AWL pool class
@anchor{design/poolawl design mps poolawl}@anchor{10bf}@anchor{design/poolawl introduction}@anchor{10c0}
@subsection Introduction


@anchor{design/poolawl design mps poolawl readership}@anchor{10c1}@ref{10c1,,.readership;} Any MPS developer.

@anchor{design/poolawl design mps poolawl intro}@anchor{10c2}@ref{10c2,,.intro;} The AWL (Automatic Weak Linked) pool is used to manage
Dylan Weak Tables (see req.dylan.fun.weak). Currently the design is
specialised for Dylan Weak Tables, but it could be generalised in the
future.

@node Requirements<39>,Definitions<11>,Introduction<64>,AWL pool class
@anchor{design/poolawl requirements}@anchor{10c3}
@subsection Requirements


See req.dylan.fun.weak.

See meeting.dylan.1997-02-27(0) where many of the requirements for
this pool were first sorted out.

Must satisfy request.dylan.170123@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/dylan/170123}.

@anchor{design/poolawl design mps poolawl req obj-format}@anchor{10c4}@ref{10c4,,.req.obj-format;} Only objects of a certain format need be
supported. This format is a subset of the Dylan Object Format. The
pool uses the first slot in the fixed part of an object to store an
association. See mail.drj.1997-03-11.12-05@footnote{https://info.ravenbrook.com/project/mps/mail/1997/03/11/12-05/0.txt}.

@node Definitions<11>,Overview<24>,Requirements<39>,AWL pool class
@anchor{design/poolawl definitions}@anchor{10c5}@anchor{design/poolawl mail-drj-1997-03-11-12-05}@anchor{10c6}
@subsection Definitions


@anchor{design/poolawl design mps poolawl def grain}@anchor{10c7}@ref{10c7,,.def.grain;} alignment grain, grain. A grain is a range of addresses
where both the base and the limit of the range are aligned and the
size of range is equal to the (same) alignment. In this context the
alignment is the pool’s alignment (@code{pool->alignment}). The grain is
the unit of allocation, marking, scanning, etc.

@node Overview<24>,Interface<25>,Definitions<11>,AWL pool class
@anchor{design/poolawl overview}@anchor{10c8}
@subsection Overview


@anchor{design/poolawl design mps poolawl overview}@anchor{10c9}@ref{10c9,,.overview;}

@anchor{design/poolawl design mps poolawl overview ms}@anchor{10ca}@ref{10ca,,.overview.ms;} The pool is mark and sweep. @anchor{design/poolawl design mps poolawl overview ms justify}@anchor{10cb}@ref{10cb,,.overview.ms.justify;}
Mark-sweep pools are slightly easier to write (than moving pools), and
there are no requirements (yet) that this pool be high performance or
moving or anything like that.

@anchor{design/poolawl design mps poolawl overview alloc}@anchor{10cc}@ref{10cc,,.overview.alloc;} It is possible to allocate weak or exact objects
using the normal reserve/commit AP protocol.
@anchor{design/poolawl design mps poolawl overview alloc justify}@anchor{10cd}@ref{10cd,,.overview.alloc.justify;} Allocation of both weak and exact objects
is required to implement Dylan Weak Tables. Objects are formatted; the
pool uses format A.

@anchor{design/poolawl design mps poolawl overview scan}@anchor{10ce}@ref{10ce,,.overview.scan;} The pool handles the scanning of weak objects
specially so that when a weak reference is deleted the corresponding
reference in an associated object is deleted. The associated object is
determined by using information stored in the object itself (see
@ref{10c4,,.req.obj-format}).

@node Interface<25>,Data structures<4>,Overview<24>,AWL pool class
@anchor{design/poolawl interface}@anchor{10cf}
@subsection Interface


@anchor{design/poolawl design mps poolawl if init}@anchor{10d0}@ref{10d0,,.if.init;} The init method takes one extra parameter in the vararg
list. This parameter should have type @code{Format} and be a format
object that describes the format of the objects to be allocated in
this pool. The format should support scan and skip methods. There is
an additional restriction on the layout of objects, see
@ref{10c4,,.req.obj-format}.

@anchor{design/poolawl design mps poolawl if buffer}@anchor{10d1}@ref{10d1,,.if.buffer;} The @code{BufferInit()} method takes one extra parameter
in the vararg list. This parameter should be either @code{RankEXACT} or
@code{RankWEAK}. It determines the rank of the objects allocated using
that buffer.

@node Data structures<4>,Functions<8>,Interface<25>,AWL pool class
@anchor{design/poolawl data-structures}@anchor{10d2}
@subsection Data structures


@anchor{design/poolawl design mps poolawl sig}@anchor{10d3}@ref{10d3,,.sig;} This signature for this pool will be 0x519bla3l (SIGPooLAWL).

@anchor{design/poolawl design mps poolawl poolstruct}@anchor{10d4}@ref{10d4,,.poolstruct;} The class specific pool structure is:

@example
struct AWLStruct @{
  PoolStruct poolStruct;
  PoolGenStruct pgenStruct; /* pool generation */
  PoolGen pgen;             /* NULL or pointer to pgenStruct */
  Count succAccesses;       /* number of successive single accesses */
  FindDependentFunction findDependent; /*  to find a dependent object */
  awlStatTotalStruct stats;
  Sig sig;                  /* <code/misc.h#sig> */
@}
@end example

@anchor{design/poolawl design mps poolawl awlseg}@anchor{10d5}@ref{10d5,,.awlseg;} The pool defines a segment class @code{AWLSegClass}, which is
a subclass of @code{MutatorSegClass} (see
design.mps.seg.over.hierarchy.mutatorseg@footnote{seg.html#design.mps.seg.over.hierarchy.mutatorseg}). All segments allocated by
the pool are instances of this class, and are of type @code{AWLSeg}, for
which the structure is:

@example
struct AWLSegStruct @{
  GCSegStruct gcSegStruct;  /* superclass fields must come first */
  BT mark;
  BT scanned;
  BT alloc;
  Count grains;
  Count freeGrains;         /* free grains */
  Count bufferedGrains;     /* grains in buffers */
  Count newGrains;          /* grains allocated since last collection */
  Count oldGrains;          /* grains allocated prior to last collection */
  Count singleAccesses;     /* number of accesses processed singly */
  awlStatSegStruct stats;
  Sig sig;                  /* <code/misc.h#sig> */
@}
@end example

@anchor{design/poolawl design mps poolawl awlseg bt}@anchor{10d6}@ref{10d6,,.awlseg.bt;} The @code{mark}, @code{alloc}, and @code{scanned} fields are
bit-tables (see design.mps.bt@footnote{bt.html}). Each bit in the table corresponds to
a single alignment grain in the pool.

@anchor{design/poolawl design mps poolawl awlseg mark}@anchor{10d7}@ref{10d7,,.awlseg.mark;} The @code{mark} bit table is used to record mark bits
during a trace. @ref{10d8,,awlSegWhiten()} (see @ref{10d9,,.fun.whiten} below) sets all
the bits of this table to zero. Fix will read and set bits in this
table. Currently there is only one mark bit table. This means that the
pool can only be condemned for one trace.

@anchor{design/poolawl design mps poolawl awlseg mark justify}@anchor{10da}@ref{10da,,.awlseg.mark.justify;} This is simple, and can be improved later
when we want to run more than one trace.

@anchor{design/poolawl design mps poolawl awlseg scanned}@anchor{10db}@ref{10db,,.awlseg.scanned;} The @code{scanned} bit-table is used to note which
objects have been scanned. Scanning (see @ref{10dc,,.fun.scan} below) a segment
will find objects that are marked but not scanned, scan each object
found and set the corresponding bits in the scanned table.

@anchor{design/poolawl design mps poolawl awlseg alloc}@anchor{10dd}@ref{10dd,,.awlseg.alloc;} The @code{alloc} bit table is used to record which
portions of a segment have been allocated. Ranges of bits in this
table are set in @ref{10de,,awlSegBufferFill()} when a buffer is attached to
the segment. When a buffer is flushed (that is,
@ref{10df,,awlSegBufferEmpty()} is called) from the segment, the bits
corresponding to the unused portion at the end of the buffer are
reset.

@anchor{design/poolawl design mps poolawl awlseg alloc invariant}@anchor{10e0}@ref{10e0,,.awlseg.alloc.invariant;} A bit is set in the alloc table if and
only if the corresponding address is currently being buffered, or the
corresponding address lies within the range of an allocated object.

@anchor{design/poolawl design mps poolawl awlseg grains}@anchor{10e1}@ref{10e1,,.awlseg.grains;} The @code{grains} field is the number of grains that
fit in the segment. Strictly speaking this is not necessary as it can
be computed from @code{SegSize} and AWL’s alignment, however,
precalculating it and storing it in the segment makes the code simpler
by avoiding lots of repeated calculations.

@anchor{design/poolawl design mps poolawl awlseg freeGrains}@anchor{10e2}@ref{10e2,,.awlseg.freeGrains;} A conservative estimate of the number of free
grains in the segment. It is always guaranteed to be greater than or
equal to the number of free grains in the segment, hence can be used
during allocation to quickly pass over a segment.

@cartouche
@quotation Note 
Maintained by blah and blah. Unfinished obviously.
@end quotation
@end cartouche

@node Functions<8>,Test,Data structures<4>,AWL pool class
@anchor{design/poolawl functions}@anchor{10e3}
@subsection Functions


@cartouche
@quotation Note 
How will pool collect? It needs an action structure.
@end quotation
@end cartouche

@menu
* External:: 
* Internal:: 

@end menu

@node External,Internal,,Functions<8>
@anchor{design/poolawl external}@anchor{10e4}
@subsubsection External


@geindex AWLInit (C function)
@anchor{design/poolawl c AWLInit}@anchor{10e5}
@deffn {C Function} @ref{55f,,Res} AWLInit (Pool pool, va_list arg)
@end deffn

@anchor{design/poolawl design mps poolawl fun init}@anchor{10e6}@ref{10e6,,.fun.init;} @code{AWLStruct} has four fields, each one needs initializing.

@anchor{design/poolawl design mps poolawl fun init poolstruct}@anchor{10e7}@ref{10e7,,.fun.init.poolstruct;} The @code{poolStruct} field has already been
initialized by generic code (impl.c.pool).

@anchor{design/poolawl design mps poolawl fun init sig}@anchor{10e8}@ref{10e8,,.fun.init.sig;} The @code{sig} field will be initialized with the
signature for this pool.

@geindex AWLFinish (C function)
@anchor{design/poolawl c AWLFinish}@anchor{10e9}
@deffn {C Function} @ref{55f,,Res} AWLFinish (Pool pool)
@end deffn

@anchor{design/poolawl design mps poolawl fun finish}@anchor{10ea}@ref{10ea,,.fun.finish;} Iterates over all segments in the pool and destroys
each segment (by calling @code{SegFree()}). Overwrites the sig field in
the @code{AWLStruct}. Finishing the generic pool structure is done by the
generic pool code (impl.c.pool).

@anchor{design/poolawl design mps poolawl fun alloc}@anchor{10eb}@ref{10eb,,.fun.alloc;} @code{PoolNoAlloc()} will be used, as this class does not
implement alloc.

@anchor{design/poolawl design mps poolawl fun free}@anchor{10ec}@ref{10ec,,.fun.free;} @code{PoolNoFree()} will be used, as this class does not
implement free.

@geindex AWLBufferFill (C function)
@anchor{design/poolawl c AWLBufferFill}@anchor{10ed}
@deffn {C Function} @ref{55f,,Res} AWLBufferFill (Seg *segReturn, Addr *baseReturn, Pool pool, Buffer buffer, Size size)
@end deffn

@anchor{design/poolawl design mps poolawl fun fill}@anchor{10ee}@ref{10ee,,.fun.fill;} This zips round all the segments applying
@code{SegBufferFill()} to each segment. @ref{10de,,awlSegBufferFill()} attempts
to find a large-enough free range; if it finds one then it may be
bigger than the actual request, in which case the remainder can be
used to “fill” the rest of the buffer. If no free range can be found
in an existing segment then a new segment will be created (which is at
least large enough). The range of buffered addresses is marked as
allocated in the segment’s alloc table.

@geindex AWLDescribe (C function)
@anchor{design/poolawl c AWLDescribe}@anchor{10ef}
@deffn {C Function} @ref{55f,,Res} AWLDescribe (Pool pool, mps_lib_FILE *stream, Count depth)
@end deffn

@anchor{design/poolawl design mps poolawl fun describe}@anchor{10f0}@ref{10f0,,.fun.describe;}

@node Internal,,External,Functions<8>
@anchor{design/poolawl internal}@anchor{10f1}
@subsubsection Internal


@geindex AWLSegCreate (C function)
@anchor{design/poolawl c AWLSegCreate}@anchor{10f2}
@deffn {C Function} @ref{55f,,Res} AWLSegCreate (AWLSeg *awlsegReturn, Size size)
@end deffn

@anchor{design/poolawl design mps poolawl fun awlsegcreate}@anchor{10f3}@ref{10f3,,.fun.awlsegcreate;} Creates a segment of class @code{AWLSegClass} of size at least @code{size}.

@anchor{design/poolawl design mps poolawl fun awlsegcreate size round}@anchor{10f4}@ref{10f4,,.fun.awlsegcreate.size.round;} @code{size} is rounded up to the arena
grain size before requesting the segment.

@anchor{design/poolawl design mps poolawl fun awlsegcreate size round justify}@anchor{10f5}@ref{10f5,,.fun.awlsegcreate.size.round.justify;} The arena requires that all
segment sizes are rounded up to the arena grain size.

@anchor{design/poolawl design mps poolawl fun awlsegcreate where}@anchor{10f6}@ref{10f6,,.fun.awlsegcreate.where;} The segment is allocated using a
generation preference, using the generation number stored in the
@code{AWLStruct} (the @code{gen} field), see @ref{10d4,,.poolstruct} above.

@geindex awlSegInit (C function)
@anchor{design/poolawl c awlSegInit}@anchor{10f7}
@deffn {C Function} @ref{55f,,Res} awlSegInit (Seg seg, Pool pool, Addr base, Size size, ArgList args)
@end deffn

@anchor{design/poolawl design mps poolawl fun awlseginit}@anchor{10f8}@ref{10f8,,.fun.awlseginit;} Init method for @code{AWLSegClass}, called for
@code{SegAlloc()} whenever an @code{AWLSeg} is created (see
@ref{10f3,,.fun.awlsegcreate} above).

@anchor{design/poolawl design mps poolawl fun awlseginit tables}@anchor{10f9}@ref{10f9,,.fun.awlseginit.tables;} The segment’s mark scanned and alloc tables
(see @ref{10d6,,.awlseg.bt} above) are allocated and initialised. The segment’s
grains field is computed and stored.

@geindex awlSegFinish (C function)
@anchor{design/poolawl c awlSegFinish}@anchor{10fa}
@deffn {C Function} void awlSegFinish (Seg seg)
@end deffn

@anchor{design/poolawl design mps poolawl fun awlsegfinish}@anchor{10fb}@ref{10fb,,.fun.awlsegfinish;} Finish method for @code{AWLSegClass}, called from
@code{SegFree()}. Will free the segment’s tables (see @ref{10d6,,.awlseg.bt}).

@geindex awlSegBufferFill (C function)
@anchor{design/poolawl c awlSegBufferFill}@anchor{10de}
@deffn {C Function} @ref{3a9,,Bool} awlSegBufferFill (Addr *baseReturn, Addr *limitReturn, Seg seg, Size size, RankSet rankSet)
@end deffn

@anchor{design/poolawl design mps poolawl fun seg buffer-fill}@anchor{10fc}@ref{10fc,,.fun.seg.buffer-fill;} Searches for a free block in the segment that
is at least @code{size} bytes long. The base address of the block is
returned in @code{*baseReturn}, the limit of the entire free block (which
must be at least as large as @code{size} and may be bigger) is returned
in @code{*limitReturn}. The requested size is converted to a number of
grains, @ref{dab,,BTFindResRange()} is called to find a run of this length in
the alloc bit-table (@ref{10dd,,.awlseg.alloc}). The results (if it is
successful) from @ref{dab,,BTFindResRange()} are in terms of grains, they are
converted back to addresses before returning the relevant values from
this function.

@geindex awlSegBufferEmpty (C function)
@anchor{design/poolawl c awlSegBufferEmpty}@anchor{10df}
@deffn {C Function} void awlSegBufferEmpty (Seg seg, Buffer buffer)
@end deffn

@anchor{design/poolawl design mps poolawl fun seg buffer-empty}@anchor{10fd}@ref{10fd,,.fun.seg.buffer-empty;} Locates the free portion of the buffer, that
is the memory between the init and the limit of the buffer and records
these locations as being free in the alloc table.

@geindex awlSegWhiten (C function)
@anchor{design/poolawl c awlSegWhiten}@anchor{10d8}
@deffn {C Function} @ref{55f,,Res} awlSegWhiten (Seg seg, Trace trace)
@end deffn

@anchor{design/poolawl design mps poolawl fun whiten}@anchor{10d9}@ref{10d9,,.fun.whiten;} The current design only permits each segment to be
condemned for one trace (see @ref{10d7,,.awlseg.mark}). This function checks
that the segment is not white for any trace (@code{seg->white ==
TraceSetEMPTY}). The segment’s mark bit-table is reset, and the
whiteness of the seg (@code{seg->white}) has the current trace added to
it.

@geindex awlSegGreyen (C function)
@anchor{design/poolawl c awlSegGreyen}@anchor{10fe}
@deffn {C Function} void awlSegGreyen (Seg seg, Trace trace)
@end deffn

@anchor{design/poolawl design mps poolawl fun grey}@anchor{10ff}@ref{10ff,,.fun.grey;} If the segment is not white for this trace, the
segment’s mark table is set to all 1s and the segment is recorded as
being grey.

@geindex awlSegScan (C function)
@anchor{design/poolawl c awlSegScan}@anchor{1100}
@deffn {C Function} @ref{55f,,Res} awlSegScan (Bool *totalReturn, Seg seg, ScanState ss)
@end deffn

@anchor{design/poolawl design mps poolawl fun scan}@anchor{10dc}@ref{10dc,,.fun.scan;}

@anchor{design/poolawl design mps poolawl fun scan overview}@anchor{1101}@ref{1101,,.fun.scan.overview;} The scanner performs a number of passes over
the segment, scanning each marked and unscanned (grey) object that is
finds.

@anchor{design/poolawl design mps poolawl fun scan overview finish}@anchor{1102}@ref{1102,,.fun.scan.overview.finish;} It keeps perform a pass over the segment
until it is finished.

@anchor{design/poolawl design mps poolawl fun scan overview finish condition}@anchor{1103}@ref{1103,,.fun.scan.overview.finish.condition;} A condition for finishing is
that no new marks got placed on objects in this segment during the
pass.

@anchor{design/poolawl design mps poolawl fun scan overview finish approximation}@anchor{1104}@ref{1104,,.fun.scan.overview.finish.approximation;} We use an even stronger
condition for finishing that assumes that scanning any object may
introduce marks onto this segment. It is finished when a pass results
in scanning no objects (that is, all objects were either unmarked or
both marked and scanned).

@anchor{design/poolawl design mps poolawl fun scan overview finished-flag}@anchor{1105}@ref{1105,,.fun.scan.overview.finished-flag;} There is a flag called
@code{finished} which keeps track of whether we should finish or not. We
only ever finish at the end of a pass. At the beginning of a pass the
flag is set. During a pass if any objects are scanned then the
@code{finished} flag is reset. At the end of a pass if the @code{finished}
flag is still set then we are finished. No more passes take place and
the function returns.

@anchor{design/poolawl design mps poolawl fun scan pass}@anchor{1106}@ref{1106,,.fun.scan.pass;} A pass consists of a setup phase and a repeated
phase.

@anchor{design/poolawl design mps poolawl fun scan pass buffer}@anchor{1107}@ref{1107,,.fun.scan.pass.buffer;} The following assumes that in the general
case the segment is buffered; if the segment is not buffered then the
actions that mention buffers are not taken (they are unimportant if
the segment is not buffered).

@anchor{design/poolawl design mps poolawl fun scan pass p}@anchor{1108}@ref{1108,,.fun.scan.pass.p;} The pass uses a cursor called @code{p} to progress
over the segment. During a pass @code{p} will increase from the base
address of the segment to the limit address of the segment. When @code{p}
reaches the limit address of the segment, the pass in complete.

@anchor{design/poolawl design mps poolawl fun scan pass setup}@anchor{1109}@ref{1109,,.fun.scan.pass.setup;} @code{p} initially points to the base address of
the segment.

@anchor{design/poolawl design mps poolawl fun scan pass repeat}@anchor{110a}@ref{110a,,.fun.scan.pass.repeat;} The following comprises the repeated phase.
The repeated phase is repeated until the pass completion condition is
true (that is, @code{p} has reached the limit of the segment, see
@ref{1108,,.fun.scan.pass.p} above and @ref{110b,,.fun.scan.pass.repeat.complete}
below).

@anchor{design/poolawl design mps poolawl fun scan pass repeat complete}@anchor{110b}@ref{110b,,.fun.scan.pass.repeat.complete;} If @code{p} is equal to the segment’s
limit then we are done. We proceed to check whether any further passes
need to be performed (see @ref{110c,,.fun.scan.pass.more} below).

@anchor{design/poolawl design mps poolawl fun scan pass repeat free}@anchor{110d}@ref{110d,,.fun.scan.pass.repeat.free;} If @code{!alloc(p)} (the grain is free)
then increment @code{p} and return to the beginning of the loop.

@anchor{design/poolawl design mps poolawl fun scan pass repeat buffer}@anchor{110e}@ref{110e,,.fun.scan.pass.repeat.buffer;} If @code{p} is equal to the buffer’s
ScanLimit, as returned by @code{BufferScanLimit()}, then set @code{p} equal
to the buffer’s Limit, as returned by @code{BufferLimit()} and return to
the beginning of the loop.

@anchor{design/poolawl design mps poolawl fun scan pass repeat object-end}@anchor{110f}@ref{110f,,.fun.scan.pass.repeat.object-end;} The end of the object is located
using the @code{format->skip} method.

@anchor{design/poolawl design mps poolawl fun scan pass repeat object}@anchor{1110}@ref{1110,,.fun.scan.pass.repeat.object;} if @code{mark(p) && !scanned(p)} then
the object pointed at is marked but not scanned, which means we must
scan it, otherwise we must skip it.

@anchor{design/poolawl design mps poolawl fun scan pass repeat object dependent}@anchor{1111}@ref{1111,,.fun.scan.pass.repeat.object.dependent;} To scan the object the
object we first have to determine if the object has a dependent object (see
@ref{10c4,,.req.obj-format}).

@anchor{design/poolawl design mps poolawl fun scan pass repeat object dependent expose}@anchor{1112}@ref{1112,,.fun.scan.pass.repeat.object.dependent.expose;} If it has a
dependent object then we must expose the segment that the dependent
object is on (only if the dependent object actually points to MPS
managed memory) prior to scanning and cover the segment subsequent to
scanning.

@anchor{design/poolawl design mps poolawl fun scan pass repeat object dependent summary}@anchor{1113}@ref{1113,,.fun.scan.pass.repeat.object.dependent.summary;} The summary of the
dependent segment must be set to @code{RefSetUNIV} to reflect the fact
that we are allowing it to be written to (and we don’t know what gets
written to the segment).

@anchor{design/poolawl design mps poolawl fun scan pass repeat object scan}@anchor{1114}@ref{1114,,.fun.scan.pass.repeat.object.scan;} The object is then scanned by
calling the format’s scan method with base and limit set to the
beginning and end of the object (@anchor{design/poolawl design mps poolawl fun scan scan improve single}@anchor{1115}@ref{1115,,.fun.scan.scan.improve.single;} A
scan1 format method would make it slightly simpler here). Then the
finished flag is cleared and the bit in the segment’s scanned table is
set.

@anchor{design/poolawl design mps poolawl fun scan pass repeat advance}@anchor{1116}@ref{1116,,.fun.scan.pass.repeat.advance;} @code{p} is advanced past the object
and we return to the beginning of the loop.

@anchor{design/poolawl design mps poolawl fun scan pass more}@anchor{110c}@ref{110c,,.fun.scan.pass.more;} At the end of a pass the finished flag is
examined.

@anchor{design/poolawl design mps poolawl fun scan pass more not}@anchor{1117}@ref{1117,,.fun.scan.pass.more.not;} If the finished flag is set then we are
done (see @ref{1105,,.fun.scan.overview.finished-flag} above), @ref{1100,,awlSegScan()}
returns.

@anchor{design/poolawl design mps poolawl fun scan pass more so}@anchor{1118}@ref{1118,,.fun.scan.pass.more.so;} Otherwise (the finished flag is reset) we
perform another pass (see @ref{1106,,.fun.scan.pass} above).

@geindex awlSegFix (C function)
@anchor{design/poolawl c awlSegFix}@anchor{1119}
@deffn {C Function} @ref{55f,,Res} awlSegFix (Seg seg, ScanState ss, Ref *refIO)
@end deffn

@anchor{design/poolawl design mps poolawl fun fix}@anchor{111a}@ref{111a,,.fun.fix;} If the rank (@code{ss->rank}) is @code{RankAMBIG} then fix
returns immediately unless the reference is in the segment bounds,
aligned to the pool alignment, and allocated.

The bit in the marked table corresponding to the referenced grain will
be read. If it is already marked then fix returns. Otherwise (the
grain is unmarked), @code{ss->wasMarked} is set to @code{FALSE} (see
design.mps.fix.was-marked.not@footnote{fix.html#design.mps.fix.was-marked.not}), the remaining actions depend on
whether the rank (@code{ss->rank}) is @code{RankWEAK} or not. If the rank is
weak then the reference is adjusted to 0 (see design.mps.weakness) and
fix returns. If the rank is something else then the mark bit
corresponding to the referenced grain is set, and the segment is
greyed using @code{SegSetGrey()}.

@geindex awlSegReclaim (C function)
@anchor{design/poolawl c awlSegReclaim}@anchor{111b}
@deffn {C Function} void awlSegReclaim (Seg seg, Trace trace)
@end deffn

@anchor{design/poolawl design mps poolawl fun reclaim}@anchor{111c}@ref{111c,,.fun.reclaim;} This iterates over all allocated objects in the
segment and frees objects that are not marked. When this iteration is
complete the marked array is completely reset.

@code{p} points to base of segment. Then:

@example
while(p < SegLimit(seg) @{
  if(!alloc(p)) @{ ++p;continue; @}
  q = skip(p) /* q points to just past the object pointed at by p */
  if !marked(p) free(p, q); /* reset the bits in the alloc table from p to q-1 inclusive. */
  p = q
@}
@end example

Finally, reset the entire marked array using @ref{d6e,,BTResRange()}.

@anchor{design/poolawl design mps poolawl fun reclaim improve pad}@anchor{111d}@ref{111d,,.fun.reclaim.improve.pad;} Consider filling free ranges with padding
objects. Now reclaim doesn’t need to check that the objects are
allocated before skipping them. There may be a corresponding change
for scan as well.

@geindex AWLDependentObject (C function)
@anchor{design/poolawl c AWLDependentObject}@anchor{111e}
@deffn {C Function} @ref{3a9,,Bool} AWLDependentObject (Addr *objReturn, Addr parent)
@end deffn

@anchor{design/poolawl design mps poolawl fun dependent-object}@anchor{111f}@ref{111f,,.fun.dependent-object;} This function abstracts the association
between an object and its linked dependent (see @ref{10c4,,.req.obj-format}).
It currently assumes that objects are Dylan Object formatted according
to design.dylan.container (see analysis.mps.poolawl.dependent.abstract
for suggested improvements). An object has a dependent object iff the
second word of the object, that is, @code{((Word *)parent)[1]}, is
non-@code{NULL}. The dependent object is the object referenced by the
second word and must be a valid object.

This function assumes objects are in Dylan Object Format (see
design.dylan.container). It will check that the first word looks like
a Dylan wrapper pointer. It will check that the wrapper indicates that
the wrapper has a reasonable format (namely at least one fixed field).
If the second word is @code{NULL} it will return @code{FALSE}. If the second
word is non-@code{NULL} then the contents of it will be assigned to
@code{*objReturn}, and it will return @code{TRUE}.

@node Test,,Functions<8>,AWL pool class
@anchor{design/poolawl test}@anchor{1120}
@subsection Test



@itemize -

@item 
must create Dylan objects.

@item 
must create Dylan vectors with at least one fixed field.

@item 
must allocate weak thingies.

@item 
must allocate exact tables.

@item 
must link tables together.

@item 
must populate tables with junk.

@item 
some junk must die.
@end itemize

Use an LO pool and an AWL pool. Three buffers. One buffer for the LO
pool, one exact buffer for the AWL pool, one weak buffer for the AWL
pool.

Initial test will allocate one object from each buffer and then
destroy all buffers and pools and exit

@geindex LO pool class; design
@geindex pool class; LO design

@node LO pool class,MFS pool class,AWL pool class,Old design
@anchor{design/poollo doc}@anchor{1121}@anchor{design/poollo design-poollo}@anchor{1122}@anchor{design/poollo lo-pool-class}@anchor{1123}
@section LO pool class


@menu
* Introduction: Introduction<65>. 
* Definitions: Definitions<12>. 
* Requirements: Requirements<40>. 
* Overview: Overview<25>. 
* Interface: Interface<26>. 
* Data structures: Data structures<5>. 
* Functions: Functions<9>. 
* Attachment:: 

@end menu

@node Introduction<65>,Definitions<12>,,LO pool class
@anchor{design/poollo design mps poollo}@anchor{1124}@anchor{design/poollo introduction}@anchor{1125}
@subsection Introduction


@anchor{design/poollo design mps poollo readership}@anchor{1126}@ref{1126,,.readership;} Any MPS developer.

@anchor{design/poollo design mps poollo intro}@anchor{1127}@ref{1127,,.intro;} The LO (Leaf Object) pool class is a pool class developed
for DylanWorks. It is designed to manage objects that have no
references (leaf objects) such as strings, bit tables, etc. It is a
garbage collected pool (in that objects allocated in the pool are
automatically reclaimed when they are discovered to be unreachable.

@cartouche
@quotation Note 
Need to sort out issue of alignment. Currently lo grabs alignment
from format, almost certainly “ought” to use the greater of the
format alignment and the @code{MPS_ALIGN} value. David Jones,
1997-07-02.
@end quotation
@end cartouche

@node Definitions<12>,Requirements<40>,Introduction<65>,LO pool class
@anchor{design/poollo definitions}@anchor{1128}
@subsection Definitions


@anchor{design/poollo design mps poollo def leaf}@anchor{1129}@ref{1129,,.def.leaf;} A “leaf” object is an object that contains no
references, or an object all of whose references refer to roots. That
is, any references that the object has must refer to a priori alive
objects that are guaranteed not to move, hence the references do not
need fixing.

@anchor{design/poollo design mps poollo def grain}@anchor{112a}@ref{112a,,.def.grain;} A grain (of some alignment) is a contiguous aligned
area of memory of the smallest size possible (which is the same size
as the alignment).

@node Requirements<40>,Overview<25>,Definitions<12>,LO pool class
@anchor{design/poollo requirements}@anchor{112b}
@subsection Requirements


@anchor{design/poollo design mps poollo req source}@anchor{112c}@ref{112c,,.req.source;} See req.dylan.fun.obj.alloc and
req.dylan.prot.ffi.access.

@anchor{design/poollo design mps poollo req leaf}@anchor{112d}@ref{112d,,.req.leaf;} The pool must manage formatted leaf objects (see
@ref{1129,,.def.leaf} above for a definition). This is intended to encompass
Dylan and C leaf objects. Dylan leaf objects have a reference to their
wrapper, but are still leaf objects (in the sense of @ref{1129,,.def.leaf})
because the wrapper will be a root.

@anchor{design/poollo design mps poollo req nofault}@anchor{112e}@ref{112e,,.req.nofault;} The memory containing objects managed by the pool
must not be protected. The client must be allowed to access these
objects without hitting an MPS barrier.

@node Overview<25>,Interface<26>,Requirements<40>,LO pool class
@anchor{design/poollo overview}@anchor{112f}
@subsection Overview


@anchor{design/poollo design mps poollo overview}@anchor{1130}@ref{1130,,.overview;}

@anchor{design/poollo design mps poollo overview ms}@anchor{1131}@ref{1131,,.overview.ms;} The LO Pool is a non-moving mark-and-sweep collector.

@anchor{design/poollo design mps poollo overview ms justify}@anchor{1132}@ref{1132,,.overview.ms.justify;} Mark-and-sweep pools are simpler than moving
pools.

@anchor{design/poollo design mps poollo overview alloc}@anchor{1133}@ref{1133,,.overview.alloc;} Objects are allocated in the pool using the
reserve/commit protocol on allocation points.

@anchor{design/poollo design mps poollo overview format}@anchor{1134}@ref{1134,,.overview.format;} The pool is formatted. The format of the objects
in the pool is specified at instantiation time, using a format object
derived from a variant A format (using variant A is overkill, see
@ref{1135,,.if.init} below) (see design.mps.format for excuse about calling the
variant ‘A’).

@node Interface<26>,Data structures<5>,Overview<25>,LO pool class
@anchor{design/poollo interface}@anchor{1136}
@subsection Interface


@anchor{design/poollo design mps poollo if init}@anchor{1135}@ref{1135,,.if.init;}

@anchor{design/poollo design mps poollo if init args}@anchor{1137}@ref{1137,,.if.init.args;} The init method for this class takes one extra
parameter in the vararg parameter list.

@anchor{design/poollo design mps poollo if init format}@anchor{1138}@ref{1138,,.if.init.format;} The extra parameter should be an object of type
Format and should describe the format of the objects that are to be
allocated in the pool.

@anchor{design/poollo design mps poollo if init format use}@anchor{1139}@ref{1139,,.if.init.format.use;} The pool uses the skip and alignment slots of
the format. The skip method is used to determine the length of objects
(during reclaim). The alignment field is used to determine the
granularity at which memory should be managed.

@anchor{design/poollo design mps poollo if init format a}@anchor{113a}@ref{113a,,.if.init.format.a;} Currently only format variant A is supported
though clearly that is overkill as only skip and alignment are used.

@node Data structures<5>,Functions<9>,Interface<26>,LO pool class
@anchor{design/poollo data-structures}@anchor{113b}
@subsection Data structures


@anchor{design/poollo design mps poollo sig}@anchor{113c}@ref{113c,,.sig;} The signature for the LO Pool Class is 0x51970b07
(SIGLOPOoL).

@anchor{design/poollo design mps poollo poolstruct}@anchor{113d}@ref{113d,,.poolstruct;} The class specific pool structure is:

@example
typedef struct LOStruct @{
  PoolStruct poolStruct;        /* generic pool structure */
  PoolGenStruct pgenStruct;     /* pool generation */
  PoolGen pgen;                 /* NULL or pointer to pgenStruct */
  Sig sig;                      /* <code/misc.h#sig> */
@} LOStruct;
@end example

@anchor{design/poollo design mps poollo loseg}@anchor{113e}@ref{113e,,.loseg;} Every segment is an instance of segment class
@code{LOSegClass}, a subclass of @code{MutatorSegClass} (see
design.mps.seg.over.hierarchy.mutatorseg@footnote{seg.html#design.mps.seg.over.hierarchy.mutatorseg}), and is an object of type
@code{LOSegStruct}.

@anchor{design/poollo design mps poollo loseg purpose}@anchor{113f}@ref{113f,,.loseg.purpose;} The purpose of the @code{LOSeg} structure is to
associate the bit tables used for recording allocation and mark
information with the segment.

@anchor{design/poollo design mps poollo loseg decl}@anchor{1140}@ref{1140,,.loseg.decl;} The declaration of the structure is as follows:

@example
typedef struct LOSegStruct @{
  GCSegStruct gcSegStruct;  /* superclass fields must come first */
  BT mark;                  /* mark bit table */
  BT alloc;                 /* alloc bit table */
  Count freeGrains;         /* free grains */
  Count bufferedGrains;     /* grains in buffers */
  Count newGrains;          /* grains allocated since last collection */
  Count oldGrains;          /* grains allocated prior to last collection */
  Sig sig;                  /* <code/misc.h#sig> */
@} LOSegStruct;
@end example

@anchor{design/poollo design mps poollo loseg sig}@anchor{1141}@ref{1141,,.loseg.sig;} The signature for a loseg is 0x519705E9 (SIGLOSEG).

@anchor{design/poollo design mps poollo loseg lo}@anchor{1142}@ref{1142,,.loseg.lo;} The lo field points to the LO structure that owns this
segment.

@anchor{design/poollo design mps poollo loseg bit}@anchor{1143}@ref{1143,,.loseg.bit;} Bit Tables (see design.mps.bt@footnote{bt.html}) are used to record
allocation and mark information. This is relatively straightforward,
but might be inefficient in terms of space in some circumstances.

@anchor{design/poollo design mps poollo loseg mark}@anchor{1144}@ref{1144,,.loseg.mark;} This is a Bit Table that is used to mark objects
during a trace. Each grain in the segment is associated with 1 bit in
this table. When @ref{4c0,,loSegFix()} (see @ref{1145,,.fun.fix} below) is called the
address is converted to a grain within the segment and the
corresponding bit in this table is set.

@anchor{design/poollo design mps poollo loseg alloc}@anchor{1146}@ref{1146,,.loseg.alloc;} This is a Bit Table that is used to record which
addresses are allocated. Addresses that are allocated and are not
buffered have their corresponding bit in this table set. If a bit in
this table is reset then either the address is free or is being
buffered.

@anchor{design/poollo design mps poollo loseg diagram}@anchor{1147}@ref{1147,,.loseg.diagram;} The following diagram is now obsolete. It’s also
not very interesting - but I’ve left the sources in case anyone ever
gets around to updating it. tony 1999-12-16

[missing diagram]

@node Functions<9>,Attachment,Data structures<5>,LO pool class
@anchor{design/poollo functions}@anchor{1148}
@subsection Functions


@menu
* External: External<2>. 
* Internal: Internal<2>. 

@end menu

@node External<2>,Internal<2>,,Functions<9>
@anchor{design/poollo external}@anchor{1149}
@subsubsection External


@anchor{design/poollo design mps poollo fun init}@anchor{114a}@ref{114a,,.fun.init;}

@anchor{design/poollo design mps poollo fun destroy}@anchor{114b}@ref{114b,,.fun.destroy;}

@anchor{design/poollo design mps poollo fun buffer-fill}@anchor{114c}@ref{114c,,.fun.buffer-fill;}

@cartouche
@quotation Note 
Explain way in which buffers interact with the alloc table and how
it could be improved.
@end quotation
@end cartouche

@anchor{design/poollo design mps poollo fun buffer-empty}@anchor{114d}@ref{114d,,.fun.buffer-empty;}

@anchor{design/poollo design mps poollo fun condemn}@anchor{114e}@ref{114e,,.fun.condemn;}

@node Internal<2>,,External<2>,Functions<9>
@anchor{design/poollo internal}@anchor{114f}
@subsubsection Internal


@geindex loSegFix (C function)
@anchor{design/poollo c loSegFix}@anchor{4c0}
@deffn {C Function} @ref{55f,,Res} loSegFix (Seg seg, ScanState ss, Ref *refIO)
@end deffn

@anchor{design/poollo design mps poollo fun fix}@anchor{1145}@ref{1145,,.fun.fix;} Fix treats references of most ranks much the same. There
is one mark table that records all marks. A reference of rank
@code{RankAMBIG} is first checked to see if it is aligned to the pool
alignment and discarded if not. The reference is converted to a grain
number within the segment (by subtracting the segments’ base from the
reference and then dividing by the grain size). The bit (the one
corresponding to the grain number) is set in the mark table.
Exception, for a weak reference (rank is @code{RankWEAK}) the mark table
is checked and the reference is fixed to 0 if this address has not
been marked otherwise nothing happens. Note that there is no check
that the reference refers to a valid object boundary (which wouldn’t
be a valid check in the case of ambiguous references anyway).

@geindex loSegReclaim (C function)
@anchor{design/poollo c loSegReclaim}@anchor{4c6}
@deffn {C Function} void loSegReclaim (Seg seg, Trace trace)
@end deffn

@anchor{design/poollo design mps poollo fun segreclaim}@anchor{1150}@ref{1150,,.fun.segreclaim;} For all the contiguous allocated regions in the
segment it locates the boundaries of all the objects in that region by
repeatedly skipping (by calling @code{format->skip}) from the beginning
of the region (the beginning of the region is guaranteed to coincide
with the beginning of an object). For each object it examines the bit
in the mark bit table that corresponds to the beginning of the object.
If that bit is set then the object has been marked as a result of a
previous call to @ref{4c0,,loSegFix()}, the object is preserved by doing
nothing. If that bit is not set then the object has not been marked
and should be reclaimed; the object is reclaimed by resetting the
appropriate range of bits in the segment’s free bit table.

@cartouche
@quotation Note 
Special things happen for buffered segments.

Explain how the marked variable is used to free segments.
@end quotation
@end cartouche

@node Attachment,,Functions<9>,LO pool class
@anchor{design/poollo attachment}@anchor{1151}
@subsection Attachment


[missing attachment “LOGROUP.CWK”]

@geindex MFS pool class; design
@geindex pool class; MFS design

@node MFS pool class,MRG pool class,LO pool class,Old design
@anchor{design/poolmfs doc}@anchor{1152}@anchor{design/poolmfs design-poolmfs}@anchor{1153}@anchor{design/poolmfs mfs-pool-class}@anchor{1154}
@section MFS pool class


@menu
* Overview: Overview<26>. 
* Implementation: Implementation<23>. 

@end menu

@node Overview<26>,Implementation<23>,,MFS pool class
@anchor{design/poolmfs design mps poolmfs}@anchor{1155}@anchor{design/poolmfs overview}@anchor{1156}
@subsection Overview


MFS stands for “Manual Fixed Small”. The MFS pool class manages
objects that are of a fixed size. It is intended to only manage small
objects efficiently. Storage is recycled manually by the client
programmer.

A particular instance of an MFS Pool can manage objects only of a
single size, but different instances can manage objects of different
sizes. The size of object that an instance can manage is declared when
the instance is created.

@node Implementation<23>,,Overview<26>,MFS pool class
@anchor{design/poolmfs implementation}@anchor{1157}
@subsection Implementation


@anchor{design/poolmfs design mps poolmfs impl extents}@anchor{1158}@ref{1158,,.impl.extents;} MFS operates in a very simple manner: each extent
allocated from the arena is divided into units.

@anchor{design/poolmfs design mps poolmfs impl free-units}@anchor{1159}@ref{1159,,.impl.free-units;} Free units are kept on a linked list using a
header stored in the unit itself. The linked list is not ordered;
allocation and deallocation simply pop and push from the head of the
list. This is fast, but successive allocations might have poor
locality if previous successive frees did.

@anchor{design/poolmfs design mps poolmfs impl extent-ring}@anchor{115a}@ref{115a,,.impl.extent-ring;} The list of extents belonging to the pool is
maintained as a ring with a node at the start of each extent.

@anchor{design/poolmfs design mps poolmfs impl extent-ring justify}@anchor{115b}@ref{115b,,.impl.extent-ring.justify;} Storing the linked list of free nodes
and the extent ring node in the managed memory is against the general
principle of the MPS design, which keeps its management structures
away from client memory. However, the MFS pool is used during the
bootstrapping process (see design.mps.bootstrap.land.sol.pool@footnote{bootstrap.html#design.mps.bootstrap.land.sol.pool}) and so
has no other memory pools available for storage.

@geindex MRG pool class; design
@geindex pool class; MRG design

@node MRG pool class,Manual Variable Temporal MVT pool design,MFS pool class,Old design
@anchor{design/poolmrg doc}@anchor{115c}@anchor{design/poolmrg design-mps-bootstrap-land-sol-pool}@anchor{115d}@anchor{design/poolmrg design-poolmrg}@anchor{115e}@anchor{design/poolmrg mrg-pool-class}@anchor{115f}
@section MRG pool class


@menu
* Introduction: Introduction<66>. 
* Goals: Goals<3>. 
* Requirements: Requirements<41>. 
* Terminology: Terminology<2>. 
* Overview: Overview<27>. 
* Protocols:: 
* Data structures: Data structures<6>. 
* Functions: Functions<10>. 
* Transgressions:: 
* Future: Future<3>. 
* Tests: Tests<2>. 
* Notes: Notes<8>. 

@end menu

@node Introduction<66>,Goals<3>,,MRG pool class
@anchor{design/poolmrg design mps poolmrg}@anchor{1160}@anchor{design/poolmrg introduction}@anchor{1161}
@subsection Introduction


@anchor{design/poolmrg design mps poolmrg readership}@anchor{1162}@ref{1162,,.readership;} Any MPS developer.

@anchor{design/poolmrg design mps poolmrg intro}@anchor{1163}@ref{1163,,.intro;} This is the design of the MRG (Manual Rank Guardian) pool
class. The MRG pool class is part of the MPS. The MRG pool class is
internal to the MPS (has no client interface) and is used to implement
finalization.

@anchor{design/poolmrg design mps poolmrg source}@anchor{1164}@ref{1164,,.source;} Some of the techniques in paper.dbe93 (“Guardians in a
Generation-Based Garbage Collector”) were used in this design. Some
analysis of this design (including various improvements and some more
in-depth justification) is in analysis.mps.poolmrg. That document
should be understood before changing this document. It is also helpful
to look at design.mps.finalize@footnote{finalize.html} and design.mps.message@footnote{message.html}.

@node Goals<3>,Requirements<41>,Introduction<66>,MRG pool class
@anchor{design/poolmrg design-mps-finalize}@anchor{1165}@anchor{design/poolmrg goals}@anchor{1166}
@subsection Goals


@anchor{design/poolmrg design mps poolmrg goal final}@anchor{1167}@ref{1167,,.goal.final;} The MRG pool class should support all
requirements pertaining to finalization.

@node Requirements<41>,Terminology<2>,Goals<3>,MRG pool class
@anchor{design/poolmrg requirements}@anchor{1168}
@subsection Requirements


@anchor{design/poolmrg design mps poolmrg req}@anchor{1169}@ref{1169,,.req;} We have only one requirement pertaining to finalization:

@anchor{design/poolmrg design mps poolmrg req dylan fun finalization}@anchor{116a}@ref{116a,,.req.dylan.fun.finalization;} Support the Dylan language-level
implementation of finalized objects: objects are registered, and are
finalized in random order when they would otherwise have died. Cycles
are broken at random places. There is no guarantee of promptness.

@anchor{design/poolmrg design mps poolmrg req general}@anchor{116b}@ref{116b,,.req.general;} However, finalization is a very common piece of
functionality that is provided by (sophisticated) memory managers, so
we can expect other clients to request this sort of functionality.

@anchor{design/poolmrg design mps poolmrg anti-req}@anchor{116c}@ref{116c,,.anti-req;} Is it required that the MRG pool class return
unused segments to the arena? MFS, for example, does not do this. MRG
will not do this in its initial implementation.

@node Terminology<2>,Overview<27>,Requirements<41>,MRG pool class
@anchor{design/poolmrg terminology}@anchor{116d}
@subsection Terminology


@anchor{design/poolmrg design mps poolmrg def mrg}@anchor{116e}@ref{116e,,.def.mrg;} `MRG': The MRG pool class’s identifier will be MRG.
This stands for “Manual Rank Guardian”. The pool is manually managed
and implements guardians for references of a particular rank
(currently just final).

@anchor{design/poolmrg design mps poolmrg def final ref}@anchor{116f}@ref{116f,,.def.final.ref;} `final reference': A reference of rank final (see
design.mps.type.rank).

@anchor{design/poolmrg design mps poolmrg def final object}@anchor{1170}@ref{1170,,.def.final.object;} `finalizable object': An object is finalizable
with respect to a final reference if, since the creation of that
reference, there was a point in time when no references to the object
of lower (that is, stronger) rank were reachable from a root.

@anchor{design/poolmrg design mps poolmrg def final object note}@anchor{1171}@ref{1171,,.def.final.object.note;} Note that this means an object can be
finalizable even if it is now reachable from the root via exact
references.

@anchor{design/poolmrg design mps poolmrg def finalize}@anchor{1172}@ref{1172,,.def.finalize;} `finalize': To finalize an object is to notify the
client that the object is finalizable. The client is presumed to be
interested in this information (typically it will apply some method to
the object).

@anchor{design/poolmrg design mps poolmrg def guardian}@anchor{1173}@ref{1173,,.def.guardian;} `guardian': An object allocated in the MRG
Pool. A guardian contains exactly one final reference, and some fields
for the pool’s internal use. Guardians are used to implement a
finalization mechanism.

@node Overview<27>,Protocols,Terminology<2>,MRG pool class
@anchor{design/poolmrg overview}@anchor{1174}
@subsection Overview


@anchor{design/poolmrg design mps poolmrg over}@anchor{1175}@ref{1175,,.over;} The MRG pool class is a pool class in the MPS. It is
intended to provide the functionality of “finalization”.

@anchor{design/poolmrg design mps poolmrg over internal}@anchor{1176}@ref{1176,,.over.internal;} The MRG pool class is internal to the MPM: it
is not intended to have a client interface. Clients are expected to
access the functionality provided by this pool (finalization) using a
separate MPS finalization interface (design.mps.finalize@footnote{finalize.html}).

@anchor{design/poolmrg design mps poolmrg over one-size}@anchor{1177}@ref{1177,,.over.one-size;} The MRG pool class manages objects of a single
size, each object containing a single reference of rank final.

@anchor{design/poolmrg design mps poolmrg over one-size justify}@anchor{1178}@ref{1178,,.over.one-size.justify;} This is all that is necessary to meet our
requirements for finalization. Whenever an object is registered for
finalization, it is sufficient to create a single reference of rank
final to it.

@anchor{design/poolmrg design mps poolmrg over queue}@anchor{1179}@ref{1179,,.over.queue;} A pool maintains a list of live guardian objects,
called (for historical reasons) the “entry” list.

@anchor{design/poolmrg design mps poolmrg over queue free}@anchor{117a}@ref{117a,,.over.queue.free;} The pool also maintains a list of free guardian
objects called the “free” list.

@anchor{design/poolmrg design mps poolmrg over queue exit not}@anchor{117b}@ref{117b,,.over.queue.exit.not;} There used to be an “exit” list, but this is
now historical and there shouldn’t be any current references to it.

@anchor{design/poolmrg design mps poolmrg over alloc}@anchor{117c}@ref{117c,,.over.alloc;} When guardians are allocated, they are placed on the
entry list. Guardians on the entry list refer to objects that have not
yet been shown to be finalizable (either the object has references of
lower rank than final to it, or the MPS has not yet got round to
determining that the object is finalizable).

@anchor{design/poolmrg design mps poolmrg over message create}@anchor{117d}@ref{117d,,.over.message.create;} When a guardian is discovered to refer to a
finalizable object it is removed from the entry list and becomes a
message on the arena’s messages queue.

@anchor{design/poolmrg design mps poolmrg over message deliver}@anchor{117e}@ref{117e,,.over.message.deliver;} When the MPS client receives the message the
message system arranges for the message to be destroyed and the pool
reclaims the storage associated with the guardian/message.

@anchor{design/poolmrg design mps poolmrg over scan}@anchor{117f}@ref{117f,,.over.scan;} When the pool is scanned at rank final each reference
will be fixed. If the reference is to an unmarked object (before the
fix), then the object must now be finalizable. In this case the
containing guardian will be removed from the entry list and posted as
a message.

@anchor{design/poolmrg design mps poolmrg over scan justify}@anchor{1180}@ref{1180,,.over.scan.justify;} The scanning process is a crucial step
necessary for implementing finalization. It is the means by which the
MPS detects that objects are finalizable.

@anchor{design/poolmrg design mps poolmrg over message}@anchor{1181}@ref{1181,,.over.message;} @code{PoolClassMRG} implements a @ref{715,,MessageClass} (see
design.mps.message@footnote{message.html}). All the messages are of one @ref{708,,MessageType}. This
type is @code{MessageTypeFINALIZATION}. Messages are created when objects
are discovered to be finalizable and destroyed when the MPS client has
received the message.

@anchor{design/poolmrg design mps poolmrg over message justify}@anchor{1182}@ref{1182,,.over.message.justify;} Messages provide a means for the MPS to
communicate with its client. Notification of finalization is just such
a communication. Messages allow the MPS to inform the client of
finalization events when it is convenient for the MPS to do so (i.e.
not in PageFault context).

@anchor{design/poolmrg design mps poolmrg over manual}@anchor{1183}@ref{1183,,.over.manual;} Objects in the MRG pool are manually managed.

@anchor{design/poolmrg design mps poolmrg over manual alloc}@anchor{1184}@ref{1184,,.over.manual.alloc;} They are allocated by @ref{55e,,ArenaFinalize()} when
objects are registered for finalization.

@anchor{design/poolmrg design mps poolmrg over manual free}@anchor{1185}@ref{1185,,.over.manual.free;} They are freed when the associated message is
destroyed.

@anchor{design/poolmrg design mps poolmrg over manual justify}@anchor{1186}@ref{1186,,.over.manual.justify;} The lifetime of a guardian object is very
easy to determine so manual memory management is appropriate.

@node Protocols,Data structures<6>,Overview<27>,MRG pool class
@anchor{design/poolmrg protocols}@anchor{1187}
@subsection Protocols


@menu
* Object Registration:: 
* Finalizer execution:: 
* Setup / destroy:: 

@end menu

@node Object Registration,Finalizer execution,,Protocols
@anchor{design/poolmrg object-registration}@anchor{1188}
@subsubsection Object Registration


@anchor{design/poolmrg design mps poolmrg protocol register}@anchor{1189}@ref{1189,,.protocol.register;} There is a protocol by which objects can be
registered for finalization. This protocol is handled by the arena
module on behalf of finalization. see
design.mps.finalize.int.finalize@footnote{finalize.html#design.mps.finalize.int.finalize}.

@node Finalizer execution,Setup / destroy,Object Registration,Protocols
@anchor{design/poolmrg design-mps-finalize-int-finalize}@anchor{118a}@anchor{design/poolmrg finalizer-execution}@anchor{118b}
@subsubsection Finalizer execution


@anchor{design/poolmrg design mps poolmrg protocol finalizer}@anchor{118c}@ref{118c,,.protocol.finalizer;} If an object is proven to be finalizable then
a message to this effect will eventually be posted. A client can
receive the message, determine what to do about it, and do it.
Typically this would involve calling the finalization method for the
object, and deleting the message. Once the message is deleted, the
object may become recyclable.

@node Setup / destroy,,Finalizer execution,Protocols
@anchor{design/poolmrg setup-destroy}@anchor{118d}
@subsubsection Setup / destroy


@anchor{design/poolmrg design mps poolmrg protocol life}@anchor{118e}@ref{118e,,.protocol.life;} An instance of PoolClassMRG is needed in order to
support finalization, it is called the “final” pool and is attached to
the arena (see design.mps.finalize.int.arena.struct@footnote{finalize.html#design.mps.finalize.int.arena.struct}).

@anchor{design/poolmrg design mps poolmrg protocol life birth}@anchor{118f}@ref{118f,,.protocol.life.birth;} The final pool is created lazily by
@ref{55e,,ArenaFinalize()}.

@anchor{design/poolmrg design mps poolmrg protocol life death}@anchor{1190}@ref{1190,,.protocol.life.death;} The final pool is destroyed during
@code{ArenaDestroy()}.

@node Data structures<6>,Functions<10>,Protocols,MRG pool class
@anchor{design/poolmrg data-structures}@anchor{1191}
@subsection Data structures


@anchor{design/poolmrg design mps poolmrg guardian}@anchor{1192}@ref{1192,,.guardian;} The guardian

@anchor{design/poolmrg design mps poolmrg guardian over}@anchor{1193}@ref{1193,,.guardian.over;} A guardian is an object used to manage the
references and other data structures that are used by the pool in
order to keep track of which objects are registered for finalization,
which ones have been finalized, and so on.

@anchor{design/poolmrg design mps poolmrg guardian state}@anchor{1194}@ref{1194,,.guardian.state;} A guardian can be in one of four states:

@anchor{design/poolmrg design mps poolmrg guardian state enum}@anchor{1195}@ref{1195,,.guardian.state.enum;} The states are Free, Prefinal, Final,
PostFinal (referred to as MRGGuardianFree, etc. in the
implementation).


@enumerate 

@item 
@anchor{design/poolmrg design mps poolmrg guardian state free}@anchor{1196}@ref{1196,,.guardian.state.free;} The guardian is free, meaning that it is
on the free list for the pool and available for allocation.

@item 
@anchor{design/poolmrg design mps poolmrg guardian state prefinal}@anchor{1197}@ref{1197,,.guardian.state.prefinal;} The guardian is allocated, and refers
to an object that has not yet been discovered to be finalizable. It
is on the entry list for the pool.

@item 
@anchor{design/poolmrg design mps poolmrg guardian state final}@anchor{1198}@ref{1198,,.guardian.state.final;} The guardian is allocated, and refers to
an object that has been shown to be finalizable; this state
corresponds to the existence of a message.

@item 
@anchor{design/poolmrg design mps poolmrg guardian state postfinal}@anchor{1199}@ref{1199,,.guardian.state.postfinal;} This state is only used briefly and
is entirely internal to the pool; the guardian enters this state
just after the associated message has been destroyed (which happens
when the client receives the message) and will be freed immediately
(whereupon it will enter the Free state). This state is used for
checking only (so that MRGFree can check that only guardians in
this state are being freed).
@end enumerate

@anchor{design/poolmrg design mps poolmrg guardian life-cycle}@anchor{119a}@ref{119a,,.guardian.life-cycle;} Guardians go through the following state life-cycle: Free ⟶ Prefinal ⟶ Final ⟶ Postfinal ⟶ Free.

@anchor{design/poolmrg design mps poolmrg guardian two-part}@anchor{119b}@ref{119b,,.guardian.two-part;} A guardian is a structure consisting abstractly
of a link part and a reference part. Concretely, the link part is a
@code{LinkPartStruct}, and the reference part is a @code{RefPartStruct}
(which is just a @ref{653,,Word}). The link part is used by the pool, the
reference part forms the object visible to clients of the pool. The
reference part is the reference of @code{RankFINAL} that refers to
objects registered for finalization and is how the MPS detects
finalizable objects.

@anchor{design/poolmrg design mps poolmrg guardian two-part union}@anchor{119c}@ref{119c,,.guardian.two-part.union;} The @code{LinkPartStruct} is a discriminated
union of a @code{RingStruct} and a @code{MessageStruct}. The @code{RingStruct}
is used when the guardian is either Free or Prefinal. The
MessageStruct is used when the guardian is Final. Neither part of the
union is used when the guardian is in the Postfinal state.

@anchor{design/poolmrg design mps poolmrg guardian two-part justify}@anchor{119d}@ref{119d,,.guardian.two-part.justify;} This may seem a little profligate with
space, but this is okay as we are not required to make finalization
extremely space efficient.

@anchor{design/poolmrg design mps poolmrg guardian parts separate}@anchor{119e}@ref{119e,,.guardian.parts.separate;} The two parts will be stored in separate
segments.

@anchor{design/poolmrg design mps poolmrg guardian parts separate justify}@anchor{119f}@ref{119f,,.guardian.parts.separate.justify;} This is so that the data
structures the pool uses to manage the objects can be separated from
the objects themselves. This avoids the pool having to manipulate data
structures that are on shielded segments
(analysis.mps.poolmrg.hazard.shield).

@anchor{design/poolmrg design mps poolmrg guardian assoc}@anchor{11a0}@ref{11a0,,.guardian.assoc;} Ref part number `n' (from the beginning of the
segment) in one segment will correspond with link part number `n' in
another segment. The association between the two segments will be
managed by the additional fields in pool-specific segment subclasses
(see @ref{11a1,,.mrgseg}).

@anchor{design/poolmrg design mps poolmrg guardian ref}@anchor{11a2}@ref{11a2,,.guardian.ref;} Guardians that are either Prefinal or Final are live
and have valid references (possibly @code{NULL}) in their ref parts.
Guardians that are free are dead and always have @code{NULL} in their ref
parts (see @ref{11a3,,.free.overwrite} and @ref{11a4,,.scan.free}).

@anchor{design/poolmrg design mps poolmrg guardian ref free}@anchor{11a5}@ref{11a5,,.guardian.ref.free;} When freeing an object, it is a pointer to the
reference part that will be passed (internally in the pool).

@anchor{design/poolmrg design mps poolmrg guardian init}@anchor{11a6}@ref{11a6,,.guardian.init;} Guardians are initialized when the pool is grown
(@ref{11a7,,.alloc.grow}). The initial state has the ref part @code{NULL} and the
link part is attached to the free ring. Freeing an object returns a
guardian to its initial state.

@anchor{design/poolmrg design mps poolmrg poolstruct}@anchor{11a8}@ref{11a8,,.poolstruct;} The Pool structure, @code{MRGStruct} will have:


@itemize -

@item 
@anchor{design/poolmrg design mps poolmrg poolstruct entry}@anchor{11a9}@ref{11a9,,.poolstruct.entry;} the head of the entry list.

@item 
@anchor{design/poolmrg design mps poolmrg poolstruct free}@anchor{11aa}@ref{11aa,,.poolstruct.free;} the head of the free list.

@item 
@anchor{design/poolmrg design mps poolmrg poolstruct rings}@anchor{11ab}@ref{11ab,,.poolstruct.rings;} The entry list, the exit list, and the free
list will each be implemented as a @ref{85c,,Ring}. Each ring will be
maintained using the link part of the guardian.

@anchor{design/poolmrg design mps poolmrg poolstruct rings justify}@anchor{11ac}@ref{11ac,,.poolstruct.rings.justify;} This is because rings are convenient to
use and are well tested. It is possible to implement all three lists
using a singly linked list, but the saving is certainly not worth
making at this stage.

@item 
@anchor{design/poolmrg design mps poolmrg poolstruct refring}@anchor{11ad}@ref{11ad,,.poolstruct.refring;} a ring of “ref” segments in use for links or
messages (see .mrgseg.ref.mrgring below).

@item 
@anchor{design/poolmrg design mps poolmrg poolstruct extend}@anchor{11ae}@ref{11ae,,.poolstruct.extend;} a precalculated @code{extendBy} field (see
@ref{11af,,.init.extend}). This value is used to determine how large a
segment should be requested from the arena for the reference part
segment when the pool needs to grow (see @ref{11b0,,.alloc.grow.size}).

@anchor{design/poolmrg design mps poolmrg poolstruct extend justify}@anchor{11b1}@ref{11b1,,.poolstruct.extend.justify;} Calculating a reasonable value for this
once and remembering it simplifies the allocation (@ref{11a7,,.alloc.grow}).
@end itemize

@anchor{design/poolmrg design mps poolmrg poolstruct init}@anchor{11b2}@ref{11b2,,.poolstruct.init;} poolstructs are initialized once for each pool
instance by @ref{11b3,,MRGInit()} (@ref{11b4,,.init}). The initial state has all the
rings initialized to singleton rings, and the @code{extendBy} field
initialized to some value (see @ref{11af,,.init.extend}).

@anchor{design/poolmrg design mps poolmrg mrgseg}@anchor{11a1}@ref{11a1,,.mrgseg;} The pool defines two segment subclasses:
@code{MRGRefSegClass} and @code{MRGLinkSegClass}. Segments of the former
class will be used to store the ref parts of guardians, segments of
the latter will be used to store the link parts of guardians (see
@ref{119b,,.guardian.two-part}). Segments are always allocated in pairs, with
one of each class, by the function @code{MRGSegPairCreate()}. Each
segment contains a link to its pair.

@anchor{design/poolmrg design mps poolmrg mrgseg ref}@anchor{11b5}@ref{11b5,,.mrgseg.ref;} @code{MRGRefSegClass} is a subclass of @code{MutatorSegClass}.
Instances are of type @code{MRGRefSeg}, and contain:


@itemize -

@item 
@anchor{design/poolmrg design mps poolmrg mrgseg ref mrgring}@anchor{11b6}@ref{11b6,,.mrgseg.ref.mrgring;} a field for the ring of ref part segments in
the pool.

@item 
@anchor{design/poolmrg design mps poolmrg mrgseg ref linkseg}@anchor{11b7}@ref{11b7,,.mrgseg.ref.linkseg;} a pointer to the paired link segment.

@item 
@anchor{design/poolmrg design mps poolmrg mrgseg ref grey}@anchor{11b8}@ref{11b8,,.mrgseg.ref.grey;} a set describing the greyness of the segment for each trace.
@end itemize

@anchor{design/poolmrg design mps poolmrg mrgseg ref init}@anchor{11b9}@ref{11b9,,.mrgseg.ref.init;} A segment is created and initialized once every
time the pool is grown (@ref{11a7,,.alloc.grow}). The initial state has the
segment ring node initialized and attached to the pool’s segment ring,
the linkseg field points to the relevant link segment, the grey field
is initialized such that the segment is not grey for all traces.

@anchor{design/poolmrg design mps poolmrg mrgseg link}@anchor{11ba}@ref{11ba,,.mrgseg.link;} @code{MRGLinkSegClass} is a subclass of @code{SegClass}.
Instances are of type @code{MRGLinkSeg}, and contain:


@itemize -

@item 
@anchor{design/poolmrg design mps poolmrg mrgseg link refseg}@anchor{11bb}@ref{11bb,,.mrgseg.link.refseg;} a pointer to the paired ref segment. This
may be @code{NULL} during initialization, while the pairing is being
established.

@item 
@anchor{design/poolmrg design mps poolmrg mrgseg link init}@anchor{11bc}@ref{11bc,,.mrgseg.link.init;} The initial state has the @code{linkseg} field
pointing to the relevant ref segment.
@end itemize

@node Functions<10>,Transgressions,Data structures<6>,MRG pool class
@anchor{design/poolmrg functions}@anchor{11bd}
@subsection Functions


@geindex MRGCheck (C function)
@anchor{design/poolmrg c MRGCheck}@anchor{11be}
@deffn {C Function} @ref{3a9,,Bool} MRGCheck (MRG mrg)
@end deffn

@anchor{design/poolmrg design mps poolmrg check}@anchor{11bf}@ref{11bf,,.check;} Check the signatures, the class, and each field of the
@code{MRGStruct}. Each field is checked as being appropriate for its
type.

@anchor{design/poolmrg design mps poolmrg check justify}@anchor{11c0}@ref{11c0,,.check.justify;} There are no non-trivial invariants that can
be easily checked.

@geindex MRGRegister (C function)
@anchor{design/poolmrg c MRGRegister}@anchor{11c1}
@deffn {C Function} @ref{55f,,Res} MRGRegister (Pool pool, Ref ref)
@end deffn

@anchor{design/poolmrg design mps poolmrg alloc}@anchor{11c2}@ref{11c2,,.alloc;} Add a guardian for @code{ref}.

@anchor{design/poolmrg design mps poolmrg alloc grow}@anchor{11a7}@ref{11a7,,.alloc.grow;} If the free list is empty then two new segments are
allocated and the free list filled up from them (note that the
reference fields of the new guardians will need to be overwritten with
@code{NULL}, see @ref{11a3,,.free.overwrite})

@anchor{design/poolmrg design mps poolmrg alloc grow size}@anchor{11b0}@ref{11b0,,.alloc.grow.size;} The size of the reference part segment will be
the pool’s @code{extendBy} (@ref{11ae,,.poolstruct.extend}) value. The link part
segment will be whatever size is necessary to accommodate `N' link
parts, where `N' is the number of reference parts that fit in the
reference part segment.

@anchor{design/poolmrg design mps poolmrg alloc error}@anchor{11c3}@ref{11c3,,.alloc.error;} If any of the requests for more resource (there are
two; one for each of two segments) fail then the successful requests
will be retracted and the result code from the failing request will be
returned.

@anchor{design/poolmrg design mps poolmrg alloc pop}@anchor{11c4}@ref{11c4,,.alloc.pop;} @ref{11c1,,MRGRegister()} pops a ring node off the free list,
and add it to the entry list.

@geindex MRGDeregister (C function)
@anchor{design/poolmrg c MRGDeregister}@anchor{11c5}
@deffn {C Function} @ref{55f,,Res} MRGDeregister (Pool pool, Ref obj)
@end deffn

@anchor{design/poolmrg design mps poolmrg free}@anchor{11c6}@ref{11c6,,.free;} Remove the guardian from the message queue and add it to the
free list.

@anchor{design/poolmrg design mps poolmrg free push}@anchor{11c7}@ref{11c7,,.free.push;} The guardian will simply be added to the front of the
free list (that is, no keeping the free list in address order or
anything like that).

@anchor{design/poolmrg design mps poolmrg free inadequate}@anchor{11c8}@ref{11c8,,.free.inadequate;} No attempt will be made to return unused free
segments to the arena (although see
analysis.mps.poolmrg.improve.free.* for suggestions).

@anchor{design/poolmrg design mps poolmrg free overwrite}@anchor{11a3}@ref{11a3,,.free.overwrite;} @ref{11c5,,MRGDeregister()} also writes over the reference
with @code{NULL}. @anchor{design/poolmrg design mps poolmrg free overwrite justify}@anchor{11c9}@ref{11c9,,.free.overwrite.justify;} This is so that when the
segment is subsequently scanned (@ref{11a4,,.scan.free}), the reference that
used to be in the object is not accidentally fixed.

@geindex MRGInit (C function)
@anchor{design/poolmrg c MRGInit}@anchor{11b3}
@deffn {C Function} @ref{55f,,Res} MRGInit (Pool pool, ArgList args)
@end deffn

@anchor{design/poolmrg design mps poolmrg init}@anchor{11b4}@ref{11b4,,.init;} Initializes the entry list, the free ring, the ref ring, and
the @code{extendBy} field.

@anchor{design/poolmrg design mps poolmrg init extend}@anchor{11af}@ref{11af,,.init.extend;} The @code{extendBy} field is initialized to the arena
grain size.

@anchor{design/poolmrg design mps poolmrg init extend justify}@anchor{11ca}@ref{11ca,,.init.extend.justify;} This is adequate as the pool is not expected
to grow very quickly.

@geindex MRGFinish (C function)
@anchor{design/poolmrg c MRGFinish}@anchor{11cb}
@deffn {C Function} void MRGFinish (Pool pool)
@end deffn

@anchor{design/poolmrg design mps poolmrg finish}@anchor{11cc}@ref{11cc,,.finish;} Iterate over all the segments, returning all the segments
to the arena.

@geindex mrgRefSegScan (C function)
@anchor{design/poolmrg c mrgRefSegScan}@anchor{11cd}
@deffn {C Function} @ref{55f,,Res} mrgRefSegScan (Bool *totalReturn, Pool pool, Seg seg, ScanState ss)
@end deffn

@anchor{design/poolmrg design mps poolmrg scan}@anchor{11ce}@ref{11ce,,.scan;} @ref{11cd,,mrgRefSegScan()} scans a segment of guardians.

@anchor{design/poolmrg design mps poolmrg scan trivial}@anchor{11cf}@ref{11cf,,.scan.trivial;} Scan will do nothing (that is, return immediately)
if the tracing rank is anything other than final.

@cartouche
@quotation Note 
This optimization is missing. impl.c.trace.scan.conservative is
not a problem because there are no faults on these segs, because
there are no references into them. But that’s why @code{TraceScan()}
can’t do it. Pekka P. Pirinen, 1997-09-19.
@end quotation
@end cartouche

@anchor{design/poolmrg design mps poolmrg scan trivial justify}@anchor{11d0}@ref{11d0,,.scan.trivial.justify;} If the rank is lower than final then
scanning is detrimental, it will only delay finalization. If the rank
is higher than final there is nothing to do, the pool only contains
final references.

@anchor{design/poolmrg design mps poolmrg scan guardians}@anchor{11d1}@ref{11d1,,.scan.guardians;} @ref{11cd,,mrgRefSegScan()} will iterate over all
guardians in the segment. Every guardian’s reference will be fixed
(@anchor{design/poolmrg design mps poolmrg scan free}@anchor{11a4}@ref{11a4,,.scan.free;} note that guardians that are on the free list have
@code{NULL} in their reference part).

@anchor{design/poolmrg design mps poolmrg scan wasold}@anchor{11d2}@ref{11d2,,.scan.wasold;} If the object referred to had not been fixed
previously (that is, was unmarked) then the object is not referenced
by a reference of a lower rank (than @code{RankFINAL}) and hence is
finalizable.

@anchor{design/poolmrg design mps poolmrg scan finalize}@anchor{11d3}@ref{11d3,,.scan.finalize;} The guardian will be finalized. This entails moving
the guardian from state Prefinal to Final; it is removed from the
entry list and initialized as a message and posted on the arena’s
message queue.

@anchor{design/poolmrg design mps poolmrg scan finalize idempotent}@anchor{11d4}@ref{11d4,,.scan.finalize.idempotent;} In fact this will only happen if the
guardian has not already been finalized (which is determined by
examining the state of the guardian).

@anchor{design/poolmrg design mps poolmrg scan unordered}@anchor{11d5}@ref{11d5,,.scan.unordered;} Because scanning occurs a segment at a time, the
order in which objects are finalized is “random” (it cannot be
predicted by considering only the references between objects
registered for finalization). See
analysis.mps.poolmrg.improve.semantics for how this can be improved.

@anchor{design/poolmrg design mps poolmrg scan unordered justify}@anchor{11d6}@ref{11d6,,.scan.unordered.justify;} Unordered finalization is all that is
required.

See analysis.mps.poolmrg.improve.scan.nomove for a suggested
improvement that avoids redundant unlinking and relinking.

@geindex MRGDescribe (C function)
@anchor{design/poolmrg c MRGDescribe}@anchor{11d7}
@deffn {C Function} @ref{55f,,Res} MRGDescribe (Pool pool, mps_lib_FILE *stream, Count depth)
@end deffn

@anchor{design/poolmrg design mps poolmrg describe}@anchor{11d8}@ref{11d8,,.describe;} Describes an MRG pool. Iterates along each of the entry
and exit lists and prints the guardians in each. The location of the
guardian and the value of the reference in it will be printed out.
Provided for debugging only.

@node Transgressions,Future<3>,Functions<10>,MRG pool class
@anchor{design/poolmrg transgressions}@anchor{11d9}
@subsection Transgressions


@anchor{design/poolmrg design mps poolmrg trans no-finish}@anchor{11da}@ref{11da,,.trans.no-finish;} The MRG pool does not trouble itself to tidy up
its internal rings properly when being destroyed.

@anchor{design/poolmrg design mps poolmrg trans free-seg}@anchor{11db}@ref{11db,,.trans.free-seg;} No attempt is made to release free segments to the
arena. A suggested strategy for this is as follows:


@itemize -

@item 
Add a count of free guardians to each segment, and maintain it in
appropriate places.

@item 
Add a free segment ring to the pool.

@item 
In @ref{11cd,,mrgRefSegScan()}, if the segment is entirely free, don’t scan
it, but instead detach its links from the free ring, and move the
segment to the free segment ring.

@item 
At some appropriate point, such as the end of @code{MRGAlloc()},
destroy free segments.

@item 
In @code{MRGAlloc()}, if there are no free guardians, check the free
segment ring before creating a new pair of segments. Note that this
algorithm would give some slight measure of segment hysteresis. It
is not the place of the pool to support general segment hysteresis.
@end itemize

@node Future<3>,Tests<2>,Transgressions,MRG pool class
@anchor{design/poolmrg future}@anchor{11dc}
@subsection Future


@anchor{design/poolmrg design mps poolmrg future array}@anchor{11dd}@ref{11dd,,.future.array;} In future, for speed or simplicity, this pool could
be rewritten to use an array. See mail.gavinm.1997-09-04.13-08@footnote{https://info.ravenbrook.com/project/mps/mail/1997/09/04/13-08/0.txt}.

@node Tests<2>,Notes<8>,Future<3>,MRG pool class
@anchor{design/poolmrg mail-gavinm-1997-09-04-13-08}@anchor{11de}@anchor{design/poolmrg tests}@anchor{11df}
@subsection Tests


@cartouche
@quotation Note 
This section is utterly out of date. Pekka P. Pirinen, 1997-09-19.
@end quotation
@end cartouche

@anchor{design/poolmrg design mps poolmrg test}@anchor{11e0}@ref{11e0,,.test;} The test impl.c.finalcv is similar to the weakness test (see
design.mps.weakness, impl.c.weakcv).

@menu
* Functionality:: 
* Attributes:: 
* Implementation: Implementation<24>. 

@end menu

@node Functionality,Attributes,,Tests<2>
@anchor{design/poolmrg functionality}@anchor{11e1}
@subsubsection Functionality


This is the functionality to be tested:


@itemize -

@item 
@anchor{design/poolmrg design mps poolmrg fun alloc}@anchor{11e2}@ref{11e2,,.fun.alloc;} Can allocate objects.

@item 
@anchor{design/poolmrg design mps poolmrg fun free}@anchor{11e3}@ref{11e3,,.fun.free;} Can free objects that were allocated.

@item 
@anchor{design/poolmrg design mps poolmrg prot write}@anchor{11e4}@ref{11e4,,.prot.write;} Can write a reference into an allocated object.

@item 
@anchor{design/poolmrg design mps poolmrg prot read}@anchor{11e5}@ref{11e5,,.prot.read;} Can read the reference from an allocated object.

@item 
@anchor{design/poolmrg design mps poolmrg promise faithful}@anchor{11e6}@ref{11e6,,.promise.faithful;} A reference stored in an allocated object will
continue to refer to the same object.

@item 
@anchor{design/poolmrg design mps poolmrg promise live}@anchor{11e7}@ref{11e7,,.promise.live;} A reference stored in an allocated object will
preserve the object referred to.

@item 
@anchor{design/poolmrg design mps poolmrg promise unreachable}@anchor{11e8}@ref{11e8,,.promise.unreachable;} Any objects referred to in finalization
messages are not (at the time of reading the message) reachable via
a chain of ambiguous or exact references. (we will not be able to
test this at first as there is no messaging interface)

@item 
@anchor{design/poolmrg design mps poolmrg promise try}@anchor{11e9}@ref{11e9,,.promise.try;} The pool will make a “good faith” effort to
finalize objects that are not reachable via a chain of ambiguous or
exact references.
@end itemize

@node Attributes,Implementation<24>,Functionality,Tests<2>
@anchor{design/poolmrg attributes}@anchor{11ea}
@subsubsection Attributes


The following attributes will be tested:


@itemize -

@item 
@anchor{design/poolmrg design mps poolmrg attr none}@anchor{11eb}@ref{11eb,,.attr.none;} There are no attribute requirements.
@end itemize

@node Implementation<24>,,Attributes,Tests<2>
@anchor{design/poolmrg implementation}@anchor{11ec}
@subsubsection Implementation


The test will simply allocate a number of objects in the AMC pool and
finalize each one, throwing away the reference to the objects. Churn.

@anchor{design/poolmrg design mps poolmrg test mpm}@anchor{11ed}@ref{11ed,,.test.mpm;} The test will use the MPM interface (impl.h.mpm).

@anchor{design/poolmrg design mps poolmrg test mpm justify}@anchor{11ee}@ref{11ee,,.test.mpm.justify;} This is because it is not intended to provide an
MPS interface to this pool directly, and the MPS interface to
finalization has not been written yet (impl.h.mps).

@anchor{design/poolmrg design mps poolmrg test mpm change}@anchor{11ef}@ref{11ef,,.test.mpm.change;} Later on it may use the MPS interface, in which
case, where the following text refers to allocating objects in the MRG
pool it will need adjusting.

@anchor{design/poolmrg design mps poolmrg test two-pools}@anchor{11f0}@ref{11f0,,.test.two-pools;} The test will use two pools, an AMC pool, and an
MRG pool.

@anchor{design/poolmrg design mps poolmrg test alloc}@anchor{11f1}@ref{11f1,,.test.alloc;} A number of objects will be allocated in the MRG pool.

@anchor{design/poolmrg design mps poolmrg test free}@anchor{11f2}@ref{11f2,,.test.free;} They will then be freed. This will test @ref{11e2,,.fun.alloc}
and @ref{11e3,,.fun.free}, although not very much.

@anchor{design/poolmrg design mps poolmrg test rw a}@anchor{11f3}@ref{11f3,,.test.rw.a;} An object, “A”, will be allocated in the AMC pool, a
reference to it will be kept in a root.

@anchor{design/poolmrg design mps poolmrg test rw alloc}@anchor{11f4}@ref{11f4,,.test.rw.alloc;} A number of objects will be allocated in the MRG
pool.

@anchor{design/poolmrg design mps poolmrg test rw write}@anchor{11f5}@ref{11f5,,.test.rw.write;} A reference to “A” will be written into each
object.

@anchor{design/poolmrg design mps poolmrg test rw read}@anchor{11f6}@ref{11f6,,.test.rw.read;} The reference in each object will be read and
checked to see if it refers to “A”.

@anchor{design/poolmrg design mps poolmrg test rw free}@anchor{11f7}@ref{11f7,,.test.rw.free;} All the objects will be freed.

@anchor{design/poolmrg design mps poolmrg test rw drop}@anchor{11f8}@ref{11f8,,.test.rw.drop;} The reference to “A” will be dropped. This will test
@ref{11e4,,.prot.write} and @ref{11e5,,.prot.read}.

@anchor{design/poolmrg design mps poolmrg test promise fl alloc}@anchor{11f9}@ref{11f9,,.test.promise.fl.alloc;} A number of objects will be allocated in
the AMC pool.

@anchor{design/poolmrg design mps poolmrg test promise fl tag}@anchor{11fa}@ref{11fa,,.test.promise.fl.tag;} Each object will be tagged uniquely.

@anchor{design/poolmrg design mps poolmrg test promise fl refer}@anchor{11fb}@ref{11fb,,.test.promise.fl.refer;} a reference to it will be stored in an
object allocated in the MRG pool.

@anchor{design/poolmrg design mps poolmrg test promise fl churn}@anchor{11fc}@ref{11fc,,.test.promise.fl.churn;} A large amount of garbage will be allocated
in the AMC pool. Regularly, whilst this garbage is being allocated, a
check will be performed that all the objects allocated in the MRG pool
refer to valid objects and that they still refer to the same objects.
All objects from the MRG pool will then be freed (thus dropping all
references to the AMC objects). This will test @ref{11e6,,.promise.faithful}
and @ref{11e7,,.promise.live}.

@anchor{design/poolmrg design mps poolmrg test promise ut alloc}@anchor{11fd}@ref{11fd,,.test.promise.ut.alloc;} A number of objects will be allocated in
the AMC pool.

@anchor{design/poolmrg design mps poolmrg test promise ut refer}@anchor{11fe}@ref{11fe,,.test.promise.ut.refer;} Each object will be referred to by a root
and also referred to by an object allocated in the MRG pool.

@anchor{design/poolmrg design mps poolmrg test promise ut drop}@anchor{11ff}@ref{11ff,,.test.promise.ut.drop;} References to a random selection of the
objects from the AMC pool will be deleted from the root.

@anchor{design/poolmrg design mps poolmrg test promise ut churn}@anchor{1200}@ref{1200,,.test.promise.ut.churn;} A large amount of garbage will be allocated
in the AMC pool.

@anchor{design/poolmrg design mps poolmrg test promise ut message}@anchor{1201}@ref{1201,,.test.promise.ut.message;} The message interface will be used to
receive finalization messages.

@anchor{design/poolmrg design mps poolmrg test promise ut final check}@anchor{1202}@ref{1202,,.test.promise.ut.final.check;} For each finalization message
received it will check that the object referenced in the message is
not referred to in the root.

@anchor{design/poolmrg design mps poolmrg test promise ut nofinal check}@anchor{1203}@ref{1203,,.test.promise.ut.nofinal.check;} After some amount of garbage has
been allocated it will check to see if any objects are not in the root
and haven’t been finalized. This will test @ref{11e8,,.promise.unreachable} and
@ref{11e9,,.promise.try}.

@node Notes<8>,,Tests<2>,MRG pool class
@anchor{design/poolmrg notes}@anchor{1204}
@subsection Notes


@anchor{design/poolmrg design mps poolmrg access inadequate}@anchor{1205}@ref{1205,,.access.inadequate;} @code{SegAccess()} will scan segments at
@cite{RankEXACT`}. Really it should be scanned at whatever the minimum rank
of all grey segments is (the trace rank phase), however there is no
way to find this out. As a consequence we will sometimes scan pages at
@code{RankEXACT} when the pages could have been scanned at @code{RankFINAL}.
This means that finalization of some objects may sometimes get
delayed.

@geindex MVT pool class; design
@geindex pool class; MVT design

@node Manual Variable Temporal MVT pool design,MVFF pool class,MRG pool class,Old design
@anchor{design/poolmvt doc}@anchor{1206}@anchor{design/poolmvt design-poolmvt}@anchor{1207}@anchor{design/poolmvt manual-variable-temporal-mvt-pool-design}@anchor{1208}
@section Manual Variable Temporal (MVT) pool design


@menu
* Introduction: Introduction<67>. 
* Definitions: Definitions<13>. 
* Abbreviations:: 
* Overview: Overview<28>. 
* Requirements: Requirements<42>. 
* Architecture: Architecture<10>. 
* Analysis: Analysis<5>. 
* Ideas:: 
* Implementation: Implementation<25>. 
* Testing: Testing<9>. 
* Text:: 

@end menu

@node Introduction<67>,Definitions<13>,,Manual Variable Temporal MVT pool design
@anchor{design/poolmvt design mps poolmvt}@anchor{1209}@anchor{design/poolmvt introduction}@anchor{120a}
@subsection Introduction


@anchor{design/poolmvt design mps poolmvt intro}@anchor{120b}@ref{120b,,.intro;} This is a second-generation design for a pool that manually
manages variable-sized objects. It is intended as a replacement for
poolmv (except in its control pool role) and poolepdl, and it is
intended to satisfy the requirements of the Dylan “misc” pool and the
product malloc/new drop-in replacement.

@anchor{design/poolmvt design mps poolmvt readership}@anchor{120c}@ref{120c,,.readership;} MM developers

@anchor{design/poolmvt design mps poolmvt source}@anchor{120d}@ref{120d,,.source;} req.dylan(6), req.epcore(16), req.product(2)

@anchor{design/poolmvt design mps poolmvt background}@anchor{120e}@ref{120e,,.background;} design.mps.poolmv, design.mps.poolepdl(0),
design.product.soft.drop(0), paper.wil95(1), paper.vo96(0),
paper.grun92(1), paper.beck82(0), mail.ptw.1998-02-25.22-18@footnote{https://info.ravenbrook.com/project/mps/mail/1998/02/25/22-18/0.txt}.

@node Definitions<13>,Abbreviations,Introduction<67>,Manual Variable Temporal MVT pool design
@anchor{design/poolmvt definitions}@anchor{120f}@anchor{design/poolmvt mail-ptw-1998-02-25-22-18}@anchor{1210}
@subsection Definitions


@anchor{design/poolmvt design mps poolmvt def alignment}@anchor{1211}@ref{1211,,.def.alignment;} Alignment is a constraint on an object’s address,
typically to be a power of 2 (see also, glossary.alignment )

@anchor{design/poolmvt design mps poolmvt def bit-map}@anchor{1212}@ref{1212,,.def.bit-map;} A bitmap is a boolean-valued vector (see also,
glossary.bitmap ).

@anchor{design/poolmvt design mps poolmvt def block}@anchor{1213}@ref{1213,,.def.block;} A block is a contiguous extent of memory. In this
document, block is used to mean a contiguous extent of memory managed
by the pool for the pool client, typically a subset of a segment
(compare with @ref{1214,,.def.segment}).

@anchor{design/poolmvt design mps poolmvt def cartesian-tree}@anchor{1215}@ref{1215,,.def.cartesian-tree;} A cartesian tree is a binary tree ordered by
two keys (paper.stephenson83(0)).

@anchor{design/poolmvt design mps poolmvt def crossing-map}@anchor{1216}@ref{1216,,.def.crossing-map;} A mechanism that supports finding the start of
an object from any address within the object, typically only required
on untagged architectures (see also, glossary.crossing.map ).

@anchor{design/poolmvt design mps poolmvt def footer}@anchor{1217}@ref{1217,,.def.footer;} A block of descriptive information describing and
immediately following another block of memory (see also
@ref{1218,,.def.header}).

@anchor{design/poolmvt design mps poolmvt def fragmentation}@anchor{1219}@ref{1219,,.def.fragmentation;} Fragmented memory is memory reserved to the
program but not usable by the program because of the arrangement of
memory already in use (see also, glossary.fragmentation ).

@anchor{design/poolmvt design mps poolmvt def header}@anchor{1218}@ref{1218,,.def.header;} A block of descriptive information describing and
immediately preceding another block of memory (see also,
glossary.in-band.header ).

@anchor{design/poolmvt design mps poolmvt def in-band}@anchor{121a}@ref{121a,,.def.in-band;} From “in band signalling”, when descriptive
information about a data structure is stored in the data structure
itself (see also, glossary.in-band.header ).

@anchor{design/poolmvt design mps poolmvt def out-of-band}@anchor{121b}@ref{121b,,.def.out-of-band;} When descriptive information about a data
structure is stored separately from the structure itself (see also,
glossary.out-of-band.header ).

@anchor{design/poolmvt design mps poolmvt def refcount}@anchor{121c}@ref{121c,,.def.refcount;} A refcount is a count of the number of users of an
object (see also, glossary.reference.count ).

@anchor{design/poolmvt design mps poolmvt def segment}@anchor{1214}@ref{1214,,.def.segment;} A segment is a contiguous extent of memory. In this
document, segment is used to mean a contiguous extent of memory
managed by the MPS arena (design.mps.arena@footnote{arena.html}) and subdivided by the
pool to provide blocks (see @ref{1213,,.def.block}) to its clients.

@anchor{design/poolmvt design mps poolmvt def splay-tree}@anchor{121d}@ref{121d,,.def.splay-tree;} A splay tree is a self-adjusting binary tree
(paper.st85(0), paper.sleator96(0)).

@anchor{design/poolmvt design mps poolmvt def splinter}@anchor{121e}@ref{121e,,.def.splinter;} A splinter is a fragment of memory that is too small
to be useful (see also, glossary.splinter )

@anchor{design/poolmvt design mps poolmvt def subblock}@anchor{121f}@ref{121f,,.def.subblock;} A subblock is a contiguous extent of memory. In this
document, subblock is used to mean a contiguous extent of memory
manage by the client for its own use, typically a subset of a block
(compare with @ref{1213,,.def.block}).

@node Abbreviations,Overview<28>,Definitions<13>,Manual Variable Temporal MVT pool design
@anchor{design/poolmvt abbreviations}@anchor{1220}
@subsection Abbreviations


@anchor{design/poolmvt design mps poolmvt abbr abq}@anchor{1221}@ref{1221,,.abbr.abq;} ABQ = Available Block Queue

@anchor{design/poolmvt design mps poolmvt abbr ap}@anchor{1222}@ref{1222,,.abbr.ap;} AP = Allocation Point

@anchor{design/poolmvt design mps poolmvt abbr cbs}@anchor{1223}@ref{1223,,.abbr.cbs;} CBS = Coalescing Block Structure

@anchor{design/poolmvt design mps poolmvt abbr mps}@anchor{1224}@ref{1224,,.abbr.mps;} MPS = Memory Pool System

@anchor{design/poolmvt design mps poolmvt abbr ps}@anchor{1225}@ref{1225,,.abbr.ps;} PS = PostScript

@node Overview<28>,Requirements<42>,Abbreviations,Manual Variable Temporal MVT pool design
@anchor{design/poolmvt overview}@anchor{1226}
@subsection Overview


@anchor{design/poolmvt design mps poolmvt overview}@anchor{1227}@ref{1227,,.overview;} MVT is intended to satisfy the requirements of the
clients that need manual-variable pools, improving on the performance
of the existing manual-variable pool implementations, and reducing the
duplication of code that currently exists. The expected clients of MVT
are: Dylan (currently for its misc pool), EP (particularly the dl
pool, but all pools other than the PS object pool), and Product
(initially the malloc/new pool, but also other manual pool classes).

@node Requirements<42>,Architecture<10>,Overview<28>,Manual Variable Temporal MVT pool design
@anchor{design/poolmvt requirements}@anchor{1228}
@subsection Requirements


@anchor{design/poolmvt design mps poolmvt req cat}@anchor{1229}@ref{1229,,.req.cat;} Requirements are categorized per guide.req(2).

@anchor{design/poolmvt design mps poolmvt req risk}@anchor{122a}@ref{122a,,.req.risk;} req.epcore(16) is known to be obsolete, but the revised
document has not yet been accepted.

@menu
* Critical requirements:: 
* Essential requirements:: 
* Nice requirements:: 

@end menu

@node Critical requirements,Essential requirements,,Requirements<42>
@anchor{design/poolmvt critical-requirements}@anchor{122b}
@subsubsection Critical requirements


@anchor{design/poolmvt design mps poolmvt req fun man-var}@anchor{122c}@ref{122c,,.req.fun.man-var;} The pool class must support manual allocation and
freeing of variable-sized blocks (source: req.dylan.fun.misc.alloc,
req.epcore.fun.@{dl,gen,tmp,stat,cache,trap@}.@{alloc,free@},
req.product.fun.@{malloc,new,man.man@}).

@anchor{design/poolmvt design mps poolmvt non-req fun gc}@anchor{122d}@ref{122d,,.non-req.fun.gc;} There is not a requirement that the pool class
support formatted objects, scanning, or collection objects; but it
should not be arbitrarily precluded.

@anchor{design/poolmvt design mps poolmvt req fun align}@anchor{122e}@ref{122e,,.req.fun.align;} The pool class must support aligned allocations to
client-specified alignments. An individual instance need only support
a single alignment; multiple instances may be used to support more
than one alignment (source: req.epcore.attr.align).

@anchor{design/poolmvt design mps poolmvt req fun reallocate}@anchor{122f}@ref{122f,,.req.fun.reallocate;} The pool class must support resizing of
allocated blocks (source req.epcore.fun.dl.promise.free,
req.product.dc.env.@{ansi-c,cpp@}).

@anchor{design/poolmvt design mps poolmvt non-req fun reallocate in-place}@anchor{1230}@ref{1230,,.non-req.fun.reallocate.in-place;} There is not a requirement blocks
must be resized in place (where possible); but it seems like a good
idea.

@anchor{design/poolmvt design mps poolmvt req fun thread}@anchor{1231}@ref{1231,,.req.fun.thread;} Each instance of the pool class must support
multiple threads of allocation (source req.epcore.fun.dl.multi,
req.product.dc.env.@{ansi-c,cpp@}).

@anchor{design/poolmvt design mps poolmvt req attr performance}@anchor{1232}@ref{1232,,.req.attr.performance;} The pool class must meet or exceed
performance of “competitive” allocators (source:
rec.epcore.attr.@{run-time,tp@}, req.product.attr.@{mkt.eval, perform@}).
[Dylan does not seem to have any requirement that storage be allocated
with a particular response time or throughput, just so long as we
don’t block for too long. Clearly there is a missing requirement.]

@anchor{design/poolmvt design mps poolmvt req attr performance time}@anchor{1233}@ref{1233,,.req.attr.performance.time;} By inference, the time overhead must be
competitive.

@anchor{design/poolmvt design mps poolmvt req attr performance space}@anchor{1234}@ref{1234,,.req.attr.performance.space;} By inference, the space overhead must
be competitive.

@anchor{design/poolmvt design mps poolmvt req attr reliability}@anchor{1235}@ref{1235,,.req.attr.reliability;} The pool class must have “rock-solid
reliability” (source: req.dylan.attr.rel.mtbf, req.epcore.attr.rel,
req.product.attr.rel).

@anchor{design/poolmvt design mps poolmvt req fun range}@anchor{1236}@ref{1236,,.req.fun.range;} The pool class must be able to manage blocks
ranging in size from 1 byte to all of addressable memory
(req.epcore.attr.@{dl,gen,tmp,stat,cache,trap@}.obj.@{min,max@}. The range
requirement may be satisfied by multiple instances each managing a
particular client-specified subrange of sizes. [Dylan has requirements
req.dylan.attr.@{capacity,obj.max@}, but no requirement that such
objects reside in a manual pool.]

@anchor{design/poolmvt design mps poolmvt req fun debug}@anchor{1237}@ref{1237,,.req.fun.debug;} The pool class must support debugging erroneous
usage by client programs (source: req.epcore.fun.@{dc.variety,
debug.support@}, req.product.attr.@{mkt.eval,perform@}). Debugging is
permitted to incur additional overhead.

@anchor{design/poolmvt design mps poolmvt req fun debug boundaries}@anchor{1238}@ref{1238,,.req.fun.debug.boundaries;} The pool class must support checking for
accesses outside the boundaries of live objects.

@anchor{design/poolmvt design mps poolmvt req fun debug log}@anchor{1239}@ref{1239,,.req.fun.debug.log;} The pool class must support logging of all
allocations and deallocations.

@anchor{design/poolmvt design mps poolmvt req fun debug enumerate}@anchor{123a}@ref{123a,,.req.fun.debug.enumerate;} The pool class must support examining all
allocated objects.

@anchor{design/poolmvt design mps poolmvt req fun debug free}@anchor{123b}@ref{123b,,.req.fun.debug.free;} The pool class must support detecting
incorrect, overlapping, and double frees.

@anchor{design/poolmvt design mps poolmvt req fun tolerant}@anchor{123c}@ref{123c,,.req.fun.tolerant;} The pool class must support tolerance of
erroneous usage (source req.product.attr.use.level.1).

@node Essential requirements,Nice requirements,Critical requirements,Requirements<42>
@anchor{design/poolmvt essential-requirements}@anchor{123d}
@subsubsection Essential requirements


@anchor{design/poolmvt design mps poolmvt req fun profile}@anchor{123e}@ref{123e,,.req.fun.profile;} The pool class should support memory usage
profiling (source: req.product.attr.@{mkt.eval, perform@}).

@anchor{design/poolmvt design mps poolmvt req attr flex}@anchor{123f}@ref{123f,,.req.attr.flex;} The pool class should be flexible so that it can be
tuned to specific allocation and freeing patterns (source:
req.product.attr.flex,req.epcore.attr.@{dl,cache,trap@}.typ). The
flexibility requirement may be satisfied by multiple instances each
optimizing a specific pattern.

@anchor{design/poolmvt design mps poolmvt req attr adapt}@anchor{1240}@ref{1240,,.req.attr.adapt;} The pool class should be adaptive so that it can
accommodate changing allocation and freeing patterns (source:
req.epcore.fun.@{tmp,stat@}.policy,
req.product.attr.@{mkt.eval,perform@}).

@node Nice requirements,,Essential requirements,Requirements<42>
@anchor{design/poolmvt nice-requirements}@anchor{1241}
@subsubsection Nice requirements


@anchor{design/poolmvt design mps poolmvt req fun suballocate}@anchor{1242}@ref{1242,,.req.fun.suballocate;} The pool class may support freeing of any
aligned, contiguous subset of an allocated block (source
req.epcore.fun.dl.free.any, req.product.attr.@{mkt.eval,perform@}).

@node Architecture<10>,Analysis<5>,Requirements<42>,Manual Variable Temporal MVT pool design
@anchor{design/poolmvt architecture}@anchor{1243}
@subsection Architecture


@anchor{design/poolmvt design mps poolmvt arch overview}@anchor{1244}@ref{1244,,.arch.overview;} The pool has several layers: client allocation is
by Allocation Points (APs).

@anchor{design/poolmvt design mps poolmvt arch overview ap}@anchor{1245}@ref{1245,,.arch.overview.ap;} APs acquire storage from the pool
available-block queue (ABQ).

@anchor{design/poolmvt design mps poolmvt arch overview abq}@anchor{1246}@ref{1246,,.arch.overview.abq;} The ABQ holds blocks of a minimum configurable
size: “reuse size”.

@anchor{design/poolmvt design mps poolmvt arch overview storage}@anchor{1247}@ref{1247,,.arch.overview.storage;} The ABQ acquires storage from the arena,
and from its internal free block managers.

@anchor{design/poolmvt design mps poolmvt arch overview storage contiguous}@anchor{1248}@ref{1248,,.arch.overview.storage.contiguous;} The arena storage is requested
to be contiguous to maximize opportunities for coalescing (Loci will
be used when available).

@anchor{design/poolmvt design mps poolmvt arch overview cbs}@anchor{1249}@ref{1249,,.arch.overview.cbs;} The free block managers hold blocks freed by
the client until, through coalescing, they have reached the reuse
size, at which point they are made available on the ABQ.

@anchor{design/poolmvt design mps poolmvt arch ap}@anchor{124a}@ref{124a,,.arch.ap;} The pool will use allocation points as the allocation
interface to the client.

@anchor{design/poolmvt design mps poolmvt arch ap two-phase}@anchor{124b}@ref{124b,,.arch.ap.two-phase;} Allocation points will request blocks from the
pool and suballocate those blocks (using the existing AP, compare and
increment, 2-phase mechanism) to satisfy client requests.

@anchor{design/poolmvt design mps poolmvt arch ap fill}@anchor{124c}@ref{124c,,.arch.ap.fill;} The pool will have a configurable “fill size” that
will be the preferred size block used to fill the allocation point.

@anchor{design/poolmvt design mps poolmvt arch ap fill size}@anchor{124d}@ref{124d,,.arch.ap.fill.size;} The fill size should be chosen to amortize the
cost of refill over a number of typical reserve/commit operations, but
not so large as to exceed the typical object population of the pool.

@anchor{design/poolmvt design mps poolmvt arch ap no-fit}@anchor{124e}@ref{124e,,.arch.ap.no-fit;} When an allocation does not fit in the remaining
space of the allocation point, there may be a remaining fragment.

@anchor{design/poolmvt design mps poolmvt arch ap no-fit sawdust}@anchor{124f}@ref{124f,,.arch.ap.no-fit.sawdust;} If the fragment is below a configurable
threshold (minimum size), it will be left unused (but returned to the
free block managers so it will be reclaimed when adjacent objects are
freed).

@anchor{design/poolmvt design mps poolmvt arch ap no-fit splinter}@anchor{1250}@ref{1250,,.arch.ap.no-fit.splinter;} otherwise, the remaining fragment will be
(effectively) returned to the head of the available-block queue, so
that it will be used as soon as possible (that is, by objects of similar
birthdate).

@anchor{design/poolmvt design mps poolmvt arch ap no-fit oversize}@anchor{1251}@ref{1251,,.arch.ap.no-fit.oversize;} If the requested allocation exceeds the
fill size it is treated exceptionally (this may indicate the client
has either misconfigured or misused the pool and should either change
the pool configuration or create a separate pool for these exceptional
objects for best performance).

@anchor{design/poolmvt design mps poolmvt arch ap no-fit oversize policy}@anchor{1252}@ref{1252,,.arch.ap.no-fit.oversize.policy;} Oversize blocks are assumed to
have exceptional lifetimes, hence are allocated to one side and do not
participate in the normal storage recycling of the pool.

@anchor{design/poolmvt design mps poolmvt arch ap refill overhead}@anchor{1253}@ref{1253,,.arch.ap.refill.overhead;} If reuse size is small, or becomes small
due to @ref{1254,,.arch.adapt}, all allocations will effectively be treated
exceptionally (the AP will trip and a oldest-fit block will be chosen
on each allocation). This mode will be within a constant factor in
overhead of an unbuffered pool.

@anchor{design/poolmvt design mps poolmvt arch abq}@anchor{1255}@ref{1255,,.arch.abq;} The available block queue holds blocks that have
coalesced sufficiently to reach reuse size.

@anchor{design/poolmvt design mps poolmvt arch abq reuse size}@anchor{1256}@ref{1256,,.arch.abq.reuse.size;} A multiple of the quantum of virtual memory
is used as the reuse size (@ref{1257,,.analysis.policy.size}).

@anchor{design/poolmvt design mps poolmvt arch abq fifo}@anchor{1258}@ref{1258,,.arch.abq.fifo;} It is a FIFO queue (recently coalesced blocks go to
the tail of the queue, blocks are taken from the head of the queue for
reuse).

@anchor{design/poolmvt design mps poolmvt arch abq delay-reuse}@anchor{1259}@ref{1259,,.arch.abq.delay-reuse;} By thus delaying reuse, coalescing
opportunities are greater.

@anchor{design/poolmvt design mps poolmvt arch abq high-water}@anchor{125a}@ref{125a,,.arch.abq.high-water;} It has a configurable high water mark, which
when reached will cause blocks at the head of the queue to be returned
to the arena, rather than reused.

@anchor{design/poolmvt design mps poolmvt arch abq return}@anchor{125b}@ref{125b,,.arch.abq.return;} When the MPS supports it, the pool will be able
to return free blocks from the ABQ to the arena on demand.

@anchor{design/poolmvt design mps poolmvt arch abq return segment}@anchor{125c}@ref{125c,,.arch.abq.return.segment;} @ref{125b,,.arch.abq.return} can be guaranteed to
be able to return a segment by setting reuse size to twice the size of
the segments the pool requests from the arena.

@anchor{design/poolmvt design mps poolmvt arch cbs}@anchor{125d}@ref{125d,,.arch.cbs;} The coalescing block structure holds blocks that have
been freed by the client.

@anchor{design/poolmvt design mps poolmvt arch cbs optimize}@anchor{125e}@ref{125e,,.arch.cbs.optimize;} The data structure is optimized for coalescing.

@anchor{design/poolmvt design mps poolmvt arch cbs abq}@anchor{125f}@ref{125f,,.arch.cbs.abq;} When a block reaches reuse size, it is added to the
ABQ.

@anchor{design/poolmvt design mps poolmvt arch cbs data-structure}@anchor{1260}@ref{1260,,.arch.cbs.data-structure;} The data structures are organized so that
a block can be both in the free block managers and on the ABQ
simultaneously to permit additional coalescing, up until the time the
block is removed from the ABQ and assigned to an AP.

@anchor{design/poolmvt design mps poolmvt arch fragmentation internal}@anchor{1261}@ref{1261,,.arch.fragmentation.internal;} Internal fragmentation results from
The pool will request large segments from the arena to minimize the
internal fragmentation due to objects not crossing segment boundaries.

@anchor{design/poolmvt design mps poolmvt arch modular}@anchor{1262}@ref{1262,,.arch.modular;} The architecture will be modular, to allow building
variations on the pool by assembling different parts.

@anchor{design/poolmvt design mps poolmvt arch modular example}@anchor{1263}@ref{1263,,.arch.modular.example;} For example, it should be possible to build
pools with any of the freelist mechanisms, with in-band or out-of-band
storage (where applicable), that do or do not support derived object
descriptions, etc.

@anchor{design/poolmvt design mps poolmvt arch modular initial}@anchor{1264}@ref{1264,,.arch.modular.initial;} The initial architecture will use
@ref{1265,,.sol.mech.free-list} for the free block managers,
@ref{1266,,.sol.mech.storage.out-of-band}, @ref{1267,,.sol.mech.desc.derived}, and
@ref{1268,,.sol.mech.allocate.buffer}.

@anchor{design/poolmvt design mps poolmvt arch segregate}@anchor{1269}@ref{1269,,.arch.segregate;} The architecture will support segregated
allocation through the use of multiple allocation points. The client
will choose the appropriate allocation point either at run time, or
when possible, at compile time.

@anchor{design/poolmvt design mps poolmvt arch segregate initial}@anchor{126a}@ref{126a,,.arch.segregate.initial;} The initial architecture will segregate
allocations into two classes: large and small. This will be
implemented by creating two pools with different parameters.

@anchor{design/poolmvt design mps poolmvt arch segregate initial choice}@anchor{126b}@ref{126b,,.arch.segregate.initial.choice;} The initial architecture will
provide glue code to choose which pool to allocate from at run time.
If possible this glue code will be written in a way that a good
compiler can optimize the selection of pool at compile time.
Eventually this glue code should be subsumed by the client or
generated automatically by a tool.

@anchor{design/poolmvt design mps poolmvt arch debug}@anchor{126c}@ref{126c,,.arch.debug;} Debugging features such as tags, fenceposts, types,
creators will be implemented in a layer above the pool and APs. A
generic pool debugging interface will be developed to support
debugging in this outer layer.

@anchor{design/poolmvt design mps poolmvt arch debug initial}@anchor{126d}@ref{126d,,.arch.debug.initial;} The initial architecture will have counters
for objects/bytes allocated/freed and support for detecting
overlapping frees.

@anchor{design/poolmvt design mps poolmvt arch dependency loci}@anchor{126e}@ref{126e,,.arch.dependency.loci;} The architecture depends on the arena being
able to efficiently provide segments of varying sizes without
excessive fragmentation. The locus mechanism should satisfy this
dependency. (See @ref{126f,,.analysis.strategy.risk}.)

@anchor{design/poolmvt design mps poolmvt arch dependency mfs}@anchor{1270}@ref{1270,,.arch.dependency.mfs;} The architecture internal data structures
depend on efficient manual management of small, fixed-sized objects (2
different sizes). The MFS pool should satisfy this dependency.

@anchor{design/poolmvt design mps poolmvt arch contingency}@anchor{1271}@ref{1271,,.arch.contingency;} Since the strategy we propose is new, it may not
work.

@anchor{design/poolmvt design mps poolmvt arch contingency pathological}@anchor{1272}@ref{1272,,.arch.contingency.pathological;} In particular, pathological
allocation patterns could result in fragmentation such that no blocks
recycle from the free bock managers to the ABQ.

@anchor{design/poolmvt design mps poolmvt arch contingency fallback}@anchor{1273}@ref{1273,,.arch.contingency.fallback;} As a fallback, there will be a pool
creation parameter for a high water mark for the free space.

@anchor{design/poolmvt design mps poolmvt arch contingency fragmentation-limit}@anchor{1274}@ref{1274,,.arch.contingency.fragmentation-limit;} When the free space as a
percentage of all the memory managed by the pool (a measure of
fragmentation) reaches that high water mark, the free block managers
will be searched oldest-fit before requesting additional segments from
the arena.

@anchor{design/poolmvt design mps poolmvt arch contingency alternative}@anchor{1275}@ref{1275,,.arch.contingency.alternative;} We also plan to implement
@ref{1276,,.sol.mech.free-list.cartesian-tree} as an alternative free block
manager, which would permit more efficient searching of the free
blocks.

@anchor{design/poolmvt design mps poolmvt arch parameters}@anchor{1277}@ref{1277,,.arch.parameters;} The architecture supports several parameters so
that multiple pools may be instantiated and tuned to support different
object cohorts. The important parameters are: reuse size, minimum
size, fill size, ABQ high water mark, free block fragmentation limit
(see @ref{1274,,.arch.contingency.fragmentation-limit}).

@anchor{design/poolmvt design mps poolmvt arch parameters client-visible}@anchor{1278}@ref{1278,,.arch.parameters.client-visible;} The client-visible parameters of
the pool are the minimum object size, the mean object size, the
maximum object size, the reserve depth and fragmentation limit. The
minimum object size determines when a splinter is kept on the head of
the ABQ (@ref{1250,,.arch.ap.no-fit.splinter}). The maximum object size
determines the fill size (@ref{124d,,.arch.ap.fill.size}) and hence when a
block is allocated exceptionally (@ref{1251,,.arch.ap.no-fit.oversize}). The
mean object size is the most likely object size. The reserve depth is
a measure of the hysteresis of the object population. The mean object
size, reserve depth and, maximum object size are used to determine the
size of the ABQ (@ref{125a,,.arch.abq.high-water}). The fragmentation limit is
used to determine when contingency mode is used to satisfy an
allocation request (@ref{1271,,.arch.contingency}).

@anchor{design/poolmvt design mps poolmvt arch adapt}@anchor{1254}@ref{1254,,.arch.adapt;} We believe that an important adaptation to explore is
tying the reuse size inversely to the fragmentation (as measured in
@ref{1274,,.arch.contingency.fragmentation-limit}).

@anchor{design/poolmvt design mps poolmvt arch adapt reuse}@anchor{1279}@ref{1279,,.arch.adapt.reuse;} By setting reuse size low when fragmentation is
high, smaller blocks will be available for reuse, so fragmentation
should diminish.

@anchor{design/poolmvt design mps poolmvt arch adapt overhead}@anchor{127a}@ref{127a,,.arch.adapt.overhead;} This will result in higher overhead as the AP
will need to be refilled more often, so reuse size should be raised
again as fragmentation diminishes.

@anchor{design/poolmvt design mps poolmvt arch adapt oldest-fit}@anchor{127b}@ref{127b,,.arch.adapt.oldest-fit;} In the limit, if reuse size goes to zero,
the pool will implement a “oldest-fit” policy: the oldest free block
of sufficient size will be used for each allocation.

@anchor{design/poolmvt design mps poolmvt arch adapt risk}@anchor{127c}@ref{127c,,.arch.adapt.risk;} This adaptation is an experimental policy and
should not be delivered to clients until thoroughly tested.

@node Analysis<5>,Ideas,Architecture<10>,Manual Variable Temporal MVT pool design
@anchor{design/poolmvt analysis}@anchor{127d}
@subsection Analysis


@anchor{design/poolmvt design mps poolmvt analysis discard}@anchor{127e}@ref{127e,,.analysis.discard;} We have discarded many traditional solutions based
on experience and analysis in paper.wil95(1). In particular, managing
the free list as a linear list arranged by address or size and basing
policy on searching such a linear list in a particular direction, from
a particular starting point, using fit and/or immediacy as criteria.
We believe that none of these solutions is derived from considering
the root of the problem to be solved (as described in
@ref{127f,,.analysis.strategy}), although their behavior as analyzed by Wilson
gives several insights.

@anchor{design/poolmvt design mps poolmvt analysis strategy}@anchor{127f}@ref{127f,,.analysis.strategy;} For any program to run in the minimum required
memory (with minimal overhead – we discard solutions such as
compression for now), fragmentation must be eliminated. To eliminate
fragmentation, simply place blocks in memory so that they die “in
order” and can be immediately coalesced. This ideal is not achievable,
but we believe we can find object attributes that correlate with
deathtime and exploit them to approximate the ideal. Initially we
believe birth time and type (as approximated by size) will be useful
attributes to explore.

@anchor{design/poolmvt design mps poolmvt analysis strategy perform}@anchor{1280}@ref{1280,,.analysis.strategy.perform;} To meet @ref{1232,,.req.attr.performance}, the
implementation of @ref{1281,,.sol.strategy} must be competitive in both time
and space.

@anchor{design/poolmvt design mps poolmvt analysis strategy risk}@anchor{126f}@ref{126f,,.analysis.strategy.risk;} The current MPS segment substrate can cause
internal fragmentation which an individual pool can do nothing about.
We expect that request.epcore.170193.sugg.loci@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/epcore/170193/} will be implemented to
remove this risk.

@anchor{design/poolmvt design mps poolmvt analysis policy}@anchor{1282}@ref{1282,,.analysis.policy;} Deferred coalescing, when taken to the extreme will
not minimize the memory consumption of a program, as no memory would
ever be reused. Eager reuse appears to lead to more fragmentation,
whereas delayed reuse appears to reduce fragmentation
(paper.wil95(1)). The systems studied by Wilson did not directly
address deferring reuse. Our proposed policy is to reuse blocks when
they reach a (configurable) size. We believe that this policy along
with the policy of segregating allocations by death time, will greatly
reduce fragmentation.

@anchor{design/poolmvt design mps poolmvt analysis policy risk}@anchor{1283}@ref{1283,,.analysis.policy.risk;} This policy could lead to pathological behavior
if allocations cannot be successfully segregated.

@anchor{design/poolmvt design mps poolmvt analysis policy allocate segregate}@anchor{1284}@ref{1284,,.analysis.policy.allocate.segregate;} This policy has some similarities
to CustomAlloc (paper.grun92(1)). CustomAlloc segregates objects by
size classes, and then within those classes chooses a different
allocator depending on whether that size class has a stable or
unstable population. Classes with stable population recycle storage
within the class, whereas classes with unstable populations return
their storage to the general allocation pool for possible reuse by
another class. CustomAlloc, however, requires profiling the
application and tuning the allocator according to those profiles.
Although we intend to support such tuning, we do not want to require
it.

@anchor{design/poolmvt design mps poolmvt analysis policy reallocate}@anchor{1285}@ref{1285,,.analysis.policy.reallocate;} For reallocation, @ref{1242,,.req.fun.suballocate}
can be used to free the remainder if a block is made smaller. Doing so
will cause the freed block to obey @ref{1286,,.sol.policy.allocate} (that is,
the freed block will not be treated specially, it will be subject to
the normal policy on reuse). Copying can be used if a block is made
larger. paper.vo96(0) reports success in over-allocating a block the
first time it is resized larger, presumably because blocks that are
resized once tend to be resized again and over-allocating may avoid a
subsequent copy. If each object that will be reallocated can be given
its own allocation point until its final reallocation, the allocation
point can be used to hold released or spare storage.

@anchor{design/poolmvt design mps poolmvt analysis policy size}@anchor{1257}@ref{1257,,.analysis.policy.size;} We believe that this will take advantage of the
underlying virtual memory system’s ability to compact the physical
memory footprint of the program by discarding free fragments that
align with the virtual memory quantum. (In a VM system one can
approximate compaction by sparse mapping. If every other page of a
segment is unused, the unused pages can be unmapped, freeing up
physical memory that can be mapped to a new contiguous vm range.)

@anchor{design/poolmvt design mps poolmvt analysis mech free-list}@anchor{1287}@ref{1287,,.analysis.mech.free-list;} The literature (paper.grun92(1),
paper.vo96(0)) indicate that @ref{1276,,.sol.mech.free-list.cartesian-tree}
provides a space-efficient implementation at some cost in speed.
@ref{1288,,.sol.mech.free-list.splay-tree} is faster but less space-efficient.
@ref{1289,,.sol.mech.free-list.bitmap} is unstudied. Many of the faster
allocators maintain caches of free blocks by size to speed allocation
of “popular” sizes. We intend to initially explore not doing so, as we
believe that policy ultimately leads to fragmentation by mixing
objects of varying death times. Instead we intend to use a free list
mechanism to support fast coalescing, deferring reuse of blocks until
a minimum size has been reached.

@anchor{design/poolmvt design mps poolmvt analysis mech allocate optimize-small}@anchor{128a}@ref{128a,,.analysis.mech.allocate.optimize-small;} Wilson (paper.wil95(1)) notes
that small blocks typically have short lifetimes and that overall
performance is improved if you optimize the management of small
blocks, e.g., @ref{128b,,.sol.mech.allocate.lookup-table} for all small blocks.
We believe that @ref{1268,,.sol.mech.allocate.buffer} does exactly that.

@anchor{design/poolmvt design mps poolmvt analysis mech allocate optimize-new}@anchor{128c}@ref{128c,,.analysis.mech.allocate.optimize-new;} Wilson (paper.wil95(1)) reports
some benefit from “preserving wilderness”, that is, when a block of
memory must be requested from the system to satisfy an allocation,
only the minimum amount of that block is used, the remainder is
preserved (effectively by putting it at the tail of the free list).
This mechanism may or may not implement @ref{1286,,.sol.policy.allocate}. We
believe a better mechanism is to choose to preserve or not, based on
@ref{1286,,.sol.policy.allocate}.

@node Ideas,Implementation<25>,Analysis<5>,Manual Variable Temporal MVT pool design
@anchor{design/poolmvt ideas}@anchor{128d}
@subsection Ideas


@anchor{design/poolmvt design mps poolmvt sol}@anchor{128e}@ref{128e,,.sol;} Many solution ideas for manual management of variable-sized
memory blocks are enumerated by paper.wil95(1). Here we list the most
promising, and some of our own.

@menu
* Strategy:: 
* Policy:: 
* Mechanism: Mechanism<2>. 

@end menu

@node Strategy,Policy,,Ideas
@anchor{design/poolmvt strategy}@anchor{128f}
@subsubsection Strategy


@anchor{design/poolmvt design mps poolmvt sol strategy}@anchor{1281}@ref{1281,,.sol.strategy;} To run a program in the minimal required memory,
with minimal overhead, utilize memory efficiently. Memory becomes
unusable when fragmented. Strategy is to minimize fragmentation. So
place blocks where they won’t cause fragmentation later.

@anchor{design/poolmvt design mps poolmvt sol strategy death}@anchor{1290}@ref{1290,,.sol.strategy.death;} Objects that will die together (in time)
should be allocated together (in space); thus they will coalesce,
reducing fragmentation.

@anchor{design/poolmvt design mps poolmvt sol strategy death birth}@anchor{1291}@ref{1291,,.sol.strategy.death.birth;} Assume objects allocated near each other
in time will have similar deathtimes (paper.beck82(0)).

@anchor{design/poolmvt design mps poolmvt sol strategy death type}@anchor{1292}@ref{1292,,.sol.strategy.death.type;} Assume objects of different type may have
different deathtimes, even if born together.

@anchor{design/poolmvt design mps poolmvt sol strategy death predict}@anchor{1293}@ref{1293,,.sol.strategy.death.predict;} Find and use program features to predict deathtimes.

@anchor{design/poolmvt design mps poolmvt sol strategy reallocate}@anchor{1294}@ref{1294,,.sol.strategy.reallocate;} Reallocation implies rebirth, or at least
a change in lifetime

@anchor{design/poolmvt design mps poolmvt sol strategy debug}@anchor{1295}@ref{1295,,.sol.strategy.debug;} As much of the debugging functionality as
possible should be implemented as a generally available MPS utility;
the pool will provide support for debugging that would be expensive or
impossible to allocate outside the pool.

@node Policy,Mechanism<2>,Strategy,Ideas
@anchor{design/poolmvt policy}@anchor{1296}
@subsubsection Policy


Policy is an implementable decision procedure, hopefully approximating
the strategy.

@anchor{design/poolmvt design mps poolmvt sol policy reuse}@anchor{1297}@ref{1297,,.sol.policy.reuse;} Defer reusing blocks, to encourage coalescing.

@anchor{design/poolmvt design mps poolmvt sol policy split}@anchor{1298}@ref{1298,,.sol.policy.split;} When a block is split to satisfy an allocation,
use the remainder as soon as possible.

@anchor{design/poolmvt design mps poolmvt sol policy size}@anchor{1299}@ref{1299,,.sol.policy.size;} Prevent @ref{1297,,.sol.policy.reuse} from consuming all
of memory by choosing a (coalesced) block for reuse when it reaches a
minimum size.

@anchor{design/poolmvt design mps poolmvt sol policy size fixed}@anchor{129a}@ref{129a,,.sol.policy.size.fixed;} Use the quantum of virtual memory (e.g.,
one page) as minimum size.

@anchor{design/poolmvt design mps poolmvt sol policy size tune}@anchor{129b}@ref{129b,,.sol.policy.size.tune;} Allow tuning minimum size.

@anchor{design/poolmvt design mps poolmvt sol policy size adapt}@anchor{129c}@ref{129c,,.sol.policy.size.adapt;} Adaptively change minimum size.

@anchor{design/poolmvt design mps poolmvt sol policy allocate}@anchor{1286}@ref{1286,,.sol.policy.allocate;} Allocate objects with similar birthdate and
lifetime together.

@anchor{design/poolmvt design mps poolmvt sol policy allocate segregate}@anchor{129d}@ref{129d,,.sol.policy.allocate.segregate;} Segregate allocations by type.

@anchor{design/poolmvt design mps poolmvt sol policy allocate segregate size}@anchor{129e}@ref{129e,,.sol.policy.allocate.segregate.size;} Use size as a substitute for type.

@anchor{design/poolmvt design mps poolmvt sol policy allocate segregate tune}@anchor{129f}@ref{129f,,.sol.policy.allocate.segregate.tune;} Permit tuning of segregation.

@anchor{design/poolmvt design mps poolmvt sol policy allocate segregate adapt}@anchor{12a0}@ref{12a0,,.sol.policy.allocate.segregate.adapt;} Adaptively segregate allocations.

@anchor{design/poolmvt design mps poolmvt sol policy reallocate}@anchor{12a1}@ref{12a1,,.sol.policy.reallocate;} Implement reallocation in a central
mechanism outside of the pool, create a generic pool interface in
support of same.

@anchor{design/poolmvt design mps poolmvt sol policy debug}@anchor{12a2}@ref{12a2,,.sol.policy.debug;} Implement a pool debugging interface.

@anchor{design/poolmvt design mps poolmvt sol policy debug counters}@anchor{12a3}@ref{12a3,,.sol.policy.debug.counters;} Implement debugging counters in the
pool that are queried with a generic interface.

@anchor{design/poolmvt design mps poolmvt sol policy debug verify}@anchor{12a4}@ref{12a4,,.sol.policy.debug.verify;} Implement debugging error returns on
overlapping frees.

@node Mechanism<2>,,Policy,Ideas
@anchor{design/poolmvt mechanism}@anchor{12a5}
@subsubsection Mechanism


Mechanisms are algorithms or data structures used to implement policy.

@anchor{design/poolmvt design mps poolmvt sol mech free-list}@anchor{1265}@ref{1265,,.sol.mech.free-list;} Mechanisms that can be used to describe the
free list.

@anchor{design/poolmvt design mps poolmvt sol mech free-list cartesian-tree}@anchor{1276}@ref{1276,,.sol.mech.free-list.cartesian-tree;} Using address and size as keys
supports fast coalescing of adjacent blocks and fast searching for
optimal-sized blocks. Unfortunately, because the shape of the tree is
constrained by the second key, it can become unbalanced. This data
structure is used in the SunOS 4.1 malloc (paper.grun92(1)).

@anchor{design/poolmvt design mps poolmvt sol mech free-list splay-tree}@anchor{1288}@ref{1288,,.sol.mech.free-list.splay-tree;} The amortized cost of a splay tree
is competitive with balanced binary trees in the worst case, but can
be significantly better for regular patterns of access because
recently-accessed keys are moved to the root of the tree and hence can
be re-accessed quickly. This data structure is used in the System Vr4
malloc (paper.vo96(0)). (For a complete analysis of the splay tree
algorithm time bounds see paper.st85(0).)

@anchor{design/poolmvt design mps poolmvt sol mech free-list bitmap}@anchor{1289}@ref{1289,,.sol.mech.free-list.bitmap;} Using address as an index and
fix-sized blocks, the booleans can represent whether a block is free
or not. Adjacent blocks can be used to construct larger blocks.
Efficient algorithms for searching for runs in a vector are known.
This data structure is used in many file system disk block managers.

@anchor{design/poolmvt design mps poolmvt sol mech free-list refcount}@anchor{12a6}@ref{12a6,,.sol.mech.free-list.refcount;} A count of the number of allocated
but not freed subblocks of a block can be used to determine when a
block is available for reuse. This is an extremely compact data
structure, but does not support subblock reuse.

@anchor{design/poolmvt design mps poolmvt sol mech free-list hybrid}@anchor{12a7}@ref{12a7,,.sol.mech.free-list.hybrid;} Bitmaps appear suited particularly to
managing small, contiguous blocks. The tree structures appear suited
particularly to managing varying-sized, discontiguous blocks. A
refcount can be very efficient if objects can be placed accurately
according to death time. A hybrid mechanism may offer better
performance for a wider range of situations.

@anchor{design/poolmvt design mps poolmvt sol mech free-list linked}@anchor{12a8}@ref{12a8,,.sol.mech.free-list.linked;} An address-ordered singly linked free
list using space in each free block to store the block’s size and a
pointer to the next block.

@anchor{design/poolmvt design mps poolmvt sol mech storage}@anchor{12a9}@ref{12a9,,.sol.mech.storage;} Methods that can be used to store the free list description.

@anchor{design/poolmvt design mps poolmvt sol mech storage in-band}@anchor{12aa}@ref{12aa,,.sol.mech.storage.in-band;} The tree data structures (and
@ref{12a8,,.sol.mech.free-list.linked}) are amenable to being stored in the
free blocks themselves, minimizing the space overhead of management.
To do so imposes a minimum size on free blocks and reduces the
locality of the data structure.

@anchor{design/poolmvt design mps poolmvt sol mech storage out-of-band}@anchor{1266}@ref{1266,,.sol.mech.storage.out-of-band;} The bit-map data structure must be
stored separately.

@anchor{design/poolmvt design mps poolmvt sol mech desc}@anchor{12ab}@ref{12ab,,.sol.mech.desc;} for an allocated block to be freed, its base and
bound must be known

@anchor{design/poolmvt design mps poolmvt sol mech desc derived}@anchor{1267}@ref{1267,,.sol.mech.desc.derived;} Most clients can supply the base of the
block. Some clients can supply the bound.

@anchor{design/poolmvt design mps poolmvt sol mech desc in-band}@anchor{12ac}@ref{12ac,,.sol.mech.desc.in-band;} When the bound cannot be supplied, it can
be stored as an in-band “header”. If neither the base nor bound can be
supplied (e.g., the client may only have an interior pointer to the
block), a header and footer may be required.

@anchor{design/poolmvt design mps poolmvt sol mech desc out-of-band}@anchor{12ad}@ref{12ad,,.sol.mech.desc.out-of-band;} In un-tagged architectures, it may be
necessary to store the header and footer out-of-band to distinguish
them from client data. Out-of-band storage can improve locality and
reliability. Any of the free-list structures can also be used to
describe allocated blocks out-of-band.

@anchor{design/poolmvt design mps poolmvt sol mech desc crossing-map}@anchor{12ae}@ref{12ae,,.sol.mech.desc.crossing-map;} An alternative for untagged
architectures is to store a “crossing map” which records an encoding
of the start of objects and then store the descriptive information
in-band.

@anchor{design/poolmvt design mps poolmvt sol mech allocate}@anchor{12af}@ref{12af,,.sol.mech.allocate;} Mechanisms that can be used to allocate blocks
(these typically sit on top of a more general free-list manager).

@anchor{design/poolmvt design mps poolmvt sol mech allocate lookup-table}@anchor{128b}@ref{128b,,.sol.mech.allocate.lookup-table;} Use a table of popular sizes to
cache free blocks of those sizes.

@anchor{design/poolmvt design mps poolmvt sol mech allocate buffer}@anchor{1268}@ref{1268,,.sol.mech.allocate.buffer;} Allocate from contiguous blocks using
compare and increment.

@anchor{design/poolmvt design mps poolmvt sol mech allocate optimize-small}@anchor{12b0}@ref{12b0,,.sol.mech.allocate.optimize-small;} Use a combination of techniques
to ensure the time spent managing a block is small relative to the
block’s lifetime; assume small blocks typically have short lifetimes.

@anchor{design/poolmvt design mps poolmvt sol mech allocate optimize-new}@anchor{12b1}@ref{12b1,,.sol.mech.allocate.optimize-new;} When “virgin” memory is acquired
from the operating system to satisfy a request, try to preserve it
(that is, use only what is necessary).

@anchor{design/poolmvt design mps poolmvt sol mech allocate segregate size}@anchor{12b2}@ref{12b2,,.sol.mech.allocate.segregate.size;} Use size as a substitute for
type.

@anchor{design/poolmvt design mps poolmvt sol mech reallocate}@anchor{12b3}@ref{12b3,,.sol.mech.reallocate;} use @ref{1242,,.req.fun.suballocate} to return unused
memory when a block shrinks, but differentiate this from an erroneous
overlapping free by using separate interfaces.

@node Implementation<25>,Testing<9>,Ideas,Manual Variable Temporal MVT pool design
@anchor{design/poolmvt implementation}@anchor{12b4}
@subsection Implementation


The implementation consists of the following separable modules:

@menu
* Splay Tree:: 
* Coalescing Block Structure:: 
* Fail-over to address-ordered free list:: 
* Available Block Queue:: 
* Pool implementation:: 
* AP Dispatch:: 

@end menu

@node Splay Tree,Coalescing Block Structure,,Implementation<25>
@anchor{design/poolmvt splay-tree}@anchor{12b5}
@subsubsection Splay Tree


@anchor{design/poolmvt design mps poolmvt impl c splay}@anchor{12b6}@ref{12b6,,.impl.c.splay;} The implementation of
@ref{1288,,.sol.mech.free-list.splay-tree}. See design.mps.splay@footnote{splay.txt.html}.

@node Coalescing Block Structure,Fail-over to address-ordered free list,Splay Tree,Implementation<25>
@anchor{design/poolmvt coalescing-block-structure}@anchor{12b7}@anchor{design/poolmvt design-mps-splay}@anchor{12b8}
@subsubsection Coalescing Block Structure


@anchor{design/poolmvt design mps poolmvt impl c cbs}@anchor{12b9}@ref{12b9,,.impl.c.cbs;} The initial implementation will use
@ref{1288,,.sol.mech.free-list.splay-tree} and
@ref{1266,,.sol.mech.storage.out-of-band}. For locality, this storage should be
managed as a linked free list of splay nodes suballocated from blocks
acquired from a pool shared by all CBS’s. Must support creation and
destruction of an empty tree. Must support search, insert and delete
by key of type Addr. Must support finding left and right neighbors of
a failed search for a key. Must support iterating over the elements of
the tree with reasonable efficiency. Must support storing and
retrieving a value of type Size associated with the key. Standard
checking and description should be provided. See design.mps.cbs@footnote{cbs.txt.html}.

@node Fail-over to address-ordered free list,Available Block Queue,Coalescing Block Structure,Implementation<25>
@anchor{design/poolmvt design-mps-cbs}@anchor{12ba}@anchor{design/poolmvt fail-over-to-address-ordered-free-list}@anchor{12bb}
@subsubsection Fail-over to address-ordered free list


@anchor{design/poolmvt design mps poolmvt impl c freelist}@anchor{12bc}@ref{12bc,,.impl.c.freelist;} Because the CBS uses out-of-band storage, it may
be unable to handle insert (design.mps.cbs.function.cbs.insert.fail@footnote{cbs.html#design.mps.cbs.function.cbs.insert.fail})
and delete (design.mps.cbs.function.cbs.delete.fail@footnote{cbs.html#design.mps.cbs.function.cbs.delete.fail}) operations. When
this happen MVT fails over to an address-ordered singly linked free
list. This uses in-band storage and so cannot run out of memory, but
it has much worse performance than the CBS. Therefore MVT eagerly
attempts to flush blocks from the free list back to the CBS. See
design.mps.freelist@footnote{freelist.html} for the design and implementation of the free
list.

@node Available Block Queue,Pool implementation,Fail-over to address-ordered free list,Implementation<25>
@anchor{design/poolmvt available-block-queue}@anchor{12bd}@anchor{design/poolmvt design-mps-freelist}@anchor{12be}
@subsubsection Available Block Queue


@anchor{design/poolmvt design mps poolmvt impl c abq}@anchor{12bf}@ref{12bf,,.impl.c.abq;} The initial implementation will be a queue of fixed
size (determined at pool creation time from the high water mark). Must
support creation and destruction of an empty queue. Must support
insertion at the head or tail of the queue (failing if full), peeking
at the head of the queue, and removal of the head (failing if empty)
or any element of the queue (found by a search). Standard checking and
description should be provided. See design.mps.abq@footnote{abq.txt.html}.

@node Pool implementation,AP Dispatch,Available Block Queue,Implementation<25>
@anchor{design/poolmvt design-mps-abq}@anchor{12c0}@anchor{design/poolmvt pool-implementation}@anchor{12c1}
@subsubsection Pool implementation


@anchor{design/poolmvt design mps poolmvt impl c}@anchor{12c2}@ref{12c2,,.impl.c;} The initial implementation will use the above modules to
implement a buffered pool. Must support creation and destruction of
the pool. Creation takes parameters: minimum size, mean size, maximum
size, reserve depth and fragmentation limit. Minimum, mean, and
maximum size are used to calculate the internal fill and reuse sizes.
Reserve depth and mean size are used to calculate the ABQ high water
mark. Fragmentation limit is used to set the contingency mode. Must
support buffer initialization, filling and emptying. Must support
freeing. Standard checking and description should be provided.
[Eventually, it should support scanning, so it can be used with
collected pools, but no manual pool currently does.]

@anchor{design/poolmvt design mps poolmvt impl c future}@anchor{12c3}@ref{12c3,,.impl.c.future;} The implementation should not preclude “buffered
free” (mail.ptw.1997-12-05.19-07@footnote{https://info.ravenbrook.com/project/mps/mail/1997/12/05/19-07/0.txt}) being added in the future.

@anchor{design/poolmvt design mps poolmvt impl c parameters}@anchor{12c4}@ref{12c4,,.impl.c.parameters;} The pool parameters are calculated as follows
from the input parameters: minimum, mean, and maximum size are taken
directly from the parameters.

@anchor{design/poolmvt design mps poolmvt impl c parameter fill-size}@anchor{12c5}@ref{12c5,,.impl.c.parameter.fill-size;} The fill size is set to the maximum
size times the reciprocal of the fragmentation limit, rounded up to
the arena grain size.

@anchor{design/poolmvt design mps poolmvt imple c parameter reuse-size}@anchor{12c6}@ref{12c6,,.imple.c.parameter.reuse-size;} The reuse size is set to twice the
fill size (see @ref{125c,,.arch.abq.return.segment},
@ref{12c7,,.impl.c.free.merge.segment}).

@anchor{design/poolmvt design mps poolmvt impl c parameter abq-limit}@anchor{12c8}@ref{12c8,,.impl.c.parameter.abq-limit;} The ABQ high-water limit is set to the
reserve depth times the mean size (that is, the queue should hold as
many reuse blocks as would take to cover the population hysteresis if
the population consisted solely of mean-sized blocks, see
@ref{125a,,.arch.abq.high-water}).

@anchor{design/poolmvt design mps poolmvt impl c parameter avail-limit}@anchor{12c9}@ref{12c9,,.impl.c.parameter.avail-limit;} The free block high-water limit is
implemented by comparing the available free space to an “available
limit”. The available limit is updated each time a segment is
allocated from or returned to the arena by setting it to the total
size of the pool times the fragmentation limit divide vy 100 (see
@ref{1273,,.arch.contingency.fallback}).

@anchor{design/poolmvt design mps poolmvt impl c ap fill}@anchor{12ca}@ref{12ca,,.impl.c.ap.fill;} An AP fill request will be handled as follows:


@itemize -

@item 
If the request is larger than fill size, attempt to request a
segment from the arena sufficient to satisfy the request.

@item 
Use any previously returned splinter (from @ref{12cb,,.impl.c.ap.empty}), if
large enough.

@item 
Attempt to retrieve a free block from the head of the ABQ (removing
it from ABQ and the free block managers if found).

@item 
If above fragmentation limit, attempt to find a block in the free
block managers, using oldest-fit search.

@item 
Attempt to request a segment of fill size from the arena.

@item 
Attempt to find a block in the free block managers, using oldest-fit
search.

@item 
Otherwise, fail.
@end itemize

@anchor{design/poolmvt design mps poolmvt impl c ap empty}@anchor{12cb}@ref{12cb,,.impl.c.ap.empty;} An AP empty request will be handled as follows:


@itemize -

@item 
If remaining free is less than min size, return it to the free block
managers.

@item 
If the remaining free is larger than any previous splinter, return
that splinter to the free block managers and save this one for use
by a subsequent fill.

@item 
Otherwise return the remaining block to the free block managers.
@end itemize

@anchor{design/poolmvt design mps poolmvt impl c free}@anchor{12cc}@ref{12cc,,.impl.c.free;} When blocks are returned to the free block managers
they may be merged with adjacent blocks. If a merge occurs with a
block on the ABQ, the ABQ must be adjusted to reflect the merge.

@anchor{design/poolmvt design mps poolmvt impl c free exception}@anchor{12cd}@ref{12cd,,.impl.c.free.exception;} Exceptional blocks are returned directly to
the arena.

@anchor{design/poolmvt design mps poolmvt impl c free merge}@anchor{12ce}@ref{12ce,,.impl.c.free.merge;} If a merge occurs and the merged block is
larger than reuse size:


@itemize -

@item 
If the ABQ is full, remove the block at the head of the ABQ from the
ABQ and the free block managers and return it to the arena(*).

@item 
Insert the newly merged block at the tail of the ABQ, leaving it in
the free block managers for further merging.
@end itemize

@anchor{design/poolmvt design mps poolmvt impl c free merge segment}@anchor{12c7}@ref{12c7,,.impl.c.free.merge.segment;} (*) Merged blocks may not align with
arena segments. If necessary, return the interior segments of a block
to the arena and return the splinters to the free block managers.

@anchor{design/poolmvt design mps poolmvt impl c free merge segment reuse}@anchor{12cf}@ref{12cf,,.impl.c.free.merge.segment.reuse;} If the reuse size (the size at
which blocks recycle from the free block managers to the ABQ) is at
least twice the fill size (the size of segments the pool allocates
from the arena), we can guarantee that there will always be a
returnable segment in every ABQ block.

@anchor{design/poolmvt design mps poolmvt impl c free merge segment overflow}@anchor{12d0}@ref{12d0,,.impl.c.free.merge.segment.overflow;} If the reuse size is set
smaller (see @ref{1254,,.arch.adapt}), there may not be a returnable segment in
an ABQ block, in which case the ABQ has “overflowed”. Whenever this
occurs, the ABQ will be refilled by searching the free block managers
for dropped reusable blocks when needed.

@anchor{design/poolmvt design mps poolmvt impl c free merge segment risk}@anchor{12d1}@ref{12d1,,.impl.c.free.merge.segment.risk;} The current segment structure does
not really support what we would like to do. Loci should do better:
support reserving contiguous address space and mapping/unmapping any
portion of that address space.

@anchor{design/poolmvt design mps poolmvt impl c free merge alternative}@anchor{12d2}@ref{12d2,,.impl.c.free.merge.alternative;} Alternatively, if the MPS segment
substrate permitted mapping/unmapping of pages, the pool could use
very large segments and map/unmap pages as needed.

@node AP Dispatch,,Pool implementation,Implementation<25>
@anchor{design/poolmvt ap-dispatch}@anchor{12d3}
@subsubsection AP Dispatch


@anchor{design/poolmvt design mps poolmvt impl c multiap}@anchor{12d4}@ref{12d4,,.impl.c.multiap;} The initial implementation will be a glue layer
that selects among several AP’s for allocation according to the
predicted deathtime (as approximated by size) of the requested
allocation. Each AP will be filled from a pool instance tuned to the
range of object sizes expected to be allocated from that AP. [For
bonus points provide an interface that creates a batch of pools and
AP’s according to some set of expected object sizes. Eventually expand
to understand object lifetimes and general lifetime prediction keys.]

@anchor{design/poolmvt design mps poolmvt impl c multiap sample-code}@anchor{12d5}@ref{12d5,,.impl.c.multiap.sample-code;} This glue code is not properly part of
the pool or MPS interface. It is a layer on top of the MPS interface,
intended as sample code for unsophisticated clients. Sophisticated
clients will likely want to choose among multiple AP’s more directly.

@node Testing<9>,Text,Implementation<25>,Manual Variable Temporal MVT pool design
@anchor{design/poolmvt testing}@anchor{12d6}
@subsection Testing


@anchor{design/poolmvt design mps poolmvt test component}@anchor{12d7}@ref{12d7,,.test.component;} Components @ref{12b6,,.impl.c.splay}, @ref{12b9,,.impl.c.cbs}, and
@ref{12bf,,.impl.c.abq} will be subjected to individual component tests to
verify their functionality.

@anchor{design/poolmvt design mps poolmvt test qa}@anchor{12d8}@ref{12d8,,.test.qa;} Once poolmvt is integrated into the MPS, the standard MPS
QA tests will be applied to poolmvt prior to each release.

@anchor{design/poolmvt design mps poolmvt test customer}@anchor{12d9}@ref{12d9,,.test.customer;} Customer acceptance tests will be performed on a
per-customer basis before release to that customer (cf.
proc.release.epcore(2).test)

@node Text,,Testing<9>,Manual Variable Temporal MVT pool design
@anchor{design/poolmvt text}@anchor{12da}
@subsection Text


Possible tweaks (from mail.pekka.1998-04-15.13-10@footnote{https://info.ravenbrook.com/project/mps/mail/1998/04/15/13-10/0.txt}):


@itemize -

@item 
Try to coalesce splinters returned from AP’s with the front (or any)
block on the ABQ.

@item 
Sort ABQ in some other way to minimize splitting/splinters. For
example, proximity to recently allocated blocks.
@end itemize

@geindex MVFF pool class; design
@geindex pool class; MVFF design

@node MVFF pool class,Protocol inheritance,Manual Variable Temporal MVT pool design,Old design
@anchor{design/poolmvff doc}@anchor{12db}@anchor{design/poolmvff design-poolmvff}@anchor{12dc}@anchor{design/poolmvff mvff-pool-class}@anchor{12dd}
@section MVFF pool class


@menu
* Introduction: Introduction<68>. 
* Overview: Overview<29>. 
* Methods: Methods<2>. 
* Implementation: Implementation<26>. 
* Details:: 

@end menu

@node Introduction<68>,Overview<29>,,MVFF pool class
@anchor{design/poolmvff design mps poolmvff}@anchor{12de}@anchor{design/poolmvff introduction}@anchor{12df}
@subsection Introduction


@anchor{design/poolmvff design mps poolmvff intro}@anchor{12e0}@ref{12e0,,.intro;} This is the design of the MVFF (Manual Variable First-Fit)
pool class. This pool implements a first (or last) fit policy for
variable-sized manually-managed objects, with control over first/last,
segment preference high/low, and slot fit low/high.

@anchor{design/poolmvff design mps poolmvff background}@anchor{12e1}@ref{12e1,,.background;} The pool was created in a response to a belief that
the ScriptWorks EPDL/EPDR’s first fit policy is beneficial for some
classes of client behaviour, but the performance of a linear free list
was unacceptable.

@node Overview<29>,Methods<2>,Introduction<68>,MVFF pool class
@anchor{design/poolmvff overview}@anchor{12e2}
@subsection Overview


@anchor{design/poolmvff design mps poolmvff over}@anchor{12e3}@ref{12e3,,.over;} This pool implements certain variants of the address-ordered
first-fit policy. The implementation allows allocation across segment
boundaries.

@anchor{design/poolmvff design mps poolmvff over buffer}@anchor{12e4}@ref{12e4,,.over.buffer;} Buffered allocation is also supported, but in that
case, the buffer-filling policy is worst-fit. Buffered and unbuffered
allocation can be used at the same time, but in that case, the first
ap must be created before any allocations.

@anchor{design/poolmvff design mps poolmvff over buffer class}@anchor{12e5}@ref{12e5,,.over.buffer.class;} The pool uses the simplest buffer class,
@code{BufferClass}. This is appropriate since these buffers don’t attach
to segments, and hence don’t constrain buffered regions to lie within
segment boundaries.

@node Methods<2>,Implementation<26>,Overview<29>,MVFF pool class
@anchor{design/poolmvff methods}@anchor{12e6}
@subsection Methods


@anchor{design/poolmvff design mps poolmvff method buffer}@anchor{12e7}@ref{12e7,,.method.buffer;} The buffer methods implement a worst-fit fill
strategy.

@node Implementation<26>,Details,Methods<2>,MVFF pool class
@anchor{design/poolmvff implementation}@anchor{12e8}
@subsection Implementation


@anchor{design/poolmvff design mps poolmvff impl alloc_list}@anchor{12e9}@ref{12e9,,.impl.alloc_list;} The pool stores the address ranges that it has
acquired from the arena in a CBS (see design.mps.cbs@footnote{cbs.html}).

@anchor{design/poolmvff design mps poolmvff impl free-list}@anchor{12ea}@ref{12ea,,.impl.free-list;} The pool stores its free list in a CBS (see
design.mps.cbs@footnote{cbs.html}), failing over in emergencies to a Freelist (see
design.mps.freelist@footnote{freelist.html}) when the CBS cannot allocate new control
structures. This is the reason for the alignment restriction above.

@node Details,,Implementation<26>,MVFF pool class
@anchor{design/poolmvff design-mps-freelist}@anchor{12eb}@anchor{design/poolmvff details}@anchor{12ec}
@subsection Details


@anchor{design/poolmvff design mps poolmvff design acquire-size}@anchor{12ed}@ref{12ed,,.design.acquire-size;} When acquiring memory from the arena, we use
@code{extendBy} as the unit of allocation unless the object won’t fit, in
which case we use the object size (in both cases we align up to the
arena alignment).

@anchor{design/poolmvff design mps poolmvff design acquire-fail}@anchor{12ee}@ref{12ee,,.design.acquire-fail;} If allocating @code{extendBy}, we try again with
an aligned size just large enough for the object we’re allocating.
This is in response to request.mps.170186@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/mps/170186}.

@geindex protocol inheritance; design

@node Protocol inheritance,POSIX thread extensions,MVFF pool class,Old design
@anchor{design/protocol doc}@anchor{12ef}@anchor{design/protocol design-protocol}@anchor{12f0}@anchor{design/protocol protocol-inheritance}@anchor{12f1}@anchor{design/protocol request-mps-170186}@anchor{12f2}
@section Protocol inheritance


@menu
* Introduction: Introduction<69>. 
* Purpose: Purpose<4>. 
* Requirements: Requirements<43>. 
* Overview: Overview<30>. 
* Interface: Interface<27>. 
* Implementation: Implementation<27>. 
* Common instance methods:: 
* References: References<23>. 

@end menu

@node Introduction<69>,Purpose<4>,,Protocol inheritance
@anchor{design/protocol design mps protocol}@anchor{12f3}@anchor{design/protocol introduction}@anchor{12f4}
@subsection Introduction


@anchor{design/protocol design mps protocol intro}@anchor{12f5}@ref{12f5,,.intro;} This document explains the design of the support for class
inheritance in MPS.

@anchor{design/protocol design mps protocol readership}@anchor{12f6}@ref{12f6,,.readership;} This document is intended for any MPS developer.

@node Purpose<4>,Requirements<43>,Introduction<69>,Protocol inheritance
@anchor{design/protocol purpose}@anchor{12f7}
@subsection Purpose


@anchor{design/protocol design mps protocol purpose code-maintain}@anchor{12f8}@ref{12f8,,.purpose.code-maintain;} The purpose of the protocol inheritance
design is to ensure that the MPS code base can make use of the
benefits of object-oriented class inheritance to maximize code reuse,
minimize code maintenance and minimize the use of boilerplate code.

@anchor{design/protocol design mps protocol purpose related}@anchor{12f9}@ref{12f9,,.purpose.related;} For related discussion, see
mail.tony.1998-08-28.16-26@footnote{https://info.ravenbrook.com/project/mps/mail/1998/08/28/16-26/0.txt}, mail.tony.1998-09-01.11-38@footnote{https://info.ravenbrook.com/project/mps/mail/1998/09/01/11-38/0.txt},
mail.tony.1998-10-06.11-03@footnote{https://info.ravenbrook.com/project/mps/mail/1998/10/06/11-03/0.txt} and other messages in the same threads.

@node Requirements<43>,Overview<30>,Purpose<4>,Protocol inheritance
@anchor{design/protocol mail-tony-1998-08-28-16-26}@anchor{12fa}@anchor{design/protocol requirements}@anchor{12fb}
@subsection Requirements


@anchor{design/protocol design mps protocol req implicit}@anchor{12fc}@ref{12fc,,.req.implicit;} The object system should provide a means for classes
to inherit the methods of their direct superclasses implicitly for all
functions in the protocol without having to write any explicit code
for each inherited function.

@anchor{design/protocol design mps protocol req override}@anchor{12fd}@ref{12fd,,.req.override;} There must additionally be a way for classes to
override the methods of their superclasses.

@anchor{design/protocol design mps protocol req next-method}@anchor{12fe}@ref{12fe,,.req.next-method;} As a result of @ref{12fc,,.req.implicit}, classes cannot
make static assumptions about methods used by direct superclasses. The
object system must provide a means for classes to extend (not just
replace) the behaviour of protocol functions, such as a mechanism for
invoking the “next-method”.

@anchor{design/protocol design mps protocol req ideal extend}@anchor{12ff}@ref{12ff,,.req.ideal.extend;} The object system must provide a standard way
for classes to implement the protocol supported by their superclass and
additionally add new methods of their own which can be specialized by
subclasses.

@anchor{design/protocol design mps protocol req ideal multiple-inheritance}@anchor{1300}@ref{1300,,.req.ideal.multiple-inheritance;} The object system should support
multiple inheritance such that sub-protocols can be “mixed in” with
several classes which do not themselves support identical protocols.

@node Overview<30>,Interface<27>,Requirements<43>,Protocol inheritance
@anchor{design/protocol overview}@anchor{1301}
@subsection Overview


@anchor{design/protocol design mps protocol overview inst}@anchor{1302}@ref{1302,,.overview.inst;} The key concept in the design is the relationship
between an “instance” and its “class”.  Every structure that
participates in the protocol system begins with an @code{InstStruct}
structure that contains a pointer to an @code{InstClassStruct} that
describes it, like this:

@example
 instance          class

.----------.      .----------.
|  class   |----->|  class   |
------------      ------------
|  ...     |      |  sig     |
------------      ------------
|  ...     |      |  name    |
------------      ------------
|  ...     |      |superclass|
------------      ------------
|          |      |   ...    |
@end example

@anchor{design/protocol design mps protocol overview prefix}@anchor{1303}@ref{1303,,.overview.prefix;} We make use of the fact that we can cast between
structures with common prefixes, or between structures and their first
members, to provide dynamic typing and subtyping (see
@ref{1304,,[Kernighan_1988]}, A.8.3).

@anchor{design/protocol design mps protocol overview method}@anchor{1305}@ref{1305,,.overview.method;} The @code{InstClassStruct} it itself at the start of
a class structure contains pointers to functions that can be called to
manipulate the instance as an abstract data type.  We refer to these
functions as “methods” to distinguish them from functions not involved
in the object-oriented protocol.  The macro @code{Method} is provided for
calling methods.

@anchor{design/protocol design mps protocol overview subclass}@anchor{1306}@ref{1306,,.overview.subclass;} An instance structure can be extended by using
it as the first field of another structure, and by overriding its
class pointer with a pointer to a “subclass” that provides different
behavior.

@anchor{design/protocol design mps protocol overview inherit}@anchor{1307}@ref{1307,,.overview.inherit;} Classes inherit the methods from their
superclasses when they are initialized, so by default they have the
same methods as the class from which they inherit.  Methods on the
superclass can be re-used, providing polymorphism.

@anchor{design/protocol design mps protocol overview inherit specialize}@anchor{1308}@ref{1308,,.overview.inherit.specialize;} Classes may specialize the behaviour
of their superclass. They do this by by overriding methods or other
fields in the class object.

@anchor{design/protocol design mps protocol overview mixin}@anchor{1309}@ref{1309,,.overview.mixin;} Groups of related overrides are provided by
“mixins”, and this provides a limited form of multiple inheritance.

@anchor{design/protocol design mps protocol overview extend}@anchor{130a}@ref{130a,,.overview.extend;} Classes may extend the protocols supported by
their superclasses by adding new fields for methods or other data.
Extending a class creates a new kind of class.

@anchor{design/protocol design mps protocol overview kind}@anchor{130b}@ref{130b,,.overview.kind;} Classes are themselves instance objects, and have
classes of their own.  A class of a class is referred to as a “kind”,
but is not otherwise special.  Classes which share the same set of
methods (or other class fields) are instances of the same kind.  If a
class is extended, it becomes a member of a different kind.  Kinds
allow subtype checking to be applied to classes as well as instances,
to determine whether methods are available.

@example
 instance          class             kind
 (e.g. CBS)        (e.g. CBSClass)   (e.g. LandClassClass)
.----------.      .----------.      .----------.
|  class   |----->|  class   |----->|  class   |-->InstClassClass
------------      ------------      ------------
|  ...     |      |  sig     |      |  sig     |
------------      ------------      ------------
|  ...     |      |  name    |      |  name    |
------------      ------------      ------------
|  ...     |      |superclass|-.    |superclass|-->InstClassClass
------------      ------------ |    ------------
|          |      |   ...    | |    |   ...    |
                               |
                               |
                    LandClass<-'
@end example

@anchor{design/protocol design mps protocol overview sig inherit}@anchor{130c}@ref{130c,,.overview.sig.inherit;} Instances (and therefore classes) will
contain signatures. Classes must not specialize (override) the
signatures they inherit from their superclasses, as they are used to
check the actual type (not sub- or supertype) of the object they’re
in.

@anchor{design/protocol design mps protocol overview sig extend}@anchor{130d}@ref{130d,,.overview.sig.extend;} When extending an instance or class, it is
normal policy for the new structure to include a new signature as the
last field.

@anchor{design/protocol design mps protocol overview superclass}@anchor{130e}@ref{130e,,.overview.superclass;} Each class contains a @code{superclass} field.
This enables classes to call “next-method”.

@anchor{design/protocol design mps protocol overview next-method}@anchor{130f}@ref{130f,,.overview.next-method;} A specialized method in a class can make use
of an overridden method from a superclass using the @ref{791,,NextMethod}
macro, statically naming the superclass.

@anchor{design/protocol design mps protocol overview next-method dynamic}@anchor{1310}@ref{1310,,.overview.next-method.dynamic;} It is possible to write a method
which does not statically know its superclass, and call the next
method by extracting a class from one of its arguments using
@code{ClassOfPoly} and finding the superclass using @code{SuperclassPoly}.
Debug pool mixins do this.  However, this is not fully general, and
combining such methods is likely to cause infinite recursion.  Take
care!

@anchor{design/protocol design mps protocol overview access}@anchor{1311}@ref{1311,,.overview.access;} Classes must be initialized by calls to
functions, since there is no way to express overrides statically in
C89.  @ref{1312,,DEFINE_CLASS} defines an “ensure” function that initializes
and returns the canonical copy of the class. The canonical copy may
reside in static storage, but no MPS code may refer to that static
storage by name.

@anchor{design/protocol design mps protocol overview init}@anchor{1313}@ref{1313,,.overview.init;} In addition to the “ensure” function, each class
must provide an “init” function, which initialises its argument as a
fresh copy of the class.  This allows subclasses to derive their
methods and other fields from superclasses.

@anchor{design/protocol design mps protocol overview naming}@anchor{1314}@ref{1314,,.overview.naming;} There are some strict naming conventions which
must be followed when defining and using classes. The use is
obligatory because it is assumed by the macros which support the
definition and inheritance mechanism. For every kind @code{Foo},
we insist upon the following naming conventions:


@itemize *

@item 
@code{Foo} names a type that points to a @code{FooStruct}.

@item 
@code{FooStruct} is the type of the instance structure, the first field
of which is the structure it inherits from (ultimately an
@code{InstStruct}).

@item 
@code{FooClass} names the type that points to a @code{FooClassStruct}.

@item 
@code{FooClassStruct} names the structure for the class pointed to by
@code{FooStruct}, containing the methods that operate on @code{Foo}.
@end itemize

@node Interface<27>,Implementation<27>,Overview<30>,Protocol inheritance
@anchor{design/protocol interface}@anchor{1315}
@subsection Interface


@menu
* Class declaration:: 
* Class definition:: 
* Class access:: 
* Single inheritance:: 
* Specialization:: 
* Extension:: 
* Methods: Methods<3>. 
* Conversion:: 
* Introspection:: 
* Protocol guidelines:: 
* Example: Example<3>. 

@end menu

@node Class declaration,Class definition,,Interface<27>
@anchor{design/protocol class-declaration}@anchor{1316}
@subsubsection Class declaration


@geindex DECLARE_CLASS (C macro)
@anchor{design/protocol c DECLARE_CLASS}@anchor{1317}
@deffn {C Macro} DECLARE_CLASS (kind, className)
@end deffn

@anchor{design/protocol design mps protocol if declare-class}@anchor{1318}@ref{1318,,.if.declare-class;} Class declaration is performed by the macro
@ref{1317,,DECLARE_CLASS}, which declares the existence of the class
definition elsewhere.  It is intended for use in headers.

@node Class definition,Class access,Class declaration,Interface<27>
@anchor{design/protocol class-definition}@anchor{1319}
@subsubsection Class definition


@geindex DEFINE_CLASS (C macro)
@anchor{design/protocol c DEFINE_CLASS}@anchor{1312}
@deffn {C Macro} DEFINE_CLASS (kind, className, var)
@end deffn

@anchor{design/protocol design mps protocol if define-class}@anchor{131a}@ref{131a,,.if.define-class;} Class definition is performed by the macro
@ref{1312,,DEFINE_CLASS}. A call to the macro must be followed by a function
body of initialization code. The parameter @code{className} is used to
name the class being defined. The parameter @code{var} is used to name a
local variable of type of classes of kind @code{kind}, which is defined
by the macro; it refers to the canonical storage for the class being
defined.  This variable may be used in the initialization code. (The
macro doesn’t just pick a name implicitly because of the danger of a
name clash with other names used by the programmer). A call to the
macro defines the ensure function for the class along with some static
storage for the canonical class object, and some other things to
ensure the class gets initialized at most once.

@node Class access,Single inheritance,Class definition,Interface<27>
@anchor{design/protocol class-access}@anchor{131b}
@subsubsection Class access


@geindex CLASS (C macro)
@anchor{design/protocol c CLASS}@anchor{780}
@deffn {C Macro} CLASS (className)
@end deffn

@anchor{design/protocol design mps protocol if class}@anchor{131c}@ref{131c,,.if.class;} To get the canonical class object, use the @ref{780,,CLASS}
macro, e.g. @code{CLASS(Land)}.

@node Single inheritance,Specialization,Class access,Interface<27>
@anchor{design/protocol single-inheritance}@anchor{131d}
@subsubsection Single inheritance


@geindex INHERIT_CLASS (C macro)
@anchor{design/protocol c INHERIT_CLASS}@anchor{131e}
@deffn {C Macro} INHERIT_CLASS (this, className, parentName)
@end deffn

@anchor{design/protocol design mps protocol if inheritance}@anchor{131f}@ref{131f,,.if.inheritance;} Class inheritance details must be provided in the
class initialization code (see @ref{131a,,.if.define-class}). Inheritance is
performed by the macro @ref{131e,,INHERIT_CLASS}. A call to this macro will
make the class being defined a direct subclass of @code{parentClassName}
by ensuring that all the fields of the embedded parent class (pointed
to by the @code{this} argument) are initialized as the parent class, and
setting the superclass field of @code{this} to be the canonical parent
class object. The parameter @code{this} must be the same kind as
@code{parentClassName}.

@node Specialization,Extension,Single inheritance,Interface<27>
@anchor{design/protocol specialization}@anchor{1320}
@subsubsection Specialization


@anchor{design/protocol design mps protocol if specialize}@anchor{1321}@ref{1321,,.if.specialize;} Fields in the class structure must be assigned
explicitly in the class initialization code (see
@ref{131a,,.if.define-class}). This must happen `after' inheritance details
are given (see @ref{131f,,.if.inheritance}), so that overrides work.

@node Extension,Methods<3>,Specialization,Interface<27>
@anchor{design/protocol extension}@anchor{1322}
@subsubsection Extension


@anchor{design/protocol design mps protocol if extend}@anchor{1323}@ref{1323,,.if.extend;} To extend the protocol when defining a new class, a
new type must be defined for the class structure. This must embed the
structure for the primarily inherited class as the first field of the
structure. Extension fields in the class structure must be assigned
explicitly in the class initialization code (see
@ref{131a,,.if.define-class}).  This should be done `after' the inheritance
details are given for consistency with @ref{131f,,.if.inheritance}.  This is,
in fact, how all the useful classes extend @code{Inst}.

@anchor{design/protocol design mps protocol if extend kind}@anchor{1324}@ref{1324,,.if.extend.kind;} In addition, a class must be defined for the new
kind of class.  This is just an unspecialized subclass of the kind of
the class being specialized by the extension.  For example:

@example
typedef struct LandClassStruct @{
  InstClassStruct instClass;  /* inherited class */
  LandInsertMethod insert;
  ...
@} LandClassStruct;

DEFINE_CLASS(Inst, LandClass, class)
@{
  INHERIT_CLASS(class, LandClass, InstClass);
@}

DEFINE_CLASS(Land, Land, class)
@{
  INHERIT_CLASS(&class->instClass, Land, Inst);
  class->insert = landInsert;
  ...
@}
@end example

@node Methods<3>,Conversion,Extension,Interface<27>
@anchor{design/protocol methods}@anchor{1325}
@subsubsection Methods


@geindex Method (C macro)
@anchor{design/protocol c Method}@anchor{1326}
@deffn {C Macro} Method (kind, inst, meth)
@end deffn

@anchor{design/protocol design mps protocol if method}@anchor{1327}@ref{1327,,.if.method;} To call a method on an instance of a class, use the
@code{Method} macro to retrieve the method.  This macro may assert if the
class is not of the kind requested.  For example, to call the
@code{insert} method on @code{land}:

@example
res = Method(Land, land, insert)(rangeReturn, land, range);
@end example

@geindex NextMethod (C macro)
@anchor{design/protocol c NextMethod}@anchor{791}
@deffn {C Macro} NextMethod (kind, className, meth)
@end deffn

@anchor{design/protocol design mps protocol if next-method}@anchor{1328}@ref{1328,,.if.next-method;} To call a method from a superclass of a class,
use the @ref{791,,NextMethod} macro to retrieve the method.  This macro may
assert if the superclass is not of the kind requested.  For example,
the function to split AMS segments wants to split the segments they
are based on, so does:

@example
res = NextMethod(Seg, AMSSeg, split)(seg, segHi, base, mid, limit);
@end example

@node Conversion,Introspection,Methods<3>,Interface<27>
@anchor{design/protocol conversion}@anchor{1329}
@subsubsection Conversion


@geindex IsA (C macro)
@anchor{design/protocol c IsA}@anchor{132a}
@deffn {C Macro} IsA (className, inst)
@end deffn

@anchor{design/protocol if-isa}@anchor{132b}if.isa: Returns non-zero iff the class of @code{inst} is a member of
the class or any of its subclasses.

@geindex MustBeA (C macro)
@anchor{design/protocol c MustBeA}@anchor{132c}
@deffn {C Macro} MustBeA (className, inst)
@end deffn

@anchor{design/protocol design mps protocol if must-be-a}@anchor{132d}@ref{132d,,.if.must-be-a;} To convert the C type of an instance to that of a
compatible class (the class of the actual object or any superclass),
use the @code{MustBeA} macro.  In hot varieties this macro performs a
fast dynamic type check and will assert if the class is not
compatible.  It is like C++ “dynamic_cast” with an assert.  In cool
varieties, the class check method is called on the object.  For
example, in a specialized Land method in the CBS class:

@example
static Res cbsInsert(Range rangeReturn, Land land, Range range)
@{
  CBS cbs = MustBeA(CBS, land);
  ...
@end example

@geindex MustBeA_CRITICAL (C macro)
@anchor{design/protocol c MustBeA_CRITICAL}@anchor{132e}
@deffn {C Macro} MustBeA_CRITICAL (className, inst)
@end deffn

@anchor{design/protocol design mps protocol if must-be-a critical}@anchor{132f}@ref{132f,,.if.must-be-a.critical;} When the cost of a type check is too
expensive in hot varieties, use @code{MustBeA_CRITICAL} in place of
@code{MustBeA}.  This only performs the check in cool varieties.  Compare
with @code{AVER_CRITICAL}.

@geindex CouldBeA (C macro)
@anchor{design/protocol c CouldBeA}@anchor{1330}
@deffn {C Macro} CouldBeA (className, inst)
@end deffn

@anchor{design/protocol design mps protocol if could-be-a}@anchor{1331}@ref{1331,,.if.could-be-a;} To make an unsafe conversion equivalent to
@code{MustBeA}, use the @code{CouldBeA} macro.  This is in effect a simple
pointer cast, but it expresses the intention of class compatibility in
the source code.  It is mainly intended for use when initializing an
object, when a class compatibility check would fail, when checking an
object, or in debugging code such as describe methods, where asserting
is inappropriate.  It is intended to be equivalent to the C++
@code{static_cast}, although since this is C there is no actual static
checking, so in fact it’s more like @code{reinterpret_cast}.

@node Introspection,Protocol guidelines,Conversion,Interface<27>
@anchor{design/protocol introspection}@anchor{1332}
@subsubsection Introspection


@anchor{design/protocol design mps protocol introspect c-lang}@anchor{1333}@ref{1333,,.introspect.c-lang;} The design includes a number of introspection
functions for dynamically examining class relationships. These
functions are polymorphic and accept arbitrary subclasses of
@code{InstClass}. C doesn’t support such polymorphism. So although these
have the semantics of functions (and could be implemented as functions
in another language with compatible calling conventions) they are
actually implemented as macros. The macros are named as function-style
macros despite the fact that this arguably contravenes
guide.impl.c.macro.method. The justification for this is that this
design is intended to promote the use of polymorphism, and it breaks
the abstraction for the users to need to be aware of what can and
can’t be expressed directly in C function syntax. These functions all
have names ending in @code{Poly} to identify them as polymorphic
functions.

@geindex SuperclassPoly (C macro)
@anchor{design/protocol c SuperclassPoly}@anchor{1334}
@deffn {C Macro} SuperclassPoly (kind, class)
@end deffn

@anchor{design/protocol design mps protocol if superclass-poly}@anchor{1335}@ref{1335,,.if.superclass-poly;} An introspection function which returns the
direct superclass of class object @code{class} as a class of kind
@code{kind}. This may assert if the superclass is not (a subtype of) the
kind requested.

@geindex ClassOfPoly (C macro)
@anchor{design/protocol c ClassOfPoly}@anchor{1336}
@deffn {C Macro} ClassOfPoly (kind, inst)
@end deffn

@anchor{design/protocol design mps protocol if class-of-poly}@anchor{1337}@ref{1337,,.if.class-of-poly;} An introspection function which returns the
class of which @code{inst} is a direct instance, as a class of kind
@code{kind}. This may assert if the class is not (a subtype of) the kind
requested.

@geindex SetClassOfPoly (C macro)
@anchor{design/protocol c SetClassOfPoly}@anchor{1338}
@deffn {C Macro} SetClassOfPoly (inst, class)
@end deffn

@anchor{design/protocol design mps protocol if set-class-of-poly}@anchor{1339}@ref{1339,,.if.set-class-of-poly;} An initialization function that sets the
class of @code{inst} to be @code{class}. This is intended only for use in
initialization functions, to specialize the instance once its fields
have been initialized. Each Init function should call its superclass
init, finally reaching InstInit, and then, once it has set up its
fields, use SetClassOfPoly to set the class and check the instance
with its check method. Compare with design.mps.sig@footnote{sig}.

@geindex IsSubclass (C macro)
@anchor{design/protocol c IsSubclass}@anchor{133a}
@deffn {C Macro} IsSubclass (sub, super)
@end deffn

@anchor{design/protocol design mps protocol if is-subclass}@anchor{133b}@ref{133b,,.if.is-subclass;} An introspection function which returns a @ref{3a9,,Bool}
indicating whether @code{sub} is a subclass of @code{super}. That is, it is
a predicate for testing subclass relationships.

@node Protocol guidelines,Example<3>,Introspection,Interface<27>
@anchor{design/protocol protocol-guidelines}@anchor{133c}
@subsubsection Protocol guidelines


@anchor{design/protocol design mps protocol guide fail}@anchor{133d}@ref{133d,,.guide.fail;} When designing an extensible method which might fail,
the design must permit the correct implementation of the failure-case
code.  Typically, a failure might occur in any method in the chain.
Each method is responsible for correctly propagating failure
information supplied by superclass methods and for managing it’s own
failures.  This is not really different from the general MPS
convention for unwinding on error paths.  It implies that the design
of a class must include an anti-method for each method that changes
the state of an instance (e.g. by allocating memory) to allow the
state to be reverted in case of a failure.  See @ref{133e,,.example.fail}
below.

@node Example<3>,,Protocol guidelines,Interface<27>
@anchor{design/protocol example}@anchor{133f}
@subsubsection Example


@anchor{design/protocol design mps protocol example inheritance}@anchor{1340}@ref{1340,,.example.inheritance;} The following example class definition shows
both inheritance and specialization. It shows the definition of the
class @code{RankBuf}, which inherits from @code{SegBuf} of kind @ref{b53,,Seg}
and has specialized @code{varargs} and @code{init} method.

@example
DEFINE_CLASS(Buffer, RankBuf, class)
@{
  INHERIT_CLASS(class, RankBuf, SegBuf);
  class->varargs = rankBufVarargs;
  class->init = rankBufInit;
@}
@end example

@anchor{design/protocol design mps protocol example extension}@anchor{1341}@ref{1341,,.example.extension;} The following (hypothetical) example class
definition shows inheritance, specialization and also extension. It
shows the definition of the class @code{EPDLDebugPool}, which inherits
from @code{EPDLPool} of kind @code{Pool}, but also implements a method for
checking properties of the pool.

@example
typedef struct EPDLDebugPoolClassStruct @{
  EPDLPoolClassStruct epdl;
  DebugPoolCheckMethod check;
  Sig sig;
@} EPDLDebugPoolClassStruct;

typedef EPDLDebugPoolClassStruct *EPDLDebugPoolClass;

DEFINE_CLASS(Inst, EPDLDebugPoolClass, class)
@{
  INHERIT_CLASS(class, EPDLPoolClass, InstClass);
@}

DEFINE_CLASS(EPDLDebugPool, EPDLDebugPool, class)
@{
  INHERIT_CLASS(&class->epdl, EPDLDebugPool, EPDLPoolClass);
  class->check = EPDLDebugCheck;
  class->sig = EPDLDebugSig;
@}
@end example

@anchor{design/protocol design mps protocol example fail}@anchor{133e}@ref{133e,,.example.fail;} The following example shows the implementation of
failure-case code for an “init” method, making use of the “finish”
anti-method to clean-up a subsequent failure.

@example
static Res AMSSegInit(Seg seg, Pool pool,
                      Addr base, Size size,
                      ArgList args)
@{
  AMS ams = MustBeA(AMSPool, pool);
  Arena arena = PoolArena(pool);
  AMSSeg amsseg;
  Res res;

  /* Initialize the superclass fields first via next-method call */
  res = NextMethod(Seg, AMSSeg, init)(seg, pool, base, size, args);
  if (res != ResOK)
    goto failNextMethod;
  amsseg = CouldBeA(AMSSeg, seg);

  amsseg->grains = size >> ams->grainShift;
  amsseg->freeGrains = amsseg->grains;
  amsseg->oldGrains = (Count)0;
  amsseg->newGrains = (Count)0;
  amsseg->marksChanged = FALSE; /* <design/poolams/#marked.unused> */
  amsseg->ambiguousFixes = FALSE;

  res = amsCreateTables(ams, &amsseg->allocTable,
                        &amsseg->nongreyTable, &amsseg->nonwhiteTable,
                        arena, amsseg->grains);
  if (res != ResOK)
    goto failCreateTables;

  /* start off using firstFree, see <design/poolams/#no-bit> */
  amsseg->allocTableInUse = FALSE;
  amsseg->firstFree = 0;
  amsseg->colourTablesInUse = FALSE;

  amsseg->ams = ams;
  RingInit(&amsseg->segRing);
  RingAppend((ams->allocRing)(ams, SegRankSet(seg), size),
             &amsseg->segRing);

  SetClassOfPoly(seg, CLASS(AMSSeg));
  amsseg->sig = AMSSegSig;
  AVERC(AMSSeg, amsseg);

  return ResOK;

failCreateTables:
  NextMethod(Seg, AMSSeg, finish)(seg);
failNextMethod:
  AVER(res != ResOK);
  return res;
@}
@end example

@node Implementation<27>,Common instance methods,Interface<27>,Protocol inheritance
@anchor{design/protocol implementation}@anchor{1342}
@subsection Implementation


@anchor{design/protocol design mps protocol impl define-class lock}@anchor{1343}@ref{1343,,.impl.define-class.lock;} The @ref{1312,,DEFINE_CLASS} macro ensures that
each class is initialized at most once (even in multi-threaded
programs) by claiming the global recursive lock (see design.mps.thread-safety.arch.global.recursive@footnote{thread-safety.html#design.mps.thread-safety.arch.global.recursive}).

@anchor{design/protocol design mps protocol impl derived-names}@anchor{1344}@ref{1344,,.impl.derived-names;} The @ref{1312,,DEFINE_CLASS()} macro derives some
additional names from the class name as part of it’s implementation.
These should not appear in the source code, but it may be useful to
know about this for debugging purposes. For each class definition for
class @code{SomeClass} of kind @code{SomeKind}, the macro defines the
following:


@itemize *

@item 
@code{extern SomeKind SomeClassGet(void);}

The class ensure function. See @ref{1314,,.overview.naming}.  This function
handles local static storage for the canonical class object and a
guardian to ensure the storage is initialized at most once.  This
function is invoked by the @ref{780,,CLASS} macro (@ref{131c,,.if.class}).

@item 
@code{static void SomeClassInit(SomeKind);}

A function called by @code{SomeClassGet()}. All the class
initialization code is actually in this function.
@end itemize

@anchor{design/protocol design mps protocol impl subclass}@anchor{1345}@ref{1345,,.impl.subclass;} The subclass test @ref{133b,,.if.is-subclass} is implemented
using an array of superclasses @ref{1346,,[Cohen_1991]} giving a fast
constant-time test.  (RB@footnote{https://www.ravenbrook.com/consultants/rb/} tried an approach using prime factors
@ref{1347,,[Gibbs_2004]} but found that they overflowed in 32-bits too easily to
be useful.)  Each class is assigned a “level” which is the distance
from the root of the class hierarchy.  The @code{InstClass} structure
contains an array of class ids indexed by level, representing the
inheritance of this class.  A class is a subclass of another if and
only if the superclass id is present in the array at the superclass
level.  The level is statically defined using enum constants, and the
id is the address of the canonical class object, so the test is fast
and simple.

@node Common instance methods,References<23>,Implementation<27>,Protocol inheritance
@anchor{design/protocol common-instance-methods}@anchor{1348}@anchor{design/protocol rb}@anchor{1349}
@subsection Common instance methods


@anchor{design/protocol design mps protocol method}@anchor{134a}@ref{134a,,.method;} These methods are available on all instances.

@geindex FinishMethod (C type)
@anchor{design/protocol c FinishMethod}@anchor{134b}
@deffn {C Type} typedef void (*FinishMethod)(Inst inst)
@end deffn

@anchor{design/protocol design mps protocol method finish}@anchor{134c}@ref{134c,,.method.finish;} The @code{finish} method should finish the instance
data structure (releasing any resources that were acquired by the
instance during its lifetime) and then call its superclass method via
the @ref{791,,NextMethod()} macro.

@geindex DescribeMethod (C type)
@anchor{design/protocol c DescribeMethod}@anchor{134d}
@deffn {C Type} typedef @ref{55f,,Res} (*DescribeMethod)(Inst inst, @ref{2d3,,mps_lib_FILE} *stream, @ref{3af,,Count} depth)
@end deffn

@anchor{design/protocol design mps protocol method describe}@anchor{134e}@ref{134e,,.method.describe;} The @code{describe} field should print out a
description of the instance to @code{stream} (by calling @ref{446,,WriteF()}).

@node References<23>,,Common instance methods,Protocol inheritance
@anchor{design/protocol references}@anchor{134f}
@subsection References


@anchor{design/protocol cohen-1991}@anchor{1346}@w{(Cohen_1991)} 
“Type-Extension Type Tests Can Be Performed In Constant Time”; Norman H Cohen; IBM Thomas J Watson Research Center; ACM Transactions on Programming Languages and Systems, Vol. 13 No. 4, pp. 626-629; 1991-10.

@anchor{design/protocol gibbs-2004}@anchor{1347}@w{(Gibbs_2004)} 
Michael Gibbs, Bjarne Stroustrup. 2004. “Fast Dynamic Casting@footnote{http://www.stroustrup.com/fast_dynamic_casting.pdf}”.

@anchor{design/protocol kernighan-1988}@anchor{1304}@w{(Kernighan_1988)} 
Brian W. Kernighan, Dennis M. Ritchie. 1988. “The C Programming language 2nd Edition”.

@geindex POSIX thread extensions; design

@node POSIX thread extensions,Root manager,Protocol inheritance,Old design
@anchor{design/pthreadext doc}@anchor{1350}@anchor{design/pthreadext design-pthreadext}@anchor{1351}@anchor{design/pthreadext posix-thread-extensions}@anchor{1352}
@section POSIX thread extensions


@menu
* Introduction: Introduction<70>. 
* Definitions: Definitions<14>. 
* Requirements: Requirements<44>. 
* Analysis: Analysis<6>. 
* Interface: Interface<28>. 
* Implementation: Implementation<28>. 
* Attachments: Attachments<2>. 
* References: References<24>. 

@end menu

@node Introduction<70>,Definitions<14>,,POSIX thread extensions
@anchor{design/pthreadext design mps pthreadext}@anchor{1353}@anchor{design/pthreadext introduction}@anchor{1354}
@subsection Introduction


@anchor{design/pthreadext design mps pthreadext readership}@anchor{1355}@ref{1355,,.readership;} Any MPS developer.

@anchor{design/pthreadext design mps pthreadext intro}@anchor{1356}@ref{1356,,.intro;} This is the design of the Pthreads extension module, which
provides some low-level threads support for use by MPS (notably
suspend and resume).

@node Definitions<14>,Requirements<44>,Introduction<70>,POSIX thread extensions
@anchor{design/pthreadext definitions}@anchor{1357}
@subsection Definitions


@anchor{design/pthreadext design mps pthreadext pthreads}@anchor{1358}@ref{1358,,.pthreads;} The term “Pthreads” means an implementation of the POSIX
1003.1c-1995 thread standard. (Or the Single UNIX Specification,
Version 2, aka USV2 or UNIX98.)

@anchor{design/pthreadext design mps pthreadext context}@anchor{1359}@ref{1359,,.context;} The “context” of a thread is a (platform-specific)
OS-defined structure which describes the current state of the
registers for that thread.

@node Requirements<44>,Analysis<6>,Definitions<14>,POSIX thread extensions
@anchor{design/pthreadext requirements}@anchor{135a}
@subsection Requirements


@anchor{design/pthreadext design mps pthreadext req suspend}@anchor{135b}@ref{135b,,.req.suspend;} A means to suspend threads, so that they don’t make
any progress.

@anchor{design/pthreadext design mps pthreadext req suspend why}@anchor{135c}@ref{135c,,.req.suspend.why;} Needed by the thread manager so that other
threads registered with an arena can be suspended (see
design.mps.thread-manager@footnote{thread-manager.html}). Not directly provided by Pthreads.

@anchor{design/pthreadext design mps pthreadext req resume}@anchor{135d}@ref{135d,,.req.resume;} A means to resume suspended threads, so that they are
able to make progress again. @anchor{design/pthreadext design mps pthreadext req resume why}@anchor{135e}@ref{135e,,.req.resume.why;} Needed by the thread
manager. Not directly provided by Pthreads.

@anchor{design/pthreadext design mps pthreadext req suspend multiple}@anchor{135f}@ref{135f,,.req.suspend.multiple;} Allow a thread to be suspended on behalf of
one arena when it has already been suspended on behalf of one or more
other arenas. @anchor{design/pthreadext design mps pthreadext req suspend multiple why}@anchor{1360}@ref{1360,,.req.suspend.multiple.why;} The thread manager
contains no design for cooperation between arenas to prevent this.

@anchor{design/pthreadext design mps pthreadext req resume multiple}@anchor{1361}@ref{1361,,.req.resume.multiple;} Allow requests to resume a thread on behalf
of each arena which had previously suspended the thread. The thread
must only be resumed when requests from all such arenas have been
received. @anchor{design/pthreadext design mps pthreadext req resume multiple why}@anchor{1362}@ref{1362,,.req.resume.multiple.why;} A thread manager for an arena
must not permit a thread to make progress before it explicitly resumes
the thread.

@anchor{design/pthreadext design mps pthreadext req suspend context}@anchor{1363}@ref{1363,,.req.suspend.context;} Must be able to access the context for a
thread when it is suspended.

@anchor{design/pthreadext design mps pthreadext req suspend protection}@anchor{1364}@ref{1364,,.req.suspend.protection;} Must be able to suspend a thread which is
currently handling a protection fault (i.e., an arena access). Such a
thread might even own an arena lock.

@anchor{design/pthreadext design mps pthreadext req legal}@anchor{1365}@ref{1365,,.req.legal;} Must use the Pthreads and other POSIX APIs in a legal
manner.

@node Analysis<6>,Interface<28>,Requirements<44>,POSIX thread extensions
@anchor{design/pthreadext analysis}@anchor{1366}
@subsection Analysis


@anchor{design/pthreadext design mps pthreadext analysis suspend}@anchor{1367}@ref{1367,,.analysis.suspend;} Thread suspension is inherently asynchronous. MPS
needs to be able to suspend another thread without prior knowledge of
the code that thread is running. (That is, we can’t rely on
cooperation between threads.) The only asynchronous communication
available on POSIX is via signals – so the suspend and resume
mechanism must ultimately be built from signals.

@anchor{design/pthreadext design mps pthreadext analysis signal safety}@anchor{1368}@ref{1368,,.analysis.signal.safety;} POSIX imposes some restrictions on what a
signal handler function might do when invoked asynchronously (see the
sigaction@footnote{https://pubs.opengroup.org/onlinepubs/007908799/xsh/sigaction.html} documentation, and search for the string “reentrant”). In
summary, a small number of POSIX functions are defined to be
“async-signal safe”, which means they may be invoked without
restriction in signal handlers. All other POSIX functions are
considered to be unsafe. Behaviour is undefined if an unsafe function
is interrupted by a signal and the signal handler then proceeds to
call another unsafe function. See mail.tony.1999-08-24.15-40@footnote{https://info.ravenbrook.com/project/mps/mail/1999/08/24/15-40/0.txt} and
followups for some further analysis.

@anchor{design/pthreadext design mps pthreadext analysis signal safety implication}@anchor{1369}@ref{1369,,.analysis.signal.safety.implication;} Since we can’t assume that we
won’t attempt to suspend a thread while it is running an unsafe
function, we must limit the use of POSIX functions in the suspend
signal handler to those which are designed to be “async-signal safe”.
One of the few such functions related to synchronization is
@code{sem_post()}.

@anchor{design/pthreadext design mps pthreadext analysis signal example}@anchor{136a}@ref{136a,,.analysis.signal.example;} An example of how to suspend threads in POSIX
was posted to newsgroup comp.programming.threads in August 1999
@ref{136b,,[Lau_1999-08-16]}. The code in the post was written by David Butenhof, who
contributed some comments on his implementation @ref{136c,,[Butenhof_1999-08-16]}

@anchor{design/pthreadext design mps pthreadext analysis signal linux-hack}@anchor{136d}@ref{136d,,.analysis.signal.linux-hack;} In the current implementation of Linux
Pthreads, it would be possible to implement suspend/resume using
@code{SIGSTOP} and @code{SIGCONT}. This is, however, nonportable and will
probably stop working on Linux at some point.

@anchor{design/pthreadext design mps pthreadext analysis component}@anchor{136e}@ref{136e,,.analysis.component;} There is no known way to meet the requirements
above in a way which cooperates with another component in the system
which also provides its own mechanism to suspend and resume threads.
The best bet for achieving this is to provide the functionality in
shared low-level component which may be used by MPS and other clients.
This will require some discussion with other potential clients and/or
standards bodies.

@anchor{design/pthreadext design mps pthreadext analysis component dylan}@anchor{136f}@ref{136f,,.analysis.component.dylan;} Note that such cooperation is actually a
requirement for Dylan (req.dylan.dc.env.self), though this is not a
problem, since all the Dylan components share the MPS mechanism.

@node Interface<28>,Implementation<28>,Analysis<6>,POSIX thread extensions
@anchor{design/pthreadext interface}@anchor{1370}
@subsection Interface


@geindex PThreadext (C type)
@anchor{design/pthreadext c PThreadext}@anchor{1371}
@deffn {C Type} typedef @ref{1372,,PThreadextStruct} *PThreadext
@end deffn

@anchor{design/pthreadext design mps pthreadext if pthreadext abstract}@anchor{1373}@ref{1373,,.if.pthreadext.abstract;} A thread is represented by the abstract
type @ref{1371,,PThreadext}. A @ref{1371,,PThreadext} object corresponds directly with
a thread (of type @code{pthread_t}). There may be more than one
@ref{1371,,PThreadext} object for the same thread.

@anchor{design/pthreadext design mps pthreadext if pthreadext structure}@anchor{1374}@ref{1374,,.if.pthreadext.structure;} The structure definition of
@ref{1371,,PThreadext} (@ref{1372,,PThreadextStruct}) is exposed by the interface so
that it may be embedded in a client datastructure (for example,
@code{ThreadStruct}). This means that all storage management can be left
to the client (which is important because there might be multiple
arenas involved). Clients may not access the fields of a
@ref{1372,,PThreadextStruct} directly.

@geindex PThreadextInit (C function)
@anchor{design/pthreadext c PThreadextInit}@anchor{1375}
@deffn {C Function} void PThreadextInit (PThreadext pthreadext, pthread_t id)
@end deffn

@anchor{design/pthreadext design mps pthreadext if init}@anchor{1376}@ref{1376,,.if.init;} Initializes a @ref{1371,,PThreadext} object for a thread with the
given @code{id}.

@geindex PThreadextCheck (C function)
@anchor{design/pthreadext c PThreadextCheck}@anchor{1377}
@deffn {C Function} @ref{3a9,,Bool} PThreadextCheck (PThreadext pthreadext)
@end deffn

@anchor{design/pthreadext design mps pthreadext if check}@anchor{1378}@ref{1378,,.if.check;} Checks a @ref{1371,,PThreadext} object for consistency. Note
that this function takes the mutex, so it must not be called with the
mutex held (doing so will probably deadlock the thread).

@geindex PThreadextSuspend (C function)
@anchor{design/pthreadext c PThreadextSuspend}@anchor{7dd}
@deffn {C Function} @ref{55f,,Res} PThreadextSuspend (PThreadext pthreadext, struct sigcontext **contextReturn)
@end deffn

@anchor{design/pthreadext design mps pthreadext if suspend}@anchor{1379}@ref{1379,,.if.suspend;} Suspends a @ref{1371,,PThreadext} object (puts it into a
suspended state). Meets @ref{135b,,.req.suspend}. The object must not already
be in a suspended state. If the function returns @code{ResOK}, the
context of the thread is returned in contextReturn, and the
corresponding thread will not make any progress until it is resumed.

@geindex PThreadextResume (C function)
@anchor{design/pthreadext c PThreadextResume}@anchor{a89}
@deffn {C Function} @ref{55f,,Res} PThreadextResume (PThreadext pthreadext)
@end deffn

@anchor{design/pthreadext design mps pthreadext if resume}@anchor{137a}@ref{137a,,.if.resume;} Resumes a @ref{1371,,PThreadext} object. Meets @ref{135d,,.req.resume}.
The object must already be in a suspended state. Puts the object into
a non-suspended state. Permits the corresponding thread to make
progress again, although that might not happen immediately if there is
another suspended @ref{1371,,PThreadext} object corresponding to the same
thread.

@geindex PThreadextFinish (C function)
@anchor{design/pthreadext c PThreadextFinish}@anchor{137b}
@deffn {C Function} void PThreadextFinish (PThreadext pthreadext)
@end deffn

@anchor{design/pthreadext design mps pthreadext if finish}@anchor{137c}@ref{137c,,.if.finish;} Finishes a PThreadext object.

@node Implementation<28>,Attachments<2>,Interface<28>,POSIX thread extensions
@anchor{design/pthreadext implementation}@anchor{137d}
@subsection Implementation


@geindex PThreadextStruct (C type)
@anchor{design/pthreadext c PThreadextStruct}@anchor{1372}
@deffn {C Type} typedef struct @ref{1372,,PThreadextStruct} PThreadextStruct
@end deffn

@anchor{design/pthreadext design mps pthreadext impl pthreadext}@anchor{137e}@ref{137e,,.impl.pthreadext;} The structure definition for a @ref{1371,,PThreadext}
object is:

@example
struct PThreadextStruct @{
  Sig sig;                         /* <design/sig/> */
  pthread_t id;                    /* Thread ID */
  MutatorContext context;          /* context if suspended */
  RingStruct threadRing;           /* ring of suspended threads */
  RingStruct idRing;               /* duplicate suspensions for id */
@};
@end example

@anchor{design/pthreadext design mps pthreadext impl field id}@anchor{137f}@ref{137f,,.impl.field.id;} The @code{id} field shows which PThread the object
corresponds to.

@anchor{design/pthreadext design mps pthreadext impl field context}@anchor{1380}@ref{1380,,.impl.field.context;} The @code{context} field contains the context
when in a suspended state. Otherwise it is @code{NULL}.

@anchor{design/pthreadext design mps pthreadext impl field threadring}@anchor{1381}@ref{1381,,.impl.field.threadring;} The @code{threadRing} field is used to chain
the object onto the suspend ring when it is in the suspended state
(see @ref{1382,,.impl.global.suspend-ring}). When not in a suspended state,
this ring is single.

@anchor{design/pthreadext design mps pthreadext impl field idring}@anchor{1383}@ref{1383,,.impl.field.idring;} The @code{idRing} field is used to group the
object with other objects corresponding to the same thread (same
@code{id} field) when they are in the suspended state. When not in a
suspended state, or when this is the only @ref{1371,,PThreadext} object with
this @code{id} in the suspended state, this ring is single.

@anchor{design/pthreadext design mps pthreadext impl global suspend-ring}@anchor{1382}@ref{1382,,.impl.global.suspend-ring;} The module maintains a global variable
@code{suspendedRing}, a ring of @ref{1371,,PThreadext} objects which are in a
suspended state. This is primarily so that it’s possible to determine
whether a thread is currently suspended anyway because of another
@ref{1371,,PThreadext} object, when a suspend attempt is made.

@anchor{design/pthreadext design mps pthreadext impl global victim}@anchor{1384}@ref{1384,,.impl.global.victim;} The module maintains a global variable
@code{suspendingVictim} which is used to indicate which @ref{1371,,PThreadext} is
the current victim during suspend operations. This is used to
communicate information between the controlling thread and the thread
being suspended (the victim). The variable has value @code{NULL} at other
times.

@anchor{design/pthreadext design mps pthreadext impl static mutex}@anchor{1385}@ref{1385,,.impl.static.mutex;} We use a lock (mutex) around the suspend and
resume operations. This protects the state data (the suspend-ring and
the victim: see @ref{1382,,.impl.global.suspend-ring} and
@ref{1384,,.impl.global.victim} respectively). Since only one thread can be
suspended at a time, there’s no possibility of two arenas suspending
each other by concurrently suspending each other’s threads.

@anchor{design/pthreadext design mps pthreadext impl static semaphore}@anchor{1386}@ref{1386,,.impl.static.semaphore;} We use a semaphore to synchronize between
the controlling and victim threads during the suspend operation. See
@ref{1387,,.impl.suspend} and @ref{1388,,.impl.suspend-handler}).

@anchor{design/pthreadext design mps pthreadext impl static init}@anchor{1389}@ref{1389,,.impl.static.init;} The static data and global variables of the
module are initialized on the first call to @ref{7dd,,PThreadextSuspend()},
using @code{pthread_once()} to avoid concurrency problems. We also enable
the signal handlers at the same time (see @ref{1388,,.impl.suspend-handler} and
@ref{138a,,.impl.resume-handler}).

@anchor{design/pthreadext design mps pthreadext impl suspend}@anchor{1387}@ref{1387,,.impl.suspend;} @ref{7dd,,PThreadextSuspend()} first ensures the module is
initialized (see @ref{1389,,.impl.static.init}). After this, it claims the
mutex (see @ref{1385,,.impl.static.mutex}). It then checks to see whether
thread of the target @ref{1371,,PThreadext} object has already been suspended
on behalf of another @ref{1371,,PThreadext} object. It does this by iterating
over the suspend ring.

@anchor{design/pthreadext design mps pthreadext impl suspend already-suspended}@anchor{138b}@ref{138b,,.impl.suspend.already-suspended;} If another object with the same id
is found on the suspend ring, then the thread is already suspended.
The context of the target object is updated from the other object, and
the other object is linked into the @code{idRing} of the target.

@anchor{design/pthreadext design mps pthreadext impl suspend not-suspended}@anchor{138c}@ref{138c,,.impl.suspend.not-suspended;} If the thread is not already
suspended, then we forcibly suspend it using a technique similar to
Butenhof’s (see @ref{136a,,.analysis.signal.example}): First we set the victim
variable (see @ref{1384,,.impl.global.victim}) to indicate the target object.
Then we send the signal @code{PTHREADEXT_SIGSUSPEND} to the thread (see
@ref{138d,,.impl.signals}), and wait on the semaphore for it to indicate that
it has received the signal and updated the victim variable with the
context. If either of these operations fail (for example, because of
thread termination) we unlock the mutex and return @code{ResFAIL}.

@anchor{design/pthreadext design mps pthreadext impl suspend update}@anchor{138e}@ref{138e,,.impl.suspend.update;} Once we have ensured that the thread is
definitely suspended, we add the target @ref{1371,,PThreadext} object to the
suspend ring, unlock the mutex, and return the context to the caller.

@anchor{design/pthreadext design mps pthreadext impl suspend-handler}@anchor{1388}@ref{1388,,.impl.suspend-handler;} The suspend signal handler is invoked in the
target thread during a suspend operation, when a
@code{PTHREADEXT_SIGSUSPEND} signal is sent by the controlling thread
(see @ref{138c,,.impl.suspend.not-suspended}). The handler determines the
context (received as a parameter, although this may be
platform-specific) and stores this in the victim object (see
@ref{1384,,.impl.global.victim}). The handler then masks out all signals except
the one that will be received on a resume operation
(@code{PTHREADEXT_SIGRESUME}) and synchronizes with the controlling
thread by posting the semaphore. Finally the handler suspends until
the resume signal is received, using @code{sigsuspend()}.

@anchor{design/pthreadext design mps pthreadext impl resume}@anchor{138f}@ref{138f,,.impl.resume;} @ref{a89,,PThreadextResume()} first claims the mutex (see
@ref{1385,,.impl.static.mutex}). It then checks to see whether thread of the
target @ref{1371,,PThreadext} object has also been suspended on behalf of
another @ref{1371,,PThreadext} object (in which case the id ring of the target
object will not be single).

@anchor{design/pthreadext design mps pthreadext impl resume also-suspended}@anchor{1390}@ref{1390,,.impl.resume.also-suspended;} If the thread is also suspended on
behalf of another @ref{1371,,PThreadext}, then the target object is removed from
the id ring.

@anchor{design/pthreadext design mps pthreadext impl resume not-also}@anchor{1391}@ref{1391,,.impl.resume.not-also;} If the thread is not also suspended on
behalf of another @ref{1371,,PThreadext}, then the thread is resumed using the
technique proposed by Butenhof (see @ref{136a,,.analysis.signal.example}). I.e. we
send it the signal @code{PTHREADEXT_SIGRESUME} (see @ref{138d,,.impl.signals}) and
expect it to wake up. If this operation fails (for example, because of
thread termination) we unlock the mutex and return @code{ResFAIL}.

@anchor{design/pthreadext design mps pthreadext impl resume update}@anchor{1392}@ref{1392,,.impl.resume.update;} Once the target thread is in the appropriate
state, we remove the target @ref{1371,,PThreadext} object from the suspend
ring, set its context to @code{NULL} and unlock the mutex.

@anchor{design/pthreadext design mps pthreadext impl resume-handler}@anchor{138a}@ref{138a,,.impl.resume-handler;} The resume signal handler is invoked in the
target thread during a resume operation, when a
@code{PTHREADEXT_SIGRESUME} signal is sent by the controlling thread (see
@ref{1391,,.impl.resume.not-also}). The resume signal handler simply returns.
This is sufficient to unblock the suspend handler, which will have
been blocking the thread at the time of the signal. The Pthreads
implementation ensures that the signal mask is restored to the value
it had before the signal handler was invoked.

@anchor{design/pthreadext design mps pthreadext impl finish}@anchor{1393}@ref{1393,,.impl.finish;} @ref{137b,,PThreadextFinish()} supports the finishing of
objects in the suspended state, and removes them from the suspend ring
and id ring as necessary. It must claim the mutex for the removal
operation (to ensure atomicity of the operation). Finishing of
suspended objects is supported so that clients can dispose of
resources if a resume operation fails (which probably means that the
PThread has terminated).

@anchor{design/pthreadext design mps pthreadext impl signals}@anchor{138d}@ref{138d,,.impl.signals;} The choice of which signals to use for suspend and
restore operations may need to be platform-specific. Some signals are
likely to be generated and/or handled by other parts of the
application and so should not be used (for example, @code{SIGSEGV}). Some
implementations of PThreads use some signals for themselves, so they
may not be used; for example, LinuxThreads uses @code{SIGUSR1} and
@code{SIGUSR2} for its own purposes, and so do popular tools like
Valgrind that we would like to be compatible with the MPS. The design
therefore abstractly names the signals @code{PTHREADEXT_SIGSUSPEND} and
@code{PTHREAD_SIGRESUME}, so that they may be easily mapped to
appropriate real signal values. Candidate choices are @code{SIGXFSZ} and
@code{SIGXCPU}.

@anchor{design/pthreadext design mps pthreadext impl signals config}@anchor{1394}@ref{1394,,.impl.signals.config;} The identity of the signals used to suspend
and resume threads can be configured at compilation time using the
preprocessor constants @ref{1fb,,CONFIG_PTHREADEXT_SIGSUSPEND} and
@ref{1fc,,CONFIG_PTHREADEXT_SIGRESUME} respectively.

@node Attachments<2>,References<24>,Implementation<28>,POSIX thread extensions
@anchor{design/pthreadext attachments}@anchor{1395}
@subsection Attachments


[missing attachment “posix.txt”]

[missing attachment “susp.c”]

@node References<24>,,Attachments<2>,POSIX thread extensions
@anchor{design/pthreadext references}@anchor{1396}
@subsection References


@anchor{design/pthreadext butenhof-1999-08-16}@anchor{136c}@w{(Butenhof_1999-08-16)} 
Dave Butenhof. comp.programming.threads. 1999-08-16. “Re: Problem with Suspend & Resume Thread Example@footnote{https://groups.google.com/group/comp.programming.threads/msg/2a604c5f03f388d0}”.

@anchor{design/pthreadext lau-1999-08-16}@anchor{136b}@w{(Lau_1999-08-16)} 
Raymond Lau. comp.programming.threads. 1999-08-16. “Problem with Suspend & Resume Thread Example@footnote{https://groups.google.com/group/comp.programming.threads/msg/dc4d9a45866331eb}”.

@geindex root manager; design

@node Root manager,The generic scanner,POSIX thread extensions,Old design
@anchor{design/root doc}@anchor{1397}@anchor{design/root design-root}@anchor{1398}@anchor{design/root root-manager}@anchor{1399}
@section Root manager


@menu
* Basics:: 
* Details: Details<2>. 

@end menu

@node Basics,Details<2>,,Root manager
@anchor{design/root basics}@anchor{139a}@anchor{design/root design mps root}@anchor{139b}
@subsection Basics


@anchor{design/root design mps root root def}@anchor{139c}@ref{139c,,.root.def;} The root node of the object graph is the node which
defines whether objects are accessible, and the place from which the
mutator acts to change the graph. In the MPS, a root is an object
which describes part of the root node. The root node is the total of
all the roots attached to the space.

@cartouche
@quotation Note 
Note that this combines two definitions of root: the accessibility
is what defines a root for tracing (see analysis.tracer.root.* and
the mutator action for barriers (see analysis.async-gc.root).
Pekka P. Pirinen, 1998-03-20.
@end quotation
@end cartouche

@anchor{design/root design mps root root repr}@anchor{139d}@ref{139d,,.root.repr;} Functionally, roots are defined by their scanning
functions. Roots `could' be represented as function closures: that is,
a pointer to a C function and some auxiliary fields. The most general
variant of roots is just that. However, for reasons of efficiency,
some special variants are separated out.

@node Details<2>,,Basics,Root manager
@anchor{design/root details}@anchor{139e}
@subsection Details


@menu
* Creation:: 
* Destruction:: 
* Invariants: Invariants<2>. 
* Scanning: Scanning<3>. 

@end menu

@node Creation,Destruction,,Details<2>
@anchor{design/root creation}@anchor{139f}
@subsubsection Creation


@anchor{design/root design mps root create}@anchor{13a0}@ref{13a0,,.create;} A root becomes “active” as soon as it is created.

@anchor{design/root design mps root create col}@anchor{13a1}@ref{13a1,,.create.col;} The root inherits its colour from the mutator, since
it can only contain references copied there by the mutator from
somewhere else. If the mutator is grey for a trace when a root is
created then that root will be used to determine accessibility for
that trace. More specifically, the root will be scanned when that
trace flips.

@node Destruction,Invariants<2>,Creation,Details<2>
@anchor{design/root destruction}@anchor{13a2}
@subsubsection Destruction


@anchor{design/root design mps root destroy}@anchor{13a3}@ref{13a3,,.destroy;} It’s OK to destroy a root at any time, except perhaps
concurrently with scanning it, but that’s prevented by the arena lock.
If a root is destroyed the references in it become invalid and
unusable.

@node Invariants<2>,Scanning<3>,Destruction,Details<2>
@anchor{design/root invariants}@anchor{13a4}
@subsubsection Invariants


@anchor{design/root design mps root inv white}@anchor{13a5}@ref{13a5,,.inv.white;} Roots are never white for any trace, because they
cannot be condemned.

@anchor{design/root design mps root inv rank}@anchor{13a6}@ref{13a6,,.inv.rank;} Roots always have a single rank. A root without ranks
would be a root without references, which would be pointless. The
tracer doesn’t support multiple ranks in a single colour.

@node Scanning<3>,,Invariants<2>,Details<2>
@anchor{design/root scanning}@anchor{13a7}
@subsubsection Scanning


@anchor{design/root design mps root method}@anchor{13a8}@ref{13a8,,.method;} Root scanning methods are provided by the client so that
the MPS can locate and scan the root set. See protocol.mps.root for
details.

@cartouche
@quotation Note 
There are some more notes about root methods in
meeting.qa.1996-10-16.
@end quotation
@end cartouche

@geindex generic scanner; design

@node The generic scanner,Segment data structure,Root manager,Old design
@anchor{design/scan doc}@anchor{13a9}@anchor{design/scan design-scan}@anchor{13aa}@anchor{design/scan the-generic-scanner}@anchor{13ab}
@section The generic scanner


@menu
* Summaries:: 

@end menu

@node Summaries,,,The generic scanner
@anchor{design/scan design mps scan}@anchor{13ac}@anchor{design/scan summaries}@anchor{13ad}
@subsection Summaries


@menu
* Scanned summary:: 
* Partial scans:: 

@end menu

@node Scanned summary,Partial scans,,Summaries
@anchor{design/scan scanned-summary}@anchor{13ae}
@subsubsection Scanned summary


@anchor{design/scan design mps scan summary subset}@anchor{13af}@ref{13af,,.summary.subset;} The summary of reference seens by scan
(@code{ss.unfixedSummary}) is a subset of the summary previously computed
(@code{SegSummary()}).

There are two reasons that it is not an equality relation:


@enumerate 

@item 
If the segment has had objects forwarded onto it then its summary
will get unioned with the summary of the segment that the object
was forwarded from. This may increase the summary. The forwarded
object of course may have a smaller summary (if such a thing were
to be computed) and so subsequent scanning of the segment may
reduce the summary. (The forwarding process may erroneously
introduce zones into the destination’s summary).

@item 
A write barrier hit will set the summary to @code{RefSetUNIV}.
@end enumerate

The reason that @code{ss.unfixedSummary} is always a subset of the
previous summary is due to an “optimization” which has not been made
in @code{TraceFix()}. See design.mps.trace.fix.fixed.all@footnote{trace.html#design.mps.trace.fix.fixed.all}.

@node Partial scans,,Scanned summary,Summaries
@anchor{design/scan design-mps-trace-fix-fixed-all}@anchor{13b0}@anchor{design/scan partial-scans}@anchor{13b1}
@subsubsection Partial scans


@anchor{design/scan design mps scan clever-summary}@anchor{13b2}@ref{13b2,,.clever-summary;} With enough cleverness, it’s possible to have
partial scans of condemned segments contribute to the segment summary.

@cartouche
@quotation Note 
We had a system which nearly worked – see MMsrc(MMdevel_poolams
at 1997/08/14 13:02:55 BST), but it did not handle the situation
in which a segment was not under the write barrier when it was
condemned.
@end quotation
@end cartouche

@anchor{design/scan design mps scan clever-summary acc}@anchor{13b3}@ref{13b3,,.clever-summary.acc;} Each time we partially scan a segment, we
accumulate the post-scan summary of the scanned objects into a field
in the group, called @code{summarySoFar}. The post-scan summary is
(summary white) ∪ fixed.

@anchor{design/scan design mps scan clever-summary acc condemn}@anchor{13b4}@ref{13b4,,.clever-summary.acc.condemn;} The cumulative summary is only
meaningful while the segment is condemned. Otherwise it is set to
@code{RefSetEMPTY} (a value which we can check).

@anchor{design/scan design mps scan clever-summary acc reclaim}@anchor{13b5}@ref{13b5,,.clever-summary.acc.reclaim;} Then when we reclaim the segment, we
set the segment summary to the cumulative summary, as it is a
post-scan summary of all the scanned objects.

@anchor{design/scan design mps scan clever-summary acc other-trace}@anchor{13b6}@ref{13b6,,.clever-summary.acc.other-trace;} If the segment is scanned by
another trace while it is condemned, the cumulative summary must be
set to the post-scan summary of this scan (otherwise it becomes
out-of-date).

@anchor{design/scan design mps scan clever-summary scan}@anchor{13b7}@ref{13b7,,.clever-summary.scan;} The scan summary is expected to be a summary
of all scanned references in the segment. We don’t know this
accurately until we’ve scanned everything in the segment. So we add in
the segment summary each time.

@anchor{design/scan design mps scan clever-summary scan fix}@anchor{13b8}@ref{13b8,,.clever-summary.scan.fix;} @code{traceScanSeg()} also expects the scan
state fixed summary to include the post-scan summary of all references
which were white. Since we don’t scan all white references, we need to
add in an approximation to the summary of all white references which
we didn’t scan. This is the intersection of the segment summary and
the white summary.

@anchor{design/scan design mps scan clever-summary wb}@anchor{13b9}@ref{13b9,,.clever-summary.wb;} If the cumulative summary is smaller than the
mutator’s summary, a write-barrier is needed to prevent the mutator
from invalidating it. This means that sometimes we’d have to put the
segment under the write-barrier at condemn, which might not be very
efficient

@cartouche
@quotation Note 
This is not an operation currently available to pool class
implementations Pekka P. Pirinen, 1998-02-26.
@end quotation
@end cartouche

@anchor{design/scan design mps scan clever-summary method wb}@anchor{13ba}@ref{13ba,,.clever-summary.method.wb;} We need a new pool class method, called
when the write barrier is hit (or possibly any barrier hit). The
generic method will do the usual TraceAccess work, the trivial method
will do nothing.

@anchor{design/scan design mps scan clever-summary acc wb}@anchor{13bb}@ref{13bb,,.clever-summary.acc.wb;} When the write barrier is hit, we need to
correct the cumulative summary to the mutator summary. This is
approximated by setting the summary to @code{RefSetUNIV}.

@geindex segments; design

@node Segment data structure,MPS Strategy,The generic scanner,Old design
@anchor{design/seg doc}@anchor{13bc}@anchor{design/seg design-seg}@anchor{13bd}@anchor{design/seg segment-data-structure}@anchor{13be}
@section Segment data structure


@menu
* Introduction: Introduction<71>. 
* Overview: Overview<31>. 
* Data Structure:: 
* Interface: Interface<29>. 
* Extensibility:: 

@end menu

@node Introduction<71>,Overview<31>,,Segment data structure
@anchor{design/seg design mps seg}@anchor{13bf}@anchor{design/seg introduction}@anchor{13c0}
@subsection Introduction


@anchor{design/seg design mps seg intro}@anchor{13c1}@ref{13c1,,.intro;} This is the design of the segment data structure.

@node Overview<31>,Data Structure,Introduction<71>,Segment data structure
@anchor{design/seg overview}@anchor{13c2}
@subsection Overview


@anchor{design/seg design mps seg over segments}@anchor{13c3}@ref{13c3,,.over.segments;} Segments are the basic units of tracing and
shielding. The MPM also uses them as units of scanning and colour,
although pool classes may subdivide segments and be able to maintain
colour on a finer grain (down to the object level, for example).

@anchor{design/seg design mps seg over objects}@anchor{13c4}@ref{13c4,,.over.objects;} The mutator’s objects are stored in segments.
Segments are contiguous blocks of memory managed by some pool.

@anchor{design/seg design mps seg segments pool}@anchor{13c5}@ref{13c5,,.segments.pool;} The arrangement of objects within a segment is
determined by the class of the pool which owns the segment. The pool
is associated with the segment indirectly via the first tract of the
segment.

@anchor{design/seg design mps seg over memory}@anchor{13c6}@ref{13c6,,.over.memory;} The relationship between segments and areas of memory
is maintained by the segment module. Pools acquire tracts from the
arena, and release them back to the arena when they don’t need them
any longer. The segment module can associate contiguous tracts owned
by the same pool with a segment. The segment module provides the
methods SegBase, SegLimit, and SegSize which map a segment onto the
addresses of the memory block it represents.

@anchor{design/seg design mps seg over hierarchy}@anchor{13c7}@ref{13c7,,.over.hierarchy;} The Segment datastructure is designed to be
subclassable (see design.mps.protocol@footnote{protocol.html}). The basic segment class
(@ref{b53,,Seg}) supports colour and protection for use by the tracer, as
well as support for a pool ring, and all generic segment functions.
Clients may use @ref{b53,,Seg} directly, but will most probably want to use a
subclass with additional properties.

@anchor{design/seg design mps seg over hierarchy gcseg}@anchor{13c8}@ref{13c8,,.over.hierarchy.gcseg;} @code{GCSeg} is a subclass of @ref{b53,,Seg} which
implements garbage collection, including buffering and the ability to
be linked onto the grey ring. It does not implement hardware barriers,
and so can only be used with software barriers, for example internally
in the MPS.

@anchor{design/seg design mps seg over hierarchy mutatorseg}@anchor{13c9}@ref{13c9,,.over.hierarchy.mutatorseg;} @code{MutatorSeg} is a subclass of
@code{GCSeg} implementing hardware barriers. It is suitable for handing
out to the mutator.

@node Data Structure,Interface<29>,Overview<31>,Segment data structure
@anchor{design/seg data-structure}@anchor{13ca}
@subsection Data Structure


@geindex Seg (C type)
@anchor{design/seg c Seg}@anchor{b53}
@deffn {C Type} typedef struct SegStruct *Seg
@end deffn

@geindex GCSeg (C type)
@anchor{design/seg c GCSeg}@anchor{13cb}
@deffn {C Type} typedef struct GCSegStruct *GCSeg
@end deffn

The implementations are as follows:

@example
typedef struct SegStruct @{      /* segment structure */
  Sig sig;                      /* <code/misc.h#sig> */
  SegClass class;               /* segment class structure */
  Tract firstTract;             /* first tract of segment */
  RingStruct poolRing;          /* link in list of segs in pool */
  Addr limit;                   /* limit of segment */
  unsigned depth : ShieldDepthWIDTH; /* see <code/shield.c#def.depth> */
  AccessSet pm : AccessLIMIT;   /* protection mode, <code/shield.c> */
  AccessSet sm : AccessLIMIT;   /* shield mode, <code/shield.c> */
  TraceSet grey : TraceLIMIT;   /* traces for which seg is grey */
  TraceSet white : TraceLIMIT;  /* traces for which seg is white */
  TraceSet nailed : TraceLIMIT; /* traces for which seg has nailed objects */
  RankSet rankSet : RankLIMIT;  /* ranks of references in this seg */
@} SegStruct;

typedef struct GCSegStruct @{    /* GC segment structure */
  SegStruct segStruct;          /* superclass fields must come first */
  RingStruct greyRing;          /* link in list of grey segs */
  RefSet summary;               /* summary of references out of seg */
  Buffer buffer;                /* non-NULL if seg is buffered */
  Sig sig;                      /* design.mps.sig */
@} GCSegStruct;
@end example

@anchor{design/seg design mps seg field rankSet}@anchor{13cc}@ref{13cc,,.field.rankSet;} The @code{rankSet} field represents the set of ranks
of the references in the segment. It is initialized to empty by
@code{SegInit()}.

@anchor{design/seg design mps seg field rankSet single}@anchor{13cd}@ref{13cd,,.field.rankSet.single;} The Tracer only permits one rank per segment
[ref?] so this field is either empty or a singleton.

@anchor{design/seg design mps seg field rankSet empty}@anchor{13ce}@ref{13ce,,.field.rankSet.empty;} An empty @code{rankSet} indicates that there are
no references. If there are no references in the segment then it
cannot contain black or grey references.

@anchor{design/seg design mps seg field rankSet start}@anchor{13cf}@ref{13cf,,.field.rankSet.start;} If references are stored in the segment then
it must be updated, along with the summary (@ref{13d0,,.field.summary.start}).

@anchor{design/seg design mps seg field depth}@anchor{13d1}@ref{13d1,,.field.depth;} The @code{depth} field is used by the Shield
(impl.c.shield) to manage protection of the segment. It is initialized
to zero by @code{SegInit()}.

@anchor{design/seg design mps seg field sm}@anchor{13d2}@ref{13d2,,.field.sm;} The @code{sm} field is used by the Shield (impl.c.shield)
to manage protection of the segment. It is initialized to
@code{AccessSetEMPTY} by @code{SegInit()}.

@anchor{design/seg design mps seg field pm}@anchor{13d3}@ref{13d3,,.field.pm;} The @code{pm} field is used by the Shield (impl.c.shield)
to manage protection of the segment. It is initialized to
@code{AccessSetEMPTY} by @code{SegInit()}. The field is used by both the
shield and the ANSI fake protection (impl.c.protan).

@anchor{design/seg design mps seg field black}@anchor{13d4}@ref{13d4,,.field.black;} The @code{black} field is the set of traces for which
there may be black objects (that is, objects containing references,
but no references to white objects) in the segment. More precisely, if
there is a black object for a trace in the segment then that trace
will appear in the @code{black} field. It is initialized to
@code{TraceSetEMPTY} by @code{SegInit()}.

@anchor{design/seg design mps seg field grey}@anchor{13d5}@ref{13d5,,.field.grey;} The @code{grey} field is the set of traces for which
there may be grey objects (i.e containing references to white objects)
in the segment. More precisely, if there is a reference to a white
object for a trace in the segment then that trace will appear in the
@code{grey} field. It is initialized to @code{TraceSetEMPTY} by @code{SegInit()}.

@anchor{design/seg design mps seg field white}@anchor{13d6}@ref{13d6,,.field.white;} The @code{white} field is the set of traces for which
there may be white objects in the segment. More precisely, if there is
a white object for a trace in the segment then that trace will appear
in the @code{white} field. It is initialized to @code{TraceSetEMPTY} by
@code{SegInit()}.

@anchor{design/seg design mps seg field summary}@anchor{13d7}@ref{13d7,,.field.summary;} The @code{summary} field is an approximation to the
set of all references in the segment. If there is a reference @code{R} in
the segment, then @code{RefSetIsMember(summary, R)} is @code{TRUE}. The
summary is initialized to @code{RefSetEMPTY} by @code{SegInit()}.

@anchor{design/seg design mps seg field summary start}@anchor{13d0}@ref{13d0,,.field.summary.start;} If references are stored in the segment then
it must be updated, along with @code{rankSet} (@ref{13cf,,.field.rankSet.start}).

@anchor{design/seg design mps seg field buffer}@anchor{13d8}@ref{13d8,,.field.buffer;} The @code{buffer} field is either @code{NULL}, or points
to the descriptor structure of the buffer which is currently
allocating in the segment. The field is initialized to @code{NULL} by
@code{SegInit()}.

@anchor{design/seg design mps seg field buffer owner}@anchor{13d9}@ref{13d9,,.field.buffer.owner;} This buffer must belong to the same pool as
the segment, because only that pool has the right to attach it.

@node Interface<29>,Extensibility,Data Structure,Segment data structure
@anchor{design/seg interface}@anchor{13da}
@subsection Interface


@menu
* Splitting and merging:: 

@end menu

@node Splitting and merging,,,Interface<29>
@anchor{design/seg splitting-and-merging}@anchor{13db}
@subsubsection Splitting and merging


@anchor{design/seg design mps seg split-and-merge}@anchor{13dc}@ref{13dc,,.split-and-merge;} There is support for splitting and merging
segments, to give pools the flexibility to rearrange their tracts
among segments as they see fit.

@geindex SegSplit (C function)
@anchor{design/seg c SegSplit}@anchor{10b3}
@deffn {C Function} @ref{55f,,Res} SegSplit (Seg *segLoReturn, Seg *segHiReturn, Seg seg, Addr at)
@end deffn

@anchor{design/seg design mps seg split}@anchor{13dd}@ref{13dd,,.split;} If successful, segment @code{seg} is split at address @code{at},
yielding two segments which are returned in segLoReturn and
segHiReturn for the low and high segments respectively. The base of
the low segment is the old base of @code{seg}. The limit of the low
segment is @code{at}. The base of the high segment is @code{at}. This limit
of the high segment is the old limit of @code{seg}. @code{seg} is
effectively destroyed during this operation (actually, it might be
reused as one of the returned segments). Segment subclasses may make
use of the optional arguments; the built-in classes do not.

@anchor{design/seg design mps seg split invariants}@anchor{13de}@ref{13de,,.split.invariants;} The client must ensure some invariants are met
before calling @ref{10b3,,SegSplit()}:


@itemize -

@item 
@anchor{design/seg design mps seg split inv align}@anchor{13df}@ref{13df,,.split.inv.align;} @code{at} must be a multiple of the arena grain
size, and lie between the base and limit of @code{seg}. Justification:
the split segments cannot be represented if this is not so.

@item 
@anchor{design/seg design mps seg split inv buffer}@anchor{13e0}@ref{13e0,,.split.inv.buffer;} If @code{seg} is attached to a buffer, the
buffered region must not include address @code{at}. Justification: the
segment module is not in a position to know how (or whether) a pool
might wish to split a buffer. This permits the buffer to remain
attached to just one of the returned segments.
@end itemize

@anchor{design/seg design mps seg split state}@anchor{13e1}@ref{13e1,,.split.state;} Except as noted above, the segments returned have the
same properties as @code{seg}. That is, their colour, summary, rankset,
nailedness etc. are set to the values of @code{seg}.

@geindex SegMerge (C function)
@anchor{design/seg c SegMerge}@anchor{10b2}
@deffn {C Function} @ref{55f,,Res} SegMerge (Seg *mergedSegReturn, Seg segLo, Seg segHi)
@end deffn

@anchor{design/seg design mps seg merge}@anchor{13e2}@ref{13e2,,.merge;} If successful, segments @code{segLo} and @code{segHi} are merged
together, yielding a segment which is returned in mergedSegReturn.
@code{segLo} and @code{segHi} are effectively destroyed during this
operation (actually, one of them might be reused as the merged
segment). Segment subclasses may make use of the optional arguments;
the built-in classes do not.

@anchor{design/seg design mps seg merge invariants}@anchor{13e3}@ref{13e3,,.merge.invariants;} The client must ensure some invariants are met
before calling @ref{10b2,,SegMerge()}:


@itemize -

@item 
@anchor{design/seg design mps seg merge inv abut}@anchor{13e4}@ref{13e4,,.merge.inv.abut;} The limit of @code{segLo} must be the same as the
base of @code{segHi}. Justification: the merged segment cannot be
represented if this is not so.

@item 
@anchor{design/seg design mps seg merge inv buffer}@anchor{13e5}@ref{13e5,,.merge.inv.buffer;} One or other of @code{segLo} and @code{segHi} may
be attached to a buffer, but not both. Justification: the segment
module does not support attachment of a single seg to 2 buffers.

@item 
@anchor{design/seg design mps seg merge inv similar}@anchor{13e6}@ref{13e6,,.merge.inv.similar;} @code{segLo} and @code{segHi} must be sufficiently
similar. Two segments are sufficiently similar if they have
identical values for each of the following fields: @code{class},
@code{grey}, @code{white}, @code{nailed}, @code{rankSet}. Justification: There
has yet to be a need to implement default behaviour for these
cases. Pool classes should arrange for these values to be the same
before calling @ref{10b2,,SegMerge()}.
@end itemize

@anchor{design/seg design mps seg merge state}@anchor{13e7}@ref{13e7,,.merge.state;} The merged segment will share the same state as
@code{segLo} and @code{segHi} for those fields which are identical (see
@ref{13e6,,.merge.inv.similar}). The summary will be the union of the summaries
of @code{segLo} and @code{segHi}.

@node Extensibility,,Interface<29>,Segment data structure
@anchor{design/seg extensibility}@anchor{13e8}
@subsection Extensibility


@menu
* Allocation: Allocation<6>. 
* Garbage collection: Garbage collection<2>. 
* Splitting and merging: Splitting and merging<2>. 

@end menu

@node Allocation<6>,Garbage collection<2>,,Extensibility
@anchor{design/seg allocation}@anchor{13e9}
@subsubsection Allocation


@geindex SegBufferFillMethod (C type)
@anchor{design/seg c SegBufferFillMethod}@anchor{13ea}
@deffn {C Type} typedef @ref{3a9,,Bool} (*SegBufferFillMethod)(@ref{632,,Addr} *baseReturn, @ref{632,,Addr} *limitReturn, @ref{b53,,Seg} seg, @ref{40e,,Size} size, @ref{b21,,RankSet} rankSet)
@end deffn

@anchor{design/seg design mps seg method buffer-fill}@anchor{13eb}@ref{13eb,,.method.buffer-fill;} Allocate a block in the segment, of at least
@code{size} bytes, with the given set of ranks. If successful, update
@code{*baseReturn} and @code{*limitReturn} to the block and return @code{TRUE}.
Otherwise, return @code{FALSE}. The allocated block must be accounted as
buffered (see design.mps.strategy.account.buffered@footnote{strategy.html#design.mps.strategy.account.buffered}).

@geindex SegBufferEmptyMethod (C type)
@anchor{design/seg c SegBufferEmptyMethod}@anchor{13ec}
@deffn {C Type} typedef void (*SegBufferEmptyMethod)(@ref{b53,,Seg} seg, Buffer buffer)
@end deffn

@anchor{design/seg design mps seg method buffer-empty}@anchor{13ed}@ref{13ed,,.method.buffer-empty;} Free the unused part of the buffer to the
segment. Account the used part as new (see design.mps.strategy.account.new@footnote{strategy.html#design.mps.strategy.account.new}) and the unused part as free (see design.mps.strategy.account.free@footnote{strategy.html#design.mps.strategy.account.free}).

@node Garbage collection<2>,Splitting and merging<2>,Allocation<6>,Extensibility
@anchor{design/seg design-mps-strategy-account-free}@anchor{13ee}@anchor{design/seg garbage-collection}@anchor{13ef}
@subsubsection Garbage collection


@geindex SegAccessMethod (C type)
@anchor{design/seg c SegAccessMethod}@anchor{13f0}
@deffn {C Type} typedef @ref{55f,,Res} (*SegAccessMethod)(@ref{b53,,Seg} seg, @ref{796,,Arena} arena, @ref{632,,Addr} addr, @ref{8ce,,AccessSet} mode, @ref{7bc,,MutatorContext} context)
@end deffn

@anchor{design/seg design mps seg method access}@anchor{13f1}@ref{13f1,,.method.access;} The @code{access} method indicates that the client
program attempted to access the address @code{addr}, but has been denied
due to a protection fault. The @code{mode} indicates whether the client
program was trying to read (@code{AccessREAD}) or write (@code{AccessWRITE})
the address. If this can’t be determined, @code{mode} is @code{AccessREAD |
AccessWRITE}. The segment should perform any work necessary to remove
the protection whilst still preserving appropriate invariants (this
might scanning the region containing @code{addr}). Segment classes are
not required to provide this method, and not doing so indicates they
never protect any memory managed by the pool. This method is called
via the generic function @code{SegAccess()}.

@geindex SegWhitenMethod (C type)
@anchor{design/seg c SegWhitenMethod}@anchor{13f2}
@deffn {C Type} typedef @ref{55f,,Res} (*SegWhitenMethod)(@ref{b53,,Seg} seg, Trace trace)
@end deffn

@anchor{design/seg design mps seg method whiten}@anchor{13f3}@ref{13f3,,.method.whiten;} The @code{whiten} method requests that the segment
@code{seg} condemn (a subset of, but typically all) its objects for the
trace @code{trace}. That is, prepare them for participation in the trace
to determine their liveness. The segment should expect fix requests
(@ref{13f4,,.method.fix}) during the trace and a reclaim request
(@ref{13f5,,.method.reclaim}) at the end of the trace. Segment
classes that automatically reclaim dead objects must provide this
method, and pools that use these segment classes must additionally set
the @code{AttrGC} attribute. This method is called via the generic
function @code{SegWhiten()}.

@geindex SegGreyenMethod (C type)
@anchor{design/seg c SegGreyenMethod}@anchor{13f6}
@deffn {C Type} typedef void (*SegGreyenMethod)(@ref{b53,,Seg} seg, Trace trace)
@end deffn

@anchor{design/seg design mps seg method grey}@anchor{13f7}@ref{13f7,,.method.grey;} The @code{greyen} method requires the segment @code{seg} to
colour its objects grey for the trace @code{trace} (excepting objects
that were already condemned for this trace). That is, make them ready
for scanning by the trace @code{trace}. The segment must arrange that any
appropriate invariants are preserved, possibly by using the protection
interface (see design.mps.prot@footnote{prot.html}). Segment classes are not required to
provide this method, and not doing so indicates that all instances of
this class will have no fixable or traceable references in them. This
method is called via the generic function @code{SegGreyen()}.

@geindex SegBlackenMethod (C type)
@anchor{design/seg c SegBlackenMethod}@anchor{13f8}
@deffn {C Type} typedef void (*SegBlackenMethod)(@ref{b53,,Seg} seg, @ref{b3e,,TraceSet} traceSet)
@end deffn

@anchor{design/seg design mps seg method blacken}@anchor{13f9}@ref{13f9,,.method.blacken;} The @code{blacken} method is called if it is known
that the segment @code{seg} cannot refer to the white set for any of the
traces in @code{traceSet}. The segment must blacken all its grey objects
for those traces. Segment classes are not required to provide this
method, and not doing so indicates that all instances of this class
will have no fixable or traceable references in them. This method is
called via the generic function @code{SegBlacken()}.

@geindex SegScanMethod (C type)
@anchor{design/seg c SegScanMethod}@anchor{13fa}
@deffn {C Type} typedef @ref{55f,,Res} (*SegScanMethod)(@ref{3a9,,Bool} *totalReturn, @ref{b53,,Seg} seg, ScanState ss)
@end deffn

@anchor{design/seg design mps seg method scan}@anchor{13fb}@ref{13fb,,.method.scan;} The @code{scan} method scans all the grey objects on the
segment @code{seg}, passing the scan state @code{ss} to
@code{TraceScanFormat()}. The segment may additionally accumulate a
summary of `all' its objects. If it succeeds in accumulating such a
summary it must indicate that it has done so by setting the
@code{*totalReturn} parameter to @code{TRUE}. Otherwise it must set
@code{*totalReturn} to @code{FALSE}. This method is called via the generic
function @code{SegScan()}.

@anchor{design/seg design mps seg method scan required}@anchor{13fc}@ref{13fc,,.method.scan.required;} Automatically managed segment classes are
required to provide this method, even if all instances of this class
will have no fixable or traceable references in them, in order to
support @ref{1a6,,mps_pool_walk()}.

@geindex SegFixMethod (C type)
@anchor{design/seg c SegFixMethod}@anchor{13fd}
@deffn {C Type} typedef @ref{55f,,Res} (*SegFixMethod)(@ref{b53,,Seg} seg, ScanState ss, @ref{b24,,Ref} *refIO)
@end deffn

@anchor{design/seg design mps seg method fix}@anchor{13f4}@ref{13f4,,.method.fix;} The @code{fix} method indicates that the reference
@code{*refIO} has been discovered at rank @code{ss->rank} by the traces in
@code{ss->traces}, and the segment must handle this discovery according
to the fix protocol (design.mps.fix@footnote{fix.html}). If the method moves the object,
it must update @code{*refIO} to refer to the new location of the object.
If the method determines that the referenced object died (for example,
because the highest-ranking references to the object were weak), it
must update @code{*refIO} to @code{NULL}. Segment classes that automatically
reclaim dead objects must provide this method, and pools that use
these classes must additionally set the @code{AttrGC} attribute. Pool
classes that use segment classes that may move objects must also set
the @code{AttrMOVINGGC} attribute. The @code{fix} method is on the critical
path (see design.mps.critical-path@footnote{critical-path.html}) and so must be fast. This method
is called via the function @code{TraceFix()}.

@anchor{design/seg design mps seg method fixEmergency}@anchor{13fe}@ref{13fe,,.method.fixEmergency;} The @code{fixEmergency} method is used to
perform fixing in “emergency” situations. Its specification is
identical to the @code{fix} method, but it must complete its work without
allocating memory (perhaps by using some approximation, or by running
more slowly). Segment classes must provide this method if and only if
they provide the @code{fix} method. If the @code{fix} method does not need
to allocate memory, then it is acceptable for @code{fix} and
@code{fixEmergency} to be the same.

@geindex SegReclaimMethod (C type)
@anchor{design/seg c SegReclaimMethod}@anchor{13ff}
@deffn {C Type} typedef void (*SegReclaimMethod)(@ref{b53,,Seg} seg, Trace trace)
@end deffn

@anchor{design/seg design mps seg method reclaim}@anchor{13f5}@ref{13f5,,.method.reclaim;} The @code{reclaim} method indicates that any
remaining white objects in the segment @code{seg} have now been proved
unreachable by the trace @code{trace}, and so are dead. The segment
should reclaim the resources associated with the dead objects. Segment
classes are not required to provide this method. If they do, pools
that use them must set the @code{AttrGC} attribute. This method is called
via the generic function @code{SegReclaim()}.

@geindex SegWalkMethod (C type)
@anchor{design/seg c SegWalkMethod}@anchor{1400}
@deffn {C Type} typedef void (*SegWalkMethod)(@ref{b53,,Seg} seg, Format format, FormattedObjectsVisitor f, void *v, size_t s)
@end deffn

@anchor{design/seg design mps seg method walk}@anchor{1401}@ref{1401,,.method.walk;} The @code{walk} method must call the visitor function
@code{f} (along with its closure parameters @code{v} and @code{s} and the
format @code{format}) once for each of the `black' objects in the segment
@code{seg}. Padding objects may or may not be included in the walk, at
the segment’s discretion: it is the responsibility of the client
program to handle them. Forwarding objects must not be included in the
walk. Segment classes need not provide this method. This method is
called by the generic function @code{SegWalk()}, which is called by the
deprecated public functions @ref{322,,mps_arena_formatted_objects_walk()} and
@ref{324,,mps_amc_apply()}.

@anchor{design/seg design mps seg method walk deprecated}@anchor{1402}@ref{1402,,.method.walk.deprecated;} The @code{walk} method is deprecated along
with the public functions @ref{322,,mps_arena_formatted_objects_walk()} and
@ref{324,,mps_amc_apply()} and will be removed along with them in a future
release.

@geindex SegFlipMethod (C type)
@anchor{design/seg c SegFlipMethod}@anchor{1403}
@deffn {C Type} typedef void (*SegFlipMethod)(@ref{b53,,Seg} seg, Trace trace)
@end deffn

@anchor{design/seg design mps seg method flip}@anchor{1404}@ref{1404,,.method.flip;} Raise the read barrier, if necessary, for a trace
that’s about to flip and for which the segment is grey and potentially
contains references.

@node Splitting and merging<2>,,Garbage collection<2>,Extensibility
@anchor{design/seg id1}@anchor{1405}
@subsubsection Splitting and merging


@geindex SegSplitMethod (C type)
@anchor{design/seg c SegSplitMethod}@anchor{1406}
@deffn {C Type} typedef @ref{55f,,Res} (*SegSplitMethod)(@ref{b53,,Seg} seg, @ref{b53,,Seg} segHi, @ref{632,,Addr} base, @ref{632,,Addr} mid, @ref{632,,Addr} limit)
@end deffn

@anchor{design/seg design mps seg method split}@anchor{1407}@ref{1407,,.method.split;} Segment subclasses may extend the support for
segment splitting by defining their own “split” method. On entry,
@code{seg} is a segment with region @code{[base,limit)}, @code{segHi} is
uninitialized, @code{mid} is the address at which the segment is to be
split. The method is responsible for destructively modifying @code{seg}
and initializing @code{segHi} so that on exit @code{seg} is a segment with
region @code{[base,mid)} and @code{segHi} is a segment with region
@code{[mid,limit)}. Usually a method would only directly modify the
fields defined for the segment subclass.

@anchor{design/seg design mps seg method split next}@anchor{1408}@ref{1408,,.method.split.next;} A split method should always call the next
method, either before or after any class-specific code (see
design.mps.protocol.overview.next-method@footnote{protocol.html#design.mps.protocol.overview.next-method}).

@anchor{design/seg design mps seg method split accounting}@anchor{1409}@ref{1409,,.method.split.accounting;} If @code{seg} belongs to a generation in a
chain, then the pool generation accounting must be updated. In the
simple case where the split segments remain in the same generation,
this can be done by calling @code{PoolGenAccountForSegSplit()}.

@geindex SegMergeMethod (C type)
@anchor{design/seg c SegMergeMethod}@anchor{140a}
@deffn {C Type} typedef @ref{55f,,Res} (*SegMergeMethod)(@ref{b53,,Seg} seg, @ref{b53,,Seg} segHi, @ref{632,,Addr} base, @ref{632,,Addr} mid, @ref{632,,Addr} limit)
@end deffn

@anchor{design/seg design mps seg method merge}@anchor{140b}@ref{140b,,.method.merge;} Segment subclasses may extend the support for
segment merging by defining their own @code{merge} method. On entry,
@code{seg} is a segment with region @code{[base,mid)}, @code{segHi} is a
segment with region @code{[mid,limit)}, The method is responsible for
destructively modifying @code{seg} and finishing @code{segHi} so that on
exit @code{seg} is a segment with region @code{[base,limit)} and @code{segHi}
is garbage. Usually a method would only modify the fields defined for
the segment subclass.

@anchor{design/seg design mps seg method merge next}@anchor{140c}@ref{140c,,.method.merge.next;} A merge method should always call the next
method, either before or after any class-specific code (see
design.mps.protocol.overview.next-method@footnote{protocol.html#design.mps.protocol.overview.next-method}).

@anchor{design/seg design mps seg method merge accounting}@anchor{140d}@ref{140d,,.method.merge.accounting;} If @code{seg} belongs to a generation in a
chain, then the pool generation accounting must be updated. In the
simple case where the two segments started in the same generation and
the merged segment remains in that generation, this can be done by
calling @code{PoolGenAccountForSegMerge()}.

@anchor{design/seg design mps seg split-merge shield}@anchor{140e}@ref{140e,,.split-merge.shield;} Split and merge methods may assume that the
segments they are manipulating are not in the shield queue.

@anchor{design/seg design mps seg split-merge shield flush}@anchor{140f}@ref{140f,,.split-merge.shield.flush;} The shield queue is flushed before any
split or merge methods are invoked.

@anchor{design/seg design mps seg split-merge shield re-flush}@anchor{1410}@ref{1410,,.split-merge.shield.re-flush;} If a split or merge method performs
an operation on a segment which might cause the segment to be queued,
the method must flush the shield queue before returning or calling
another split or merge method.

@anchor{design/seg design mps seg split-merge fail}@anchor{1411}@ref{1411,,.split-merge.fail;} Split and merge methods might fail, in which
case segments @code{seg} and @code{segHi} must be equivalently valid and
configured at exit as they were according to the entry conditions.
It’s simplest if the failure can be detected before calling the next
method (for example, by allocating any objects early in the method).

@anchor{design/seg design mps seg split-merge fail anti}@anchor{1412}@ref{1412,,.split-merge.fail.anti;} If it’s not possible to detect failure
before calling the next method, the appropriate anti-method must be
used (see design.mps.protocol.guide.fail.after-next@footnote{protocol.html#design.mps.protocol.guide.fail.after-next}). Split methods
are anti-methods for merge methods, and vice-versa.

@anchor{design/seg design mps seg split-merge fail anti constrain}@anchor{1413}@ref{1413,,.split-merge.fail.anti.constrain;} In general, care should be taken
when writing split and merge methods to ensure that they really are
anti-methods for each other. The anti-method must not fail if the
initial method succeeded. The anti-method should reverse any side
effects of the initial method, except where it’s known to be safe to
avoid this (see @ref{1414,,.split-merge.fail.summary} for an example of a safe
case).

@anchor{design/seg design mps seg split-merge fail anti no}@anchor{1415}@ref{1415,,.split-merge.fail.anti.no;} If this isn’t possible (it might not be)
then the methods won’t support after-next failure. This fact should be
documented, if the methods are intended to support further
specialization. Note that using va_arg with the @code{args} parameter is
sufficient to make it impossible to reverse all side effects.

@anchor{design/seg design mps seg split-merge fail summary}@anchor{1414}@ref{1414,,.split-merge.fail.summary;} The segment summary might not be
restored exactly after a failed merge operation. Each segment would be
left with a summary which is the union of the original summaries (see
@ref{13e7,,.merge.state}). This increases the conservatism in the summaries,
but is otherwise safe.

@anchor{design/seg design mps seg split-merge unsupported}@anchor{1416}@ref{1416,,.split-merge.unsupported;} Segment classes need not support segment
merging at all. The function @code{SegClassMixInNoSplitMerge()} is supplied
to set the split and merge methods to unsupporting methods that will
report an error in checking varieties.

@geindex strategy; design

@node MPS Strategy,Telemetry<3>,Segment data structure,Old design
@anchor{design/strategy doc}@anchor{1417}@anchor{design/strategy design-strategy}@anchor{1418}@anchor{design/strategy mps-strategy}@anchor{1419}
@section MPS Strategy


@menu
* Introduction: Introduction<72>. 
* Overview: Overview<32>. 
* Requirements: Requirements<45>. 
* Generations: Generations<2>. 
* Policy: Policy<2>. 
* References: References<25>. 

@end menu

@node Introduction<72>,Overview<32>,,MPS Strategy
@anchor{design/strategy design mps strategy}@anchor{141a}@anchor{design/strategy introduction}@anchor{141b}
@subsection Introduction


@anchor{design/strategy intro}@anchor{141c}.intro This is the design of collection strategy for the MPS.

@anchor{design/strategy readership}@anchor{141d}.readership MPS developers.

@node Overview<32>,Requirements<45>,Introduction<72>,MPS Strategy
@anchor{design/strategy overview}@anchor{141e}
@subsection Overview


@anchor{design/strategy id1}@anchor{141f}.overview The MPS uses “strategy” code to make three decisions:


@itemize -

@item 
when to start a collection trace;

@item 
what to condemn;

@item 
how to schedule tracing work.
@end itemize

This document describes the current strategy, identifies some
weaknesses in it, and outlines some possible future development
directions.

@node Requirements<45>,Generations<2>,Overview<32>,MPS Strategy
@anchor{design/strategy requirements}@anchor{1420}
@subsection Requirements


[TODO: source some from req.dylan, or do an up-to-date requirements
analysis – NB 2013-03-25]

Garbage collection is a trade-off between time and space: it consumes
some [CPU] time in order to save some [memory] space.  Strategy shifts
the balance point.  A better strategy will take less time to produce
more space.  Examples of good strategy might include:


@itemize -

@item 
choosing segments to condemn which contain high proportions of dead
objects;

@item 
starting a trace when a large number of objects have just died;

@item 
doing enough collection soon enough that the client program never
suffers low-memory problems;

@item 
using otherwise-idle CPU resources for tracing.
@end itemize

Conversely, it would be bad strategy to do the reverse of each of
these (condemning live objects; tracing when there’s very little
garbage; not collecting enough; tracing when the client program is
busy).

Abstracting from these notions, requirements on strategy would
relate to:


@itemize -

@item 
Maximum pause time and other utilization metrics (for example,
bounded mutator utilization, minimum mutator utilization, total MPS
CPU usage);

@item 
Collecting enough garbage (for example: overall heap size;
low-memory requirements).

@item 
Allowing client control (for example, client recommendations for
collection timing or condemnation).
@end itemize

There are other possible strategy considerations which are so far
outside the scope of current strategy and MPS design that this
document disregards them. For example, either inferring or allowing
the client to specify preferred relative object locations (“this
object should be kept in the same cache line as that one”), to improve
cache locality.

@node Generations<2>,Policy<2>,Requirements<45>,MPS Strategy
@anchor{design/strategy generations}@anchor{1421}
@subsection Generations


The largest part of the current MPS strategy implementation is the
support for generational garbage collections.

@menu
* General data structures:: 
* AMC data structures:: 
* Collections:: 
* Zones:: 
* Parameters:: 
* Accounting:: 
* Ramps: Ramps<2>. 

@end menu

@node General data structures,AMC data structures,,Generations<2>
@anchor{design/strategy general-data-structures}@anchor{1422}
@subsubsection General data structures


The fundamental structure of generational garbage collection is the
@code{Chain}, which describes a sequence of generations.

A chain specifies the “capacity” and “mortality” for each generation.
When creating an automatically collected pool, the client code may
specify the chain which will control collections for that pool. The
same chain may be used for multiple pools. If no chain is specified,
the pool uses the arena’s default generation chain.

Each generation in a chain has a @code{GenDesc} structure, allocated in
an array pointed to from the chain. In addition to the generations in
the chains, the arena has a unique @code{GenDesc} structure, named
@code{topGen} and described in comments as “the dynamic generation”
(misleadingly: in fact it is the `least' dynamic generation).

Each automatically collected pool has a set of @code{PoolGen} structures,
one for each generation that it can allocate or promote into. The
@code{PoolGen} structures for each generation point to the @code{GenDesc}
for that generation, and are linked together in a ring on the
@code{GenDesc}. These structures are used to gather accounting
information for strategy decisions.

The non-moving automatic pool classes (AMS, AWL and LO) do not support
generational collection, so they allocate into a single generation.
The moving automatic pool classes (AMC and AMCZ) have one pool
generations for each generation in the chain, plus one pool generation
for the arena’s “top generation”.

@node AMC data structures,Collections,General data structures,Generations<2>
@anchor{design/strategy amc-data-structures}@anchor{1423}
@subsubsection AMC data structures


An AMC pool creates an array of pool generation structures of type
@code{amcGen} (a subclass of @code{PoolGen}). Each pool generation points to
the `forwarding buffer' for that generation: this is the buffer that
surviving objects are copied into.

AMC segments point to the AMC pool generation that the segment belongs
to, and AMC buffers point to the AMC pool generation that the buffer
will be allocating into.

The forwarding buffers are set up during AMC pool creation. Each
generation forwards into the next higher generation in the chain,
except for the top generation, which forwards to itself. Thus, objects
are “promoted” up the chain of generations until they end up in the
top generations, which is shared between all generational pools.

@node Collections,Zones,AMC data structures,Generations<2>
@anchor{design/strategy collections}@anchor{1424}
@subsubsection Collections


Collections in the MPS start in one of two ways:


@enumerate 

@item 
A collection of the world starts via @code{TraceStartCollectAll()}.
This simply condemns all segments in all automatic pools.

@item 
A collection of some set of generations starts via
@ref{1425,,PolicyStartTrace()}. See @ref{1426,,.policy.start}.
@end enumerate

@node Zones,Parameters,Collections,Generations<2>
@anchor{design/strategy zones}@anchor{1427}
@subsubsection Zones


Each generation in each chain has a zoneset associated with it
(@code{gen->zones}); the condemned zoneset is the union of some number of
generation’s zonesets.

An attempt is made to use distinct zonesets for different generations.
Segments in automatic pools are allocated using @code{PoolGenAlloc()}
which creates a @code{LocusPref} using the zoneset from the generation’s
@code{GenDesc}. The zoneset for each generation starts out empty. If the
zoneset is empty, an attempt is made to allocate from a free zone. The
@code{GenDesc} zoneset is augmented with whichever zones the new segment
occupies.

Note that this zoneset can never shrink.

@node Parameters,Accounting,Zones,Generations<2>
@anchor{design/strategy parameters}@anchor{1428}
@subsubsection Parameters


@anchor{design/strategy design mps strategy param intro}@anchor{1429}@ref{1429,,.param.intro;} A generation has two parameters, `capacity' and
`mortality', specified by the client program.

@anchor{design/strategy design mps strategy param capacity}@anchor{142a}@ref{142a,,.param.capacity;} The `capacity' of a generation is the amount of
`new' allocation in that generation (that is, allocation since the
last time the generation was condemned) that will cause the generation
to be collected by @code{TracePoll()}.

@anchor{design/strategy design mps strategy param capacity misnamed}@anchor{142b}@ref{142b,,.param.capacity.misnamed;} The name `capacity' is unfortunate since
it suggests that the total amount of memory in the generation will not
exceed this value. But that will only be the case for pool classes
that always promote survivors to another generation. When there is
`old' allocation in the generation (that is, prior to the last time
the generation was condemned), as there is in the case of non-moving
pool classes, the size of a generation is unrelated to its capacity.

@anchor{design/strategy design mps strategy param mortality}@anchor{142c}@ref{142c,,.param.mortality;} The `mortality' of a generation is the proportion
(between 0 and 1) of memory in the generation that is expected to be
dead when the generation is collected. It is used in @code{TraceStart()}
to estimate the amount of data that will have to be scanned in order
to complete the trace.

@node Accounting,Ramps<2>,Parameters,Generations<2>
@anchor{design/strategy accounting}@anchor{142d}
@subsubsection Accounting


@anchor{design/strategy design mps strategy accounting intro}@anchor{142e}@ref{142e,,.accounting.intro;} Pool generations maintain the sizes of various
categories of data allocated in that generation for that pool. This
accounting information is reported via the event system, but also used
in two places:

@anchor{design/strategy design mps strategy accounting poll}@anchor{142f}@ref{142f,,.accounting.poll;} @code{ChainDeferral()} uses the `new size' of
each generation to determine which generations in the chain are over
capacity and so might need to be collected by @ref{1425,,PolicyStartTrace()}.

@anchor{design/strategy design mps strategy accounting condemn}@anchor{1430}@ref{1430,,.accounting.condemn;} @ref{1425,,PolicyStartTrace()} uses the `new size' of
each generation to determine which generations in the chain will be
collected; it also uses the `total size' of the generation to compute
the mortality.

@anchor{design/strategy design mps strategy accounting check}@anchor{1431}@ref{1431,,.accounting.check;} Computing the new size for a pool generation is
far from straightforward: see job003772@footnote{https://www.ravenbrook.com/project/mps/issue/job003772/} and job004007@footnote{https://www.ravenbrook.com/project/mps/issue/job004007/} for some
(former) errors in this code. In order to assist with checking that
this has been computed correctly, the locus module uses a double-entry
book-keeping system to account for every byte in each pool generation.
This uses seven accounts:

@anchor{design/strategy design mps strategy account total}@anchor{1432}@ref{1432,,.account.total;} Memory acquired from the arena.

@anchor{design/strategy design mps strategy account total negated}@anchor{1433}@ref{1433,,.account.total.negated;} From the point of view of the double-entry
system, the `total' should be negative as it is owing to the arena,
but it is inconvenient to represent negative sizes, and so the
positive value is stored instead.

@anchor{design/strategy design mps strategy account total negated justification}@anchor{1434}@ref{1434,,.account.total.negated.justification;} We don’t have a type for
signed sizes; but if we represented it in two’s complement using the
unsigned @ref{40e,,Size} type then Clang’s unsigned integer overflow detector
would complain.

@anchor{design/strategy design mps strategy account free}@anchor{1435}@ref{1435,,.account.free;} Memory that is not in use (free or lost to
fragmentation).

@anchor{design/strategy design mps strategy account buffered}@anchor{1436}@ref{1436,,.account.buffered;} Memory in a buffer that was handed out to the
client program via @ref{7a2,,BufferFill()}, and which has not yet been
condemned.

@anchor{design/strategy design mps strategy account new}@anchor{1437}@ref{1437,,.account.new;} Memory in use by the client program, allocated
since the last time the generation was condemned.

@anchor{design/strategy design mps strategy account old}@anchor{1438}@ref{1438,,.account.old;} Memory in use by the client program, allocated
prior to the last time the generation was condemned.

@anchor{design/strategy design mps strategy account newDeferred}@anchor{1439}@ref{1439,,.account.newDeferred;} Memory in use by the client program,
allocated since the last time the generation was condemned, but which
should not cause collections via @code{TracePoll()}. (Due to ramping; see
below.)

@anchor{design/strategy design mps strategy account oldDeferred}@anchor{143a}@ref{143a,,.account.oldDeferred;} Memory in use by the client program,
allocated prior to the last time the generation was condemned, but
which should not cause collections via @code{TracePoll()}. (Due to
ramping; see below.)

@anchor{design/strategy design mps strategy accounting op}@anchor{143b}@ref{143b,,.accounting.op;} The following operations are provided:

@anchor{design/strategy design mps strategy accounting op alloc}@anchor{143c}@ref{143c,,.accounting.op.alloc;} Allocate a segment in a pool generation.
Debit `total', credit `free'. (But see @ref{1433,,.account.total.negated}.)

@anchor{design/strategy design mps strategy accounting op free}@anchor{143d}@ref{143d,,.accounting.op.free;} Free a segment. First, ensure that the
contents of the segment are accounted as free, by artificially ageing
any memory accounted as `new' or `newDeferred' (see
@ref{143e,,.accounting.op.age}) and then artificially reclaiming any memory
accounted as `old' or `oldDeferred' (see @ref{143f,,.accounting.op.reclaim}).
Finally, debit `free', credit `total'. (But see
@ref{1433,,.account.total.negated}.)

@anchor{design/strategy design mps strategy accounting op fill}@anchor{1440}@ref{1440,,.accounting.op.fill;} Fill a buffer. Debit `free', credit `buffered'.

@anchor{design/strategy design mps strategy accounting op empty}@anchor{1441}@ref{1441,,.accounting.op.empty;} Empty a buffer. Debit `buffered', credit
`new' or `newDeferred' with the allocated part of the buffer, credit
`free' with the unused part of the buffer.

@anchor{design/strategy design mps strategy accounting op age}@anchor{143e}@ref{143e,,.accounting.op.age;} Condemn memory. Debit `buffered' (if part or
all of a buffer was condemned) and either `new' or `newDeferred',
credit `old' or `oldDeferred'. Note that the condemned part of the
buffer remains part of the buffer until the buffer is emptied, but is
now accounted as `old' or `oldDeferred'. The uncondemned part of the
buffer, if any, remains accounted as `buffered' until it is either
emptied or condemned in its turn.

@anchor{design/strategy design mps strategy accounting op reclaim}@anchor{143f}@ref{143f,,.accounting.op.reclaim;} Reclaim dead memory. Debit `old' or
`oldDeferred', credit `free'.

@anchor{design/strategy design mps strategy accounting op undefer}@anchor{1442}@ref{1442,,.accounting.op.undefer;} Stop deferring the accounting of memory. Debit `oldDeferred', credit `old'. Debit `newDeferred', credit `new'.

@node Ramps<2>,,Accounting,Generations<2>
@anchor{design/strategy ramps}@anchor{1443}
@subsubsection Ramps


The intended semantics of ramping are pretty simple.  It allows the
client to advise us of periods of large short-lived allocation on a
particular AP.  Stuff allocated using that AP during its “ramp” will
probably be dead when the ramp finishes.  How the MPS makes use of this
advice is up to us, but for instance we might segregate those objects,
collect them less enthusiastically during the ramp and then more
enthusiastically soon after the ramp finishes.  Ramps can nest.

A ramp is entered by calling:

@example
mps_ap_alloc_pattern_begin(ap, mps_alloc_pattern_ramp())
@end example

or similar, and left in a similar way.

This is implemented on a per-pool basis, for AMC only (it’s ignored by
the other automatic pools).  PoolAMC throws away the identity of the AP
specified by the client.  The implementation is intended to work by
changing the generational forwarding behaviour, so that there is a “ramp
generation” - one of the regular AMC generations - which forwards to
itself if collected during a ramp (instead of promoting to an older
generation).  It also tweaks the strategy calculation code, in a way
with consequences I am documenting elsewhere.

Right now, the code sets this ramp generation to the last generation
specified in the pool’s “chain”: it ordinarily forwards to the
“after-ramp” generation, which is the “dynamic generation” (i.e. the
least dynamic generation, i.e. the arena-wide “top generation”).  My
recollection, and some mentions in design/poolamc, suggests that the
ramp generation used to be chosen differently from this.

So far, it doesn’t sound too ghastly, I guess, although the subversion
of the generational system seems a little daft.  Read on….

An AMC pool has a @code{rampMode} (which is really a state of a state
machine), taking one of five values: OUTSIDE, BEGIN, RAMPING, FINISH,
and COLLECTING (actually the enum values are called RampX for these
X). We initialize in OUTSIDE.  The pool also has a @code{rampCount},
which is the ramp nesting depth and is used to allow us to ignore ramp
transitions other than the outermost.  According to design/poolamc,
there’s an invariant (in BEGIN or RAMPING, @code{rampCount > 0}; in
COLLECTING or OUTSIDE, @code{rampCount == 0}), but this isn’t checked in
@code{AMCCheck()} and in fact is false for COLLECTING (see below).

There is a small set of events causing state machine transitions:


@itemize -

@item 
entering an outermost ramp;

@item 
leaving an outermost ramp;

@item 
condemning any segment of a ramp generation (detected in AMCWhiten);

@item 
reclaiming any AMC segment.
@end itemize

Here’s pseudo-code for all the transition events:


@table @asis

@item Entering an outermost ramp:

if not FINISH, go to BEGIN.

@item Leaving an outermost ramp:

if RAMPING, go to FINISH.   Otherwise, go to OUTSIDE.

@item Condemning a ramp generation segment:

If BEGIN, go to RAMPING and make the ramp generation forward
to itself (detach the forwarding buffer and reset its generation).
If FINISH, go to COLLECTING and make the ramp generation
forward to the after-ramp generation.

@item Reclaiming any AMC segment:


@table @asis

@item If COLLECTING:

if @code{rampCount > 0}, go to BEGIN.  Otherwise go to OUTSIDE.
@end table
@end table

Now, some deductions:


@enumerate 

@item 
When OUTSIDE, the count is always zero, because (a) it starts that
way, and the only ways to go OUTSIDE are (b) by leaving an
outermost ramp (count goes to zero) or (c) by reclaiming when the
count is zero.

@item 
When BEGIN, the count is never zero (consider the transitions to
BEGIN and the transition to zero).

@item 
When RAMPING, the count is never zero (again consider transitions
to RAMPING and the transition to zero).

@item 
When FINISH, the count can be anything (the transition to FINISH
has zero count, but the Enter transition when FINISH can change
that and then it can increment to any value).

@item 
When COLLECTING, the count can be anything (from the previous fact,
and the transition to COLLECTING).

@item 
`This is a bug!!' The ramp generation is not always reset (to
forward to the after-ramp generation). If we get into FINISH and
then see another ramp before the next condemnation of the ramp
generation, we will Enter followed by Leave. The Enter will keep us
in FINISH, and the Leave will take us back to OUTSIDE, skipping the
transition to the COLLECTING state which is what resets the ramp
generation forwarding buffer. [TODO: check whether I made an issue
and/or fixed it; NB 2013-06-04]
@end enumerate

The simplest change to fix this is to change the behaviour of the Leave
transition, which should only take us OUTSIDE if we are in BEGIN or
COLLECTING.  We should also update design/poolamc to tell the truth, and
check the invariants, which will be these:

@quotation

OUTSIDE => zero
BEGIN => non-zero
RAMPING => non-zero
@end quotation

A cleverer change might radically rearrange the state machine
(e.g. reduce the number of states to three) but that would require
closer design thought and should probably be postponed until we have a
clearer overall strategy plan.

While I’m writing pseudo-code versions of ramp-related code, I should
mention this other snippet, which is the only other code relating to
ramping (these notes are useful when thinking about the broader strategy
code):

@quotation

In @ref{903,,AMCBufferFill()}, if we’re RAMPING, and filling the forwarding
buffer of the ramp generation, and the ramp generation is the
forwarding buffer’s generation, set @code{amcSeg->new} to FALSE.  Otherwise,
add the segment size to @code{poolGen.newSize}.
@end quotation

And since I’ve now mentioned the @code{amcSeg->new} flag, here are the only
other uses of that:


@itemize -

@item 
it initializes as TRUE.

@item 
When leaving an outermost ramp, go through all the segments in the
pool.  Any non-white segment in the rampGen with new set to FALSE has
its size added to @code{poolGen->newSize} and gets new set to TRUE.

@item 
in @code{amcSegWhiten()}, if new is TRUE, the segment size is deducted
from @code{poolGen.newSize} and new is set to FALSE.
@end itemize

@node Policy<2>,References<25>,Generations<2>,MPS Strategy
@anchor{design/strategy policy}@anchor{1444}
@subsection Policy


@anchor{design/strategy design mps strategy policy}@anchor{1445}@ref{1445,,.policy;} Functions that make decisions about what action to take
are collected into the policy module (policy.c). The purpose of doing
so is to make it easier to understand this set of decisions and how
they interact, and to make it easier to maintain and update the policy.

@menu
* Assignment of zones:: 
* Deciding whether to collect the world:: 
* Starting a trace:: 
* Trace progress:: 

@end menu

@node Assignment of zones,Deciding whether to collect the world,,Policy<2>
@anchor{design/strategy assignment-of-zones}@anchor{1446}
@subsubsection Assignment of zones


@geindex PolicyAlloc (C function)
@anchor{design/strategy c PolicyAlloc}@anchor{904}
@deffn {C Function} @ref{55f,,Res} PolicyAlloc (Tract *tractReturn, Arena arena, LocusPref pref, Size size, Pool pool)
@end deffn

@anchor{design/strategy design mps strategy policy alloc}@anchor{1447}@ref{1447,,.policy.alloc;} Allocate @code{size} bytes of memory on behalf of
@code{pool}, based on the preferences described by @code{pref}. If
successful, update @code{*tractReturn} to point to the first tract in the
allocated memory and return @code{ResOK}. Otherwise, return a result code
describing the problem, for example @code{ResCOMMIT_LIMIT}.

@anchor{design/strategy design mps strategy policy alloc impl}@anchor{1448}@ref{1448,,.policy.alloc.impl;} This tries various methods in succession until
one succeeds. First, it tries to allocate from the arena’s free land
in the requested zones. Second, it tries allocating from free zones.
Third, it tries extending the arena and then trying the first two
methods again. Fourth, it tries allocating from any zone that is not
blacklisted. Fifth, it tries allocating from any zone at all.

@anchor{design/strategy design mps strategy policy alloc issue}@anchor{1449}@ref{1449,,.policy.alloc.issue;} This plan performs poorly under stress. See
for example job003898@footnote{https://www.ravenbrook.com/project/mps/issue/job003898/}.

@node Deciding whether to collect the world,Starting a trace,Assignment of zones,Policy<2>
@anchor{design/strategy deciding-whether-to-collect-the-world}@anchor{144a}@anchor{design/strategy job003898}@anchor{144b}
@subsubsection Deciding whether to collect the world


@geindex PolicyShouldCollectWorld (C function)
@anchor{design/strategy c PolicyShouldCollectWorld}@anchor{144c}
@deffn {C Function} @ref{3a9,,Bool} PolicyShouldCollectWorld (Arena arena, double availableTime, Clock now, Clock clocks_per_sec)
@end deffn

@anchor{design/strategy design mps strategy policy world}@anchor{144d}@ref{144d,,.policy.world;} Determine whether now is a good time for
@ref{19c,,mps_arena_step()} to start a collection of the world. Return
@code{TRUE} if so, @code{FALSE} if not. The @code{availableTime} argument is an
estimate of the time that’s available for the collection, @code{now} is
the current time as returned by @code{ClockNow()}, and @code{clocks_per_sec}
is the result of calling @code{ClocksPerSec()}.

@anchor{design/strategy design mps strategy policy world impl}@anchor{144e}@ref{144e,,.policy.world.impl;} There are two conditions: the estimate of the
available time must be enough to complete the collection, and the last
collection of the world must be long enough in the past that the
@ref{19c,,mps_arena_step()} won’t be spending more than a certain fraction of
runtime in collections. (This fraction is given by the
@code{ARENA_MAX_COLLECT_FRACTION} configuration parameter.)

@node Starting a trace,Trace progress,Deciding whether to collect the world,Policy<2>
@anchor{design/strategy starting-a-trace}@anchor{144f}
@subsubsection Starting a trace


@geindex PolicyStartTrace (C function)
@anchor{design/strategy c PolicyStartTrace}@anchor{1425}
@deffn {C Function} @ref{3a9,,Bool} PolicyStartTrace (Trace *traceReturn, Bool *collectWorldReturn, Arena arena, Bool collectWorldAllowed)
@end deffn

@anchor{design/strategy design mps strategy policy start}@anchor{1426}@ref{1426,,.policy.start;} Consider starting a trace. If a trace was started,
update @code{*traceReturn} to point to the trace and return TRUE.
Otherwise, leave @code{*traceReturn} unchanged and return FALSE.

@anchor{design/strategy design mps strategy policy start world}@anchor{1450}@ref{1450,,.policy.start.world;} If @code{collectWorldAllowed} is TRUE, consider
starting a collection of the whole world, and if such a collection is
started, set @code{*collectWorldReturn} to TRUE.

This decision uses the “Lisp Machine” strategy, which tries to
schedule collections of the world so that the collector just keeps
pace with the mutator: that is, it starts a collection when the
predicted completion time of the collection is around the time when
the mutator is predicted to reach the current memory limit. See
@ref{1451,,[Pirinen]}.

@anchor{design/strategy design mps strategy policy start world hack}@anchor{1452}@ref{1452,,.policy.start.world.hack;} The @code{collectWorldAllowed} flag was
added to fix job004011@footnote{https://www.ravenbrook.com/project/mps/issue/job004011/} by ensuring that the MPS starts at most one
collection of the world in each call to @code{ArenaPoll()}. But this is
is fragile and inelegant. Ideally the MPS would be able to deduce that
a collection of a set of generations can’t possibly make progress
(because nothing that refers to this set of generations has changed),
and so not start such a collection.

@anchor{design/strategy design mps strategy policy start chain}@anchor{1453}@ref{1453,,.policy.start.chain;} If @code{collectWorldAllowed} is FALSE, or if it
is not yet time to schedule a collection of the world,
@ref{1425,,PolicyStartTrace()} considers collecting a set of zones
corresponding to a set of generations on a chain.

It picks these generations by calling @code{ChainDeferral()} for each
chain; this function indicates if the chain needs collecting, and if
so, how urgent it is to collect that chain. The most urgent chain in
need of collection (if any) is then condemned by calling
@code{policyCondemnChain()}, which chooses the set of generations to
condemn, and condemns all the segments in those generations.

@node Trace progress,,Starting a trace,Policy<2>
@anchor{design/strategy trace-progress}@anchor{1454}
@subsubsection Trace progress


@geindex PolicyPoll (C function)
@anchor{design/strategy c PolicyPoll}@anchor{1455}
@deffn {C Function} @ref{3a9,,Bool} PolicyPoll (Arena arena)
@end deffn

@anchor{design/strategy design mps strategy policy poll}@anchor{1456}@ref{1456,,.policy.poll;} Return TRUE if the MPS should do some tracing work;
FALSE if it should return to the mutator.

@geindex PolicyPollAgain (C function)
@anchor{design/strategy c PolicyPollAgain}@anchor{cd2}
@deffn {C Function} @ref{3a9,,Bool} PolicyPollAgain (Arena arena, Clock start, Bool moreWork, Work tracedWork)
@end deffn

@anchor{design/strategy design mps strategy policy poll again}@anchor{1457}@ref{1457,,.policy.poll.again;} Return TRUE if the MPS should do another unit
of work; FALSE if it should return to the mutator. @code{start} is the
clock time when the MPS was entered; @code{moreWork} and @code{tracedWork}
are the results of the last call to @code{TracePoll()}.

@anchor{design/strategy design mps strategy policy poll impl}@anchor{1458}@ref{1458,,.policy.poll.impl;} The implementation keep doing work until either
the maximum pause time is exceeded (see design.mps.arena.pause-time@footnote{arena.html#design.mps.arena.pause-time}),
or there is no more work to do. Then it schedules the next collection
so that there is approximately one call to @code{TracePoll()} for every
@code{ArenaPollALLOCTIME} bytes of allocation.

@node References<25>,,Policy<2>,MPS Strategy
@anchor{design/strategy design-mps-arena-pause-time}@anchor{1459}@anchor{design/strategy references}@anchor{145a}
@subsection References


@anchor{design/strategy pirinen}@anchor{1451}@w{(Pirinen)} 
“The Lisp Machine Strategy”; Pekka Pirinin; 1998-04-27; <@indicateurl{https://info.ravenbrook.com/project/mps/doc/2002-06-18/obsolete-mminfo/mminfo/strategy/lisp-machine/}>

@geindex telemetry; design

@node Telemetry<3>,Tracer,MPS Strategy,Old design
@anchor{design/telemetry doc}@anchor{145b}@anchor{design/telemetry design-telemetry}@anchor{145c}@anchor{design/telemetry telemetry}@anchor{145d}
@section Telemetry


@menu
* Introduction: Introduction<73>. 
* Overview: Overview<33>. 
* Requirements: Requirements<46>. 
* Architecture: Architecture<11>. 
* Analysis: Analysis<7>. 
* Ideas: Ideas<2>. 
* Implementation: Implementation<29>. 

@end menu

@node Introduction<73>,Overview<33>,,Telemetry<3>
@anchor{design/telemetry design mps telemetry}@anchor{145e}@anchor{design/telemetry introduction}@anchor{145f}
@subsection Introduction


@anchor{design/telemetry design mps telemetry intro}@anchor{1460}@ref{1460,,.intro;} This documents the design of the telemetry mechanism within
the MPS.

@anchor{design/telemetry design mps telemetry readership}@anchor{1461}@ref{1461,,.readership;} This document is intended for any MPS developer.

@anchor{design/telemetry design mps telemetry source}@anchor{1462}@ref{1462,,.source;} Various meetings and brainstorms, including
meeting.general.1997-03-04(0), mail.richard.1997-07-03.17-01@footnote{https://info.ravenbrook.com/project/mps/mail/1997/07/03/17-01/0.txt},
mail.gavinm.1997-05-01.12-40@footnote{https://info.ravenbrook.com/project/mps/mail/1997/05/01/12-40/0.txt}.

@node Overview<33>,Requirements<46>,Introduction<73>,Telemetry<3>
@anchor{design/telemetry mail-richard-1997-07-03-17-01}@anchor{1463}@anchor{design/telemetry overview}@anchor{1464}
@subsection Overview


@anchor{design/telemetry design mps telemetry over}@anchor{1465}@ref{1465,,.over;} Telemetry permits the emission of events from the MPS. These
can be used to drive a graphical tool, or to debug, or whatever. The
system is flexible and robust, but doesn’t require heavy support from
the client.

@node Requirements<46>,Architecture<11>,Overview<33>,Telemetry<3>
@anchor{design/telemetry requirements}@anchor{1466}
@subsection Requirements


@anchor{design/telemetry design mps telemetry req simple}@anchor{1467}@ref{1467,,.req.simple;} It must be possible to generate code both for the MPS
and any tool without using complicated build tools.

@anchor{design/telemetry design mps telemetry req open}@anchor{1468}@ref{1468,,.req.open;} We must not constrain the nature of events before we are
certain of what we want them to be.

@anchor{design/telemetry design mps telemetry req multi}@anchor{1469}@ref{1469,,.req.multi;} We must be able to send events to multiple streams.

@anchor{design/telemetry design mps telemetry req share}@anchor{146a}@ref{146a,,.req.share;} It must be possible to share event descriptions between
the MPS and any tool.

@anchor{design/telemetry design mps telemetry req version}@anchor{146b}@ref{146b,,.req.version;} It must be possible to version the set of events so
that any tool can detect whether it can understand the MPS.

@anchor{design/telemetry design mps telemetry req back}@anchor{146c}@ref{146c,,.req.back;} Tools should be able to understand older and newer
version of the MPS, so far as is appropriate.

@anchor{design/telemetry design mps telemetry req type}@anchor{146d}@ref{146d,,.req.type;} It must be possible to transmit a rich variety of types
to the tool, including doubles, and strings.

@anchor{design/telemetry design mps telemetry req port}@anchor{146e}@ref{146e,,.req.port;} It must be possible to transmit and receive events
between different platforms.

@anchor{design/telemetry design mps telemetry req control}@anchor{146f}@ref{146f,,.req.control;} It must be possible to control whether and what
events are transmitted at least at a coarse level.

@anchor{design/telemetry design mps telemetry req examine}@anchor{1470}@ref{1470,,.req.examine;} There should be a cheap means to examine the contents
of logs.

@anchor{design/telemetry design mps telemetry req pm}@anchor{1471}@ref{1471,,.req.pm;} The event mechanism should provide for post mortem to
detect what significant events led up to death.

@anchor{design/telemetry design mps telemetry req perf}@anchor{1472}@ref{1472,,.req.perf;} Events should not have a significant effect on
performance when unwanted.

@anchor{design/telemetry design mps telemetry req small}@anchor{1473}@ref{1473,,.req.small;} Telemetry streams should be small.

@anchor{design/telemetry design mps telemetry req avail}@anchor{1474}@ref{1474,,.req.avail;} Events should be available in all varieties, subject to
performance requirements.

@anchor{design/telemetry design mps telemetry req impl}@anchor{1475}@ref{1475,,.req.impl;} The plinth support for telemetry should be easy to write
and flexible.

@anchor{design/telemetry design mps telemetry req robust}@anchor{1476}@ref{1476,,.req.robust;} The telemetry protocol should be robust against some
forms of corruption, e.g. packet loss.

@anchor{design/telemetry design mps telemetry req intern}@anchor{1477}@ref{1477,,.req.intern;} It should be possible to support string-interning.

@node Architecture<11>,Analysis<7>,Requirements<46>,Telemetry<3>
@anchor{design/telemetry architecture}@anchor{1478}
@subsection Architecture


@anchor{design/telemetry design mps telemetry arch}@anchor{1479}@ref{1479,,.arch;} Event annotations are scattered throughout the code, but
there is a central registration of event types and properties. Events
are written to a buffer via a specialist structure, and are optionally
written to the plinth. Events can take any number of parameters of a
range of types, indicated as a format both in the annotation and the
registry.

@node Analysis<7>,Ideas<2>,Architecture<11>,Telemetry<3>
@anchor{design/telemetry analysis}@anchor{147a}
@subsection Analysis


@anchor{design/telemetry design mps telemetry analysis}@anchor{147b}@ref{147b,,.analysis;} The proposed order of development, with summary of
requirements impact is as follows (★ for positive impact, ⇓ for
negative impact):


@multitable {xxxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxxxxxxx} 
@headitem

solution

@tab

si

@tab

op

@tab

mu

@tab

sh

@tab

ve

@tab

ty

@tab

po

@tab

co

@tab

ex

@tab

pm

@tab

pe

@tab

sm

@tab

av

@tab

im

@tab

ro

@tab

in

@tab

ba

@tab

status

@item

@ref{147c,,.sol.format}

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

merged

@item

@ref{147d,,.sol.struct}

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

⇓

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

merged

@item

@ref{147e,,.sol.string}

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

·

@tab

merged

@item

@ref{147f,,.sol.relation}

@tab

★

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

merged

@item

@ref{1480,,.sol.dumper}

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

merged

@item

@ref{1481,,.sol.kind}

@tab

·

@tab

⇓

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

·

@tab

★

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

merged

@item

@ref{1482,,.sol.control}

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

merged

@item

@ref{1483,,.sol.variety}

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

★

@tab

·

@tab

★

@tab

·

@tab

·

@tab

·

@tab

·

@tab

@end multitable


The following are not yet ordered:


@multitable {xxxxxxxxxxxxxxxxxxxxxxxxxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxx} {xxxxxxxxx} 
@headitem

solution

@tab

si

@tab

op

@tab

mu

@tab

sh

@tab

ve

@tab

ty

@tab

po

@tab

co

@tab

ex

@tab

pm

@tab

pe

@tab

sm

@tab

av

@tab

im

@tab

ro

@tab

in

@tab

ba

@tab

status

@item

@ref{1484,,.sol.buffer}

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

·

@tab

★

@tab

★

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

.

@tab

@item

@ref{1485,,.sol.traceback}

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

.

@tab

@item

@ref{1486,,.sol.client}

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

.

@tab

@item

@ref{1487,,.sol.head}

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

.

@tab

@item

@ref{1488,,.sol.version}

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

@item

@ref{1489,,.sol.exit}

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

.

@tab

@item

@ref{148a,,.sol.block}

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

⇓

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

@item

@ref{148b,,.sol.code}

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

@item

@ref{148c,,.sol.msg}

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

·

@tab

★

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

·

@tab

★

@tab

★

@tab

·

@tab

.

@tab

@end multitable


@anchor{design/telemetry design mps telemetry file-format}@anchor{148d}@ref{148d,,.file-format;} One of the objectives of this plan is to minimise the
impact of the changes to the log file format. This is to be achieved
firstly by completing all necessary support before changes are
initiated, and secondly by performing all changes at the same time.

@node Ideas<2>,Implementation<29>,Analysis<7>,Telemetry<3>
@anchor{design/telemetry ideas}@anchor{148e}
@subsection Ideas


@anchor{design/telemetry design mps telemetry sol format}@anchor{147c}@ref{147c,,.sol.format;} Event annotations indicate the types of their
arguments, for example, @code{EVENT_WD} for a @ref{653,,Word} and a @code{double}.
(@ref{146d,,.req.type})

@anchor{design/telemetry design mps telemetry sol struct}@anchor{147d}@ref{147d,,.sol.struct;} Copy event data into a structure of the appropriate
type, for example, @code{EventWDStruct}. (@ref{146d,,.req.type}, @ref{1472,,.req.perf}, but
not @ref{1473,,.req.small} because of padding)

@anchor{design/telemetry design mps telemetry sol string}@anchor{147e}@ref{147e,,.sol.string;} Permit at most one string per event, at the end, and
use the @code{char[1]} hack, and specialised code; deduce the string
length from the event length and also @code{NUL}-terminate (@ref{146d,,.req.type},
@ref{1477,,.req.intern})

@anchor{design/telemetry design mps telemetry sol buffer}@anchor{1484}@ref{1484,,.sol.buffer;} Enter all events initially into internal buffers, and
conditionally send them to the message stream. (@ref{1471,,.req.pm},
@ref{146f,,.req.control}, @ref{1472,,.req.perf})

@anchor{design/telemetry design mps telemetry sol variety}@anchor{1483}@ref{1483,,.sol.variety;} In optimized varieties, have internal events (see
@ref{1484,,.sol.buffer}) for a subset of events and no external events; in
normal varieties have all internal events, and the potential for
external events. (@ref{1474,,.req.avail}, @ref{1471,,.req.pm}, @ref{1472,,.req.perf})

@anchor{design/telemetry design mps telemetry sol kind}@anchor{1481}@ref{1481,,.sol.kind;} Divide events by some coarse type into around 6 groups,
probably related to frequency. (@ref{146f,,.req.control}, @ref{1471,,.req.pm}, but not
@ref{1468,,.req.open})

@anchor{design/telemetry design mps telemetry sol control}@anchor{1482}@ref{1482,,.sol.control;} Hold flags to determine which events are emitted
externally. (@ref{146f,,.req.control}, @ref{1472,,.req.perf})

@anchor{design/telemetry design mps telemetry sol dumper}@anchor{1480}@ref{1480,,.sol.dumper;} Write a simple tool to dump event logs as text.
(@ref{1470,,.req.examine})

@anchor{design/telemetry design mps telemetry sol msg}@anchor{148c}@ref{148c,,.sol.msg;} Redesign the plinth interface to send and receive
messages, based on any underlying IPC mechanism, for example, append
to file, TCP/IP, messages, shared memory. (@ref{1476,,.req.robust},
@ref{1475,,.req.impl}, @ref{146e,,.req.port}, @ref{1469,,.req.multi})

@anchor{design/telemetry design mps telemetry sol block}@anchor{148a}@ref{148a,,.sol.block;} Buffer the events and send them as fixed size blocks,
commencing with a timestamp, and ending with padding. (@ref{1476,,.req.robust},
@ref{1472,,.req.perf}, but not @ref{1473,,.req.small})

@anchor{design/telemetry design mps telemetry sol code}@anchor{148b}@ref{148b,,.sol.code;} Commence each event with two bytes of event code, and
two bytes of length. (@ref{1473,,.req.small}, @ref{146c,,.req.back})

@anchor{design/telemetry design mps telemetry sol head}@anchor{1487}@ref{1487,,.sol.head;} Commence each event stream with a platform-independent
header block giving information about the session, version (see
@ref{1488,,.sol.version}), and file format; file format will be sufficient to
decode the (platform-dependent) rest of the file. (@ref{146e,,.req.port})

@anchor{design/telemetry design mps telemetry sol exit}@anchor{1489}@ref{1489,,.sol.exit;} Provide a mechanism to flush events in the event of
graceful sudden death. (@ref{1471,,.req.pm})

@anchor{design/telemetry design mps telemetry sol version}@anchor{1488}@ref{1488,,.sol.version;} Maintain a three part version number for the file
comprising major (incremented when the format of the entire file
changes (other than platform differences)), median (incremented when
an existing event changes its form or semantics), and minor
(incremented when a new event type is added); tools should normally
fail when the median or major is unsupported. (@ref{146b,,.req.version},
@ref{146c,,.req.back})

@anchor{design/telemetry design mps telemetry sol relation}@anchor{147f}@ref{147f,,.sol.relation;} Event types will be defined in terms of a relation
specifying their name, code, optimised behaviour (see
@ref{1483,,.sol.variety}), kind (see @ref{1481,,.sol.kind}), and format (see
@ref{147c,,.sol.format}); both the MPS and tool can use this by suitable
@code{#define} hacks. (@ref{1467,,.req.simple}, @ref{146a,,.req.share}, @ref{1470,,.req.examine},
@ref{1473,,.req.small} (no format information in messages))

@anchor{design/telemetry design mps telemetry sol traceback}@anchor{1485}@ref{1485,,.sol.traceback;} Provide a mechanism to output recent events (see
@ref{1484,,.sol.buffer}) as a form of backtrace when @code{AVER} statements fire
or from a debugger, or whatever. (@ref{1471,,.req.pm})

@anchor{design/telemetry design mps telemetry sol client}@anchor{1486}@ref{1486,,.sol.client;} Provide a mechanism for user events. (@ref{1477,,.req.intern})

@node Implementation<29>,,Ideas<2>,Telemetry<3>
@anchor{design/telemetry implementation}@anchor{148f}
@subsection Implementation


@menu
* Annotation:: 
* Registration:: 
* Control:: 
* Debugging:: 
* Dumper tool:: 
* Allocation replayer tool:: 

@end menu

@node Annotation,Registration,,Implementation<29>
@anchor{design/telemetry annotation}@anchor{1490}
@subsubsection Annotation


@anchor{design/telemetry design mps telemetry annot}@anchor{1491}@ref{1491,,.annot;} An event annotation is of the form:

@example
EVENT3(FooCreate, pointer, address, word)
@end example

@anchor{design/telemetry design mps telemetry annot string}@anchor{1492}@ref{1492,,.annot.string;} If there is a string in the format, it must be the
last parameter (and hence there can be only one). There is currently
a maximum string length, defined by @code{EventMaxStringLength} in
impl.h.eventcom.

@anchor{design/telemetry design mps telemetry annot type}@anchor{1493}@ref{1493,,.annot.type;} The event type should be given as the first parameter
to the event macro, as registered in impl.h.eventdef.

@anchor{design/telemetry design mps telemetry annot param}@anchor{1494}@ref{1494,,.annot.param;} The parameters of the event should be given as the
remaining parameters of the event macro, in order as indicated in the
event parameters definition in impl.h.eventdef.

@node Registration,Control,Annotation,Implementation<29>
@anchor{design/telemetry registration}@anchor{1495}
@subsubsection Registration


@anchor{design/telemetry design mps telemetry reg}@anchor{1496}@ref{1496,,.reg;} All event types and parameters should be registered in
impl.h.eventdef, in the form of a higher-order list macros.

@anchor{design/telemetry design mps telemetry reg just}@anchor{1497}@ref{1497,,.reg.just;} This use of a higher-order macros enables great
flexibility in the use of this file.

@anchor{design/telemetry design mps telemetry reg rel}@anchor{1498}@ref{1498,,.reg.rel;} The event type registration is of the form:

@example
EVENT(X, FooCreate, 0x1234, TRUE, Arena)
@end example

@anchor{design/telemetry design mps telemetry reg type}@anchor{1499}@ref{1499,,.reg.type;} The first parameter of the relation is the event type.
This needs no prefix, and should correspond to that used in the
annotation.

@anchor{design/telemetry design mps telemetry reg code}@anchor{149a}@ref{149a,,.reg.code;} The second parameter is the event code, a 16-bit value
used to represent this event type. Codes should not be re-used for new
event types, to allow interpretation of event log files of all ages.

@anchor{design/telemetry design mps telemetry reg always}@anchor{149b}@ref{149b,,.reg.always;} The third parameter is a boolean value indicating
whether this event type should be implemented in all varieties. See
@ref{149c,,.control.buffer}. Unless your event is on the critical path
(typically per reference or per object), you will want this to be
@code{TRUE}.

@anchor{design/telemetry design mps telemetry reg kind}@anchor{149d}@ref{149d,,.reg.kind;} The fourth parameter is a kind keyword indicating what
category this event falls into. See @ref{149e,,.control}. The possible values
are:


@itemize -

@item 
@ref{796,,Arena} – per space or arena or global

@item 
@code{Pool} – pool-related

@item 
@code{Trace} – per trace or scan

@item 
@ref{b53,,Seg} – per segment

@item 
@ref{b24,,Ref} – per reference or fix

@item 
@code{Object} – per object or allocation

@item 
@code{User} – invoked by the user through the MPS interface
@end itemize

This list can be seen in impl.h.eventcom.

@anchor{design/telemetry design mps telemetry reg doc}@anchor{149f}@ref{149f,,.reg.doc;} Add a docstring column. [RB 2012-09-03]

@anchor{design/telemetry design mps telemetry reg params}@anchor{14a0}@ref{14a0,,.reg.params;} The event parameters registration is of the form:

@example
#define EVENT_FooCreate_PARAMS(PARAM, X) \
  PARAM(X,  0, P, firstParamPointer) \
  PARAM(X,  1, U, secondParamUnsigned)
@end example

@anchor{design/telemetry design mps telemetry reg param index}@anchor{14a1}@ref{14a1,,.reg.param.index;} The first column is the index, and must start at
zero and increase by one for each row.

@anchor{design/telemetry design mps telemetry reg param sort}@anchor{14a2}@ref{14a2,,.reg.param.sort;} The second column is the parameter “sort”, which,
when appended to @code{EventF}, yields a type for the parameter. It is a
letter from the following list:


@itemize -

@item 
@code{P} – @code{void *}

@item 
@code{A} – @ref{632,,Addr}

@item 
@code{W} – @ref{653,,Word}

@item 
@code{U} – @code{unsigned int}

@item 
@code{S} – @code{char *}

@item 
@code{D} – @code{double}

@item 
@code{B} – @ref{3a9,,Bool}
@end itemize

The corresponding event parameter must be assignment compatible with
the type.

@anchor{design/telemetry design mps telemetry param types}@anchor{14a3}@ref{14a3,,.param.types;} When an event has parameters whose type is not in the
above list, use the following guidelines: All @code{C} pointer types not
representing strings use @code{P}; @ref{40e,,Size}, @ref{3af,,Count}, @ref{b19,,Index} use
@code{W}; others should be obvious.

@anchor{design/telemetry design mps telemetry reg param name}@anchor{14a4}@ref{14a4,,.reg.param.name;} The third column is the parameter name. It should
be a valid C identifier and is used for debugging display and human
readable output.

@anchor{design/telemetry design mps telemetry reg param doc}@anchor{14a5}@ref{14a5,,.reg.param.doc;} Add a docstring column. [RB 2012-09-03]

@anchor{design/telemetry design mps telemetry reg dup}@anchor{14a6}@ref{14a6,,.reg.dup;} It is permissible for the one event type to be used for
more than one annotation. There are generally two reasons for this:


@itemize -

@item 
Variable control flow for successful function completion;

@item 
Platform/Otherwise-dependent implementations of a function.
@end itemize

Note that all annotations for one event type must have the same format
(as implied by @ref{147c,,.sol.format}).

@node Control,Debugging,Registration,Implementation<29>
@anchor{design/telemetry control}@anchor{14a7}
@subsubsection Control


@anchor{design/telemetry design mps telemetry control}@anchor{149e}@ref{149e,,.control;} There are two types of event control, buffer and output.

@anchor{design/telemetry design mps telemetry control buffer}@anchor{149c}@ref{149c,,.control.buffer;} Buffer control affects whether particular events
implemented at all, and is controlled statically by variety using the
always value (see @ref{149b,,.reg.always}) for the event type. The hot variety
does compiles out annotations with @code{always=FALSE}. The cool variety
does not, so always buffers a complete set of events.

@anchor{design/telemetry design mps telemetry control output}@anchor{14a8}@ref{14a8,,.control.output;} Output control affects whether events written to
the internal buffer are output via the plinth. This is set on a
per-kind basis (see @ref{149d,,.reg.kind}), using a control bit table stored in
EventKindControl. By default, all event kinds are off. You may switch
some kinds on using a debugger.

For example, to enable @code{Pool} events using gdb (see impl.h.eventcom for
numeric codes):

@example
$ gdb ./xci3gc/cool/amcss
(gdb) break GlobalsInit
(gdb) run
...
(gdb) print EventKindControl |= 2
$2 = 2
(gdb) continue
...
(gdb) quit
$ mpseventcnv -v | sort | head
0000178EA03ACF6D PoolInit                9C1E0    9C000 0005E040
0000178EA03C2825 PoolInitMFS             9C0D8    9C000     1000        C
0000178EA03C2C27 PoolInitMFS             9C14C    9C000     1000       44
0000178EA03C332C PoolInitMV              9C080    9C000     1000       20    10000
0000178EA03F4DB4 BufferInit             2FE2C4   2FE1B0        0
0000178EA03F4EC8 BufferInitSeg          2FE2C4   2FE1B0        0
0000178EA03F57DA AMCGenCreate           2FE1B0   2FE288
0000178EA03F67B5 BufferInit             2FE374   2FE1B0        0
0000178EA03F6827 BufferInitSeg          2FE374   2FE1B0        0
0000178EA03F6B72 AMCGenCreate           2FE1B0   2FE338
@end example

@anchor{design/telemetry design mps telemetry control env}@anchor{14a9}@ref{14a9,,.control.env;} The initial value of @code{EventKindControl} is read
from the C environment when the ANSI Plinth is used, and so event
output can be controlled like this:

@example
MPS_TELEMETRY_CONTROL=127 amcss
@end example

or like this:

@example
MPS_TELEMETRY_CONTROL="Pool Arena" amcss
@end example

where the variable is set to a space-separated list of names defined by @code{EventKindENUM}.

@anchor{design/telemetry design mps telemetry control just}@anchor{14aa}@ref{14aa,,.control.just;} These controls are coarse, but very cheap.

@anchor{design/telemetry design mps telemetry control external}@anchor{14ab}@ref{14ab,,.control.external;} The MPS interface functions
@ref{176,,mps_telemetry_set()} and @ref{2b4,,mps_telemetry_reset()} can be used to
change @code{EventKindControl}.

@anchor{design/telemetry design mps telemetry control tool}@anchor{14ac}@ref{14ac,,.control.tool;} The tools will be able to control
@code{EventKindControl}.

@node Debugging,Dumper tool,Control,Implementation<29>
@anchor{design/telemetry debugging}@anchor{14ad}
@subsubsection Debugging


@anchor{design/telemetry design mps telemetry debug buffer}@anchor{14ae}@ref{14ae,,.debug.buffer;} Each event kind is logged in a separate buffer,
@code{EventBuffer[kind]}.

@anchor{design/telemetry design mps telemetry debug buffer reverse}@anchor{14af}@ref{14af,,.debug.buffer.reverse;} The events are logged in reverse order from
the top of the buffer, with the last logged event at
@code{EventLast[kind]}. This allows recovery of the list of recent events
using the @code{event->any.size} field.

@anchor{design/telemetry design mps telemetry debug dump}@anchor{14b0}@ref{14b0,,.debug.dump;} The contents of all buffers can be dumped with the
@code{EventDump} function from a debugger, for example:

@example
gdb> print EventDump(mps_lib_get_stdout())
@end example

@anchor{design/telemetry design mps telemetry debug describe}@anchor{14b1}@ref{14b1,,.debug.describe;} Individual events can be described with the
EventDescribe function, for example:

@example
gdb> print EventDescribe(EventLast[3], mps_lib_get_stdout(), 0)
@end example

@anchor{design/telemetry design mps telemetry debug core}@anchor{14b2}@ref{14b2,,.debug.core;} The event buffers are preserved in core dumps and can
be used to work out what the MPS was doing before a crash. Since the
kinds correspond to frequencies, ancient events may still be available
in some buffers, even if they have been flushed to the output stream.
Some digging may be required.

@node Dumper tool,Allocation replayer tool,Debugging,Implementation<29>
@anchor{design/telemetry dumper-tool}@anchor{14b3}
@subsubsection Dumper tool


@anchor{design/telemetry design mps telemetry dumper}@anchor{14b4}@ref{14b4,,.dumper;} A primitive dumper tool is available in impl.c.eventcnv.
For details, see guide.mps.telemetry.

@node Allocation replayer tool,,Dumper tool,Implementation<29>
@anchor{design/telemetry allocation-replayer-tool}@anchor{14b5}
@subsubsection Allocation replayer tool


@anchor{design/telemetry design mps telemetry replayer}@anchor{14b6}@ref{14b6,,.replayer;} A tool for replaying an allocation sequence from a log
is available in impl.c.replay.

@geindex tracer; design

@node Tracer,,Telemetry<3>,Old design
@anchor{design/trace doc}@anchor{14b7}@anchor{design/trace design-trace}@anchor{14b8}@anchor{design/trace tracer}@anchor{14b9}
@section Tracer


@menu
* Introduction: Introduction<74>. 
* Architecture: Architecture<12>. 
* Analysis: Analysis<8>. 
* Ideas: Ideas<3>. 
* Implementation: Implementation<30>. 
* Life cycle of a trace object:: 
* References: References<26>. 

@end menu

@node Introduction<74>,Architecture<12>,,Tracer
@anchor{design/trace design mps trace}@anchor{14ba}@anchor{design/trace introduction}@anchor{14bb}
@subsection Introduction


@cartouche
@quotation Warning 
This document is currently a mixture of very old design notes (the
preformatted section immediately following) and some newer stuff.
It doesn’t yet form anything like a complete picture.
@end quotation
@end cartouche

@node Architecture<12>,Analysis<8>,Introduction<74>,Tracer
@anchor{design/trace architecture}@anchor{14bc}
@subsection Architecture


@anchor{design/trace design mps trace instance limit}@anchor{14bd}@ref{14bd,,.instance.limit;} There is a limit on the number of traces that can
be created at any one time. This limits the number of concurrent
traces. This limitation is expressed in the symbol @code{TraceLIMIT}.

@cartouche
@quotation Note 
@code{TraceLIMIT} is currently set to 1 as the MPS assumes in various
places that only a single trace is active at a time. See
request.mps.160020@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/mps/160020} “Multiple traces would not work”. David Jones,
1998-06-15.
@end quotation
@end cartouche

@anchor{design/trace design mps trace rate}@anchor{14be}@ref{14be,,.rate;} See mail.nickb.1997-07-31.14-37@footnote{https://info.ravenbrook.com/project/mps/mail/1997/07/31/14-37/0.txt}.

@cartouche
@quotation Note 
Now revised? See request.epcore.160062@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/epcore/160062} and
change.epcore.minnow.160062. David Jones, 1998-06-15.
@end quotation
@end cartouche

@anchor{design/trace design mps trace exact legal}@anchor{14bf}@ref{14bf,,.exact.legal;} Exact references must either point outside the arena
(to non-managed address space) or to a tract allocated to a pool.
Exact references that are to addresses which the arena has reserved
but hasn’t allocated memory to are illegal (such a reference cannot
possibly refer to a real object, and so cannot be exact). We check
that this is the case in @code{TraceFix()}.

@cartouche
@quotation Note 
Depending on the future semantics of @code{PoolDestroy()} we might
need to adjust our strategy here. See mail.dsm.1996-02-14.18-18@footnote{https://info.ravenbrook.com/project/mps/mail/1996/02/14/18-18/0.txt}
for a strategy of coping gracefully with @code{PoolDestroy()}.
@end quotation
@end cartouche

@anchor{design/trace design mps trace fix fixed all}@anchor{14c0}@ref{14c0,,.fix.fixed.all;} @code{ss->fixedSummary} is accumulated (in
@code{TraceFix()}) for all pointers, whether or not they are genuine
references. We could accumulate fewer pointers here; if a pointer
fails the @ref{4c4,,TractOfAddr()} test then we know it isn’t a reference, so
we needn’t accumulate it into the fixed summary. The design allows
this, but it breaks a useful post-condition on scanning (if the
accumulation of @code{ss->fixedSummary} was moved the accuracy of
@code{ss->fixedSummary} would vary according to the “width” of the white
summary). See mail.pekka.1998-02-04.16-48@footnote{https://info.ravenbrook.com/project/mps/mail/1998/02/04/16-48/0.txt} for improvement suggestions.

@node Analysis<8>,Ideas<3>,Architecture<12>,Tracer
@anchor{design/trace analysis}@anchor{14c1}@anchor{design/trace mail-pekka-1998-02-04-16-48}@anchor{14c2}
@subsection Analysis


@anchor{design/trace design mps trace fix copy-fail}@anchor{14c3}@ref{14c3,,.fix.copy-fail;} Fixing can always succeed, even if copying the
referenced object has failed (due to lack of memory, for example), by
backing off to treating a reference as ambiguous. Assuming that fixing
an ambiguous reference doesn’t allocate memory (which is no longer
true for AMC for example). See request.dylan.170560@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/dylan/170560} for a slightly
more sophisticated way to proceed when you can no longer allocate
memory for copying.

@node Ideas<3>,Implementation<30>,Analysis<8>,Tracer
@anchor{design/trace ideas}@anchor{14c4}@anchor{design/trace request-dylan-170560}@anchor{14c5}
@subsection Ideas


@anchor{design/trace design mps trace flip after}@anchor{14c6}@ref{14c6,,.flip.after;} To avoid excessive barrier impact on the mutator
immediately after flip, we could scan during flip other objects which
are “near” the roots, or otherwise known to be likely to be accessed
in the near future.

@node Implementation<30>,Life cycle of a trace object,Ideas<3>,Tracer
@anchor{design/trace implementation}@anchor{14c7}
@subsection Implementation


@menu
* Speed:: 

@end menu

@node Speed,,,Implementation<30>
@anchor{design/trace speed}@anchor{14c8}
@subsubsection Speed


@anchor{design/trace design mps trace fix}@anchor{14c9}@ref{14c9,,.fix;} The function implementing the fix operation should be called
@code{TraceFix()} and this name is pervasive in the MPS and its documents
to describe this function. Nonethless, optimisation and strict
aliasing rules have meant that we need to use the external name for
it, @code{_mps_fix2()}.

@anchor{design/trace design mps trace fix speed}@anchor{14ca}@ref{14ca,,.fix.speed;} The fix path is critical to garbage collection speed.
Abstractly, the fix operation is applied to all references in the
non-white heap and all references in the copied heap. Remembered sets
cut down the number of segments we have to scan. The zone test cuts
down the number of references we call fix on. The speed of the
remainder of the fix path is still critical to system performance.
Various modifications to and aspects of the system are concerned with
maintaining the speed along this path. See
design.mps.critical_path@footnote{critical_path.html}.

@anchor{design/trace design mps trace fix tractofaddr}@anchor{14cb}@ref{14cb,,.fix.tractofaddr;} A reference that passes the zone test is then
looked up to find the tract it points to, an operation equivalent to
calling @ref{4c4,,TractOfAddr()}.

@anchor{design/trace design mps trace fix tractofaddr inline}@anchor{14cc}@ref{14cc,,.fix.tractofaddr.inline;} @code{TraceFix()} doesn’t actually call
@ref{4c4,,TractOfAddr()}. Instead, it expands this operation inline (calling
@code{ChunkOfAddr()}, then @code{INDEX_OF_ADDR()}, checking the appropriate
bit in the chunk’s @code{allocTable}, and finally looking up the tract in
the chunk’s page table). The reason for inlining this code is that we
need to know whether the reference points to a chunk (and not just
whether it points to a tract) in order to check the @ref{14bf,,.exact.legal}
condition.

@anchor{design/trace design mps trace fix whiteseg}@anchor{14cd}@ref{14cd,,.fix.whiteseg;} The reason for looking up the tract is to determine
whether the reference is to a white segment.

@cartouche
@quotation Note 
It is likely to be more efficient to maintain a separate lookup
table from address to white segment, rather than indirecting
through the chunk and the tract. See job003796@footnote{https://www.ravenbrook.com/project/mps/issue/job003796/}.
@end quotation
@end cartouche

@anchor{design/trace design mps trace fix noaver}@anchor{14ce}@ref{14ce,,.fix.noaver;} @code{AVER()} statements in the code add bulk to the code
(reducing I-cache efficacy) and add branches to the path (polluting
the branch pedictors) resulting in a slow down. Replacing the
@code{AVER()} statements with @code{AVER_CRITICAL()} on the critical path
improves the overall speed of the Dylan compiler by as much as 9%. See
design.mps.critical_path@footnote{critical_path.html}.

@anchor{design/trace design mps trace fix nocopy}@anchor{14cf}@ref{14cf,,.fix.nocopy;} @ref{4bf,,amcSegFix()} used to copy objects by using the
format’s copy method. This involved a function call (through an
indirection) and in @code{dylan_copy} a call to @code{dylan_skip} (to
recompute the length) and call to @code{memcpy} with general parameters.
Replacing this with a direct call to @code{memcpy} removes these
overheads and the call to @code{memcpy} now has aligned parameters. The
call to @code{memcpy} is inlined by the C compiler. This change results
in a 4–5% speed-up in the Dylan compiler.

@anchor{design/trace design mps trace reclaim}@anchor{14d0}@ref{14d0,,.reclaim;} Because the reclaim phase of the trace (implemented by
@code{TraceReclaim()}) examines every segment it is fairly time
intensive. Richard Tucker’s profiles presented in
request.dylan.170551@footnote{https://info.ravenbrook.com/project/mps/import/2001-11-05/mmprevol/request/dylan/170551} show a gap between the two varieties variety.hi
and variety.wi.

@anchor{design/trace design mps trace reclaim noaver}@anchor{14d1}@ref{14d1,,.reclaim.noaver;} Accordingly, reclaim methods use
@code{AVER_CRITICAL()} instead of @code{AVER()}.

@node Life cycle of a trace object,References<26>,Implementation<30>,Tracer
@anchor{design/trace life-cycle-of-a-trace-object}@anchor{14d2}
@subsection Life cycle of a trace object


@code{TraceCreate()} creates a trace in state @code{TraceINIT}

Some segments get condemned (made white).

@code{TraceStart()} gets called which:


@itemize -

@item 
Derives an initial reference partition based on the existing
white set.  The white zone set and the segments’ summaries are used to
create an initial grey set.

@item 
Emits a @code{GCStart()} message.

@item 
Initialises @code{trace->rate} by estimating the required scanning
rate.

@item 
Moves the trace into the state @code{TraceUNFLIPPED}.

@item 
Immediately calls @code{traceFlip} which flips the trace and moves
it into state @code{TraceFLIPPED}.
@end itemize

Whilst a trace is alive every so often its @code{TraceAdvance()} method
gets invoked (via @code{TracePoll()}) in order to do a step of tracing
work. @code{TraceAdvance()} is responsible for ticking through the trace’s
top-level state machine. Most of the interesting work, the tracing,
happens in the @code{TraceFLIPPED} state.

The trace transitions through its states in the following sequence:
@code{TraceINIT} → (@code{TraceUNFLIPPED}) → @code{TraceFLIPPED} →
@code{TraceRECLAIM} → @code{TraceFINISHED}.

Whilst @code{TraceUNFLIPPED} appears in the code, no trace does any work
in this state; all traces are immediately flipped to be in the
@code{TraceFLIPPED} state (see above).

Once the trace is in the @code{TraceFINISHED} state it performs no more
work and it can be safely destroyed. Generally the callers of
@code{TraceAdvance()} will destroy the trace.

@menu
* Making progress; scanning grey segments: Making progress scanning grey segments. 

@end menu

@node Making progress scanning grey segments,,,Life cycle of a trace object
@anchor{design/trace making-progress-scanning-grey-segments}@anchor{14d3}
@subsubsection Making progress: scanning grey segments


Most of the interesting work of a trace, the actual tracing, happens
in the @code{TraceFLIPPED} state (work `would' happen in the
@code{TraceUNFLIPPED} state, but that is not implemented).

The tracer makes progress by choosing a grey segment to scan, and
scanning it. The actual scanning is performed by pools.

Note that at all times a reference partition is maintained.

The order in which the trace scans things determines the semantics of
certain types of references (in particular, weak and final
references). Or, to put it another way the desired semantics of weak
and final references impose certain restrictions on the order in which
the trace can scan things.

.rank: The tracer uses a system of `reference ranks' (or just ranks)
so that it can impose an order on its scanning work. The ranks are
ordered.  [TODO: Explain how ordering is also required for transforms.
See impl.c.trans.rank-order.  RB 2023-06-16]

The tracer proceeds band by band. The first band is all objects it can
reach by following references of the first rank. The second band is
all subsequent objects it can reach by following references of the
second and first ranks. The third band is all subsequent objects it
can reach by following references of the third, second, and first
ranks. And so on. The description of the tracer working like this
originated in @ref{14d4,,[RHSK_2007-06-25]}.

A trace keeps track of which band it is tracing. This is returned by
the @code{TraceBand()} method. Keeping this band information helps it
implement the semantics of finalization and weakness. The band used to
not be explicitly stored, but this hindered the implementation of good
finalization semantics (in some circumstances finalization messages
were delayed by at least one collection cycle: see job001658@footnote{https://info.ravenbrook.com/project/mps/issue/job001658/}).

The band is used when selecting a grey segment to scan (the selection
occurs in @code{traceFindGrey()}). The tracer attempts to first find
segments whose rank is the current band, then segments whose rank is
previous to the current band, and so on. If there are no segments
found then the current band is exhausted and the current band is
incremented to the next rank. When the current band is moved through
all the ranks in this fashion there is no more tracing to be done.

@node References<26>,,Life cycle of a trace object,Tracer
@anchor{design/trace references}@anchor{14d5}
@subsection References


@anchor{design/trace rhsk-2007-06-25}@anchor{14d4}@w{(RHSK_2007-06-25)} 
Richard Kistruck. Ravenbrook Limited. 2007-06-25. “The semantics of rank-based tracing@footnote{https://info.ravenbrook.com/mail/2007/06/25/11-35-57/0/}”.

@node Bibliography,Memory Management Glossary,Old design,Top
@anchor{bib doc}@anchor{14d6}@anchor{bib bibliography}@anchor{14d7}@anchor{bib id1}@anchor{14d8}
@chapter Bibliography



@itemize *

@item @anchor{bib ad97}@anchor{14d9}
Ole Agesen, David L. Detlefs. 1997.  “Finding References in Java Stacks@footnote{http://www-plan.cs.colorado.edu/diwan/class-papers/finding-references-in-java.pdf}”. Sun Labs. OOPSLA97 Workshop on Garbage Collection and Memory Management.

@cartouche
@quotation Abstract 
Exact garbage collection for the strongly-typed Java language may
seem straightforward. Unfortunately, a single pair of bytecodes in
the Java Virtual Machine instruction set presents an obstacle that
has thus far not been discussed in the literature. We explain the
problem, outline the space of possible solutions, and present a
solution utilizing bytecode-preprocessing to enable exact garbage
collection while maintaining compatibility with existing compiled
Java class files.
@end quotation
@end cartouche

@item @anchor{bib adm98}@anchor{14da}
Ole Agesen, David L. Detlefs, J. Eliot B. Moss. 1998.  “Garbage Collection and Local Variable Type-precision and Liveness in Java Virtual Machines@footnote{http://pdf.aminer.org/000/542/332/garbage_collection_and_local_variable_type_precision_and_liveness_in.pdf}”. ACM. Proceedings of the ACM SIGPLAN ‘98 conference on Programming language design and implementation, pp. 269–279.

@cartouche
@quotation Abstract 
Full precision in garbage collection implies retaining only those
heap allocated objects that will actually be used in the future.
Since full precision is not computable in general, garbage
collectors use safe (i.e., conservative) approximations such as
reachability from a set of root references. Ambiguous roots
collectors (commonly called “conservative”) can be overly
conservative because they overestimate the root set, and thereby
retain unexpectedly large amounts of garbage. We consider two more
precise collection schemes for Java virtual machines (JVMs). One
uses a type analysis to obtain a type-precise root set (only those
variables that contain references); the other adds a live variable
analysis to reduce the root set to only the live reference
variables. Even with the Java programming language’s strong
typing, it turns out that the JVM specification has a feature that
makes type-precise root sets difficult to compute. We explain the
problem and ways in which it can be solved.

Our experimental results include measurements of the costs of the
type and liveness analyses at load time, of the incremental
benefits at run time of the liveness analysis over the
type-analysis alone, and of various map sixes and counts. We find
that the liveness analysis often produces little or no improvement
in heap size, sometimes modest improvements, and occasionally the
improvement is dramatic. While further study is in order, we
conclude that the main benefit of the liveness analysis is
preventing bad surprises.
@end quotation
@end cartouche

@item @anchor{bib ael88}@anchor{14db}
Andrew Appel, John R. Ellis, Kai Li. 1988.  “Real-time Concurrent Collection on Stock Multiprocessors@footnote{http://apotheca.hpl.hp.com/ftp/pub/compaq/SRC/research-reports/SRC-025.pdf}”. ACM, SIGPLAN. ACM PLDI 88, SIGPLAN Notices 23, 7 (July 88), pp. 11–20.

@cartouche
@quotation Abstract 
We’ve designed and implemented a copying garbage-collection
algorithm that is efficient, real-time, concurrent, runs on
commercial uniprocessors and shared-memory multiprocessors, and
requires no change to compilers. The algorithm uses standard
virtual-memory hardware to detect references to “from space”
objects and to synchronize the collector and mutator threads.
We’ve implemented and measured a prototype running on SRC’s
5-processor Firefly. It will be straightforward to merge our
techniques with generational collection. An incremental,
non-concurrent version could be implemented easily on many
versions of Unix.
@end quotation
@end cartouche

@item @anchor{bib apple94}@anchor{14dc}
Apple Computer, Inc. 1994. `Inside Macintosh: Memory'. Addison-Wesley. ISBN 0-201-63240-3.

@cartouche
@quotation Abstract 
Inside Macintosh: Memory describes the parts of the Macintosh®
Operating System that allow you to directly allocate, release, or
otherwise manipulate memory. Everyone who programs Macintosh
computers should read this book.

Inside Macintosh: Memory shows in detail how your application can
manage the memory partition it is allocated and perform other
memory-related operations. It also provides a complete technical
reference for the Memory Manager, the Virtual Memory Manager, and
other memory-related utilities provided by the system software.
@end quotation
@end cartouche

@item @anchor{bib attardi94}@anchor{14dd}
Giuseppe Attardi & Tito Flagella. 1994.  “A Customisable Memory Management Framework@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.50.257&rep=rep1&type=pdf}”. TR-94-010.

@cartouche
@quotation Abstract 
Memory management is a critical issue for many large
object-oriented applications, but in C++ only explicit memory
reclamation through the delete operator is generally available. We
analyse different possibilities for memory management in C++ and
present a dynamic memory management framework which can be
customised to the need of specific applications. The framework
allows full integration and coexistence of different memory
management techniques. The Customisable Memory Management (CMM) is
based on a primary collector which exploits an evolution of
Bartlett’s mostly copying garbage collector. Specialised
collectors can be built for separate memory heaps. A Heap class
encapsulates the allocation strategy for each heap. We show how to
emulate different garbage collection styles or user-specific
memory management techniques. The CMM is implemented in C++
without any special support in the language or the compiler. The
techniques used in the CMM are general enough to be applicable
also to other languages.
@end quotation
@end cartouche

@item @anchor{bib afi98}@anchor{14de}
Giuseppe Attardi, Tito Flagella, Pietro Iglio. 1998.  “A customisable memory management framework for C++@footnote{ftp://ftp.di.unipi.it/pub/Papers/attardi/SPE.ps.gz}”. Software – Practice and Experience. 28(11), 1143–1183.

@cartouche
@quotation Abstract 
Automatic garbage collection relieves programmers from the burden
of managing memory themselves and several techniques have been
developed that make garbage collection feasible in many
situations, including real time applications or within traditional
programming languages. However optimal performance cannot always
be achieved by a uniform general purpose solution. Sometimes an
algorithm exhibits a predictable pattern of memory usage that
could be better handled specifically, delaying as much as possible
the intervention of the general purpose collector. This leads to
the requirement for algorithm specific customisation of the
collector strategies. We present a dynamic memory management
framework which can be customised to the needs of an algorithm,
while preserving the convenience of automatic collection in the
normal case. The Customisable Memory Manager (CMM) organises
memory in multiple heaps. Each heap is an instance of a C++ class
which abstracts and encapsulates a particular storage discipline.
The default heap for collectable objects uses the technique of
mostly copying garbage collection, providing good performance and
memory compaction. Customisation of the collector is achieved
exploiting object orientation by defining specialised versions of
the collector methods for each heap class. The object oriented
interface to the collector enables coexistence and coordination
among the various collectors as well as integration with
traditional code unaware of garbage collection. The CMM is
implemented in C++ without any special support in the language or
the compiler. The techniques used in the CMM are general enough to
be applicable also to other languages. The performance of the CMM
is analysed and compared to other conservative collectors for
C/C++ in various configurations.
@end quotation
@end cartouche

@item @anchor{bib akpy98}@anchor{14df}
Alain Azagury, Elliot K. Kolodner, Erez Petrank, Zvi Yehudai. 1998.  “Combining Card Marking with Remembered Sets: How to Save Scanning Time@footnote{http://pdf.aminer.org/000/465/100/combining_card_marking_with_remembered_sets_how_to_save_scanning.pdf}”. ACM. ISMM’98 pp. 10–19.

@cartouche
@quotation Abstract 
We consider the combination of card marking with remembered sets
for generational garbage collection as suggested by Hosking and
Moss. When more than two generations are used, a naive
implementation may cause excessive and wasteful scanning of the
cards and thus increase the collection time. We offer a simple
data structure and a corresponding algorithm to keep track of
which cards need be scanned for which generation. We then extend
these ideas for the Train Algorithm of Hudson and Moss. Here, the
solution is more involved, and allows tracking of which card
should be scanned for which car-collection in the train.
@end quotation
@end cartouche

@item @anchor{bib baker77}@anchor{14e0}
Henry G. Baker, Carl Hewitt. 1977.  “The Incremental Garbage Collection of Processes@footnote{http://home.pipeline.com/~hbaker1/Futures.html}”. ACM. SIGPLAN Notices 12, 8 (August 1977), pp. 55–59.

@cartouche
@quotation Abstract 
This paper investigates some problems associated with an argument
evaluation order that we call “future” order, which is different
from both call-by-name and call-by-value. In call-by-future, each
formal parameter of a function is bound to a separate process
(called a “future”) dedicated to the evaluation of the
corresponding argument. This mechanism allows the fully parallel
evaluation of arguments to a function, and has been shown to
augment the expressive power of a language.

We discuss an approach to a problem that arises in this context:
futures which were thought to be relevant when they were created
become irrelevant through being ignored in the body of the
expression where they were bound. The problem of irrelevant
processes also appears in multiprocessing problem-solving systems
which start several processors working on the same problem but
with different methods, and return with the solution which
finishes first. This “parallel method strategy” has the drawback
that the processes which are investigating the losing methods must
be identified, stopped, and reassigned to more useful tasks.

The solution we propose is that of garbage collection. We propose
that the goal structure of the solution plan be explicitly
represented in memory as part of the graph memory (like Lisp’s
heap) so that a garbage collection algorithm can discover which
processes are performing useful work, and which can be recycled
for a new task. An incremental algorithm for the unified garbage
collection of storage and processes is described.
@end quotation
@end cartouche

@item @anchor{bib baker78}@anchor{14e1}
Henry G. Baker. 1978.  “List Processing in Real Time on a Serial Computer@footnote{http://home.pipeline.com/~hbaker1/RealTimeGC.html}”. ACM. Communications of the ACM 21, 4 (April 1978), pp. 280–294.

@cartouche
@quotation Abstract 
A real-time list processing system is one in which the time
required by the elementary list operations (e.g. CONS, CAR, CDR,
RPLACA, RPLACD, EQ, and ATOM in LISP) is bounded by a (small)
constant. Classical implementations of list processing systems
lack this property because allocating a list cell from the heap
may cause a garbage collection, which process requires time
proportional to the heap size to finish. A real-time list
processing system is presented which continuously reclaims
garbage, including directed cycles, while linearizing and
compacting the accessible cells into contiguous locations to avoid
fragmenting the free storage pool. The program is small and
requires no time-sharing interrupts, making it suitable for
microcode. Finally, the system requires the same average time, and
not more than twice the space, of a classical implementation, and
those space requirements can be reduced to approximately classical
proportions by compact list representation. Arrays of different
sizes, a program stack, and hash linking are simple extensions to
our system, and reference counting is found to be inferior for
many applications.
@end quotation
@end cartouche

@item @anchor{bib baker79}@anchor{14e2}
Henry G. Baker. 1979.  “Optimizing Allocation and Garbage Collection of Spaces@footnote{http://home.pipeline.com/~hbaker1/OptAlloc.html}”. In Winston and Brown, eds. `Artificial Intelligence: An MIT Perspective.' MIT Press.

@cartouche
@quotation Abstract 
MACLISP, unlike some other implementations of LISP, allocates
storage for different types of objects in noncontiguous areas
called “spaces”. These spaces partition the active storage into
disjoint areas, each of which holds a different type of object.
For example, “list cells” are stored in one space, “full-word
integers” reside in another space, “full-word floating point
numbers” in another, and so on.

Allocating space in this manner has several advantages. An
object’s type can easily be computed from a pointer to it, without
any memory references to the object itself. Thus, the LISP
primitive ATOM(x) can easily compute its result without even
paging in x. Another advantage is that the type of an object does
not require any storage within the object, so that arithmetic with
hardware data types such as full-word integers can use hardware
instructions directly.

There are problems associated with this method of storage and type
management, however. When all data types are allocated from the
same heap, there is no problem with varying demand for the
different data types; all data types require storage from the same
pool, so that only the total amount of storage is important. Once
different data types must be allocated from different spaces,
however, the relative sizes of the spaces becomes important.
@end quotation
@end cartouche

@item @anchor{bib baker91}@anchor{14e3}
Henry G. Baker. 1991.  “Cache-Conscious Copying Collectors@footnote{http://home.pipeline.com/~hbaker1/CacheCGC.html}”. OOPSLA’91/GC’91 Workshop on Garbage Collection.

@cartouche
@quotation Abstract 
Garbage collectors must minimize the scarce resources of cache
space and off-chip communications bandwidth to optimize
performance on modern single-chip computer architectures.
Strategies for achieving these goals in the context of copying
garbage collection are discussed. A multi-processor
mutator/collector system is analyzed. Finally, the Intel 80860XP
architecture is studied.
@end quotation
@end cartouche

@item @anchor{bib baker92a}@anchor{14e4}
Henry G. Baker. 1992.  “Lively Linear Lisp -- 'Look Ma@comma{} No Garbage!'@footnote{http://home.pipeline.com/~hbaker1/LinearLisp.html}”. ACM. SIGPLAN Notices 27, 8 (August 1992), pp. 89–98.

@cartouche
@quotation Abstract 
Linear logic has been proposed as one solution to the problem of
garbage collection and providing efficient “update-in-place”
capabilities within a more functional language. Linear logic
conserves accessibility, and hence provides a “mechanical
metaphor” which is more appropriate for a distributed-memory
parallel processor in which copying is explicit. However, linear
logic’s lack of sharing may introduce significant inefficiencies
of its own.

We show an efficient implementation of linear logic called “Linear
Lisp” that runs within a constant factor of non-linear logic. This
Linear Lisp allows RPLACX operations, and manages storage as
safely as a non-linear Lisp, but does not need a garbage
collector. Since it offers assignments but no sharing, it occupies
a twilight zone between functional languages and imperative
languages. Our Linear Lisp Machine offers many of the same
capabilities as combinator/graph reduction machines, but without
their copying and garbage collection problems.
@end quotation
@end cartouche

@item @anchor{bib baker92c}@anchor{14e5}
Henry G. Baker. 1992.  “The Treadmill: Real-Time Garbage Collection Without Motion Sickness@footnote{http://home.pipeline.com/~hbaker1/NoMotionGC.html}”. ACM. SIGPLAN Notices 27, 3 (March 1992), pp. 66–70.

@cartouche
@quotation Abstract 
A simple real-time garbage collection algorithm is presented which
does not copy, thereby avoiding some of the problems caused by the
asynchronous motion of objects. This in-place “treadmill” garbage
collection scheme has approximately the same complexity as other
non-moving garbage collectors, thus making it usable in a
high-level language implementation where some pointers cannot be
traced. The treadmill is currently being used in a Lisp system
built in Ada.
@end quotation
@end cartouche

@item @anchor{bib baker92}@anchor{14e6}
Henry G. Baker. 1992.  “CONS Should not CONS its Arguments@comma{} or@comma{} a Lazy Alloc is a Smart Alloc@footnote{http://home.pipeline.com/~hbaker1/LazyAlloc.html}”. ACM. SIGPLAN Notices 27, 3 (March 1992), 24–34.

@cartouche
@quotation Abstract 
“Lazy allocation” is a model for allocating objects on the
execution stack of a high-level language which does not create
dangling references. Our model provides safe transportation into
the heap for objects that may survive the deallocation of the
surrounding stack frame. Space for objects that do not survive the
deallocation of the surrounding stack frame is reclaimed without
additional effort when the stack is popped. Lazy allocation thus
performs a first-level garbage collection, and if the language
supports garbage collection of the heap, then our model can reduce
the amortized cost of allocation in such a heap by filtering out
the short-lived objects that can be more efficiently managed in
LIFO order. A run-time mechanism called “result expectation”
further filters out unneeded results from functions called only
for their effects. In a shared-memory multi-processor environment,
this filtering reduces contention for the allocation and
management of global memory.

Our model performs simple local operations, and is therefore
suitable for an interpreter or a hardware implementation. Its
overheads for functional data are associated only with
`assignments', making lazy allocation attractive for “mostly
functional” programming styles. Many existing stack allocation
optimizations can be seen as instances of this generic model, in
which some portion of these local operations have been optimized
away through static analysis techniques.

Important applications of our model include the efficient
allocation of temporary data structures that are passed as
arguments to anonymous procedures which may or may not use these
data structures in a stack-like fashion. The most important of
these objects are functional arguments (funargs), which require
some run-time allocation to preserve the local environment. Since
a funarg is sometimes returned as a first-class value, its
lifetime can survive the stack frame in which it was created.
Arguments which are evaluated in a lazy fashion (Scheme “delays”
or “suspensions”) are similarly handled. Variable-length argument
“lists” themselves can be allocated in this fashion, allowing
these objects to become “first-class”. Finally, lazy allocation
correctly handles the allocation of a Scheme control stack,
allowing Scheme continuations to become first-class values.
@end quotation
@end cartouche

@item @anchor{bib baker92b}@anchor{14e7}
Henry G. Baker. 1992.  “NREVERSAL of Fortune -- The Thermodynamics of Garbage Collection@footnote{http://home.pipeline.com/~hbaker1/ReverseGC.html}”. Springer-Verlag. LNCS Vol. 637.

@cartouche
@quotation Abstract 
The need to `reverse' a computation arises in many contexts –
debugging, editor undoing, optimistic concurrency undoing,
speculative computation undoing, trace scheduling, exception
handling undoing, database recovery, optimistic discrete event
simulations, subjunctive computing, etc. The need to `analyze' a
reversed computation arises in the context of static analysis –
liveness analysis, strictness analysis, type inference, etc.
Traditional means for restoring a computation to a previous state
involve checkpoints; checkpoints require time to copy, as well as
space to store, the copied material. Traditional reverse abstract
interpretation produces relatively poor information due to its
inability to guess the previous values of assigned-to variables.

We propose an abstract computer model and a programming language
– Psi-Lisp – whose primitive operations are injective and hence
reversible, thus allowing arbitrary undoing without the overheads
of checkpointing. Such a computer can be built from reversible
conservative logic circuits, with the serendipitous advantage of
dissipating far less heat than traditional Boolean AND/OR/NOT
circuits. Unlike functional languages, which have one “state” for
all times, Psi-Lisp has at all times one “state”, with unique
predecessor and successor states.

Compiling into a reversible pseudocode can have benefits even when
targeting a traditional computer. Certain optimizations, e.g.,
update-in-place, and compile-time garbage collection may be more
easily performed, because the information may be elicited without
the difficult and time-consuming iterative abstract interpretation
required for most non-reversible models.

In a reversible machine, garbage collection for recycling storage
can always be performed by a reversed (sub)computation. While this
“collection is reversed mutation” insight does not reduce space
requirements when used for the computation as a whole, it does
save space when used to recycle at finer scales. This insight also
provides an explanation for the fundamental importance of the
push-down stack both for recognizing palindromes and for managing
storage.

Reversible computers are related to `Prolog', `linear logic' and
`chemical abstract machines'.
@end quotation
@end cartouche

@item @anchor{bib baker93}@anchor{14e8}
Henry G. Baker. 1993.  “'Infant Mortality' and Generational Garbage Collection@footnote{http://home.pipeline.com/~hbaker1/YoungGen.html}”. ACM. SIGPLAN Notices 28, 4 (April 1993), pp. 55–57.

@cartouche
@quotation Abstract 
Generation-based garbage collection has been advocated by
appealing to the intuitive but vague notion that “young objects
are more likely to die than old objects”. The intuition is, that
if a generation-based garbage collection scheme focuses its effort
on scanning recently created objects, then its scanning efforts
will pay off more in the form of more recovered garbage, than if
it scanned older objects. In this note, we show a counterexample
of a system in which “infant mortality” is as high as you please,
but for which generational garbage collection is ineffective for
improving the average mark/cons ratio. Other benefits, such as
better locality and a smaller number of large delays, may still
make generational garbage collection attractive for such a system,
however.
@end quotation
@end cartouche

@item @anchor{bib baker93a}@anchor{14e9}
Henry G. Baker. 1993.  “Equal Rights for Functional Objects or@comma{} The More Things Change@comma{} The More They Are the Same@footnote{http://home.pipeline.com/~hbaker1/ObjectIdentity.html}”. ACM. OOPS Messenger 4, 4 (October 1993), pp. 2–27.

@cartouche
@quotation Abstract 
We argue that intensional object identity in object-oriented
programming languages and databases is best defined operationally
by side-effect semantics. A corollary is that “functional” objects
have extensional semantics. This model of object identity, which
is analogous to the normal forms of relational algebra, provides
cleaner semantics for the value-transmission operations and
built-in primitive equality predicate of a programming language,
and eliminates the confusion surrounding “call-by-value” and
“call-by-reference” as well as the confusion of multiple equality
predicates.

Implementation issues are discussed, and this model is shown to
have significant performance advantages in persistent, parallel,
distributed and multilingual processing environments. This model
also provides insight into the “type equivalence” problem of
Algol-68, Pascal and Ada.
@end quotation
@end cartouche

@item @anchor{bib baker94}@anchor{14ea}
Henry G. Baker. 1994.  “Minimizing Reference Count Updating with Deferred and Anchored Pointers for Functional Data Structures@footnote{http://home.pipeline.com/~hbaker1/LRefCounts.html}”. ACM. SIGPLAN Notices 29, 9 (September 1994), pp. 38–43.

@cartouche
@quotation Abstract 
“Reference counting” can be an attractive form of dynamic storage
management. It recovers storage promptly and (with a garbage stack
instead of a free list) it can be made “real-time” – i.e., all
accesses can be performed in constant time. Its major drawbacks
are its inability to reclaim cycles, its count storage, and its
count update overhead. Update overhead is especially irritating
for functional (read-only) data where updates may dirty pristine
cache lines and pages.

We show how reference count updating can be largely eliminated for
functional data structures by using the “linear style” of
programming that is inspired by Girard’s linear logic, and by
distinguishing normal pointers from “anchored pointers”, which
indicate not only the object itself, but also the depth of the
stack frame that anchors the object. An “anchor” for a pointer is
essentially an enclosing data structure that is temporarily locked
from being collected for the duration of the anchored pointer’s
existence by a deferred reference count. An “anchored pointer”
thus implies a reference count increment that has been deferred
until it is either cancelled or performed.

Anchored pointers are generalizations of “borrowed” pointers and
“phantom” pointers. Anchored pointers can provide a solution to
the “derived pointer problem” in garbage collection.
@end quotation
@end cartouche

@item @anchor{bib baker94a}@anchor{14eb}
Henry G. Baker. 1994.  “Thermodynamics and Garbage Collection@footnote{http://home.pipeline.com/~hbaker1/ThermoGC.html}”. ACM. SIGPLAN Notices 29, 4 (April 1994), pp. 58–63.

@cartouche
@quotation Abstract 
We discuss the principles of statistical thermodynamics and their
application to storage management problems. We point out problems
which result from imprecise usage of the terms “information”,
“state”, “reversible”, “conservative”, etc.
@end quotation
@end cartouche

@item @anchor{bib baker95a}@anchor{14ec}
Henry G. Baker. 1995.  “'Use-Once' Variables and Linear Objects -- Storage Management@comma{} Reflection and Multi-Threading@footnote{http://home.pipeline.com/~hbaker1/Use1Var.html}”. ACM. SIGPLAN Notices 30, 1 (January 1995), pp. 45–52.

@cartouche
@quotation Abstract 
Programming languages should have ‘use-once’ variables in addition
to the usual ‘multiple-use’ variables. ‘Use-once’ variables are
bound to linear (unshared, unaliased, or singly-referenced)
objects. Linear objects are cheap to access and manage, because
they require no synchronization or tracing garbage collection.
Linear objects can elegantly and efficiently solve otherwise
difficult problems of functional/mostly-functional systems –
e.g., in-place updating and the efficient initialization of
functional objects. Use-once variables are ideal for directly
manipulating resources which are inherently linear such as
freelists and ‘engine ticks’ in reflective languages.

A ‘use-once’ variable must be dynamically referenced exactly once
within its scope. Unreferenced use-once variables must be
explicitly killed, and multiply-referenced use-once variables must
be explicitly copied; this duplication and deletion is subject to
the constraint that some linear datatypes do not support
duplication and deletion methods. Use-once variables are bound
only to linear objects, which may reference other linear or
non-linear objects. Non-linear objects can reference other
non-linear objects, but can reference a linear object only in a
way that ensures mutual exclusion.

Although implementations have long had implicit use-once variables
and linear objects, most languages do not provide the programmer
any help for their utilization. For example, use-once variables
allow for the safe/controlled use of reified language
implementation objects like single-use continuations.

Linear objects and use-once variables map elegantly into dataflow
models of concurrent computation, and the graphical
representations of dataflow models make an appealing visual linear
programming language.
@end quotation
@end cartouche

@item @anchor{bib baker95}@anchor{14ed}
Henry G. Baker. 1995. `Memory Management: International Workshop IWMM’95'. Springer-Verlag. ISBN 3-540-60368-9.

@cartouche
@quotation From the Preface 
The International Workshop on Memory Management 1995 (IWMM’95) is
a continuation of the excellent series started by Yves Bekkers and
Jacques Cohen with IWMM’92. The present volume assembles the
refereed and invited technical papers which were presented during
this year’s workshop.
@end quotation
@end cartouche

@item @anchor{bib bbw97}@anchor{14ee}
Nick Barnes, Richard Brooksby, David Jones, Gavin Matthews, Pekka P. Pirinen, Nick Dalton, P. Tucker Withington. 1997. “A Proposal for a Standard Memory Management Interface@footnote{http://www.cs.utexas.edu/ftp/garbage/GC97/withingt.ps}”. OOPSLA97 Workshop on Garbage Collection and Memory Management.

@cartouche
@quotation From the notes 
There is no well-defined memory-management library API which would
allow programmers to easily choose the best memory management
implementation for their application.

Some languages allow replacement of their memory management
functions, but usually only the program API is specified, hence
replacement of the entire program interface is required.

Few languages support multiple memory management policies within a
single program. Those that do use proprietary memory management
policies.

We believe that the design of an abstract program API is a
prerequisite to the design of a “server” API and eventually an API
that would permit multiple cooperating memory “servers”. If the
interface is simple yet powerful enough to encompass most memory
management systems, it stands a good chance of being widely
adopted.
@end quotation
@end cartouche

@item @anchor{bib zorn93b}@anchor{14ef}
David A. Barrett, Benjamin Zorn. 1993. “Using Lifetime Predictors to Improve Memory Allocation Performance@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.6712&rep=rep1&type=pdf}”. ACM. SIGPLAN’93 Conference on Programming Language Design and Implementation, pp. 187–196.

@cartouche
@quotation Abstract 
Dynamic storage allocation is used heavily in many application
areas including interpreters, simulators, optimizers, and
translators. We describe research that can improve all aspects of
the performance of dynamic storage allocation by predicting the
lifetimes of short-lived objects when they are allocated. Using
five significant, allocation-intensive C programs, we show that a
great fraction of all bytes allocated are short-lived (> 90% in
all cases). Furthermore, we describe an algorithm for lifetime
prediction that accurately predicts the lifetimes of 42–99% of all
objects allocated. We describe and simulate a storage allocator
that takes advantage of lifetime prediction of short-lived objects
and show that it can significantly improve a program’s memory
overhead and reference locality, and even, at times, improve CPU
performance as well.
@end quotation
@end cartouche

@item @anchor{bib barrett93}@anchor{14f0}
David A. Barrett, Benjamin Zorn. 1995. “Garbage Collection using a Dynamic Threatening Boundary@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.45.1835&rep=rep1&type=pdf}”. ACM. SIGPLAN’95 Conference on Programming Language Design and Implementation, pp. 301–314.

@cartouche
@quotation Abstract 
Generational techniques have been very successful in reducing the
impact of garbage collection algorithms upon the performance of
programs. However, it is impossible for designers of collection
algorithms to anticipate the memory allocation behavior of all
applications in advance. Existing generational collectors rely
upon the applications programmer to tune the behavior of the
collector to achieve maximum performance for each application.
Unfortunately, because the many tuning parameters require detailed
knowledge of both the collection algorithm and the program
allocation behavior in order to be used effectively, such tuning
is difficult and error prone. We propose a new garbage collection
algorithm that uses just two easily understood tuning parameters
that directly reflect the maximum memory and pause time
constraints familiar to application programmers and users.

Like generational collectors, ours divides memory into two spaces,
one for short-lived, and another for long-lived objects. Unlike
previous work, our collector dynamically adjusts the boundary
between these two spaces in order to directly meet the resource
constraints specified by the user. We describe two methods for
adjusting this boundary, compare them with several existing
algorithms, and show how effectively ours meets the specified
constraints. Our pause time collector saved memory by holding
median pause times closer to the constraint than the other pause
time constrained algorithm and, when not over-constrained, our
memory constrained collector exhibited the lowest CPU overhead of
the algorithms we measured yet was capable of maintaining a
maximum memory constraint.
@end quotation
@end cartouche

@item @anchor{bib bartlett88}@anchor{14f1}
Joel F. Bartlett. 1988. “Compacting Garbage Collection with Ambiguous Roots@footnote{http://computer-refuge.org/classiccmp/ftp.digital.com-jun2004/pub/Compaq/WRL/research-reports/WRL-TR-88.2.pdf}”. Digital Equipment Corporation.

@cartouche
@quotation Abstract 
This paper introduces a copying garbage collection algorithm which
is able to compact most of the accessible storage in the heap
without having an explicitly defined set of pointers that contain
all the roots of all accessible storage. Using “hints” found in
the processor’s registers and stack, the algorithm is able to
divide heap allocated objects into two groups: those that might be
referenced by a pointer in the stack or registers, and those that
are not. The objects which might be referenced are left in place,
and the other objects are copied into a more compact
representation.

A Lisp compiler and runtime system which uses such a collector
need not have complete control of the processor in order to force
a certain discipline on the stack and registers. A Scheme
implementation has been done for the Digital WRL Titan processor
which uses a garbage collector based on this “mostly copying”
algorithm. Like other languages for the Titan, it uses the Mahler
intermediate language as its target. This simplifies the compiler
and allows it to take advantage of the significant machine
dependent optimizations provided by Mahler. The common
intermediate language also simplifies call-outs from Scheme
programs to functions written in other languages and call-backs
from functions in other languages.

Measurements of the Scheme implementation show that the algorithm
is efficient, as little unneeded storage is retained and only a
very small fraction of the heap is left in place.

Simple pointer manipulation protocols also mean that compiler
support is not needed in order to correctly handle pointers. Thus
it is reasonable to provide garbage collected storage in languages
such as C. A collector written in C which uses this algorithm is
included in the Appendix.
@end quotation
@end cartouche

@item @anchor{bib bartlett89}@anchor{14f2}
Joel F. Bartlett. 1989. “Mostly-Copying Garbage Collection Picks Up Generations and C++@footnote{http://www.hpl.hp.com/techreports/Compaq-DEC/WRL-TN-12.pdf}”. Digital Equipment Corporation.

@cartouche
@quotation Abstract 
The “mostly-copying” garbage collection algorithm provides a way
to perform compacting garbage collection in spite of the presence
of ambiguous pointers in the root set. As originally defined, each
collection required almost all accessible objects to be moved.
While adequate for many applications, programs that retained a
large amount of storage spent a significant amount of time garbage
collecting. To improve performance of these applications, a
generational version of the algorithm has been designed. This note
reports on this extension of the algorithm, and its application in
collectors for Scheme and C++.
@end quotation
@end cartouche

@item @anchor{bib bc92}@anchor{14f3}
Yves Bekkers & Jacques Cohen. 1992. “Memory Management@comma{} International Workshop IWMM 92@footnote{http://www.informatik.uni-trier.de/%7Eley/db/conf/iwmm/iwmm92.html}”. Springer-Verlag. LNCS Vol. 637, ISBN 3-540-55940-X.

@item @anchor{bib bb99}@anchor{14f4}
Emery D. Berger, Robert D. Blumofe. 1999. “Hoard: A Fast@comma{} Scalable@comma{} and Memory-Efficient Allocator for Shared-Memory Multiprocessors@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.81.5049&rep=rep1&type=pdf}”. University of Texas at Austin. UTCS TR99-22.

@cartouche
@quotation Abstract 
In this paper, we present Hoard, a memory allocator for
shared-memory multiprocessors. We prove that its worst-case memory
fragmentation is asymptotically equivalent to that of an optimal
uniprocessor allocator. We present experiments that demonstrate
its speed and scalability.
@end quotation
@end cartouche

@item @anchor{bib berger01}@anchor{14f5}
Emery D. Berger, Benjamin G. Zorn, Kathryn S. McKinley. 2001. “Composing high-performance memory allocators@footnote{http://www.cs.utexas.edu/users/speedway/DaCapo/papers/pldi2001.pdf}” ACM SIGPLAN Conference on Programming Language Design and Implementation 2001, pp. 114–124.

@cartouche
@quotation Abstract 
Current general-purpose memory allocators do not provide
sufficient speed or flexibility for modern high-performance
applications. Highly-tuned general purpose allocators have
per-operation costs around one hundred cycles, while the cost of
an operation in a custom memory allocator can be just a handful of
cycles. To achieve high performance, programmers often write
custom memory allocators from scratch – a difficult and
error-prone process.

In this paper, we present a flexible and efficient infrastructure
for building memory allocators that is based on C++ templates and
inheritance. This novel approach allows programmers to build
custom and general-purpose allocators as “heap layers” that can be
composed without incurring any additional runtime overhead or
additional programming cost. We show that this infrastructure
simplifies allocator construction and results in allocators that
either match or improve the performance of heavily-tuned
allocators written in C, including the Kingsley allocator and the
GNU obstack library. We further show this infrastructure can be
used to rapidly build a general-purpose allocator that has
performance comparable to the Lea allocator, one of the best
uniprocessor allocators available. We thus demonstrate a clean,
easy-to-use allocator interface that seamlessly combines the power
and efficiency of any number of general and custom allocators
within a single application.
@end quotation
@end cartouche

@item @anchor{bib bw88}@anchor{14f6}
Hans-J. Boehm, Mark Weiser. 1988. “Garbage collection in an uncooperative environment@footnote{http://hboehm.info/spe_gc_paper/preprint.pdf}”. Software – Practice and Experience. 18(9):807–820.

@cartouche
@quotation Abstract 
We describe a technique for storage allocation and garbage
collection in the absence of significant co-operation from the
code using the allocator. This limits garbage collection overhead
to the time actually required for garbage collection. In
particular, application programs that rarely or never make use of
the collector no longer encounter a substantial performance
penalty. This approach greatly simplifies the implementation of
languages supporting garbage collection. It further allows
conventional compilers to be used with a garbage collector, either
as the primary means of storage reclamation, or as a debugging
tool.
@end quotation
@end cartouche

@item @anchor{bib bds91}@anchor{14f7}
Hans-J. Boehm, Alan J. Demers, Scott Shenker. 1991. “Mostly Parallel Garbage Collection@footnote{http://hboehm.info/gc/papers/pldi91.ps.Z}”. Xerox PARC. ACM PLDI 91, SIGPLAN Notices 26, 6 (June 1991), pp. 157–164.

@cartouche
@quotation Abstract 
We present a method for adapting garbage collectors designed to
run sequentially with the client, so that they may run
concurrently with it. We rely on virtual memory hardware to
provide information about pages that have been updated or
“dirtied” during a given period of time. This method has been used
to construct a mostly parallel trace-and-sweep collector that
exhibits very short pause times. Performance measurements are
given.
@end quotation
@end cartouche

@item @anchor{bib bc92a}@anchor{14f8}
Hans-J. Boehm, David Chase. 1992. “A Proposal for Garbage-Collector-Safe C Compilation@footnote{http://hboehm.info/gc/papers/boecha.ps.gz}”. `Journal of C Language Translation.' vol. 4, 2 (December 1992), pp. 126–141.

@cartouche
@quotation Abstract 
Conservative garbage collectors are commonly used in combination
with conventional C programs. Empirically, this usually works
well. However, there are no guarantees that this is safe in the
presence of “improved” compiler optimization. We propose that C
compilers provide a facility to suppress optimizations that are
unsafe in the presence of conservative garbage collection. Such a
facility can be added to an existing compiler at very minimal
cost, provided the additional analysis is done in a
machine-independent source-to-source prepass. Such a prepass may
also check the source code for garbage-collector-safety.
@end quotation
@end cartouche

@item @anchor{bib boehm93}@anchor{14f9}
Hans-J. Boehm. 1993. “Space Efficient Conservative Garbage Collection@footnote{http://hboehm.info/gc/papers/pldi93.ps.Z}”. ACM, SIGPLAN. Proceedings of the ACM SIGPLAN ‘91 Conference on Programming Language Design and Implementation, SIGPLAN Notices 28, 6, pp 197–206.

@cartouche
@quotation Abstract 
We call a garbage collector conservative if it has only partial
information about the location of pointers, and is thus forced to
treat arbitrary bit patterns as though they might be pointers, in
at least some cases. We show that some very inexpensive, but
previously unused techniques can have dramatic impact on the
effectiveness of conservative garbage collectors in reclaiming
memory. Our most significant observation is that static data that
appears to point to the heap should not result in misidentified
reference to the heap. The garbage collector has enough
information to allocate around such references. We also observe
that programming style has a significantly impact on the amount of
spuriously retained storage, typically even if the collector is
not terribly conservative. Some fairly common C and C++
programming styles significantly decrease the effectiveness of any
garbage collector. These observations suffice to explain some of
the different assessments of conservative collection that have
appeared in the literature.
@end quotation
@end cartouche

@item @anchor{bib boehm00}@anchor{14fa}
Hans-J. Boehm. 2000. “Reducing Garbage Collector Cache Misses@footnote{http://www.hpl.hp.com/techreports/2000/HPL-2000-99.html}”. ACM. ISMM’00 pp. 59–64.

@cartouche
@quotation Abstract 
Cache misses are currently a major factor in the cost of garbage
collection, and we expect them to dominate in the future.
Traditional garbage collection algorithms exhibit relatively litle
temporal locality; each live object in the heap is likely to be
touched exactly once during each garbage collection. We measure
two techniques for dealing with this issue: prefetch-on-grey, and
lazy sweeping. The first of these is new in this context. Lazy
sweeping has been in common use for a decade. It was introduced as
a mechanism for reducing paging and pause times; we argue that it
is also crucial for eliminating cache misses during the sweep
phase.

Our measurements are obtained in the context of a non-moving
garbage collector. Fully copying garbage collection inherently
requires more traffic through the cache, and thus probably also
stands to benefit substantially from something like the
prefetch-on-grey technique. Generational garbage collection may
reduce the benefit of these techniques for some applications, but
experiments with a non-moving generational collector suggest that
they remain quite useful.
@end quotation
@end cartouche

@item @anchor{bib boehm01}@anchor{14fb}
Hans-J. Boehm. 2001. “Bounding Space Usage of Conservative Garbage Collectors @indicateurl{http://www.hpl.hp.com/techreports/2001/HPL-2001-251.html}”. HP Labs technical report HPL-2001-251.

@cartouche
@quotation Abstract 
Conservative garbage collectors can automatically reclaim unused
memory in the absence of precise pointer location information. If
a location can possibly contain a pointer, it is treated by the
collector as though it contained a pointer. Although it is
commonly assumed that this can lead to unbounded space use due to
misidentified pointers, such extreme space use is rarely observed
in practice, and then generally only if the number of
misidentified pointers is itself unbounded. We show that if the
program manipulates only data structures satisfying a simple
GC-robustness criterion, then a bounded number of misidentified
pointers can result at most in increasing space usage by a
constant factor. We argue that nearly all common data structures
are already GC- robust, and it is typically easy to identify and
replace those that are not. Thus it becomes feasible to prove
space bounds on programs collected by mildly conservative garbage
collectors, such as the one in Barabash et al. (2001). The
worst-case space overhead introduced by such mild conservatism is
comparable to the worst-case fragmentation overhead for inherent
in any non-moving storage allocator. The same GC-robustness
criterion also ensures the absence of temporary space leaks of the
kind discussed in Rojemo (1995) for generational garbage
collectors.
@end quotation
@end cartouche

@item @anchor{bib boehm02}@anchor{246}
Hans-J. Boehm. 2002. “Destructors@comma{} Finalizers@comma{} and Synchronization@footnote{http://www.hpl.hp.com/techreports/2002/HPL-2002-335.html}”. HP Labs technical report HPL-2002-335.

@cartouche
@quotation Abstract 
We compare two different facilities for running cleanup actions
for objects that are about to reach the end of their life.
Destructors, such as we find in C++, are invoked synchronously
when an object goes out of scope. They make it easier to implement
cleanup actions for objects of well-known lifetime, especially in
the presence of exceptions. Languages like Java, Modula-3, and C#
provide a different kind of “finalization” facility: Cleanup
methods may be run when the garbage collector discovers a heap
object to be otherwise inaccessible. Unlike C++ destructors, such
methods run in a separate thread at some much less well-defined
time. We argue that these are fundamentally different, and
potentially complementary, language facilities. We also try to
resolve some common misunderstandings about finalization in the
process. In particular: 1. The asynchronous nature of finalizers
is not just an accident of implementation or a shortcoming of
tracing collectors; it is necessary for correctness of client
code, fundamentally affects how finalizers must be written, and
how finalization facilities should be presented to the user. 2. An
object may legitimately be finalized while one of its methods are
still running. This should and can be addressed by the language
specification and client code.
@end quotation
@end cartouche

@item @anchor{bib bm77}@anchor{14fc}
Robert S. Boyer and J. Strother Moore. 1977. “A Fast String Searching Algorithm@footnote{http://www.cs.utexas.edu/~moore/publications/fstrpos.pdf}”. `Communications of the ACM' 20(10):762–772.

@cartouche
@quotation Abstract 
An algorithm is presented that searches for the location, “`i',”
of the first occurrence of a character string, “`pat',” in another
string, “`string'.” During the search operation, the characters of
`pat' are matched starting with the last character of `pat'. The
information gained by starting the match at the end of the pattern
often allows the algorithm to proceed in large jumps through the
text being searched. Thus the algorithm has the unusual property
that, in most cases, not all of the first `i' characters of
`string' are inspected. The number of characters actually
inspected (on the average) decreases as a function of the length
of `pat'. For a random English pattern of length 5, the algorithm
will typically inspect `i'/4 characters of string before finding a
match at `i'. Furthermore, the algorithm has been implemented so
that (on the average) fewer than `i' + `patlen' machine
instructions are executed. These conclusions are supported with
empirical evidence and a theoretical analysis of the average
behavior of the algorithm. The worst case behavior of the
algorithm is linear in `i' + `patlen', assuming the availability
of array space for tables linear in `patlen' plus the size of the
alphabet.
@end quotation
@end cartouche

@item @anchor{bib bl72}@anchor{14fd}
P. Branquart, J. Lewi. 1972. “A scheme of storage allocation and garbage collection for ALGOL 68”. Elsevier/North-Holland. ALGOL 68 Implementation – Proceedings of the IFIP Working Conference on ALGOL 68 Implementation, July 1970.

@item @anchor{bib brooksby02}@anchor{2e}
Richard Brooksby. 2002. “The Memory Pool System: Thirty person-years of memory management development goes Open Source@footnote{https://www.ravenbrook.com/project/mps/doc/2002-01-30/ismm2002-paper/}”. ISMM’02.

@cartouche
@quotation Abstract 
The Memory Pool System (MPS) is a very general, adaptable,
flexible, reliable, and efficient memory management system. It
permits the flexible combination of memory management techniques,
supporting manual and automatic memory management, in-line
allocation, finalization, weakness, and multiple simultaneous
co-operating incremental generational garbage collections. It also
includes a library of memory pool classes implementing specialized
memory management policies.

Between 1994 and 2001, Harlequin (now part of Global Graphics)
invested about thirty person-years of effort developing the MPS.
The system contained many innovative techniques and abstractions
which were kept secret. In 1997 Richard Brooksby, the manager and
chief architect of the project, and Nicholas Barnes, a senior
developer, left Harlequin to form their own consultancy company,
Ravenbrook, and in 2001, Ravenbrook acquired the MPS technology
from Global Graphics. We are happy to announce that we are
publishing the source code and documentation under an open source
licence. This paper gives an overview of the system.
@end quotation
@end cartouche

@item @anchor{bib c1990}@anchor{14fe}
International Standard ISO/IEC 9899:1990. “Programming languages — C”.

@item @anchor{bib c1999}@anchor{14ff}
International Standard ISO/IEC 9899:1999. “Programming languages — C@footnote{http://www.open-std.org/jtc1/sc22/WG14/www/docs/n1256.pdf}”.

@item @anchor{bib cgz94}@anchor{1500}
Brad Calder, Dirk Grunwald, Benjamin Zorn. 1994. “Quantifying Behavioral Differences Between C and C++ Programs@footnote{http://cseclassic.ucsd.edu/users/calder/papers/JplVersion.pdf}”. `Journal of Programming Languages.' 2(4):313–351.

@cartouche
@quotation Abstract 
Improving the performance of C programs has been a topic of great
interest for many years. Both hardware technology and compiler
optimization research has been applied in an effort to make C
programs execute faster. In many application domains, the C++
language is replacing C as the programming language of choice. In
this paper, we measure the empirical behavior of a group of
significant C and C++ programs and attempt to identify and
quantify behavioral differences between them. Our goal is to
determine whether optimization technology that has been successful
for C programs will also be successful in C++ programs. We
furthermore identify behavioral characteristics of C++ programs
that suggest optimizations that should be applied in those
programs. Our results show that C++ programs exhibit behavior that
is significantly different than C programs. These results should
be of interest to compiler writers and architecture designers who
are designing systems to execute object-oriented programs.
@end quotation
@end cartouche

@item @anchor{bib cpc00}@anchor{1501}
Dante J. Cannarozzi, Michael P. Plezbert, Ron K. Cytron. 2000. “Contaminated garbage collection@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.9649&rep=rep1&type=pdf}”. ACM. Proceedings of the ACM SIGPLAN ‘00 conference on on Programming language design and implementation, pp. 264–273.

@cartouche
@quotation Abstract 
We describe a new method for determining when an object can be
garbage collected. The method does not require marking live
objects. Instead, each object `X' is `dynamically' associated with
a stack frame `M', such that `X' is collectable when `M' pops.
Because `X' could have been dead earlier, our method is
conservative. Our results demonstrate that the methos nonetheless
idenitifies a large percentage of collectable objects. The method
has been implemented in Sun’s Java™ Virtual Machine interpreter,
and results are presented based on this implementation.
@end quotation
@end cartouche

@item @anchor{bib cw86}@anchor{1502}
Patrick J. Caudill, Allen Wirfs-Brock. 1986. “A Third-Generation Smalltalk-80 Implementation”. ACM. SIGPLAN Notices. 21(11), OOPSLA’86 ACM Conference on Object-Oriented Systems, Languages and Applications.

@cartouche
@quotation Abstract 
A new, high performance Smalltalk-80™ implementation is described
which builds directly upon two previous implementation efforts.
This implementation supports a large object space while retaining
compatibility with previous Smalltalk-80™ images. The
implementation utilizes a interpreter which incorporates a
generation based garbage collector and which does not have an
object table. This paper describes the design decisions which lead
to this implementation and reports preliminary performance
results.
@end quotation
@end cartouche

@item @anchor{bib cheney70}@anchor{1503}
C. J. Cheney. 1970. “A non-recursive list compacting algorithm@footnote{http://people.cs.umass.edu/~emery/classes/cmpsci691s-fall2004/papers/p677-cheney.pdf}”. CACM. 13-11 pp. 677–678.

@cartouche
@quotation Abstract 
A simple nonrecursive list structure compacting scheme or garbage
collector suitable for both compact and LISP-like list structures
is presented. The algorithm avoids the need for recursion by using
the partial structure as it is built up to keep track of those
lists that have been copied.
@end quotation
@end cartouche

@item @anchor{bib chl98}@anchor{1504}
Perry Cheng, Robert Harper, Peter Lee. 1998. “Generational stack collection and profile-driven pretenuring@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.9229&rep=rep1&type=pdf}”. ACM. Proceedings of SIGPLAN’98 Conference on Programming Language Design and Implementation, pp. 162–173.

@cartouche
@quotation Abstract 
This paper presents two techniques for improving garbage
collection performance: generational stack collection and
profile-driven pretenuring. The first is applicable to stack-based
implementations of functional languages while the second is useful
for any generational collector. We have implemented both
techniques in a generational collector used by the TIL compiler,
and have observed decreases in garbage collection times of as much
as 70% and 30%, respectively.

Functional languages encourage the use of recursion which can lead
to a long chain of activation records. When a collection occurs,
these activation records must be scanned for roots. We show that
scanning many activation records can take so long as to become the
dominant cost of garbage collection. However, most deep stacks
unwind very infrequently, so most of the root information obtained
from the stack remains unchanged across successive garbage
collections. `Generational stack collection' greatly reduces the
stack scan cost by reusing information from previous scans.

Generational techniques have been successful in reducing the cost
of garbage collection. Various complex heap arrangements and
tenuring policies have been proposed to increase the effectiveness
of generational techniques by reducing the cost and frequency of
scanning and copying. In contrast, we show that by using profile
information to make lifetime predictions, `pretenuring' can avoid
copying data altogether. In essence, this technique uses a
refinement of the generational hypothesis (most data die young)
with a locality principle concerning the age of data: most
allocations sites produce data that immediately dies, while a few
allocation sites consistently produce data that survives many
collections.
@end quotation
@end cartouche

@item @anchor{bib cl98}@anchor{1505}
Trishul M. Chilimbi, James R. Larus. 1998. “Using Generational Garbage Collection To Implement Cache-Conscious Data Placement@footnote{http://ftp2.cs.wisc.edu/wwt/ismm98_cache_gc.pdf}”. ACM. ISMM’98 pp. 37–48.

@cartouche
@quotation Abstract 
Processor and memory technology trends show a continual increase
in the cost of accessing main memory. Machine designers have tried
to mitigate the effect of this trend through a variety of
techniques that attempt to reduce or tolerate memory latency.
These techniques, unfortunately, have only been partially
successful for pointer-manipulating programs. Recent research has
demonstrated that these programs can benefit greatly from the
complementary approach of reorganizing pointer data structures to
improve cache locality. This paper describes how a generational
garbage collector can be used to achieve a cache-conscious data
layout, in which objects with high temporal affinity are placed
next to each other, so they are likely to reside in the same cache
block. The paper demonstrates the feasibility of collecting low
overhead, real-time profiling information about data access
patterns for object-oriented languages, and describes a new
copying algorithm that utilizes this information to produce a
cache-conscious object layout. Preliminary results indicate that
this technique reduces cache miss rates by 21-42%, and improves
program performance by 14-37%.
@end quotation
@end cartouche

@item @anchor{bib ch97}@anchor{1506}
William D Clinger & Lars T Hansen. 1997. “Generational Garbage Collection and the Radioactive Decay Model@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.164.370&rep=rep1&type=pdf}”. ACM. Proceedings of PLDI 1997.

@cartouche
@quotation Abstract 
If a fixed exponentially decreasing probability distribution
function is used to model every object’s lifetime, then the age of
an object gives no information about its future life expectancy.
This `radioactive decay model' implies that there can be no
rational basis for deciding which live objects should be promoted
to another generation. Yet there remains a rational basis for
deciding how many objects to promote, when to collect garbage, and
which generations to collect.

Analysis of the model leads to a new kind of generational garbage
collector whose effectiveness does not depend upon heuristics that
predict which objects will live longer than others.

This result provides insight into the computational advantages of
generational garbage collection, with implications for the
management of objects whose life expectancies are difficult to
predict.
@end quotation
@end cartouche

@item @anchor{bib cohen81}@anchor{1507}
Jacques Cohen. 1981. “Garbage collection of linked data structures”. Computing Surveys. Vol. 13, no. 3.

@cartouche
@quotation Abstract 
A concise and unified view of the numerous existing algorithms for
performing garbage collection of linked data structures is
presented. The emphasis is on garbage collection proper, rather
than on storage allocation.

First, the classical garbage collection algorithms and their
marking and collecting phases, with and without compacting, are
discussed.

Algorithms describing these phases are classified according to the
type of cells to be collected: those for collecting single-sized
cells are simpler than those for varisized cells. Recently
proposed algorithms are presented and compared with the classical
ones. Special topics in garbage collection are also covered. A
bibliography with topical annotations is included.
@end quotation
@end cartouche

@item @anchor{bib ccz98}@anchor{1508}
Dominique Colnet, Philippe Coucaud, Olivier Zendra. 1998. “Compiler Support to Customize the Mark and Sweep Algorithm@footnote{http://pdf.aminer.org/000/465/134/compiler_support_to_customize_the_mark_and_sweep_algorithm.pdf}”. ACM. ISMM’98 pp. 154–165.

@cartouche
@quotation Abstract 
Mark and sweep garbage collectors (GC) are classical but still
very efficient automatic memory management systems. Although
challenged by other kinds of systems, such as copying collectors,
mark and sweep collectors remain among the best in terms of
performance.

This paper describes our implementation of an efficient mark and
sweep garbage collector tailored to each program. Compiler support
provides the type information required to statically and
automatically generate this customized garbage collector. The
segregation of object by type allows the production of a more
efficient GC code. This technique, implemented in SmallEiffel, our
compiler for the object-oriented language Eiffel, is applicable to
other languages and other garbage collection algorithms, be they
distributed or not.

We present the results obtained on programs featuring a variety of
programming styles and compare our results to a well-known and
high-quality garbage collector.
@end quotation
@end cartouche

@item @anchor{bib cwz93}@anchor{1509}
Jonathan E. Cook, Alexander L. Wolf, Benjamin Zorn. 1994. “Partition Selection Policies in Object Database Garbage Collection@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.3656&rep=rep1&type=pdf}”. ACM. SIGMOD. International Conference on the Management of Data (SIGMOD’94), pp. 371–382.

@cartouche
@quotation Abstract 
The automatic reclamation of storage for unreferenced objects is
very important in object databases. Existing language system
algorithms for automatic storage reclamation have been shown to be
inappropriate. In this paper, we investigate methods to improve
the performance of algorithms for automatic storage reclamation of
object databases. These algorithms are based on a technique called
partitioned garbage collection, in which a subset of the entire
database is collected independently of the rest. Specifically, we
investigate the policy that is used to select what partition in
the database should be collected. The new partition selection
policies that we propose and investigate are based on the
intuition that the values of overwritten pointers provide good
hints about where to find garbage. Using trace-driven simulation,
we show that one of our policies requires less I/O to collect more
garbage than any existing implementable policy and performs close
to an impractical-to-implement but near-optimal policy over a wide
range of database sizes and connectivities.
@end quotation
@end cartouche

@item @anchor{bib ckwz96}@anchor{150a}
Jonathan E. Cook, Artur Klauser, Alexander L. Wolf, Benjamin Zorn. 1996. “Semi-automatic@comma{} Self-adaptive Control of Garbage Collection Rates in Object Databases@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.46.8140&rep=rep1&type=pdf}”. ACM, SIGMOD. International Conference on the Management of Data (SIGMOD’96), pp. 377–388.

@cartouche
@quotation Abstract 
A fundamental problem in automating object database storage
reclamation is determining how often to perform garbage
collection. We show that the choice of collection rate can have a
significant impact on application performance and that the “best”
rate depends on the dynamic behavior of the application, tempered
by the particular performance goals of the user. We describe two
semi-automatic, self-adaptive policies for controlling collection
rate that we have developed to address the problem. Using
trace-driven simulations, we evaluate the performance of the
policies on a test database application that demonstrates two
distinct reclustering behaviors. Our results show that the
policies are effective at achieving user-specified levels of I/O
operations and database garbage percentage. We also investigate
the sensitivity of the policies over a range of object
connectivities. The evaluation demonstrates that semi-automatic,
self-adaptive policies are a practical means for flexibly
controlling garbage collection rate.
@end quotation
@end cartouche

@item @anchor{bib cns92}@anchor{150b}
Eric Cooper, Scott Nettles, Indira Subramanian. 1992. “Improving the Performance of SML Garbage Collection using Application-Specific Virtual Memory Management”. ACM Conference on LISP and Functional Programming, pp. 43–52.

@cartouche
@quotation Abstract 
We improved the performance of garbage collection in the Standard ML of
New Jersey system by using the virtual memory facilities provided by
the Mach kernel.  We took advantage of Mach’s support for large sparse
address spaces and user-defined paging servers.  We decreased the
elapsed time for realistic applications by as much as a factor of 4.
@end quotation
@end cartouche

@item @anchor{bib daconta93}@anchor{150c}
Michael C. Daconta. 1993. `C Pointers and Dynamic Memory Management.' Wiley. ISBN 0-471-56152-5.

@item @anchor{bib daconta95}@anchor{150d}
Michael C. Daconta. 1995. `C++ Pointers and Dynamic Memory Management.' Wiley. ISBN 0-471-04998-0.

@cartouche
@quotation From the back cover 
Using techniques developed in the classroom at America Online’s
Programmer’s University, Michael Daconta deftly pilots programmers
through the intricacies of the two most difficult aspects of C++
programming: pointers and dynamic memory management. Written by a
programmer for programmers, this no-nonsense, nuts-and-bolts guide
shows you how to fully exploit advanced C++ programming features,
such as creating class-specific allocators, understanding
references versus pointers, manipulating multidimensional arrays
with pointers, and how pointers and dynamic memory are the core of
object-oriented constructs like inheritance, name-mangling, and
virtual functions.
@end quotation
@end cartouche

@item @anchor{bib dahl63}@anchor{150e}
O.-J. Dahl. 1963. “The SIMULA Storage Allocation Scheme”. Norsk Regnesentral. NCC Document no. 162.

@item @anchor{bib denning68}@anchor{150f}
P. J. Denning. 1968. “Thrashing: Its Causes and Prevention@footnote{https://cs.uwaterloo.ca/~Brecht/courses/702/Possible-Readings/vm-and-gc/thrashing-denning-afips-1968.pdf}”. Proceedings AFIPS,1968 Fall Joint Computer Conference, vol. 33, pp. 915–922.

@cartouche
@quotation From the introduction 
A particularly troublesome phenomenon, thrashing, may seriously
interfere with the performance of paged memory systems, reducing
computing giants (Multics, IBM System 360, and others not
necessarily excepted) to computing dwarfs. The term thrashing
denotes excessive overhead and severe performance degradation or
collapse caused by too much paging. Thrashing inevitably turns a
shortage of memory space into a surplus of processor time.
@end quotation
@end cartouche

@item @anchor{bib denning70}@anchor{1510}
P. J. Denning. 1970. “Virtual Memory@footnote{http://denninginstitute.com/pjd/PUBS/VirtMem_1970.pdf}”. ACM. ACM Computing Surveys, vol. 2, no. 3, pp. 153–190, Sept. 1970.

@cartouche
@quotation Abstract 
The need for automatic storage allocation arises from desires for
program modularity, machine independence, and resource sharing.
Virtual memory is an elegant way of achieving these objectives. In
a virtual memory, the addresses a program may use to identify
information are distinguished from the addresses the memory system
uses to identify physical storage sites, and program-generated
addresses are translated automatically to the corresponding
machine addresses. Two principal methods for implementing virtual
memory, segmentation and paging, are compared and contrasted. Many
contemporary implementations have experienced one or more of these
problems: poor utilization of storage, thrashing, and high costs
associated with loading information into memory. These and
subsidiary problems are studied from a theoretic view, and are
shown to be controllable by a proper combination of hardware and
memory management policies.
@end quotation
@end cartouche

@item @anchor{bib ds72}@anchor{1511}
P. J. Denning, S. C. Schwartz. 1972. “Properties of the Working-set Model@footnote{http://denninginstitute.com/pjd/PUBS/WSProp_1972.pdf}”. CACM. vol. 15, no. 3, pp. 191–198.

@cartouche
@quotation Abstract 
A program’s working set `W'(`t', `T') at time `t' is the set of
distinct pages among the `T' most recently referenced pages.
Relations between the average working-set size, the missing-page
rate, and the interreference-interval distribution may be derived
both from time-average definitions and from ensemble-average
(statistical) definitions. An efficient algorithm for estimating
these quantities is given. The relation to LRU (least recently
used) paging is characterized. The independent-reference model, in
which page references are statistically independent, is used to
assess the effects of interpage dependencies on working-set size
observations. Under general assumptions, working-set size is shown
to be normally distributed.
@end quotation
@end cartouche

@item @anchor{bib detlefs92}@anchor{1512}
David L. Detlefs. 1992. “Garbage collection and runtime typing as a C++ library@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.71.2755&rep=rep1&type=pdf}”. USENIX C++ Conference.

@cartouche
@quotation From the introduction 
Automatic storage management, or `garbage collection', is a
feature that can ease program development and enhance program
reliability. Many high-level languages other than C++ provide
garbage collection. This paper proposes the use of “smart pointer”
template classes as an interface for the use of garbage collection
in C++. Template classes and operator overloading are techniques
allowing language extension at the level of user code; I claim
that using these techniques to create smart pointer classes
provdes a syntax for manipulating garbage-collected storage safely
and conveniently. Further, the use of a smart-pointer template
class offers the possibility of implementing the collector at the
user-level, without requiring support from the compiler. If such a
compiler-independent implementation is possible with adequate
performance, then programmers can start to write code using
garbage collection without waiting for language and compiler
modifications. If the use of such a garbage collection interface
becomes widespread, then C++ compilation systems can be built to
specially support tht garbage collection interface, thereby
allowing the use of collection algorithms with enhanced
performance.
@end quotation
@end cartouche

@item @anchor{bib zorn93}@anchor{1513}
David L. Detlefs, Al Dosser, Benjamin Zorn. 1994. “Memory Allocation Costs in Large C and C++ Programs@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.30.3073&rep=rep1&type=pdf}”. Software – Practice and Experience. 24(6):527–542.

@cartouche
@quotation Abstract 
Dynamic storage allocation is an important part of a large class
of computer programs written in C and C++. High-performance
algorithms for dynamic storage allocation have been, and will
continue to be, of considerable interest. This paper presents
detailed measurements of the cost of dynamic storage allocation in
11 diverse C and C++ programs using five very different dynamic
storage allocation implementations, including a conservative
garbage collection algorithm. Four of the allocator
implementations measured are publicly-available on the Internet. A
number of the programs used in these measurements are also
available on the Internet to facilitate further research in
dynamic storage allocation. Finally, the data presented in this
paper is an abbreviated version of more extensive statistics that
are also publicly-available on the Internet.
@end quotation
@end cartouche

@item @anchor{bib db76}@anchor{1514}
L. Peter Deutsch, Daniel G. Bobrow. 1976. “An Efficient@comma{} Incremental@comma{} Automatic Garbage Collector@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.63.4603&rep=rep1&type=pdf}”. CACM. vol. 19, no. 9, pp. 522–526.

@cartouche
@quotation Abstract 
This paper describes a new way of solving the storage reclamation
problem for a system such as Lisp that allocates storage
automatically from a heap, and does not require the programmer to
give any indication that particular items are no longer useful or
accessible. A reference count scheme for reclaiming
non-self-referential structures, and a linearizing, compacting,
copying scheme to reorganize all storage at the users discretion
are proposed. The algorithms are designed to work well in systems
which use multiple levels of storage, and large virtual address
space. They depend on the fact that most cells are referenced
exactly once, and that reference counts need only be accurate when
storage is about to be reclaimed. A transaction file stores
changes to reference counts, and a multiple reference table stores
the count for items which are referenced more than once.
@end quotation
@end cartouche

@item @anchor{bib dlmss76}@anchor{1515}
E. W. Dijkstra, Leslie Lamport, A. J. Martin, C. S. Scholten, E. F. M. Steffens. 1976. “On-the-fly Garbage Collection: An Exercise in Cooperation@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.63.4752&rep=rep1&type=pdf}”. Springer-Verlag. Lecture Notes in Computer Science, Vol. 46.

@cartouche
@quotation Abstract 
As an example of cooperation between sequential processes with
very little mutual interference despite frequent manipulations of
a large shared data space, a technique is developed which allows
nearly all of the activity needed for garbage detection and
collection to be performed by an additional processor operating
con- currently with the processor devoted to the computation
proper. Exclusion and synchronization constraints have been kept
as weak as could be achieved; the severe complexities engendered
by doing so are illustrated.
@end quotation
@end cartouche

@item @anchor{bib dmh92}@anchor{1516}
Amer Diwan, Richard L. Hudson, J. Eliot B. Moss. 1992. “Compiler Support for Garbage Collection in a Statically Typed Language@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.87.71&rep=rep1&type=pdf}”. ACM. Proceedings of the 5th ACM SIGPLAN conference on Programming language design and implementation, pp. 273–282.

@cartouche
@quotation Abstract 
We consider the problem of supporting compacting garbage
collection in the presence of modern compiler optimizations. Since
our collector may move any heap object, it must accurately locate,
follow, and update all pointers and values derived from pointers.
To assist the collector, we extend the compiler to emit tables
describing live pointers, and values derived from pointers, at
each program location where collection may occur. Significant
results include identification of a number of problems posed by
optimizations, solutions to those problems, a working compiler,
and experimental data concerning table sizes, table compression,
and time overhead of decoding tables during collection. While gc
support can affect the code produced, our sample programs show no
significant changes, the table sizes are a modest fraction of the
size of the optimized code, and stack tracing is a small fraction
of total gc time. Since the compiler enhancements are also modest,
we conclude that the approach is practical.
@end quotation
@end cartouche

@item @anchor{bib dtm93}@anchor{1517}
Amer Diwan, David Tarditi, J. Eliot B. Moss. 1993. “Memory Subsystem Performance of Programs with Intensive Heap Allocation@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.27.9220&rep=rep1&type=pdf}”. Carnegie Mellon University. CMU-CS-93-227.

@cartouche
@quotation Abstract 
Heap allocation with copying garbage collection is a general
storage management technique for modern programming languages. It
is believed to have poor memory subsystem performance. To
investigate this, we conducted an in-depth study of the memory
subsystem performance of heap allocation for memory subsystems
found on many machines. We studied the performance of
mostly-functional Standard ML programs which made heavy use of
heap allocation. We found that most machines support heap
allocation poorly. However, with the appropriate memory subsystem
organization, heap allocation can have good performance. The
memory subsystem property crucial for achieving good performance
was the ability to allocate and initialize a new object into the
cache without a penalty. This can be achieved by having subblock
placement with a subblock size of one word with a write allocate
policy, along with fast page-mode writes or a write buffer. For
caches with subblock placement, the data cache overhead was under
9% for a 64k or larger data cache; without subblock placement the
overhead was often higher than 50%.
@end quotation
@end cartouche

@item @anchor{bib dtm93a}@anchor{1518}
Amer Diwan, David Tarditi, J. Eliot B. Moss. 1994. “Memory Subsystem Performance of Programs Using Copying Garbage Collection@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.27.9220&rep=rep1&type=pdf}”. ACM. CMU-CS-93-210, also in POPL ‘94.

@cartouche
@quotation Abstract 
Heap allocation with copying garbage collection is believed to
have poor memory subsystem performance. We conducted a study of
the memory subsystem performance of heap allocation for memory
subsystems found on many machines. We found that many machines
support heap allocation poorly. However, with the appropriate
memory subsystem organization, heap allocation can have good
memory subsystem performance.
@end quotation
@end cartouche

@item @anchor{bib doligez93}@anchor{1519}
Damien Doligez & Xavier Leroy. 1993. “A concurrent@comma{} generational garbage collector for a multithreaded implementation of ML@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.52.9494&rep=rep1&type=pdf}”. ACM. POPL ‘93, 113–123.

@cartouche
@quotation Abstract 
This paper presents the design and implementation of a “quasi
real-time” garbage collector for Concurrent Caml Light, an
implementation of ML with threads. This two-generation system
combines a fast, asynchronous copying collector on the young
generation with a non-disruptive concurrent marking collector on
the old generation. This design crucially relies on the ML
compile-time distinction between mutable and immutable objects.
@end quotation
@end cartouche

@item @anchor{bib doligez94}@anchor{151a}
Damien Doligez & Georges Gonthier. 1994. “Portable@comma{} unobtrusive garbage collection for multiprocessor systems@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.52.4710&rep=rep1&type=pdf}”. ACM. POPL ‘94, 70–83.

@cartouche
@quotation Abstract 
We describe and prove the correctness of a new concurrent
mark-and-sweep garbage collection algorithm. This algorithm
derives from the classical on-the-fly algorithm from Dijkstra et
al. A distinguishing feature of our algorithm is that it supports
multiprocessor environments where the registers of running
processes are not readily accessible, without imposing any
overhead on the elementary operations of loading a register or
reading or initializing a field. Furthermore our collector never
blocks running mutator processes except possibly on requests for
free memory; in particular, updating a field or creating or
marking or sweeping a heap object does not involve
system-dependent synchronization primitives such as locks. We also
provide support for process creation and deletion, and for
managing an extensible heap of variable-sized objects.
@end quotation
@end cartouche

@item @anchor{bib dbe93}@anchor{151b}
R. Kent Dybvig, Carl Bruggeman, David Eby. 1993. “Guardians in a Generation-Based Garbage Collector@footnote{http://www.cs.indiana.edu/~dyb/pubs/guardians-pldi93.pdf}”. SIGPLAN. Proceedings of the ACM SIGPLAN ‘93 Conference on Programming Language Design and Implementation, June 1993.

@cartouche
@quotation Abstract 
This paper describes a new language feature that allows
dynamically allocated objects to be saved from deallocation by an
automatic storage management system so that clean-up or other
actions can be performed using the data stored within the objects.
The program has full control over the timing of clean-up actions,
which eliminates several potential problems and often eliminates
the need for critical sections in code that interacts with
clean-up actions. Our implementation is “generation-friendly” in
the sense that the additional overhead within the mutator is
proportional to the number of clean-up actions actually performed.
@end quotation
@end cartouche

@item @anchor{bib edelson92a}@anchor{151c}
Daniel R. Edelson. 1992. “Smart pointers: They're smart@comma{} but they're not pointers@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.54.530&rep=rep1&type=pdf}”. USENIX C++ Conference.

@cartouche
@quotation From the introduction 
This paper shows hhow the behaviour of smart pointers diverges
from that of pointers in certain common C++ constructs. Given
this, we conclude that the C++ programming language does not
support seamless smart pointers: smart pointers cannot
transparently replace raw pointers in all ways except declaration
syntax. We show that this conclusion also applies to `accessors'.
@end quotation
@end cartouche

@item @anchor{bib edelson92}@anchor{151d}
Daniel R. Edelson. 1992. “Comparing Two Garbage Collectors for C++@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.6011&rep=rep1&type=pdf}”. University of California at Santa Cruz. Technical Report UCSC-CRL-93-20.

@cartouche
@quotation Abstract 
Our research is concerned with compiler- independent, tag-free
garbage collection for the C++ programming language. This paper
presents a mark-and-sweep collector, and explains how it
ameliorates shortcomings of a previous copy collector. The new
collector, like the old, uses C++’s facilities for creating
abstract data types to define a `tracked reference' type, called
`roots', at the level of the application program. A programmer
wishing to utilize the garbage collection service uses these roots
in place of normal, raw pointers. We present a detailed study of
the cost of using roots, as compared to both normal pointers and
reference counted pointers, in terms of instruction counts. We
examine the efficiency of a small C++ application using roots,
reference counting, manual reclamation, and conservative
collection. Coding the application to use garbage collection, and
analyzing the resulting efficiency, helped us identify a number of
memory leaks and inefficiencies in the original, manually
reclaimed version. We find that for this program, garbage
collection using roots is much more efficient than reference
counting, though less efficient than manual reclamation. It is
hard to directly compare our collector to the conservative
collector because of the differing efficiencies of their
respective memory allocators.
@end quotation
@end cartouche

@item @anchor{bib edwards}@anchor{151e}
Daniel J. Edwards. n.d. “Lisp II Garbage Collector@footnote{ftp://publications.ai.mit.edu/ai-publications/0-499/AIM-019.ps}”. MIT. AI Memo 19 (AIM-19).

@cartouche
@quotation Our summary 
(This short memo doesn’t have an abstract. Basically, it describes
the plan for the LISP II Relocating Garbage Collector. It has four
phases: marking, collection, relocation and moving. Marking is by
recursive descent using a bit table. The remaining phases are
linear sweeps through the bit table. The collection phase
calculates how much everything needs to move, storing this
information in the free blocks. The relocation phase updates all
relocatable addresses. The moving phase moves the surviving
objects into one contiguous block.)
@end quotation
@end cartouche

@item @anchor{bib ellis93}@anchor{151f}
John R. Ellis, David L. Detlefs. 1993. “Safe@comma{} Efficient Garbage Collection for C++@footnote{http://www.hpl.hp.com/techreports/Compaq-DEC/SRC-RR-102.pdf}”. Xerox PARC.

@cartouche
@quotation Abstract 
We propose adding safe, efficient garbage collection to C++,
eliminating the possibility of storage-management bugs and making
the design of complex, object-oriented systems much easier. This
can be accomplished with almost no change to the language itself
and only small changes to existing implementations, while
retaining compatibility with existing class libraries.
@end quotation
@end cartouche

@item @anchor{bib ferreira96}@anchor{1520}
Paulo Ferreira. 1996. “Larchant: garbage collection in a cached distributed shared store with persistence by reachability@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.31.8434&rep=rep1&type=pdf}”. Université Paris VI. Thése de doctorat.

@cartouche
@quotation Abstract 
The model of Larchant is that of a `Shared Address Space'
(spanning every site in a network including secondary storage)
with `Persistence By Reachability'. To provide the illusion of a
shared address space across the network, despite the fact that
site memories are disjoint, Larchant implements a `distributed
shared memory' mechanism. Reachability is accessed by tracing the
pointer graph, starting from the persistent root, and reclaiming
unreachable objects. This is the task of `Garbage Collection'
(GC).

GC was until recently thought to be intractable in a large-scale
system, due to problems of scale, incoherence, asynchrony, and
performance. This thesis presents the solutions that Larchant
proposes to these problems.

The GC algorithm in Larchant combines tracing and
reference-listing. It traces whenever economically feasible, i.e.,
as long as the memory subset being collected remains local to a
site, and counts references that would cost I/O traffic to trace.
GC is orthogonal to coherence, i.e., makes progress even if only
incoherent replicas are locally available. The garbage collector
runs concurrently and asynchronously to applications. The
reference-listing boundary changes dynamically and seamlessly, and
independently at each site, in order to collect cycles of
unreachable objects.

We prove formally that our GC algorithm is correct, i.e., it is
safe and live. The performance results from our Larchant prototype
show that our design goals (scalability, coherence orthogonality,
and good performance) are fulfilled.
@end quotation
@end cartouche

@item @anchor{bib fs98}@anchor{1521}
Paulo Ferreira & Marc Shapiro. 1998. “Modelling a Distributed Cached Store for Garbage Collection@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.45.6176&rep=rep1&type=pdf}”. Springer-Verlag. Proceedings of 12th European Conference on Object-Oriented Programming, ECOOP98, LNCS 1445.

@cartouche
@quotation Abstract 
Caching and persistence support efficient, convenient and
transparent distributed data sharing. The most natural model of
persistence is persistence by reachability, managed automatically
by a garbage collector (GC). We propose a very general model of
such a system (based on distributed shared memory) and a scalable,
asynchronous distributed GC algorithm. Within this model, we show
sufficient and widely applicable correctness conditions for the
interactions between applications, store, memory, coherence, and
GC.

The GC runs as a set of processes (local to each participating
machine) communicating by asynchronous messages. Collection does
not interfere with applications by setting locks, polluting
caches, or causing I/O; this requirement raised some novel and
interesting challenges which we address in this article. The
algorithm is safe and live; it is not complete, i.e. it collects
some distributed cycles of garbage but not necessarily all.
@end quotation
@end cartouche

@item @anchor{bib fw76}@anchor{1522}
Daniel P Friedman, David S. Wise. 1976. “Garbage collecting a heap which includes a scatter table@footnote{http://www.cs.indiana.edu/pub/techreports/TR34.pdf}”. `Information Processing Letters.' 5, 6 (December 1976): 161–164.

@cartouche
@quotation Abstract 
A new algorithm is introduced for garbage collecting a heap which
contains shared data structures accessed from a scatter table. The
scheme provides for the purging of useless entries from the
scatter table with no traversals beyond the two required by
classic collection schemes. For languages which use scatter tables
to sustain unique existence of complex structures, like natural
variables of SNOBOL, it indirectly allows liberal use of a single
scatter table by ensuring efficient deletion of useless entries.
Since the scatter table is completely restructured during the
course of execution, the hashing scheme itself is easily altered
during garbage collection whenever skewed loading of the scatter
table warrants abandonment of the old hashing. This procedure is
applicable to the maintenance of dynamic structures such as those
in information retrieval schemes or in languages like LISP and
SNOBOL.
@end quotation
@end cartouche

@item @anchor{bib fw77}@anchor{1523}
Daniel P Friedman, David S. Wise. 1977. “The One Bit Reference Count@footnote{http://www.cs.indiana.edu/pub/techreports/TR57.pdf}”. `BIT.' (17)3: 351–359.

@cartouche
@quotation Abstract 
Deutsch and Bobrow propose a storage reclamation scheme for a heap
which is a hybrid of garbage collection and reference counting.
The point of the hybrid scheme is to keep track of very low
reference counts between necessary invocation of garbage
collection so that nodes which are allocated and rather quickly
abandoned can be returned to available space, delaying necessity
for garbage collection. We show how such a scheme may be
implemented using the mark bit already required in every node by
the garbage collector. Between garbage collections that bit is
used to distinguish nodes with a reference count known to be one.
A significant feature of our scheme is a small cache of references
to nodes whose implemented counts “ought to be higher” which
prevents the loss of logical count information in simple
manipulations of uniquely referenced structures.
@end quotation
@end cartouche

@item @anchor{bib fw79}@anchor{1524}
Daniel P Friedman, David S. Wise. 1979. “Reference counting can manage the circular environments of mutual recursion@footnote{http://www.cs.indiana.edu/pub/techreports/TR73.pdf}”. `Information Processing Letters.' 8, 1 (January 1979): 41–45.

@cartouche
@quotation From the introduction 
In this note we advance reference counting as a storage management
technique viable for implementing recursive languages like ISWIM
or pure LISP with the @code{labels} construct for implementing mutual
recursion from SCHEME. @code{Labels} is derived from @code{letrec} and
displaces the @code{label} operator, a version of the paradoxical
Y-combinator. The key observation is that the requisite circular
structure (which ordinarily cripples reference counts) occurs only
within the language–rather than the user–structure, and that the
references into this structure are well-controlled.
@end quotation
@end cartouche

@item @anchor{bib gzh93}@anchor{1525}
Dirk Grunwald, Benjamin Zorn, R. Henderson. 1993. “Improving the Cache Locality of Memory Allocation@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.6621&rep=rep1&type=pdf}”. SIGPLAN. SIGPLAN ‘93, Conference on PLDI, June 1993, Albuquerque, New Mexico.

@cartouche
@quotation Abstract 
The allocation and disposal of memory is a ubiquitous operation in
most programs. Rarely do programmers concern themselves with
details of memory allocators; most assume that memory allocators
provided by the system perform well. This paper presents a
performance evaluation of the reference locality of dynamic
storage allocation algorithms based on trace-driven simulation of
five large allocation-intensive C programs. In this paper, we show
how the design of a memory allocator can significantly affect the
reference locality for various applications. Our measurements show
that poor locality in sequential-fit algorithms reduces program
performance, both by increasing paging and cache miss rates. While
increased paging can be debilitating on any architecture, cache
misses rates are also important for modern computer architectures.
We show that algorithms attempting to be space-efficient, by
coalescing adjacent free objects show poor reference locality,
possibly negating the benefits of space efficiency. At the other
extreme, algorithms can expend considerable effort to increase
reference locality yet gain little in total execution performance.
Our measurements suggest an allocator design that is both very
fast and has good locality of reference.
@end quotation
@end cartouche

@item @anchor{bib grun92}@anchor{1526}
Dirk Grunwald & Benjamin Zorn. 1993. “CustoMalloc: Efficient Synthesized Memory Allocators@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.35.5260&rep=rep1&type=pdf}”. Software – Practice and Experience. 23(8):851–869.

@cartouche
@quotation Abstract 
The allocation and disposal of memory is a ubiquitous operation in
most programs. Rarely do programmers concern themselves with
details of memory allocators; most assume that memory allocators
provided by the system perform well. Yet, in some applications,
programmers use domain-specific knowledge in an attempt to improve
the speed or memory utilization of memory allocators. In this
paper, we describe a program (CustoMalloc) that synthesizes a
memory allocator customized for a specific application. Our
experiments show that the synthesized allocators are uniformly
faster than the common binary-buddy (BSD) allocator, and are more
space efficient. Constructing a custom allocator requires little
programmer effort. The process can usually be accomplished in a
few minutes, and yields results superior even to domain-specific
allocators designed by programmers. Our measurements show the
synthesized allocators are from two to ten times faster than
widely used allocators.
@end quotation
@end cartouche

@item @anchor{bib gudeman93}@anchor{1527}
David Gudeman. 1993. “Representing Type Information in Dynamically Typed Languages@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.4394&rep=rep1&type=pdf}”. University of Arizona at Tucson. Technical Report TR 93-27.

@cartouche
@quotation Abstract 
This report is a discussion of various techniques for representing
type information in dynamically typed languages, as implemented on
general-purpose machines (and costs are discussed in terms of
modern RISC machines). It is intended to make readily available a
large body of knowledge that currently has to be absorbed
piecemeal from the literature or re-invented by each language
implementor. This discussion covers not only tagging schemes but
other forms of representation as well, although the discussion is
strictly limited to the representation of type information. It
should also be noted that this report does not purport to contain
a survey of the relevant literature. Instead, this report gathers
together a body of folklore, organizes it into a logical
structure, makes some generalizations, and then discusses the
results in terms of modern hardware.
@end quotation
@end cartouche

@item @anchor{bib harris99}@anchor{1528}
Timothy Harris. 1999. “Early storage reclamation in a tracing garbage collector@footnote{http://www.timharris.co.uk/papers/1999-sigplan.pdf}”. ACM. ACM SIG-PLAN Notices 34:4, pp. 46–53.

@cartouche
@quotation Abstract 
This article presents a technique for allowing the early recovery
of storage space occupied by garbage data. The idea is similar to
that of generational garbage collection, except that the heap is
partitioned based on a static analysis of data type definitions
rather than on the approximate age of allocated objects. A
prototype implementation is presented, along with initial results
and ideas for future work.
@end quotation
@end cartouche

@item @anchor{bib henrik94}@anchor{1529}
Roger Henriksson. 1994. “Scheduling Real Time Garbage Collection”. Department of Computer Science at Lund University. LU-CS-TR:94-129.

@cartouche
@quotation Abstract 
This paper presents a new model for scheduling the work of an
incremental garbage collector in a system with hard real time
requirements. The method utilizes the fact that just some of the
processes in the system have to meet hard real time requirements
and that these processes typically run periodically, a fact that
we can make use of when scheduling the garbage collection. The
work of the collector is scheduled to be performed in the pauses
between the critical processes and is suspended when the processes
with hard real time requirements run. It is shown that this
approach is feasible for many real time systems and that it leaves
the time-critical parts of the system undisturbed from garbage
collection induced delays.
@end quotation
@end cartouche

@item @anchor{bib henrik96}@anchor{152a}
Roger Henriksson. 1996. “Adaptive Scheduling of Incremental Copying Garbage Collection for Interactive Applications@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.51.1554&rep=rep1&type=pdf}”. NWPER96.

@cartouche
@quotation Abstract 
Incremental algorithms are often used to interleave the work of a
garbage collector with the execution of an application program,
the intention being to avoid long pauses. However, overestimating
the worst-case storage needs of the program often causes all the
garbage collection work to be performed in the beginning of the
garbage collection cycles, slowing down the application program to
an unwanted degree. This paper explores an approach to
distributing the work more evenly over the garbage collection
cycle.
@end quotation
@end cartouche

@item @anchor{bib henriksson98}@anchor{152b}
Roger Henriksson. 1998. “Scheduling Garbage Collection in Embedded Systems@footnote{http://lup.lub.lu.se/luur/download?func=downloadFile&recordOId=18921&fileOId=630830}”. Department of Computer Science at Lund University. Ph.D. thesis.

@cartouche
@quotation Abstract 
The complexity of systems for automatic control and other
safety-critical applications grows rapidly. Computer software
represents an increasing part of the complexity. As larger systems
are developed, we need to find scalable techniques to manage the
complexity in order to guarantee high product quality. Memory
management is a key quality factor for these systems. Automatic
memory management, or garbage collection, is a technique that
significantly reduces the complex problem of correct memory
management. The risk of software errors decreases and development
time is reduced.

Garbage collection techniques suitable for interactive and soft
real-time systems exist, but few approaches are suitable for
systems with hard real-time requirements, such as control systems
(embedded systems). One part of the problem is solved by
incremental garbage collection algorithms, which have been
presented before. We focus on the scheduling problem which forms
the second part of the problem, i.e. how the work of a garbage
collector should be scheduled in order to disturb the application
program as little as possible. It is studied how a priori
scheduling analysis of systems with automatic memory management
can be made. The field of garbage collection research is thus
joined with the field of scheduling analysis in order to produce a
practical synthesis of the two fields.

A scheduling strategy is presented that employs the properties of
control systems to ensure that no garbage collection work is
performed during the execution of critical processes. The hard
real-time part of the system is thus never disturbed by garbage
collection work. Existing incremental garbage collection
algorithms are adapted to the presented strategy. Necessary
modifications of the algorithms and the real-time kernel are
discussed. A standard scheduling analysis technique, rate
monotonic analysis, is extended in order to make a priori analysis
of the schedulability of the garbage collector possible.

The scheduling algorithm has been implemented in an industrially
relevant real-time environment in order to show that the strategy
is feasible in practice. The experimental evaluation shows that
predictable behaviour and sub-millisecond worst-case delays can be
achieved on standard hardware even by a non-optimized prototype
garbage collector.
@end quotation
@end cartouche

@item @anchor{bib hosking91}@anchor{152c}
Antony L. Hosking. 1991. “Main memory management for persistence@footnote{ftp://ftp.cs.purdue.edu/pub/hosking/papers/oopsla91gc-alh.pdf}”. ACM. Proceedings of the ACM OOPSLA’91 Workshop on Garbage Collection.

@cartouche
@quotation Abstract 
Reachability-based persistence imposes new requirements for main
memory management in general, and garbage collection in
particular. After a brief introduction to the characteristics and
requirements of reachability-based persistence, we present the
design of a run-time storage manager for Persistent Smalltalk and
Persistent Modula-3, which allows the reclamation of storage from
both temporary objects and buffered persistent objects.
@end quotation
@end cartouche

@item @anchor{bib hms92}@anchor{152d}
Antony L. Hosking, J. Eliot B. Moss, Darko Stefanovic. 1992. “A comparative performance evaluation of write barrier implementations@footnote{ftp://ftp.cs.purdue.edu/pub/hosking/papers/oopsla92.pdf}”. ACM. OOPSLA’92 Conference Proceedings, ACM SIGPLAN Notices 27(10), pp 92–109.

@cartouche
@quotation Abstract 
Generational garbage collectors are able to achieve very small
pause times by concentrating on the youngest (most recently
allocated) objects when collecting, since objects have been
observed to die young in many systems. Generational collectors
must keep track of all pointers from older to younger generations,
by “monitoring” all stores into the heap. This `write barrier' has
been implemented in a number of ways, varying essentially in the
granularity of the information observed and stored. Here we
examine a range of write barrier implementations and evaluate
their relative performance within a generation scavenging garbage
collector for Smalltalk.
@end quotation
@end cartouche

@item @anchor{bib hh93}@anchor{152e}
Antony L. Hosking, Richard L. Hudson. 1993. “Remembered sets can also play cards@footnote{ftp://ftp.cs.purdue.edu/pub/hosking/papers/gc-workshop93c.pdf}”. ACM. Proceedings of the ACM OOPSLA’93 Workshop on Memory Management and Garbage Collection.

@cartouche
@quotation Abstract 
Remembered sets and dirty bits have been proposed as alternative
implementations of the write barrier for garbage collection. There
are advantages to both approaches. Dirty bits can be efficiently
maintained with minimal, bounded overhead per store operation,
while remembered sets concisely, and accurately record the
necessary information. Here we present evidence to show that
hybrids can combine the virtues of both schemes and offer
competitive performance. Moreover, we argue that a hybrid can
better avoid the devils that are the downfall of the separate
alternatives.
@end quotation
@end cartouche

@item @anchor{bib hm93}@anchor{152f}
Antony L. Hosking, J. Eliot B. Moss. 1993. “Protection traps and alternatives for memory management of an object-oriented language@footnote{ftp://ftp.cs.purdue.edu/pub/hosking/papers/sosp93.pdf}”. ACM. Proceedings of the Fourteenth ACM Symposium on Operating Systems Principles, ACM Operating Systems Review 27(5), pp 106–119.

@cartouche
@quotation Abstract 
Many operating systems allow user programs to specify the
protection level (inaccessible, read-only, read-write) of pages in
their virtual memory address space, and to handle any protection
violations that may occur. Such page-protection techniques have
been exploited by several user-level algorithms for applications
including generational garbage collection and persistent stores.
Unfortunately, modern hardware has made efficient handling of page
protection faults more difficult. Moreover, page-sized granularity
may not match the natural granularity of a given application. In
light of these problems, we reevaluate the usefulness of
page-protection primitives in such applications, by comparing the
performance of implementations that make use of the primitives
with others that do not. Our results show that for certain
applications software solutions outperform solutions that rely on
page-protection or other related virtual memory primitives.
@end quotation
@end cartouche

@item @anchor{bib hmdw91}@anchor{1530}
Richard L. Hudson, J. Eliot B. Moss, Amer Diwan, Christopher F. Weight. 1991. “A Language-Independent Garbage Collector Toolkit@footnote{http://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1210&context=cs_faculty_pubs}”. University of Massachusetts at Amherst. COINS Technical Report 91–47.

@cartouche
@quotation Abstract 
We describe a memory management toolkit for language implementors.
It offers efficient and flexible generation scavenging garbage
collection. In addition to providing a core of
language-independent algorithms and data structures, the toolkit
includes auxiliary components that ease implementation of garbage
collection for programming languages. We have detailed designs for
Smalltalk and Modula-3 and are confident the toolkit can be used
with a wide variety of languages. The toolkit approach is itself
novel, and our design includes a number of additional innovations
in flexibility, efficiency, accuracy, and cooperation between the
compiler and the collector.
@end quotation
@end cartouche

@item @anchor{bib hm92}@anchor{1531}
Richard L. Hudson, J. Eliot B. Moss. 1992. “Incremental Collection of Mature Objects@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.3883&rep=rep1&type=pdf}”. Springer-Verlag. LNCS #637  International Workshop on Memory Management, St. Malo, France, Sept. 1992, pp. 388–403.

@cartouche
@quotation Abstract 
We present a garbage collection algorithm that extends
generational scavenging to collect large older generations (mature
objects) non-disruptively. The algorithm’s approach is to process
bounded-size pieces of mature object space at each collection; the
subtleties lie in guaranteeing that it eventually collects any and
all garbage. The algorithm does not assume any special hardware or
operating system support, e.g., for forwarding pointers or
protection traps. The algorithm copies objects, so it naturally
supports compaction and reclustering.
@end quotation
@end cartouche

@item @anchor{bib hmmm97}@anchor{1532}
Richard L. Hudson, Ron Morrison, J. Eliot B. Moss, David S. Munro. 1997. “Garbage Collecting the World: One Car at a Time@footnote{http://www.cs.umass.edu/~moss/papers/oopsla-1997-gc-world.pdf}”. ACM. Proc. OOPSLA 97, pp. 162–175.

@cartouche
@quotation Abstract 
A new garbage collection algorithm for distributed object systems,
called DMOS (Distributed Mature Object Space), is presented. It is
derived from two previous algorithms, MOS (Mature Object Space),
sometimes called the train algorithm, and PMOS (Persistent Mature
Object Space). The contribution of DMOS is that it provides the
following unique combination of properties for a distributed
collector: safety, completeness, non-disruptiveness,
incrementality, and scalability. Furthermore, the DMOS collector
is non-blocking and does not use global tracing.
@end quotation
@end cartouche

@item @anchor{bib johnstone97}@anchor{381}
Mark S. Johnstone. 1997. “Non-Compacting Memory Allocation and Real-Time Garbage Collection@footnote{ftp://ftp.cs.utexas.edu/pub/garbage/johnstone-dissertation.ps.gz}”. University of Texas at Austin.

@cartouche
@quotation Abstract 
Dynamic memory use has been widely recognized to have profound
effects on program performance, and has been the topic of many
research studies over the last forty years. In spite of years of
research, there is considerable confusion about the effects of
dynamic memory allocation. Worse, this confusion is often
unrecognized, and memory allocators are widely thought to be
fairly well understood.

In this research, we attempt to clarify many issues for both
manual and automatic non-moving memory management. We show that
the traditional approaches to studying dynamic memory allocation
are unsound, and develop a sound methodology for studying this
problem. We present experimental evidence that fragmentation costs
are much lower than previously recognized for most programs, and
develop a framework for understanding these results and enabling
further research in this area. For a large class of programs using
well-known allocation policies, we show that fragmentation costs
are near zero. We also study the locality effects of memory
allocation on programs, a research area that has been almost
completely ignored. We show that these effects can be quite
dramatic, and that the best allocation policies in terms of
fragmentation are also among the best in terms of locality at both
the cache and virtual memory levels of the memory hierarchy.

We extend these fragmentation and locality results to real-time
garbage collection. We have developed a hard real-time,
non-copying generational garbage collector which uses a
write-barrier to coordinate collection work only with
modifications of pointers, therefore making coordination costs
cheaper and more predictable than previous approaches. We combine
this write-barrier approach with implicit non-copying reclamation,
which has most of the advantages of copying collection (notably
avoiding both the sweep phase required by mark-sweep collectors,
and the referencing of garbage objects when reclaiming their
space), without the disadvantage of having to actually copy the
objects. In addition, we present a model for non-copying
implicit-reclamation garbage collection. We use this model to
compare and contrast our work with that of others, and to discuss
the tradeoffs that must be made when developing such a garbage
collector.
@end quotation
@end cartouche

@item @anchor{bib jw98}@anchor{1533}
Mark S. Johnstone, Paul R. Wilson. 1998. “The Memory Fragmentation Problem: Solved?@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.45.3382&rep=rep1&type=pdf}”. ACM. ISMM’98 pp. 26–36.

@cartouche
@quotation Abstract 
We show that for 8 real and varied C and C++ programs, several
conventional dynamic storage allocators provide near-zero
fragmentation, once overheads due to implementation details
(headers, alignment, etc.) are properly accounted for. This
substantially strengthens our previous results showing that the
memory fragmentation problem has generally been misunderstood, and
that good allocator policies can provide good memory usage for
most programs. The new results indicate that for most programs,
excellent allocator policies are readily available, and efficiency
of implementation is the major challenge. While we believe that
our experimental results are state-of-the-art and our methodology
is superior to most previous work, more work should be done to
identify and study unusual problematic program behaviors not
represented in our sample.
@end quotation
@end cartouche

@item @anchor{bib jones92}@anchor{1534}
Richard E. Jones. 1992. “Tail recursion without space leaks@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.45.5083&rep=rep1&type=pdf}”. `Journal of Functional Programming.' 2(1):73–79.

@cartouche
@quotation Abstract 
The G-machine is a compiled graph reduction machine for lazy
functional languages. The G-machine compiler contains many
optimisations to improve performance. One set of such
optimisations is designed to improve the performance of tail
recursive functions. Unfortunately the abstract machine is subject
to a space leak–objects are unnecessarily preserved by the
garbage collector.

This paper analyses why a particular form of space leak occurs in
the G-machine, and presents some ideas for fixing this problem.
This phenomena in other abstract machines is also examined
briefly.
@end quotation
@end cartouche

@item @anchor{bib jl92}@anchor{1535}
Richard E. Jones, Rafael Lins. 1992. “Cyclic weighted reference counting without delay@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.8499&rep=rep1&type=pdf}”. Computing Laboratory, The University of Kent at Canterbury. Technical Report 28-92.

@cartouche
@quotation Abstract 
Weighted Reference Counting is a low-communication distributed
storage reclamation scheme for loosely-coupled multiprocessors.
The algorithm we present herein extends weighted reference
counting to allow the collection of cyclic data structures. To do
so, the algorithm identifies candidate objects that may be part of
cycles and performs a tricolour mark-scan on their subgraph in a
lazy manner to discover whether the subgraph is still in use. The
algorithm is concurrent in the sense that multiple useful
computation processes and garbage collection processes can be
performed simultaneously.
@end quotation
@end cartouche

@item @anchor{bib jones96}@anchor{1536}
Richard E. Jones, Rafael Lins. 1996. “Garbage Collection: Algorithms for Automatic Dynamic Memory Management@footnote{http://www.cs.ukc.ac.uk/people/staff/rej/gcbook/gcbook.html}”. Wiley. ISBN 0-471-94148-4.

@cartouche
@quotation From the back cover 
The memory storage requirements of complex programs are extremely
difficult to manage correctly by hand. A single error may lead to
indeterminate and inexplicable program crashes. Worse still,
failures are often unrepeatable and may surface only long after
the program has been delivered to the customer. The eradication of
memory errors typically consumes a substantial amount of
development time. And yet the answer is relatively easy – garbage
collection; removing the clutter of memory management from module
interfaces, which then frees the programmer to concentrate on the
problem at hand rather than low-level book-keeping details. For
this reason, most modern object-oriented languages such as
Smalltalk, Eiffel, Java and Dylan, are supported by garbage
collection. Garbage collecting libraries are even available for
such uncooperative languages as C and C++.

This book considers how dynamic memory can be recycled
automatically to guarantee error-free memory management. There is
an abundant but disparate literature on the subject, largely
confined to research papers. This book sets out to pool this
experience in a single accessible and unified framework.

Each of the important algorithms is explained in detail, often
with illustrations of its characteristic features and animations
of its use. Techniques are described and compared for declarative
and imperative programming styles, for sequential, concurrent and
distributed architectures.

For professionals developing programs from simple software tools
to complex systems, as well as for researchers and students
working in compiler construction, functional, logic and
object-oriented programming design, this book will provide not
only a clear introduction but also a convenient reference source
for modern garbage collection techniques.
@end quotation
@end cartouche

@item @anchor{bib acm98}@anchor{1537}
Richard E. Jones. 1998. “ISMM'98 International Symposium on Memory Management@footnote{http://www.acm.org/pubs/contents/proceedings/plan/286860/}”. ACM. ISBN 1-58113-114-3.

@cartouche
@quotation From the Preface 
The International Symposium on Memory Management is a forum for
research in several related areas of memory management, especially
garbage collectors and dynamic storage allocators. […] The
nineteen papers selected for publication in this volume cover a
remarkably broad range of memory management topics from explicit
malloc-style allocation to automatic memory management, from
cache-conscious data layout to efficient management of distributed
references, from conservative to type-accurate garbage collection,
for applications ranging from user application to long-running
servers, supporting languages as different as C, C++, Modula-3,
Java, Eiffel, Erlang, Scheme, ML, Haskell and Prolog.
@end quotation
@end cartouche

@item @anchor{bib jones12}@anchor{1538}
Richard E. Jones, Antony Hosking, and Eliot Moss. 2012. “The Garbage Collection Handbook@footnote{http://gchandbook.org/}”. Chapman & Hall.

@item @anchor{bib joyner96}@anchor{1539}
Ian Joyner. 1996. “C++??: A Critique of C++@footnote{http://www.emu.edu.tr/aelci/Courses/D-318/D-318-Files/cppcrit/index.htm}.”.

@cartouche
@quotation Abstract 
The C++?? Critique is an analysis of some of the flaws of C++. It
is by no means exhaustive, nor does it attempt to document every
little niggle with C++, rather concentrating on main themes. The
critique uses Java and Eiffel as comparisons to C++ to give a more
concrete feel to the criticisms, viewing conceptual differences
rather than syntactic ones as being more important. Some C++
authors realising there are glaring deficiencies in C++ have
chosen to defend C++ by also being critical within their own work.
Most notable are Bjarne Stroustup’s “Design and Evolution of C++,”
and Scott Meyers’ “Effective” and “More Effective C++.” These warn
of many traps and pitfalls, but reach the curious conclusion that
since “good” C++ programmers are aware of these problems and know
how to avoid them, C++ is alright.

The C++ critique makes many of the same criticisms, but comes to
the different conclusion that these pitfalls are not acceptable,
and should not be in a language used for modern large scale
software engineering. Clean design is more important than after
the fact warnings, and it is inconceivable that purchasers of end
user software would tolerate this tactic on the part of vendors.
The critique also takes a look at C, and concludes that many of
the features of C should be left out of modern languages, and that
C is a flawed base for a language.
@end quotation
@end cartouche

@item @anchor{bib kanefsky89}@anchor{153a}
Bob Kanefsky. 1989. “Recursive Memory Allocation@footnote{http://www.songworm.com/db/songworm-parody/RecursiveMemoryAllocation.html}”. Bob Kanefsky. Songworm 3, p.?.

@item @anchor{bib kqh98}@anchor{153b}
Jin-Soo Kim, Xiaohan Qin, Yarsun Hsu. 1998. “Memory Characterization of a Parallel Data Mining Workload@footnote{http://csl.skku.edu/papers/wwc98.pdf}”. IEEE. Proc. Workload Characterization: Methodology and Case Studies, pp. .

@cartouche
@quotation Abstract 
This paper studies a representative of an important class of
emerging applications, a parallel data mining workload. The
application, extracted from the IBM Intelligent Miner, identifies
groups of records that are mathematically similar based on a
neural network model called self-organizing map. We examine and
compare in details two implementations of the application:
(1) temporal locality or working set sizes; (2) spatial locality
and memory block utilization; (3) communication characteristics
and scalability; and (4) TLB performance.

First, we find that the working set hierarchy of the application
is governed by two parameters, namely the size of an input record
and the size of prototype array; it is independent of the number
of input records. Second, the application shows good spatial
locality, with the implementation optimized for sparse data sets
having slightly worse spatial locality. Third, due to the batch
update scheme, the application bears very low communication.
Finally, a 2-way set associative TLB may result in severely skewed
TLB performance in a multiprocessor environment caused by the
large discrepancy in the amount of conflict misses. Increasing the
set associativity is more effective in mitigating the problem than
increasing the TLB size.
@end quotation
@end cartouche

@item @anchor{bib kh00}@anchor{153c}
Jin-Soo Kim & Yarsun Hsu. 2000. “Memory system behavior of Java programs: methodology and analysis”. ACM. Proc. International conference on measurements and modeling of computer systems, pp. 264–274.

@cartouche
@quotation Abstract 
This paper studies the memory system behavior of Java programs by
analyzing memory reference traces of several SPECjvm98
applications running with a Just-In-Time (JIT) compiler. Trace
information is collected by an exception-based tracing tool called
JTRACE, without any instrumentation to the Java programs or the
JIT compiler.First, we find that the overall cache miss ratio is
increased due to garbage collection, which suffers from higher
cache misses compared to the application. We also note that going
beyond 2-way cache associativity improves the cache miss ratio
marginally. Second, we observe that Java programs generate a
substantial amount of short-lived objects. However, the size of
frequently-referenced long-lived objects is more important to the
cache performance, because it tends to determine the application’s
working set size. Finally, we note that the default heap
configuration which starts from a small initial heap size is very
inefficient since it invokes a garbage collector frequently.
Although the direct costs of garbage collection decrease as we
increase the available heap size, there exists an optimal heap
size which minimizes the total execution time due to the
interaction with the virtual memory performance.
@end quotation
@end cartouche

@item @anchor{bib kolodner92}@anchor{153d}
Elliot K. Kolodner. 1992. “Atomic Incremental Garbage Collection and Recovery for a Large Stable Heap”. Laboratory for Computer Science at MIT. MIT-LCS-TR-534.

@cartouche
@quotation Abstract 
A stable heap is a storage that is managed automatically using
garbage collection, manipulated using atomic transactions, and
accessed using a uniform storage model. These features enhance
reliability and simplify programming by preventing errors due to
explicit deallocation, by masking failures and concurrency using
transactions, and by eliminating the distinction between accessing
temporary storage and permanent storage. Stable heap management is
useful for programming language for reliable distributed
computing, programming languages with persistent storage, and
object-oriented database systems. Many applications that could
benefit from a stable heap (e.g., computer-aided design,
computer-aided software engineering, and office information
systems) require large amounts of storage, timely responses for
transactions, and high availability. We present garbage collection
and recovery algorithms for a stable heap implementation that meet
these goals and are appropriate for stock hardware. The collector
is incremental: it does not attempt to collect the whole heap at
once. The collector is also atomic: it is coordinated with the
recovery system to prevent problems when it moves and modifies
objects . The time for recovery is independent of heap size, and
can be shortened using checkpoints.
@end quotation
@end cartouche

@item @anchor{bib lk98}@anchor{153e}
Per-Åke Larson & Murali Krishnan. 1998. “Memory Allocation for Long-Running Server Applications@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.45.1947&rep=rep1&type=pdf}”. ACM. ISMM’98 pp. 176–185.

@cartouche
@quotation Abstract 
Prior work on dynamic memory allocation has largely neglected
long-running server applications, for example, web servers and
mail servers. Their requirements differ from those of one-shot
applications like compilers or text editors. We investigated how
to build an allocator that is not only fast and memory efficient
but also scales well on SMP machines. We found that it is not
sufficient to focus on reducing lock contention. Only limited
improvement can be achieved this way; higher speedups require a
reduction in cache misses and cache invalidation traffic. We then
designed and prototyped a new allocator, called Lkmalloc, targeted
for both traditional applications and server applications.
LKmalloc uses several subheaps, each one with a separate set of
free lists and memory arena. A thread always allocates from the
same subheap but can free a block belonging to any subheap. A
thread is assigned to a subheap by hashing on its thread ID. We
compared its performance with several other allocators on a
server-like, simulated workload and found that it indeed scales
well and is quite fast but could use memory more efficiently.
@end quotation
@end cartouche

@item @anchor{bib lh83}@anchor{153f}
Henry Lieberman & Carl Hewitt. 1983. “A real-time garbage collector based on the lifetimes of objects@footnote{http://web.media.mit.edu/~lieber/Lieberary/GC/Realtime/Realtime.html}”. ACM. 26(6):419–429.

@cartouche
@quotation Abstract 
In previous heap storage systems, the cost of creating objects and
garbage collection is independent of the lifetime of the object.
Since objects with short lifetimes account for a large portion of
storage use, it is worth optimizing a garbage collector to reclaim
storage for these objects more quickly. The garbage collector
should spend proportionately less effort reclaiming objects with
longer lifetimes. We present a garbage collection algorithm that
(1) makes storage for short-lived objects cheaper than storage for
long-lived objects, (2) that operates in real-time–object
creation and access times are bounded, (3) increases locality of
reference, for better virtual memory performance, (4) works well
with multiple processors and a large address space.
@end quotation
@end cartouche

@item @anchor{bib mm59}@anchor{1540}
J. McCarthy, M. L. Minsky. 1959. “Artificial Intelligence@comma{} Quarterly Progress Report no. 53@footnote{http://dspace.mit.edu/bitstream/handle/1721.1/52263/RLE_QPR_053_XIII.pdf}”. Research Laboratory of Electronics at MIT.

@item @anchor{bib mccarthy60}@anchor{1541}
J. McCarthy. 1960. “Recursive Functions of Symbolic Expressions and Their Computation by Machine@footnote{http://www-formal.stanford.edu/jmc/recursive.html}”. CACM.

@cartouche
@quotation Abstract 
A programming system called LISP (for LISt Processor) has been
developed for the IBM 704 computer by the Artificial Intelligence
group at M.I.T. The system was designed to facilitate experiments
with a proposed system called the Advice Taker, whereby a machine
could be instructed to handle declarative as well as imperative
sentences and could exhibit “common sense” in carrying out its
instructions. The original proposal for the Advice Taker was made
in November 1958. The main requirement was a programming system
for manipulating expressions representing formalized declarative
and imperative sentences so that the Advice Taker could make
deductions.

In the course of its development the LISP system went through
several stages of simplification and eventually came to be based
on a scheme for representing the partial recursive functions of a
certain class of symbolic expressions. This representation is
independent of the IBM 704 computer, or of any other electronic
computer, and it now seems expedient to expound the system by
starting with the class of expressions called S-expressions and
the functions called S-functions.
@end quotation
@end cartouche

@item @anchor{bib mccarthy79}@anchor{28b}
John McCarthy. 1979. “History of Lisp@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.16.4634&rep=rep1&type=pdf}”. In `History of programming languages I', pp. 173–185. ACM.

@item @anchor{bib ptm98}@anchor{1542}
Veljko Milutinovic, Jelica Protic, Milo Tomasevic. 1997. “Distributed shared memory: concepts and systems@footnote{http://www.cs.umass.edu/~mcorner/courses/691J/papers/VM/protic_dsm/protic_dsm.pdf}”. IEEE Computer Society Press. ISBN 0-8186-7737-6.

@cartouche
@quotation From the publisher’s catalog 
Presents a survey of both distributed shared memory (DSM) efforts
and commercial DSM systems. The book discusses relevant issues
that make the concept of DSM one of the most attractive approaches
for building large-scale, high-performance multiprocessor systems.
Its text provides a general introduction to the DSM field as well
as a broad survey of the basic DSM concepts, mechanisms, design
issues, and systems.

Distributed Shared Memory concentrates on basic DSM algorithms,
their enhancements, and their performance evaluation. In addition,
it details implementations that employ DSM solutions at the
software and the hardware level. The book is a research and
development reference that provides state-of-the art information
that will be useful to architects, designers, and programmers of
DSM systems.
@end quotation
@end cartouche

@item @anchor{bib minsky63}@anchor{1543}
M. L. Minsky. 1963. “A LISP Garbage Collector Algorithm Using Serial Secondary Storage@footnote{http://dspace.mit.edu/bitstream/handle/1721.1/6080/AIM-058.pdf}”. MIT. Memorandum MAC-M-129, Artificial Intelligence Project, Memo 58 (revised).

@cartouche
@quotation Abstract 
This paper presents an algorithm for reclaiming unused free
storage memory cells is LISP. It depends on availability of a fast
secondary storage device, or a large block of available temporary
storage. For this price, we get 1. Packing of free-storage into a
solidly packed block. 2. Smooth packing of arbitrary linear blocks
and arrays. 3. The collector will handle arbitrarily complex
re-entrant list structure with no introduction of spurious copies.
4. The algorithm is quite efficient; the marking pass visits words
at most twice and usually once, and the loading pass is linear.
5. The system is easily modified to allow for increase in size of
already fixed consecutive blocks, provide one can afford to
initiate a collection pass or use a modified array while waiting
for such a pass to occur.
@end quotation
@end cartouche

@item @anchor{bib moon84}@anchor{1544}
David Moon. 1984. “Garbage Collection in a Large Lisp System@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.125.2438&rep=rep1&type=pdf}”. ACM. Symposium on Lisp and Functional Programming, August 1984.

@cartouche
@quotation Abstract 
This paper discusses garbage collection techniques used in a
high-performance Lisp implementation with a large virtual memory,
the Symbolics 3600. Particular attention is paid to practical
issues and experience. In a large system problems of scale appear
and the most straightforward garbage-collection techniques do not
work well. Many of these problems involve the interaction of the
garbage collector with demand-paged virtual memory. Some of the
solutions adopted in the 3600 are presented, including incremental
copying garbage collection, approximately depth-first copying,
ephemeral objects, tagged architecture, and hardware assists. We
discuss techniques for improving the efficiency of garbage
collection by recognizing that objects in the Lisp world have a
variety of lifetimes. The importance of designing the architecture
and the hardware to facilitate garbage collection is stressed.
@end quotation
@end cartouche

@item @anchor{bib moon85}@anchor{1545}
David Moon. 1985. “Architecture of the Symbolics 3600”. IEEE. 12th International Symposium on Computer Architecture, pp. 76–83.

@item @anchor{bib moon87}@anchor{1546}
David Moon. 1990. “Symbolics Architecture”. Wiley. Chapter 3 of `Computers for Artificial Intelligence Processing', ISBN 0-471-84811-5.

@item @anchor{bib moon91}@anchor{1547}
David Moon. 1991. “Genera Retrospective”. IEEE. 1991 International Workshop on Object Orientation in Operating Systems, order #2265.

@item @anchor{bib mordec84}@anchor{1548}
Ben-Ari Mordechai. 1984. “Algorithms for On-the-fly Garbage Collection”. `TOPLAS' 6(3): 333–344 (1984).

@item @anchor{bib moreau98}@anchor{1549}
Luc Moreau. 1998. “Hierarchical Distributed Reference Counting@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.4593&rep=rep1&type=pdf}”. ACM. ISMM’98 pp. 57–67.

@cartouche
@quotation Abstract 
Massively distributed computing is a challenging problem for
garbage collection algorithm designers as it raises the issue of
scalability. The high number of hosts involved in a computation
can require large tables for reference listing, whereas the lack
of information sharing between hosts in a same locality can entail
redundant GC traffic. In this paper, we argue that a conceptual
hierarchical organisation of massive distributed computations can
solve this problem. By conceptual hierarchical organisation, we
mean that processors are still able to communicate in a peer to
peer manner using their usual communication mechanism, but GC
messages will be routed as if processors were organised in
hierarchy. We present an extension of a distributed reference
counting algorithm that uses such a hierarchical organisation. It
allows us to bound table sizes by the number of hosts in a domain,
and it allows us to share GC information between hosts in a same
locality in order to reduce cross-network GC traffic.
@end quotation
@end cartouche

@item @anchor{bib mfh95}@anchor{154a}
Greg Morrisett, Matthias Felleisen, Robert Harper. 1995. “Abstract Models of Memory Management@footnote{http://www.eecs.harvard.edu/~greg/papers/fpca_gc.ps}”. Carnegie Mellon University. CMU-CS-FOX-95-01.

@cartouche
@quotation Abstract 
Most specifications of garbage collectors concentrate on the
low-level algorithmic details of how to find and preserve
accessible objects. Often, they focus on bit-level manipulations
such as “scanning stack frames,” “marking objects,” “tagging
data,” etc. While these details are important in some contexts,
they often obscure the more fundamental aspects of memory
management: what objects are garbage and why?

We develop a series of calculi that are just low-level enough that
we can express allocation and garbage collection, yet are
sufficiently abstract that we may formally prove the correctness
of various memory management strategies. By making the heap of a
program syntactically apparent, we can specify memory actions as
rewriting rules that allocate values on the heap and automatically
dereference pointers to such objects when needed. This formulation
permits the specification of garbage collection as a relation that
removes portions of the heap without affecting the outcome of
evaluation.

Our high-level approach allows us to specify in a compact manner a
wide variety of memory management techniques, including standard
trace-based garbage collection (i.e., the family of copying and
mark/sweep collection algorithms), generational collection, and
type-based, tag-free collection. Furthermore, since the definition
of garbage is based on the semantics of the underlying language
instead of the conservative approximation of inaccessibility, we
are able to specify and prove the idea that type inference can be
used to collect some objects that are accessible but never used.
@end quotation
@end cartouche

@item @anchor{bib mbmm99}@anchor{154b}
David S. Munro, Alfred Brown, Ron Morrison, J. Eliot B. Moss. 1999. “Incremental Garbage Collection of a Persistent Object Store using PMOS@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.3687&rep=rep1&type=pdf}”. Morgan Kaufmann. in Advances in Persistent Object Systems, pp. 78–91.

@cartouche
@quotation Abstract 
PMOS is an incremental garbage collector designed specifically to
reclaim space in a persistent object store. It is complete in that
it will, after a finite number of invocations, reclaim all
unreachable storage. PMOS imposes minimum constraints on the order
of collection and offers techniques to reduce the I/O traffic
induced by the collector. Here we present the first implementation
of the PMOS collector called PMOS#1. The collector has been
incorporated into the stable heap layer of the generic persistent
object store used to support a number of languages including
Napier88. Our main design goals are to maintain the independence
of the language from the store and to retain the existing store
interface. The implementation has been completed and tested using
a Napier88 system. The main results of this work show that the
PMOS collector is implementable in a persistent store and that it
can be built without requiring changes to the language
interpreter. Initial performance measurements are reported. These
results suggest however, that effective use of PMOS requires
greater co-operation between language and store.
@end quotation
@end cartouche

@item @anchor{bib noph92}@anchor{154c}
Scott Nettles, James O’Toole, David Pierce, Nickolas Haines. 1992. “Replication-Based Incremental Copying Collection@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.28.4233&rep=rep1&type=pdf}”. IWMM’92.

@cartouche
@quotation Abstract 
We introduce a new replication-based copying garbage collection
technique. We have implemented one simple variation of this method
to provide incremental garbage collection on stock hardware with
no special operating system or virtual memory support. The
performance of the prototype implementation is excellent: major
garbage collection pauses are completely eliminated with only a
slight increase in minor collection pause times.

Unlike the standard copying algorithm, the replication-based
method does not destroy the original replica when a copy is
created. Instead, multiple copies may exist, and various standard
strategies for maintaining consistency may be applied. In our
implementation for Standard ML of New Jersey, the mutator
continues to use the from-space replicas until the collector has
achieved a consistent replica of all live data in to-space.

We present a design for a concurrent garbage collector using the
replication-based technique. We also expect replication-based GC
methods to be useful in providing services for persistence and
distribution, and briefly discuss these possibilities.
@end quotation
@end cartouche

@item @anchor{bib nettles92}@anchor{154d}
Scott Nettles. 1992. “A Larch Specification of Copying Garbage Collection@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.45.1498&rep=rep1&type=pdf}”. Carnegie Mellon University. CMU-CS-92-219.

@cartouche
@quotation Abstract 
Garbage collection (GC) is an important part of many language
implementations. One of the most important garbage collection
techniques is copying GC. This paper consists of an informal but
abstract description of copying collection, a formal specification
of copying collection written in the Larch Shared Language and the
Larch/C Interface Language, a simple implementation of a copying
collector written in C, an informal proof that the implementation
satisfies the specification, and a discussion of how the
specification applies to other types of copying GC such as
generational copying collectors. Limited familiarity with copying
GC or Larch is needed to read the specification.
@end quotation
@end cartouche

@item @anchor{bib no93a}@anchor{154e}
Scott Nettles & James O’Toole. 1993. “Implementing Orthogonal Persistence: A Simple Optimization Using Replicating Collection”. USENIX. IWOOOS’93.

@cartouche
@quotation Abstract 
Orthogonal persistence provides a safe and convenient model of
object persistence. We have implemented a transaction system which
supports orthogonal persistence in a garbage-collected heap. In
our system, replicating collection provides efficient concurrent
garbage collection of the heap. In this paper, we show how
replicating garbage collection can also be used to reduce commit
operation latencies in our implementation.

We describe how our system implements transaction commit. We
explain why the presence of non-persistent objects can add to the
cost of this operation. We show how to eliminate these additional
costs by using replicating garbage collection. The resulting
implementation of orthogonal persistence should provide
transaction performance that is independent of the quantity of
non-persistent data in use. We expect efficient support for
orthogonal persistence to be valuable in operating systems
applications which use persistent data.
@end quotation
@end cartouche

@item @anchor{bib no93}@anchor{154f}
Scott Nettles & James O’Toole. 1993. “Real-Time Replication Garbage Collection@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.69.1875&rep=rep1&type=pdf}”. ACM. PLDI’93.

@cartouche
@quotation Abstract 
We have implemented the first copying garbage collector that
permits continuous unimpeded mutator access to the original
objects during copying. The garbage collector incrementally
replicates all accessible objects and uses a mutation log to bring
the replicas up-to-date with changes made by the mutator. An
experimental implementation demonstrates that the costs of using
our algorithm are small and that bounded pause times of 50
milliseconds can be readily achieved.
@end quotation
@end cartouche

@item @anchor{bib nielsen77}@anchor{1550}
Norman R. Nielsen. 1977. “Dynamic Memory Allocation in Computer Simulation”. ACM. CACM 20:11.

@cartouche
@quotation Abstract 
This paper investigates the performance of 35 dynamic memory
allocation algorithms when used to service simulation programs as
represented by 18 test cases. Algorithm performance was measured
in terms of processing time, memory usage, and external memory
fragmentation. Algorithms maintaining separate free space lists
for each size of memory block used tended to perform quite well
compared with other algorithms. Simple algorithms operating on
memory ordered lists (without any free list) performed
surprisingly well. Algorithms employing power-of-two block sizes
had favorable processing requirements but generally unfavorable
memory usage. Algorithms employing LIFO, FIFO, or memory ordered
free lists generally performed poorly compared with others.
@end quotation
@end cartouche

@item @anchor{bib otoole90}@anchor{1551}
James O’Toole. 1990. “Garbage Collecting Locally”.

@cartouche
@quotation Abstract 
Generational garbage collection is a simple technique for
automatic partial memory reclamation. In this paper, I present the
basic mechanics of generational collection and discuss its
characteristics. I compare several published algorithms and argue
that fundamental considerations of locality, as reflected in the
changing relative speeds of processors, memories, and disks,
strongly favor a focus on explicit optimization of I/O
requirements during garbage collection. I show that this focus on
I/O costs due to memory hierarchy debunks a well-known claim about
the relative costs of garbage collection and stack allocation. I
suggest two directions for future research in this area and
discuss some simple architectural changes in virtual memory
interfaces which may enable efficient garbage collector
utilization of standard virtual memory hardware.
@end quotation
@end cartouche

@item @anchor{bib on94}@anchor{1552}
James O’Toole & Scott Nettles. 1994. “Concurrent Replicating Garbage Collection@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.5001&rep=rep1&type=pdf}”. ACM. LFP’94.

@cartouche
@quotation Abstract 
We have implemented a concurrent copying garbage collector that
uses replicating garbage collection. In our design, the client can
continuously access the heap during garbage collection. No
low-level synchronization between the client and the garbage
collector is required on individual object operations. The garbage
collector replicates live heap objects and periodically
synchronizes with the client to obtain the client’s current root
set and mutation log. An experimental implementation using the
Standard ML of New Jersey system on a shared-memory multiprocessor
demonstrates excellent pause time performance and moderate
execution time speedups.
@end quotation
@end cartouche

@item @anchor{bib jrr99}@anchor{1553}
Simon Peyton Jones, Norman Ramsey, Fermin Reig. 1999. “C--: a portable assembly language that supports garbage collection@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.11.1815&rep=rep1&type=pdf}”. Springer-Verlag. International Conference on Principles and Practice of Declarative Programming 1999, LNCS 1702, pp. 1–28.

@cartouche
@quotation Abstract 
For a compiler writer, generating good machine code for a variety
of platforms is hard work. One might try to reuse a retargetable
code generator, but code generators are complex and difficult to
use, and they limit one’s choice of implementation language. One
might try to use C as a portable assembly language, but C limits
the compiler writer’s flexibility and the performance of the
resulting code. The wide use of C, despite these drawbacks, argues
for a portable assembly language. C– is a new language designed
expressly for this purpose. The use of a portable assembly
language introduces new problems in the support of such high-level
run-time services as garbage collection, exception handling,
concurrency, profiling, and debugging. We address these problems
by combining the C– language with a C– run-time interface. The
combination is designed to allow the compiler writer a choice of
source-language semantics and implementation techniques, while
still providing good performance.
@end quotation
@end cartouche

@item @anchor{bib pieper93}@anchor{1554}
John S. Pieper. 1993. “Compiler Techniques for Managing Data Motion”. Carnegie Mellon University. Technical report number CMU-CS-93-217.

@cartouche
@quotation Abstract 
Software caching, automatic algorithm blocking, and data overlays
are different names for the same problem: compiler management of
data movement throughout the memory hierarchy. Modern
high-performance architectures often omit hardware support for
moving data between levels of the memory hierarchy: iWarp does not
include a data cache, and Cray supercomputers do not have virtual
memory. These systems have effectively traded a more complicated
programming model for performance by replacing a
hardware-controlled memory hierarchy with a simple fast memory.
The simpler memories have less logic in the critical path, so the
cycle time of the memories is improved.

For programs which fit in the resulting memory, the extra
performance is great. Unfortunately, the driving force behind
supercomputing today is a class of very large scientific problems,
both in terms of computation time and in terms of the amount of
data used. Many of these programs do not fit in the memory of the
machines available. When architects trade hardware support for
data migration to gain performance, control of the memory
hierarchy is left to the programmer. Either the program size must
be cut down to fit into the machine, or every loop which accesses
more data than will fit into memory must be restructured by hand.
This thesis describes how a compiler can relieve the programmer of
this burden, and automate data motion throughout the memory
hierarchy without direct hardware support.

This works develops a model of how data is accessed within a
nested loop by typical scientific programs. It describes
techniques which can be used by compilers faced with the task of
managing data motion. The concentration is on nested loops which
process large data arrays using linear array subscripts. Because
the array subscripts are linear functions of the loop indices and
the loop indices form an integer lattice, linear algebra can be
applied to solve many compilation problems.

The approach it to tile the iteration space of the loop nest.
Tiling allows the compiler to improve locality of reference. The
tiling basis matrix is chosen from a set of candidate vectors
which neatly divide the data set. The execution order of the tiles
is selected to maximize locality between tiles. Finally, the tile
sizes are chosen to minimize execution time.

The approach has been applied to several common scientific loop
nests: matrix-matrix multiplication, QR-decomposition, and
LU-decomposition. In addition, an illustrative example from the
Livermore Loop benchmark set is examined. Although more compiler
time can be required in some cases, this technique produces better
code at no cost for most programs.
@end quotation
@end cartouche

@item @anchor{bib pirinen98}@anchor{1555}
Pekka P. Pirinen. 1998. “Barrier techniques for incremental tracing”. ACM. ISMM’98 pp. 20–25.

@cartouche
@quotation Abstract 
This paper presents a classification of barrier techniques for
interleaving tracing with mutator operation during an incremental
garbage collection. The two useful tricolour invariants are
derived from more elementary considerations of graph traversal.
Barrier techniques for maintaining these invariants are classified
according to the action taken at the barrier (such as scanning an
object or changing its colour), and it is shown that the
algorithms described in the literature cover all the possibilities
except one. Unfortunately, the new technique is impractical. Ways
of combining barrier techniques are also discussed.
@end quotation
@end cartouche

@item @anchor{bib printezis96}@anchor{1556}
Tony Printezis. 1996. “Disk Garbage Collection Strategies for Persistent Java”. Proceedings of the First International Workshop on Persistence and Java.

@cartouche
@quotation Abstract 
This paper presents work currently in progress on Disk Garbage
Collection issues for PJava, an orthogonally persistent version of
Java. In particular, it concentrates on the initial Prototype of
the Disk Garbage Collector of PJava0 which has already been
implemented. This Prototype was designed to be very simple and
modular in order to be easily changed, evolved, improved, and
allow experimentation. Several experiments were performed in order
to test possible optimisations; these experiments concentrated on
the following four areas: a) efficient access to the store; b)
page-replacement algorithms; c) efficient discovery of live
objects during compaction; and d) dealing with forward references.
The paper presents a description of the Prototype’s architecture,
the results of these experiments and related discussion, and some
future directions based on the experience gained from this work.
@end quotation
@end cartouche

@item @anchor{bib pc96}@anchor{1557}
Tony Printezis & Quentin Cutts. 1996. “Measuring the Allocation Rate of Napier88”. Department of Computing Science at University of Glasgow. TR ?.

@item @anchor{bib reinhold93}@anchor{1558}
M. B. Reinhold. 1993. “Cache Performance of Garbage Collected Programming Languages@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.5454&rep=rep1&type=pdf}”. Laboratory for Computer Science at MIT. MIT/LCS/TR-581.

@cartouche
@quotation Abstract 
As processor speeds continue to improve relative to main-memory
access times, cache performance is becoming an increasingly
important component of program performance. Prior work on the
cache performance of garbage-collected programming languages has
either assumed or argued that conventional garbage-collection
methods will yield poor performance, and has therefore
concentrated on new collection algorithms designed specifically to
improve cache-level reference locality. This dissertation argues
to the contrary: Many programs written in garbage-collected
languages are naturally well-suited to the direct-mapped caches
typically found in modern computer systems.

Using a trace-driven cache simulator and other analysis tools,
five nontrivial, long-running Scheme programs are studied. A
control experiment shows that the programs have excellent cache
performance without any garbage collection at all. A second
experiment indicates that the programs will perform well with a
simple and infrequently-run generational compacting collector.

An analysis of the test programs’ memory usage patterns reveals
that the mostly-functional programming style typically used in
Scheme programs, in combination with simple linear storage
allocation, causes most data objects to be dispersed in time and
space so that references to them cause little cache interference.
From this it follows that other Scheme programs, and programs
written in similar styles in different languages, should perform
well with a simple generational compacting collector;
sophisticated collectors intended to improve cache performance are
unlikely to be effective. The analysis also suggests that, as
locality becomes ever more important to program performance,
programs written in garbage-collected languages may turn out to
have significant performance advantage over programs written in
more conventional languages.
@end quotation
@end cartouche

@item @anchor{bib robson77}@anchor{1559}
J. M. Robson. 1977. “Worst case fragmentation of first fit and best fit storage allocation strategies”. ACM. ACM Computer Journal, 20(3):242–244.

@item @anchor{bib rr97}@anchor{155a}
Gustavo Rodriguez-Rivera & Vince Russo. 1997. “Non-intrusive Cloning Garbage Collection with Stock Operating System Support”. Software – Practice and Experience. 27:8.

@cartouche
@quotation Abstract 
It is well accepted that automatic garbage collection simplifies
programming, promotes modularity, and reduces development effort.
However it is commonly believed that these advantages do not
counteract the perceived price: excessive overheads, possible long
pause times while garbage collections occur, and the need to
modify existing code. Even though there are publically available
garbage collector implementations that can be used in existing
programs, they do not guarantee short pauses, and some
modification of the application using them is still required. In
this paper we describe a snapshot-at-beginning concurrent garbage
collector algorithm and its implementation. This algorithm
guarantees short pauses, and can be easily implemented on stock
UNIX-like operating systems. Our results show that our collector
performs comparable to other garbage collection implementations on
uniprocessor machines and outperforms similar collectors on
multiprocessor machines. We also show our collector to be
competitive in performance with explicit deallocation. Our
collector has the added advantage of being non-intrusive. Using a
dynamic linking technique and effective root set inferencing, we
have been able to successfully run our collector even in
commercial programs where only the binary executable and no source
code is available. In this paper we describe our algorithm, its
implementation, and provide both an algorithmic and a performance
comparison between our collector and other similar garbage
collectors.
@end quotation
@end cartouche

@item @anchor{bib rojemo95}@anchor{155b}
Niklas Röjemo. 1995. “Highlights from nhc – a space-efficient Haskell compiler”. Chalmers University of Technology.

@cartouche
@quotation Abstract 
Self-compiling implementations of Haskell, i.e., those written in
Haskell, have been and, except one, are still space consuming
monsters. Object code size for the compilers themselves are 3-8Mb,
and they need 12-20Mb to recompile themselves. One reason for the
huge demands for memory is that the main goal for these compilers
is to produce fast code. However, the compiler described in this
paper, called “nhc” for “Nearly a Haskell Compiler”, is the one
above mentioned exception. This compiler concentrates on keeping
memory usage down, even at a cost in time. The code produced is
not fast, but nhc is usable, and the resulting programs can be run
on computers with small memory.

This paper describes some of the implementation choices done, in
the Haskell part of the source code, to reduce memory consumption
in nhc. It is possible to use these also in other Haskell
compilers with no, or very small, changes to their run-time
systems.

Time is neither the main focus of nhc nor of this paper, but there
is nevertheless a small section about the speed of nhc. The most
notable observation concerning speed is that nhc spends
approximately half the time processing interface files, which is
much more than needed in the type checker. Processing interface
files is also the most space consuming part of nhc in most cases.
It is only when compiling source files with large sets of mutually
recursive functions that more memory is needed to type check than
to process interface files.
@end quotation
@end cartouche

@item @anchor{bib rojemo95a}@anchor{155c}
Niklas Röjemo. 1995. “Generational garbage collection for lazy functional languages without temporary space leaks”. Chalmers University of Technology.

@cartouche
@quotation Abstract 
Generational garbage collection is an established method for
creating efficient garbage collectors. Even a simple
implementation where all nodes that survive one garbage collection
are `tenured', i.e., moved to an old generation, works well in
strict languages. In lazy languages, however, such an
implementation can create severe `temporary space leaks'. The
temporary space leaks appear in programs that traverse large
lazily built data structures, e.g., a lazy list representing a
large file, where only a small part is needed at any time. A
simple generational garbage collector cannot reclaim the memory,
used by the lazily built list, at minor collections. The reason is
that at least one of the nodes in the list belongs to the old
generation, after the first minor collection, and will hold on to
the rest of the nodes in the list until the next major collection.
@end quotation
@end cartouche

@item @anchor{bib rr96}@anchor{155d}
Niklas Röjemo & Colin Runciman. 1996. “Lag, drag, void and use – heap profiling and space-efficient compilation revisited”. ACM, SIGPLAN. ICFP’96, ACM SIGPLAN Notices 31:6, ISBN 0-89791-770-7, pp. 34–41.

@cartouche
@quotation Abstract 
The context for this paper is functional computation by graph
reduction. Our overall aim is more efficient use of memory. The
specific topic is the detection of dormant cells in the live graph
– those retained in heap memory though not actually playing a
useful role in computation. We describe a profiler that can
identify heap consumption by such ‘useless’ cells. Unlike heap
profilers based on traversals of the live heap, this profiler
works by examining cells post-mortem. The new profiler has
revealed a surprisingly large proportion of ‘useless’ cells, even
in some programs that previously seemed space-efficient such as
the bootstrapping Haskell compiler “nhc”.
@end quotation
@end cartouche

@item @anchor{bib rw99}@anchor{155e}
David J. Roth, David S. Wise. 1999. “One-bit counts between unique and sticky@footnote{http://www.cs.indiana.edu/pub/techreports/TR516.pdf}”. ACM. ISMM’98, pp. 49–56.

@cartouche
@quotation Abstract 
Stoye’s one-bit reference tagging scheme can be extended to local
counts of two or more via two strategies. The first, suited to
pure register transactions, is a cache of referents to two shared
references. The analog of Deutch’s and Bobrow’s multiple-reference
table, this cache is sufficient to manage small counts across
successive assignment statements. Thus, accurate reference counts
above one can be tracked for short intervals, like that bridging
one function’s environment to its successor’s.

The second, motivated by runtime stacks that duplicate references,
avoids counting any references from the stack. It requires a local
pointer-inversion protocol in the mutator, but one still local to
the referent and the stack frame. Thus, an accurate reference
count of one can be maintained regardless of references from the
recursion stack.
@end quotation
@end cartouche

@item @anchor{bib rovner85}@anchor{155f}
Paul Rovner. 1985. “On Adding Garbage Collection and Runtime Types to a Strongly-Typed@comma{} Statically-Checked@comma{} Concurrent Language@footnote{https://archive.org/details/bitsavers_xeroxparctddingGarbageCollectionandRuntimeTypestoa_1765837}”. Xerox PARC. TR CSL-84-7.

@cartouche
@quotation Abstract 
Enough is known now about garbage collection, runtime types,
strong-typing, static-checking and concurrency that it is possible
to explore what happens when they are combined in a real
programming system.

Storage management is one of a few central issues through which
one can get a good view of the design of an entire system.
Tensions between ease of integration and the need for protection;
between generality, simplicity, flexibility, extensibility and
efficiency are all manifest when assumptions and attitudes about
managing storage are studied. And deep understanding follows best
from the analysis of systems that people use to get real work
done.

This paper is not for those who seek arguments pro or con about
the need for these features in programming systems; such issues
are for other papers. This one assumes these features to be good
and describes how they combine and interact in Cedar, a
programming language and environment designed to help programmers
build moderate-sized experimental systems for moderate numbers of
people to test and use.
@end quotation
@end cartouche

@item @anchor{bib runciman92}@anchor{1560}
Colin Runciman & David Wakeling. 1992. “Heap Profiling of Lazy Functional Programs@footnote{ftp://ftp.cs.york.ac.uk/reports/YCS-92-172.ps.Z}”. University of York.

@cartouche
@quotation Abstract 
We describe the design, implementation, and use of a new kind of
profiling tool that yields valuable information about the memory
use of lazy functional programs. The tool has two parts: a
modified functional language implementation which generated
profiling implementation during the execution of programs, and a
separate program which converts this information to graphical
form. With the aid of profile graphs, one can make alterations to
a functional program which dramatically reduce its space
consumption. We demonstrate that this is the case of a genuine
example – the first to which the tool has been applied – for
which the results are strikingly successful.
@end quotation
@end cartouche

@item @anchor{bib rr94}@anchor{1561}
Colin Runciman & Niklas Röjemo. 1994. “New dimensions in heap profiling@footnote{http://www.cs.york.ac.uk/plasma/publications/pdf/RuncimanWakelingJFP93.pdf}”. University of York.

@cartouche
@quotation Abstract 
First-generation heap profilers for lazy functional languages have
proved to be effective tools for locating some kinds of space
faults, but in other cases they cannot provide sufficient
information to solve the problem. This paper describes the design,
implementation and use of a new profiler that goes beyond the
two-dimensional “who produces what” view of heap cells to provide
information about their more dynamic and structural attributes.
Specifically, the new profiler can distinguish between cells
according to their `eventual lifetime', or on the basis of the
`closure retainers' by virtue of which they remain part of the
live heap. A bootstrapping Haskell compiler (nhc) hosts the
implementation: among examples of the profiler’s use we include
self-application to nhc. Another example is the original
heap-profiling case study “clausify”, which now consumes even less
memory and is much faster.
@end quotation
@end cartouche

@item @anchor{bib rr96a}@anchor{1562}
Colin Runciman & Niklas Röjemo. 1996. “Two-pass heap profiling: a matter of life and death”. Department of Computer Science, University of York.

@cartouche
@quotation Abstract 
A heap profile is a chart showing the contents of heap memory
throughout a computation. Contents are depicted abstractly by
showing how much space is occupied by memory cells in each of
several classes. A good heap profiler can use a variety of
attributes of memory cells to de-fine a classification. Effective
profiling usually involves a combination of attributes. The ideal
profiler gives full support for combination in two ways. First, a
section of the heap of interest to the programmer can be specified
by constraining the values of any combination of cell attributes.
Secondly, no matter what attributes are used to specify such a
section, a heap profile can be obtained for that section only, and
any other attribute can be used to define the classification.

Achieving this ideal is not simple For some combinations of
attributes. A heap profile is derived by interpolation of a series
of censuses of heap contents at different stages. The obvious way
to obtain census data is to traverse the live heap at intervals
throughout the computation. This is fine for static attributes
(e.g. What type of value does this memory cell represent?), and
for dynamic attributes that can be determined for each cell by
examining the heap at any given moment (e.g. From which function
closures can this cell be reached?). But some attributes of cells
can only be determined retrospectively by post-mortem inspection
asa cell is overwritten or garbage-collected (e.g. Is this cell
ever used again?). Now we see the problem: if a profiler supports
both live and pose-mortem attributes, how can we implement the
ideal of unrestricted combinations? That is the problem me solve
in this paper. We give techniques for profiling a. heap section
specified in terms of both live and post-mortem attributes. We
show how to generate live-attribute profiles of a section of the
heal, specified using post-mortem attributes, and vice versa.
@end quotation
@end cartouche

@item @anchor{bib sg95}@anchor{1563}
Jacob Seligmann & Steffen Grarup. 1995. “Incremental Mature Garbage Collection Using the Train Algorithm@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.7307&rep=rep1&type=pdf}”. Springer-Verlag. ECOOP’95, Lecture Notes in Computer Science, Vol. 952, pp. 235–252, ISBN 3-540-60160-0.

@cartouche
@quotation Abstract 
We present an implementation of the Train Algorithm, an
incremental collection scheme for reclamation of mature garbage in
generation-based memory management systems. To the best of our
knowledge, this is the first Train Algorithm implementation ever.
Using the algorithm, the traditional mark-sweep garbage collector
employed by the Mj&oslash;lner run-time system for the
object-oriented BETA programming language was replaced by a
non-disruptive one, with only negligible time and storage
overheads.
@end quotation
@end cartouche

@item @anchor{bib sb00}@anchor{1564}
Manuel Serrano, Hans-J. Boehm. 2000. “Understanding memory allocation of Scheme programs@footnote{http://www.hpl.hp.com/techreports/2000/HPL-2000-62.html}”. ACM. Proceedings of International Conference on Functional Programming 2000.

@cartouche
@quotation Abstract 
Memory is the performance bottleneck of modern architectures.
Keeping memory consumption as low as possible enables fast and
unobtrusive applications. But it is not easy to estimate the
memory use of programs implemented in functional languages, due to
both the complex translations of some high level constructs, and
the use of automatic memory managers. To help understand memory
allocation behavior of Scheme programs, we have designed two
complementary tools. The first one reports on frequency of
allocation, heap configurations and on memory reclamation. The
second tracks down memory leaks. We have applied these tools to
our Scheme compiler, the largest Scheme program we have been
developing. This has allowed us to drastically reduce the amount
of memory consumed during its bootstrap process, without requiring
much development time. Development tools will be neglected unless
they are both conveniently accessible and easy to use. In order to
avoid this pitfall, we have carefully designed the user interface
of these two tools. Their integration into a real programming
environment for Scheme is detailed in the paper.
@end quotation
@end cartouche

@item @anchor{bib shapiro94}@anchor{1565}
Marc Shapiro & Paulo Ferreira. 1994. “Larchant-RDOSS: a distributed shared persistent memory and its garbage collector@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.52.8468&rep=rep1&type=pdf}”. INRIA. INRIA Rapport de Recherche no. 2399; Cornell Computer Science TR94-1466.

@cartouche
@quotation Abstract 
Larchant-RDOSS is a distributed shared memory that persists on
reliable storage across process lifetimes. Memory management is
automatic: including consistent caching of data and of locks,
collecting objects unreachable from the persistent root, writing
reachable objects to disk, and reducing store fragmentation.
Memory management is based on a novel garbage collection
algorithm, that approximates a global trace by a series of local
traces, with no induced I/O or locking traffic, and no
synchronization between the collector and the application
processes. This results in a simple programming model, and
expected minimal added application latency. The algorithm is
designed for the most unfavorable environment (uncontrolled
programming language, reference by pointers, distributed system,
non-coherent shared memory) and should work well also in more
favorable settings.
@end quotation
@end cartouche

@item @anchor{bib shaw87}@anchor{1566}
Robert A. Shaw. 1987. “Improving Garbage Collector Performance in Virtual Memory”. Stanford University. CSL-TR-87-323.

@item @anchor{bib shaw88}@anchor{1567}
Robert A. Shaw. 1988. “Empirical Analysis of a LISP System”. Stanford University. CSL-TR-88-351.

@item @anchor{bib singhal92}@anchor{1568}
Vivek Singhal, Sheetal V. Kakkad, Paul R. Wilson. 1992. “Texas: An Efficient@comma{} Portable Persistent Store@footnote{ftp://ftp.cs.utexas.edu/pub/garbage/texaspstore.ps}”. University of Texas at Austin.

@cartouche
@quotation Abstract 
Texas is a persistent storage system for C++, providing high
performance while emphasizing simplicity, modularity and
portability. A key component of the design is the use of pointer
swizzling at page fault time, which exploits existing virtual
memory features to implement large address spaces efficiently on
stock hardware, with little or no change to existing compilers.
Long pointers are used to implement an enormous address space, but
are transparently converted to the hardware-supported pointer
format when pages are loaded into virtual memory.

Runtime type descriptors and slightly modified heap allocation
routines support pagewise pointer swizzling by allowing objects
and their pointer fields to be identified within pages. If
compiler support for runtime type identification is not available,
a simple preprocessor can be used to generate type descriptors.

This address translation is largely independent of issues of data
caching, sharing, and checkpointing; it employs operating systems’
existing virtual memories for caching, and a simple and flexible
log-structured storage manager to improve checkpointing
performance.

Pagewise virtual memory protections are also used to detect writes
for logging purposes, without requiring any changes to compiled
code. This may degrade checkpointing performance for small
transactions with poor locality of writes, but page diffing and
sub-page logging promise to keep performance competitive with
finer-grained checkpointing schemes.

Texas presents a simple programming interface; an application
creates persistent objects by simply allocating them on the
persistent heap. In addition, the implementation is relatively
small, and is easy to incorporate into existing applications. The
log-structured storage module easily supports advanced extensions
such as compressed storage, versioning, and adaptive
reorganization.
@end quotation
@end cartouche

@item @anchor{bib sobalvarro88}@anchor{1569}
P. G. Sobalvarro. 1988. “A Lifetime-based Garbage Collector for LISP Systems on General-Purpose Computers@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.57.2188&rep=rep1&type=pdf}”. MIT. AITR-1417.

@cartouche
@quotation Abstract 
Garbage collector performance in LISP systems on custom hardware has been substantially improved by the adoption of lifetime-based garbage collection techniques.  To date, however, successful lifetime-based garbage collectors have required special-purpose hardware, or at least privileged access to data structures maintained by the virtual memory system.  I present here a lifetime-based garbage collector requiring no special-purpose hardware or virtual memory system support, and discuss its performance.
@end quotation
@end cartouche

@item @anchor{bib steele75}@anchor{156a}
Guy L. Steele. 1975. “Multiprocessing Compactifying Garbage Collection”. CACM. 18:9 pp. 495–508.

@cartouche
@quotation Abstract 
Algorithms for a multiprocessing compactifying garbage collector
are presented and discussed. The simple case of two processors,
one performing LISP-like list operations and the other performing
garbage collection continuously, is thoroughly examined. The
necessary capabilities of each processor are defined, as well as
interprocessor communication and interlocks. Complete procedures
for garbage collection and for standard list processing primitives
are presented and thoroughly explained. Particular attention is
given to the problems of marking and relocating list cells while
another processor may be operating on them. The primary aim
throughout is to allow the list processor to run unimpeded while
the other processor reclaims list storage The more complex case
involving several list processors and one or more garbage
collection processors are also briefly discussed.
@end quotation
@end cartouche

@item @anchor{bib steele76}@anchor{156b}
Guy L. Steele. 1976. “Corrigendum: Multiprocessing Compactifying Garbage Collection”. CACM. 19:6 p.354.

@item @anchor{bib steele77}@anchor{156c}
Guy L. Steele. 1977. “Data Representation in PDP-10 MACLISP@footnote{http://dspace.mit.edu/bitstream/handle/1721.1/6278/AIM-420.pdf}”. MIT. AI Memo 420.

@cartouche
@quotation Abstract 
The internal representations of the various MacLISP data types are
presented and discussed. Certain implementation tradeoffs are
considered. The ultimate decisions on these tradeoffs are
discussed in the light of MacLISP’s prime objective of being an
efficient high-level language for the implementation of large
systems such as MACSYMA. The basic strategy of garbage collection
is outlined, with reference to the specific representations
involved. Certain “clever tricks” are explained and justified. The
“address space crunch” is explained and some alternative solutions
explored.
@end quotation
@end cartouche

@item @anchor{bib slc99}@anchor{156d}
James M. Stichnoth, Guei-Yuan Lueh, Michal Cierniak. 1999. “Support for Garbage Collection at Every Instruction in a Java Compiler@footnote{http://www.cs.tufts.edu/~nr/cs257/archive/james-stichnoth/p118-stichnoth.pdf}”. SIGPLAN. Proceedings of the 1999 ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI). SIGPLAN Notices 34(5). pp. 118–127.

@cartouche
@quotation Abstract 
A high-performance implementation of a Java Virtual Machine
requires a compiler to translate Java bytecodes into native
instructions, as well as an advanced garbage collector (e.g.,
copying or generational). When the Java heap is exhausted and the
garbage collector executes, the compiler must report to the
garbage collector all live object references contained in physical
registers and stack locations. Typical compilers only allow
certain instructions (e.g., call instructions and backward
branches) to be GC-safe; if GC happens at some other instruction,
the compiler may need to advance execution to the next GC-safe
point. Until now, no one has ever attempted to make every
compiler-generated instruction GC-safe, due to the perception that
recording this information would require too much space. This kind
of support could improve the GC performance in multithreaded
applications. We show how to use simple compression techniques to
reduce the size of the GC map to about 20% of the generated code
size, a result that is competitive with the best previously
published results. In addition, we extend the work of Agesen,
Detlefs, and Moss, regarding the so-called “JSR Problem” (the
single exception to Java’s type safety property), in a way that
eliminates the need for extra runtime overhead in the generated
code.
@end quotation
@end cartouche

@item @anchor{bib scn84}@anchor{156e}
Will R Stoye, T J W Clarke, Arthur C Norman. 1984. “Some Practical Methods for Rapid Combinator Reduction”. In LFP 1984, 159–166.

@cartouche
@quotation Abstract 
The SKIM II processor is a microcoded hardware machine for the
rapid evaluation of functional languages. This paper gives details
of some of the more novel methods employed by SKIM II, and
resulting performance measurements. The authors conclude that
combinator reduction can still form the basis for the efficient
implementation of a functional language.
@end quotation
@end cartouche

@item @anchor{bib td95}@anchor{156f}
David Tarditi & Amer Diwan. 1995. “Measuring the Cost of Storage Management@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.45.4550&rep=rep1&type=pdf}”. Carnegie Mellon University. CMU-CS-94-201.

@cartouche
@quotation Abstract 
We study the cost of storage management for garbage-collected
programs compiled with the Standard ML of New Jersey compiler. We
show that the cost of storage management is not the same as the
time spent garbage collecting. For many of the programs, the time
spent garbage collecting is less than the time spent doing other
storage-management tasks.
@end quotation
@end cartouche

@item @anchor{bib tj94}@anchor{1570}
Stephen Thomas, Richard E. Jones. 1994. “Garbage Collection for Shared Environment Closure Reducers”. Computing Laboratory, The University of Kent at Canterbury. Technical Report 31-94.

@cartouche
@quotation Abstract 
Shared environment closure reducers such as Fairbairn and Wray’s
TIM incur a comparatively low cost when creating a suspension, and
so provide an elegant method for implementing lazy functional
evaluation. However, comparatively little attention has been given
to the problems involved in identifying which portions of a shared
environment are needed (and ignoring those which are not) during a
garbage collection. Proper consideration of this issue has subtle
consequences when implementing a storage manager in a TIM-like
system. We describe the problem and illustrate the negative
consequences of ignoring it.

We go on to describe a solution in which the compiler determines
statically which portions of that code’s environment are required
for each piece of code it generates, and emits information to
assist the run-time storage manager to scavenge environments
selectively. We also describe a technique for expressing this
information directly as executable code, and demonstrate that a
garbage collector implemented in this way can perform
significantly better than an equivalent, table-driven interpretive
collector.
@end quotation
@end cartouche

@item @anchor{bib thomas95}@anchor{1571}
Stephen Thomas. 1995. “Garbage Collection in Shared-Environment Closure Reducers: Space-Efficient Depth First Copying using a Tailored Approach”. `Information Processing Letters.' 56:1, pp. 1–7.

@cartouche
@quotation Abstract 
Implementations of abstract machines such as the OP-TIM and the
PG-TIM need to use a tailored garbage collector which seems to
require an auxiliary stack,with a potential maximum size that is
directly proportional to the amount of live data in the heap.
However, it turns out that it is possible to build a recursive
copying collector that does not require additional space by
reusing already-scavenged space. This paper is a description of
this technique.
@end quotation
@end cartouche

@item @anchor{bib tt97}@anchor{1572}
Mads Tofte & Jean-Pierre Talpin. 1997. “Region-Based Memory Management@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.9105&rep=rep1&type=pdf}”. Information and Computation 132(2), pp. 109–176.

@cartouche
@quotation Abstract 
This paper describes a memory management discipline for programs
that perform dynamic memory allocation and de-allocation. At
runtime, all values are put into regions. The store consists of a
stack of regions. All points of region allocation and
de-allocation are inferred automatically, using a type and effect
based program analysis. The scheme does not assume the presence of
a garbage collector. The scheme was first presented in 1994 (M.
Tofte and J.-P. Talpin, in `Proceedings of the 21st ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages,'
pp. 188–201); subsequently, it has been tested in the ML Kit with
Regions, a region-based, garbage-collection free implementation of
the Standard ML Core Language, which includes recursive datatypes,
higher-order functions and updatable references (L. Birkedal, M.
Tofte, and M. Vejlstrup, (1996), in `Proceedings of the 23rd ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages,'
pp. 171–183). This paper defines a region-based dynamic semantics
for a skeletal programming language extracted from Standard ML. We
present the inference system which specifies where regions can be
allocated and de-allocated and a detailed proof that the system is
sound with respect to a standard semantics. We conclude by giving
some advice on how to write programs that run well on a stack of
regions, based on practical experience with the ML Kit.
@end quotation
@end cartouche

@item @anchor{bib ungar84}@anchor{1573}
Dave Ungar. 1984. “Generation Scavenging: A Non-disruptive High Performance Storage Reclamation Algorithm@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.122.4295&rep=rep1&type=pdf}”. ACM, SIGSOFT, SIGPLAN. Practical Programming Environments Conference.

@cartouche
@quotation Abstract 
Many interactive computing environments provide automatic storage
reclamation and virtual memory to ease the burden of managing
storage. Unfortunately, many storage reclamation algorithms impede
interaction with distracting pauses. `Generation Scavenging' is a
reclamation algorithm that has no noticeable pauses, eliminates
page faults for transient objects, compacts objects without
resorting to indirection, and reclaims circular structures, in one
third the time of traditional approaches.
@end quotation
@end cartouche

@item @anchor{bib ungar88}@anchor{1574}
Dave Ungar & Frank Jackson. 1988. “Tenuring Policies for Generation-Based Storage Reclamation@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.115.2810&rep=rep1&type=pdf}”. SIGPLAN. OOPSLA ‘88 Conference Proceedings, ACM SIGPLAN Notices, Vol. 23, No. 11, pp. 1–17.

@cartouche
@quotation Abstract 
One of the most promising automatic storage reclamation
techniques, generation-based storage reclamation, suffers poor
performance if many objects live for a fairly long time and then
die. We have investigated the severity of the problem by
simulating Generation Scavenging automatic storage reclamation
from traces of actual four-hour sessions. There was a wide
variation in the sample runs, with garbage-collection overhead
ranging from insignificant, during interactive runs, to sever,
during a single non-interactive run. All runs demonstrated that
performance could be improved with two techniques: segregating
large bitmaps and strings, and mediating tenuring with demographic
feedback. These two improvements deserve consideration for any
generation-based storage reclamation strategy.
@end quotation
@end cartouche

@item @anchor{bib vo96}@anchor{1575}
Kiem-Phong Vo. 1996. “Vmalloc: A General and Efficient Memory Allocator”. Software – Practice and Experience. 26(3): 357–374 (1996).

@cartouche
@quotation Abstract 
On C/Unix systems, the malloc interface is standard for dynamic
memory allocation. Despite its popularity, malloc’s shortcomings
frequently cause programmers to code around it. The new library
Vmalloc generalizes malloc to give programmers more control over
memory allocation. Vmalloc introduces the idea of organizing
memory into separate regions, each with a discipline to get raw
memory and a method to manage allocation. Applications can write
their own disciplines to manipulate arbitrary type of memory or
just to better organize memory in a region by creating new regions
out of its memory. The provided set of allocation methods include
general purpose allocations, fast special cases and aids for
memory debugging or profiling. A compatible malloc interface
enables current applications to select allocation methods using
environment variables so they can tune for performance or perform
other tasks such as profiling memory usage, generating traces of
allocation calls or debugging memory errors. A performance study
comparing Vmalloc and currently popular malloc implementations
shows that Vmalloc is competitive to the best of these allocators.
Applications can gain further performance improvement by using the
right mixture of regions with different Vmalloc methods.
@end quotation
@end cartouche

@item @anchor{bib ww76}@anchor{1576}
Daniel C. Watson, David S. Wise. 1976. “Tuning Garwick’s algorithm for repacking sequential storage”. `BIT.' 16, 4 (December 1976): 442–450.

@cartouche
@quotation Abstract 
Garwick’s algorithm, for repacking LIFO lists stored in a
contiguous block of memory, bases the allocation of remaining
space upon both sharing and previous stack growth. A system
whereby the weight applied to each method can be adjusted
according to the current behaviour of the stacks is discussed.

We also investigate the problem of determining during memory
repacking that the memory is used to saturation and the driving
program should therefore be aborted. The tuning parameters studied
here seem to offer no new grasp on this problem.
@end quotation
@end cartouche

@item @anchor{bib wlm92}@anchor{1577}
Paul R. Wilson, Michael S. Lam, Thomas G. Moher. 1992. “Caching Considerations for Generational Garbage Collection”. ACM. L&FP 92.

@cartouche
@quotation Abstract 
GC systems allocate and reuse memory cyclically; this imposes a
cyclic pattern on memory accesses that has its own distinctive
locality characteristics. The cyclic reuse of memory tends to
defeat caching strategies if the reuse cycle is too large to fit
in fast memory. Generational GCs allow a smaller amount of memory
to be reused more often. This improves VM performance, because the
frequently-reused area stays in main memory. The same principle
can be applied at the level of high-speed cache memories, if the
cache is larger than the youngest generation. Because of the
repeated cycling through a fixed amount of memory, however,
generational GC interacts with cache design in unusual ways, and
modestly set-associative caches can significantly outperform
direct-mapped caches.

While our measurements do not show very high miss rates for GCed
systems, they indicate that performance problems are likely in
faster next-generation systems, where second-level cache misses
may cost scores of cycles. Software techniques can improve cache
performance of garbage-collected systems, by decreasing the cache
“footprint” of the youngest generation; compiler techniques that
reduce the amount of heap allocation also improve locality. Still,
garbage-collected systems with a high rate of heap allocation
require somewhat more cache capacity and/or main memory bandwidth
than conventional systems.
@end quotation
@end cartouche

@item @anchor{bib wil92a}@anchor{1578}
Paul R. Wilson, Sheetal V. Kakkad. 1992. “Pointer Swizzling at Page Fault Time@footnote{ftp://ftp.cs.utexas.edu/pub/garbage/swizz.ps}”. University of Texas at Austin.

@cartouche
@quotation Abstract 
Pointer swizzling at page fault time is a novel address
translation mechanism that exploits conventional address
translation hardware. It can support huge address spaces
efficiently without long hardware addresses; such large address
spaces are attractive for persistent object stores, distributed
shared memories, and shared address space operating systems. This
swizzling scheme can be used to provide data compatibility across
machines with different word sizes, and even to provide binary
code compatibility across machines with different hardware address
sizes.

Pointers are translated (“swizzled”) from a long format to a
shorter hardware-supported format at page fault time. No extra
hardware is required, and no continual software overhead is
incurred by presence checks of indirection of pointers. This
pagewise technique exploits temporal and spatial locality in much
the same way as normal virtual memory; this gives it many
desirable performance characteristics, especially given the trend
toward larger main memories. It is easy to implement using common
compilers and operating systems.
@end quotation
@end cartouche

@item @anchor{bib wil94}@anchor{1579}
Paul R. Wilson. 1994. “Uniprocessor Garbage Collection Techniques@footnote{ftp://ftp.cs.utexas.edu/pub/garbage/bigsurv.ps}”. University of Texas.

@cartouche
@quotation Abstract 
We survey basic garbage collection algorithms, and variations such
as incremental and generational collection; we then discuss
low-level implementation considerations and the relationships
between storage management systems, languages, and compilers.
Throughout, we attempt to present a unified view based on abstract
traversal strategies, addressing issues of conservatism,
opportunism, and immediacy of reclamation; we also point out a
variety of implementation details that are likely to have a
significant impact on performance.
@end quotation
@end cartouche

@item @anchor{bib wil95}@anchor{157a}
Paul R. Wilson, Mark S. Johnstone, Michael Neely, David Boles. 1995. “Dynamic Storage Allocation: A Survey and Critical Review@footnote{ftp://ftp.cs.utexas.edu/pub/garbage/allocsrv.ps}”. University of Texas at Austin.

@cartouche
@quotation Abstract 
Dynamic memory allocation has been a fundamental part of most
computer systems since roughly 1960, and memory allocation is
widely considered to be either a solved problem or an insoluble
one. In this survey, we describe a variety of memory allocator
designs and point out issues relevant to their design and
evaluation. We then chronologically survey most of the literature
on allocators between 1961 and 1995. (Scores of papers are
discussed, in varying detail, and over 150 references are given.)

We argue that allocator designs have been unduly restricted by an
emphasis on mechanism, rather than policy, while the latter is
more important; higher-level strategic issues are still more
important, but have not been given much attention.

Most theoretical analyses and empirical allocator evaluations to
date have relied on very strong assumptions of randomness and
independence, but real program behavior exhibits important
regularities that must be exploited if allocators are to perform
well in practice.
@end quotation
@end cartouche

@item @anchor{bib wise78}@anchor{157b}
David S. Wise. 1978. “The double buddy system@footnote{http://www.cs.indiana.edu/ftp/techreports/TR79.pdf}”. Department of Computer Science at Indiana University. Technical Report 79.

@cartouche
@quotation Abstract 
A new buddy system is described in which the region of storage
being managed is partitioned into two sub-regions, each managed by
a fairly standard “binary” buddy system. Like the weighted buddy
systems of Shen and Peterson, the block sizes are of sizes 2@w{^n+1} or 3·2@w{^n}, but unlike theirs
there is no extra overhead for typing information or for buddy
calculation, and an allocation which requires splitting an extant
available block only rarely creates a block smaller than the one
being allocated. Such smaller blocks are carved out only when the
boundary between the two subregions floats; the most interesting
property of this system is that the procedures for allocation and
deallocation are designed to keep blocks immediately adjacent to
the subregion boundary free, so that the boundary may be moved
within a range of unused space without disturbing blocks in use.
This option is attained with a minimum of extra computation beyond
that of a binary buddy system, and provides this scheme with a new
approach to the problem of external fragmentation.
@end quotation
@end cartouche

@item @anchor{bib wise79}@anchor{157c}
David S. Wise. 1979. “Morris's garbage compaction algorithm restores reference counts@footnote{http://www.cs.indiana.edu/ftp/techreports/TR75.pdf}”. TOPLAS. 1, 1 (July 1979): 115–120.

@cartouche
@quotation Abstract 
The two-pass compaction algorithm of F.L. Morris, which follows
upon the mark phase in a garbage collector, may be modified to
recover reference counts for a hybrid storage management system.
By counting the executions of two loops in that algorithm where
upward and downward references, respectively, are forwarded to the
relocation address of one node, we can initialize a count of
active references and then update it but once. The reference count
may share space with the mark bit in each node, but it may not
share the additional space required in each pointer by Morris’s
algorithm, space which remains unused outside the garbage
collector.
@end quotation
@end cartouche

@item @anchor{bib wise85}@anchor{157d}
David S. Wise. 1985. “Design for a multiprocessing heap with on-board reference counting@footnote{http://www.cs.indiana.edu/ftp/techreports/TR163.pdf}”. Springer-Verlag. In J.-P. Jouannaud (ed.), Functional Programming Languages and Computer Architecture, Lecture Notes in Computer Science 201: 289–304.

@cartouche
@quotation Abstract 
A project to design a pair of memory chips with a modicum of
intelligence is described. Together, the two allow simple
fabrication of a small memory bank, a heap of binary (LISP-like)
nodes that offers the following features: 64-bit nodes; two
pointer fields per node up to 29 bits each; reference counts
implicitly maintained on writes; 2 bits per node for marking
(uncounted) circular references; 4 bits per node for
conditional-store testing at the memory; provision for
processor-driven, recounting garbage collection.
@end quotation
@end cartouche

@item @anchor{bib wise92}@anchor{157e}@anchor{bib wise93}@anchor{157f}
David S. Wise. 1993. “Stop-and-copy and one-bit reference counting@footnote{http://www.cs.indiana.edu/ftp/techreports/TR360.pdf}”. `Information Processing Letters.' 46, 5 (July 1993): 243–249.

@cartouche
@quotation Abstract 
A stop-and-copy garbage collector updates one-bit reference
counting with essentially no extra space and minimal memory cycles
beyond the conventional collection algorithm. Any object that is
uniquely referenced during a collection becomes a candidate for
cheap recovery before the next one, or faster recopying then if it
remains uniquely referenced. Since most objects stay uniquely
referenced, subsequent collections run faster even if none are
recycled between garbage collections. This algorithm extends to
generation scavenging, it admits uncounted references from roots,
and it corrects conservatively stuck counters, that result from
earlier uncertainty whether references were unique.
@end quotation
@end cartouche

@item @anchor{bib ww95}@anchor{1580}
David S. Wise, Joshua Walgenbach. 1996. “Static and Dynamic Partitioning of Pointers as Links and Threads@footnote{http://www.cs.indiana.edu/ftp/techreports/TR437.pdf}”. SIGPLAN. Proc. 1996 ACM SIGPLAN Intl. Conf. on Functional Programming, SIGPLAN Not. 31, 6 (June 1996), pp. 42–49.

@cartouche
@quotation Abstract 
Identifying some pointers as invisible threads, for the purposes
of storage management, is a generalization from several widely
used programming conventions, like threaded trees. The necessary
invariant is that nodes that are accessible (without threads) emit
threads only to other accessible nodes. Dynamic tagging or static
typing of threads ameliorates storage recycling both in functional
and imperative languages.

We have seen the distinction between threads and links sharpen
both hardware- and software-supported storage management in
SCHEME, and also in C. Certainly, therefore, implementations of
languages that already have abstract management and concrete
typing, should detect and use this as a new static type.
@end quotation
@end cartouche

@item @anchor{bib whhho94}@anchor{1581}
David S. Wise, Brian Heck, Caleb Hess, Willie Hunt, Eric Ost. 1997. “Uniprocessor Performance of a Reference-Counting Hardware Heap@footnote{http://www.cs.indiana.edu/ftp/techreports/TR401.pdf}”. `LISP and Symbolic Computation.' 10, 2 (July 1997), pp. 159–181.

@cartouche
@quotation Abstract 
A hardware self-managing heap memory (RCM) for languages like
LISP, SMALLTALK, and JAVA has been designed, built, tested and
benchmarked. On every pointer write from the processor,
reference-counting transactions are performed in real time within
this memory, and garbage cells are reused without processor
cycles. A processor allocates new nodes simply by reading from a
distinguished location in its address space. The memory hardware
also incorporates support for off-line, multiprocessing,
mark-sweep garbage collection.

Performance statistics are presented from a partial implementation
of SCHEME over five different memory models and two garbage
collection strategies, from main memory (no access to RCM) to a
fully operational RCM installed on an external bus. The
performance of the RCM memory is more than competitive with main
memory.
@end quotation
@end cartouche

@item @anchor{bib withington91}@anchor{1582}
P. Tucker Withington. 1991. “How Real is 'Real-Time' Garbage Collection?@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.116.3169&rep=rep1&type=pdf}”. ACM. OOPSLA/ECOOP ‘91 Workshop on Garbage Collection in Object-Oriented Systems.

@cartouche
@quotation Abstract 
A group at Symbolics is developing a Lisp runtime kernel, derived
from its Genera operating system, to support real-time control
applications. The first candidate application has strict
response-time requirements (so strict that it does not permit the
use of paged virtual memory). Traditionally, Lisp’s automatic
storage-management mechanism has made it unsuitable to real-time
systems of this nature. A number of garbage collector designs and
implementations exist (including the Genera garbage collector)
that purport to be “real-time”, but which actually have only
mitigated the impact of garbage collection sufficiently that it
usually goes unnoticed by humans. Unfortunately,
electro-mechanical systems are not so forgiving. This paper
examines the limitations of existing real-time garbage collectors
and describes the avenues that we are exploring in our work to
develop a CLOS-based garbage collector that can meet the real-time
requirements of real real-time systems.
@end quotation
@end cartouche

@item @anchor{bib yip91}@anchor{1583}
G. May Yip. 1991. “Incremental@comma{} Generational Mostly-Copying Garbage Collection in Uncooperative Environments@footnote{http://www.hpl.hp.com/techreports/Compaq-DEC/WRL-91-8.pdf}”. Digital Equipment Corporation.

@cartouche
@quotation Abstract 
The thesis of this project is that incremental collection can be
done feasibly and efficiently in an architecture and compiler
independent manner. The design and implementation of an
incremental, generational mostly-copying garbage collector for C++
is presented. The collector achieves, simultaneously, real-time
performance (from incremental collection), low total garbage
collection delay (from generational collection), and the ability
to function without hardware and compiler support (from
mostly-copying collection).

The incremental collector runs on commercially-available
uniprocessors, such as the DECStation 3100, without any special
hardware support. It uses UNIX’s user controllable page protection
facility (mprotect) to synchronize between the scanner (of the
collector) and the mutator (of the application program). Its
implementation does not require any modification to the C++
compiler. The maximum garbage collection pause is well within the
100-millisecond limit imposed by real-time applications executing
on interactive workstations. Compared to its non-incremental
version, the total execution time of the incremental collector is
not adversely affected.
@end quotation
@end cartouche

@item @anchor{bib yuasa90}@anchor{1584}
Taiichi Yuasa. 1990. “Real-Time Garbage Collection on General-Purpose Machines”. Journal of Software and Systems. 11:3 pp. 181–198.

@cartouche
@quotation Abstract 
An algorithm for real-time garbage collection is presented, proved
correct, and evaluated. This algorithm is intended for
list-processing systems on general-purpose machines, i.e., Von
Neumann style serial computers with a single processor. On these
machines, real-time garbage collection inevitably causes some
overhead on the overall execution of the list-processing system,
because some of the primitive list-processing operations must
check the status of garbage collection. By removing such overhead
from frequently used primitives such as pointer references (e.g.,
Lisp car and cdr) and stack manipulations, the presented algorithm
reduces the execution overhead to a great extent. Although the
algorithm does not support compaction of the whole data space, it
efficiently supports partial compaction such as array relocation.
@end quotation
@end cartouche

@item @anchor{bib zorn88}@anchor{1585}
Benjamin Zorn & Paul Hilfinger. 1988. “A Memory Allocation Profiler for C and Lisp Programs@footnote{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.1689&rep=rep1&type=pdf}”. USENIX. Proceedings for the Summer 1988 USENIX Conference, pp. 223–237.

@cartouche
@quotation Abstract 
This paper describes inprof, a tool used to study the memory
allocation behavior of programs. mprof records the amount of
memory each function allocates, breaks down allocation information
by type and size, and displays a program’s dynamic cal graph so
that functions indirectly responsible for memory allocation are
easy to identify. mprof is a two-phase tool. The monitor phase is
linked into executing programs and records information each time
memory is allocated. The display phase reduces the data generated
by the monitor and displays the information to the user in several
tables. mprof has been implemented for C and Kyoto Common Lisp.
Measurements of these implementations are presented.
@end quotation
@end cartouche

@item @anchor{bib zorn89}@anchor{1586}
Benjamin Zorn. 1989. “Comparative Performance Evaluation of Garbage Collection Algorithms@footnote{http://www.eecs.berkeley.edu/Pubs/TechRpts/1989/CSD-89-544.pdf}”. Computer Science Division (EECS) of University of California at Berkeley. Technical Report UCB/CSD 89/544 and PhD thesis.

@cartouche
@quotation Abstract 
This thesis shows that object-level, trace-driven simulation can
facilitate evaluation of language runtime systems and reaches new
conclusions about the relative performance of important garbage
collection algorithms. In particular, I reach the unexpected
conclusion that mark-and-sweep garbage collection, when augmented
with generations, shows comparable CPU performance and much better
reference locality than the more widely used copying algorithms.
In the past, evaluation of garbage collection algorithms has been
limited by the high cost of implementing the algorithms.
Substantially different algorithms have rarely been compared in a
systematic way.

With the availability of high-performance, low-cost workstations,
trace-driven performance evaluation of these algorithms is now
economical. This thesis describes MARS, a runtime system simulator
that is driven by operations on program objects, and not memory
addresses. MARS has been attached to a commercial Common Lisp
system and eight large Lisp applications are used in the thesis as
test programs. To illustrate the advantages of the object-level
tracing technique used by MARS, this thesis compares the relative
performance of stop-and-copy, incremental, and mark-and-sweep
collection algorithms, all organized with multiple generations.
The comparative evaluation is based on several metrics: CPU
overhead, reference locality, and interactive availability.

Mark-and-sweep collection shows slightly higher CPU overhead than
stop-and-copy ability (5 percent), but requires significantly less
physical memory to achieve the same page fault rate (30-40
percent). Incremental collection has very good interactive
availability, but implementing the read barrier on stock hardware
incurs a substantial CPU overhead (30-60 percent). In the future,
I will use MARS to investigate other performance aspects of
sophisticated runtime systems.
@end quotation
@end cartouche

@item @anchor{bib zorn90b}@anchor{1587}
Benjamin Zorn. 1990. “Comparing Mark-and-sweep and Stop-and-copy Garbage Collection”. ACM. Conference on Lisp and Functional Programming, pp. 87–98.

@cartouche
@quotation Abstract 
Stop-and-copy garbage collection has been preferred to
mark-and-sweep collection in the last decade because its
collection time is proportional to the size of reachable data and
not to the memory size. This paper compares the CPU overhead and
the memory requirements of the two collection algorithms extended
with generations, and finds that mark-and-sweep collection
requires at most a small amount of additional CPU overhead (3-6%)
but requires an average of 20% (and up to 40%) less memory to
achieve the same page fault rate. The comparison is based on
results obtained using trace-driven simulation with large Common
Lisp programs.
@end quotation
@end cartouche

@item @anchor{bib zorn90}@anchor{1588}
Benjamin Zorn. 1990. “Barrier Methods for Garbage Collection@footnote{http://www.cs.colorado.edu/department/publications/reports/docs/CU-CS-494-90.pdf}”. University of Colorado at Boulder. Technical Report CU-CS-494-90.

@cartouche
@quotation Abstract 
Garbage collection algorithms have been enhanced in recent years
with two methods: generation-based collection and Baker
incremental copying collection. Generation-based collection
requires special actions during certain store operations to
implement the “write barrier”. Incremental collection requires
special actions on certain load operations to implement the “read
barrier”. This paper evaluates the performance of different
implementations of the read and write barriers and reaches several
important conclusions. First, the inlining of barrier checks
results in surprisingly low overheads, both for the write barrier
(2%-6%) and the read barrier (&lt; 20%). Contrary to previous
belief, these results suggest that a Baker-style read barrier can
be implemented efficiently without hardware support. Second, the
use of operating system traps to implement garbage collection
methods results in extremely high overheads because the cost of
trap handling is so high. Since this large overhead is completely
unnecessary, operating system memory protection traps should be
reimplemented to be as fast as possible. Finally, the performance
of these approaches on several machine architectures is compared
to show that the results are generally applicable.
@end quotation
@end cartouche

@item @anchor{bib zorn91}@anchor{1589}
Benjamin Zorn. 1991. “The Effect of Garbage Collection on Cache Performance@footnote{http://www.cs.colorado.edu/department/publications/reports/docs/CU-CS-528-91.pdf}”. University of Colorado at Boulder. Technical Report CU-CS-528-91.

@cartouche
@quotation Abstract 
Cache performance is an important part of total performance in
modern computer systems. This paper describes the use of
trace-driven simulation to estimate the effect of garbage
collection algorithms on cache performance. Traces from four large
Common Lisp programs have been collected and analyzed with an
all-associativity cache simulator. While previous work has focused
on the effect of garbage collection on page reference locality,
this evaluation unambiguously shows that garbage collection
algorithms can have a profound effect on cache performance as
well. On processors with a direct-mapped cache, a generation
stop-and-copy algorithm exhibits a miss rate up to four times
higher than a comparable generation mark-and-sweep algorithm.
Furthermore, two-way set-associative caches are shown to reduce
the miss rate in stop-and-copy algorithms often by a factor of two
and sometimes by a factor of almost five over direct-mapped
caches. As processor speeds increase, cache performance will play
an increasing role in total performance. These results suggest
that garbage collection algorithms will play an important part in
improving that performance.
@end quotation
@end cartouche

@item @anchor{bib zorn92b}@anchor{158a}
Benjamin Zorn & Dirk Grunwald. 1992. “Empirical Measurements of Six Allocation-intensive C Programs@footnote{http://www.cs.colorado.edu/department/publications/reports/docs/CU-CS-604-92.pdf}”. ACM, SIGPLAN. SIGPLAN notices, 27(12):71–80.

@cartouche
@quotation Abstract 
Dynamic memory management is an important part of a large class of
computer programs and high-performance algorithms for dynamic
memory management have been, and will continue to be, of
considerable interest. This paper presents empirical data from a
collection of six allocation-intensive C programs. Extensive
statistics about the allocation behavior of the programs measured,
including the distributions of object sizes, lifetimes, and
interarrival times, are presented. This data is valuable for the
following reasons: first, the data from these programs can be used
to design high-performance algorithms for dynamic memory
management. Second, these programs can be used as a benchmark test
suite for evaluating and comparing the performance of different
dynamic memory management algorithms. Finally, the data presented
gives readers greater insight into the storage allocation patterns
of a broad range of programs. The data presented in this paper is
an abbreviated version of more extensive statistics that are
publicly available on the internet.
@end quotation
@end cartouche

@item @anchor{bib zorn92}@anchor{158b}
Benjamin Zorn. 1993. “The Measured Cost of Conservative Garbage Collection@footnote{http://www.cs.colorado.edu/department/publications/reports/docs/CU-CS-573-92.pdf}”. Software – Practice and Experience. 23(7):733–756.

@cartouche
@quotation Abstract 
Because dynamic memory management is an important part of a large
class of computer programs, high-performance algorithms for
dynamic memory management have been, and will continue to be, of
considerable interest. Experience indicates that for many
programs, dynamic storage allocation is so important that
programmers feel compelled to write and use their own
domain-specific allocators to avoid the overhead of system
libraries. Conservative garbage collection has been suggested as
an important algorithm for dynamic storage management in C
programs. In this paper, I evaluate the costs of different dynamic
storage management algorithms, including domain-specific
allocators; widely-used general-purpose allocators; and a publicly
available conservative garbage collection algorithm. Surprisingly,
I find that programmer enhancements often have little effect on
program performance. I also find that the true cost of
conservative garbage collection is not the CPU overhead, but the
memory system overhead of the algorithm. I conclude that
conservative garbage collection is a promising alternative to
explicit storage management and that the performance of
conservative collection is likely to be improved in the future. C
programmers should now seriously consider using conservative
garbage collection instead of malloc/free in programs they write.
@end quotation
@end cartouche

@item @anchor{bib zorn92a}@anchor{158c}
Benjamin Zorn & Dirk Grunwald. 1994. “Evaluating Models of Memory Allocation@footnote{http://www.cs.colorado.edu/department/publications/reports/docs/CU-CS-603-92.pdf}”. ACM. Transactions on Modeling and Computer Simulation 4(1):107–131.

@cartouche
@quotation Abstract 
Because dynamic memory management is an important part of a large
class of computer programs, high-performance algorithms for
dynamic memory management have been, and will continue to be, of
considerable interest. We evaluate and compare models of the
memory allocation behavior in actual programs and investigate how
these models can be used to explore the performance of memory
management algorithms. These models, if accurate enough, provide
an attractive alternative to algorithm evaluation based on
trace-driven simulation using actual traces. We explore a range of
models of increasing complexity including models that have been
used by other researchers. Based on our analysis, we draw three
important conclusions. First, a very simple model, which generates
a uniform distribution around the mean of observed values, is
often quite accurate. Second, two new models we propose show
greater accuracy than those previously described in the
literature. Finally, none of the models investigated appear
adequate for generating an operating system workload.
@end quotation
@end cartouche
@end itemize

@node Memory Management Glossary,Index to source code,Bibliography,Top
@anchor{glossary/index doc}@anchor{158d}@anchor{glossary/index glossary}@anchor{158e}@anchor{glossary/index memory-management-glossary}@anchor{158f}
@chapter Memory Management Glossary


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}

@menu
* Memory Management Glossary; A: Memory Management Glossary A. 
* Memory Management Glossary; B: Memory Management Glossary B. 
* Memory Management Glossary; C: Memory Management Glossary C. 
* Memory Management Glossary; D: Memory Management Glossary D. 
* Memory Management Glossary; E: Memory Management Glossary E. 
* Memory Management Glossary; F: Memory Management Glossary F. 
* Memory Management Glossary; G: Memory Management Glossary G. 
* Memory Management Glossary; H: Memory Management Glossary H. 
* Memory Management Glossary; I: Memory Management Glossary I. 
* Memory Management Glossary; K: Memory Management Glossary K. 
* Memory Management Glossary; L: Memory Management Glossary L. 
* Memory Management Glossary; M: Memory Management Glossary M. 
* Memory Management Glossary; N: Memory Management Glossary N. 
* Memory Management Glossary; O: Memory Management Glossary O. 
* Memory Management Glossary; P: Memory Management Glossary P. 
* Memory Management Glossary; Q: Memory Management Glossary Q. 
* Memory Management Glossary; R: Memory Management Glossary R. 
* Memory Management Glossary; S: Memory Management Glossary S. 
* Memory Management Glossary; T: Memory Management Glossary T. 
* Memory Management Glossary; U: Memory Management Glossary U. 
* Memory Management Glossary; V: Memory Management Glossary V. 
* Memory Management Glossary; W: Memory Management Glossary W. 
* Memory Management Glossary; Z: Memory Management Glossary Z. 
* All:: 

@end menu

@node Memory Management Glossary A,Memory Management Glossary B,,Memory Management Glossary
@anchor{glossary/a doc}@anchor{15a7}@anchor{glossary/a glossary-a}@anchor{1590}@anchor{glossary/a memory-management-glossary-a}@anchor{15a8}
@section Memory Management Glossary: A


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/a term-absolute-address}@anchor{15a9}
@geindex absolute address

@item absolute address

@ref{15aa,,physical address}.
@anchor{glossary/a term-activation-frame}@anchor{15ab}
@geindex activation frame

@item activation frame

@ref{15ac,,activation record}.
@anchor{glossary/a term-activation-record}@anchor{15ac}
@geindex activation record

@item activation record

`activation frame', `function record'.

An activation or function record is a data structure,
associated with the invocation of a function, procedure, or
control block that stores the variables, temporaries, and
fixed-sized data that are local to the block, and the
information required to return to the invoking context. It is
often stored on a @ref{27,,control stack}.

In a register-based hardware architecture, the current
activation record is typically partially stored in registers.

@ref{1ee,,Closures} and @ref{15ad,,continuations} are specializations
of activation records in support of particular language
features of @ref{28a,,LISP}, @ref{46,,Scheme} and related
languages.

The current activation record is part of the state of the
@ref{30c,,mutator}, and is therefore a @ref{97,,root} to the
@ref{15ae,,collector (2)}. In languages that permit recursion,
activation records have @ref{24a,,dynamic extent}. In
languages that permit closures or continuations,
activation records may have @ref{15af,,indefinite extent}.
Although they may not be visible to the programmer, their
@ref{15b0,,memory (1)} must be managed by the
language run-time support. Because they are usually not
visible to the programmer, they may be a source of
inexplicable memory overhead.


@subsubheading See also


@ref{15b1,,stack frame}.

@anchor{glossary/a term-activation-stack}@anchor{15b2}
@geindex activation stack

@item activation stack

@ref{27,,control stack}.
@anchor{glossary/a term-active}@anchor{15b3}
@geindex active

@item active

@ref{78,,live}.
@anchor{glossary/a term-address}@anchor{126}
@geindex address

@item address

An address is a specification of a @ref{15b4,,memory location} in
an @ref{54,,address space}.

An address is almost always represented as an unsigned integer
stored in a single @ref{15b5,,machine word}. The address is
decoded by the hardware in order to access a location on a
@ref{15b6,,physical memory (2)} device (such as a @ref{55,,RAM}) or
some @ref{15b7,,memory-mapped} resource.


@float Figure

@image{MemoryPoolSystem-figures/address,,,Diagram: A simplified view of addresses@comma{} address space@comma{} and locations on a 32-bit architecture.,svg}

@caption{A simplified view of addresses, address space, and
locations on a 32-bit architecture.}

@end float


@ref{15b8,,pointer}.

An address is represented by a value of the type
@ref{11d,,mps_addr_t}.
@anchor{glossary/a term-address-space}@anchor{54}
@geindex address space

@item address space

An `address space' is the set of possible @ref{126,,addresses}.
It can also be considered to be a partial function from
addresses to @ref{15b4,,locations}.

Typically, addresses start at zero and run to 2@w{^n}−1,
where `n' is the address width (for example, 15, 16, 24, 32,
64), which is usually the same as the width of the address
bus. This may not be true for @ref{15b9,,segmented} architectures.

In modern systems, large parts of the whole address space may
be reserved by the operating system or architecture, or not
@ref{190,,mapped} at any given time. The mapped part of the
address space may be discontiguous or sparse.


@subsubheading See also


@ref{15ba,,physical address space}, @ref{15bb,,virtual address space}.

@anchor{glossary/a term-address-space-layout-randomization}@anchor{cc}
@geindex address space layout randomization

@item address space layout randomization

`ASLR'.

The random placement in @ref{54,,address space} of the
@ref{15bc,,stack}, data segment, @ref{47,,heap}, and so on, of a
process.

The purpose of ASLR is to make it harder for an attacker to
exploit buffer overflow bugs, by making it harder to determine
the addresses of data structures.

ASLR also makes it hard to prepare a repeatable test case
for a program that performs computation based on the
addresses of objects, for example, hashing objects by
their address. See @ref{cd,,Address space layout randomization} for techniques
to deal with this.
@anchor{glossary/a term-address-translation-cache}@anchor{15bd}
@geindex address translation cache

@item address translation cache

@ref{15be,,translation lookaside buffer}.
@anchor{glossary/a term-address-ordered-first-fit}@anchor{384}
@geindex address-ordered first fit

@item address-ordered first fit

The @ref{380,,allocation policy} that always uses the suitable
@ref{15bf,,free block} with the lowest address. One of the most
common allocation policies in use. Commonly implemented by
@ref{37f,,first fit} on a single address-ordered @ref{15c0,,free block chain}. Sometimes just called “first fit”.


@subsubheading See also


@ref{385,,FIFO-ordered first fit}, @ref{15c1,,LIFO-ordered first fit}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/a term-aging-space}@anchor{15c2}
@geindex aging space

@item aging space

In some @ref{e,,generational garbage collection} systems, when
@ref{e1,,generations} are divided into
@ref{15c3,,buckets}, the aging space is where
@ref{1ab,,objects} which survive a @ref{1a2,,collection cycle} stay until they are old enough to be @ref{223,,promoted}.

@ref{15c4,,creation space}.
@anchor{glossary/a term-algebraic-data-type}@anchor{15c5}
@geindex algebraic data type

@item algebraic data type

Algebraic data types aggregate or alternate a number of
dissimilarly-typed objects. They are termed `algebraic'
because they can be expressed using the sum and product
operators, for example (a and b and c) or d.

Examples of algebraic data types include: structures, records,
tuples, and unions.

Algebraic data types are usually represented using a
@ref{47,,heap}. Because of their non-uniformity, algebraic
data types are more difficult to @ref{65,,scan}.


@subsubheading See also


@ref{15c6,,scalar data type}, @ref{15c7,,vector data type}, @ref{47,,heap}.

@anchor{glossary/a term-alignment}@anchor{68}
@geindex alignment

@item alignment

Alignment is a constraint on the @ref{126,,address} of an
@ref{1ab,,object} in @ref{194,,memory (2)}.

The constraint is usually that the object’s address must be a
multiple of a power of two, 2@w{^n}, and therefore that
the least significant `n' bits of the address must be zero.

The bus hardware of many modern processors cannot access
multi-@ref{15c8,,byte (2)} objects at any memory address. Often
@ref{37c,,word}-sized objects must be aligned to word boundaries,
double-words to double-word boundaries, double-floats to
8-byte boundaries, and so on. If a program attempts to access
an object that is incorrectly aligned, a @ref{15c9,,bus error}
occurs.

A memory manager must take care to @ref{15ca,,allocate} memory
with an appropriate alignment for the object that is going
to be stored there. Implementations of @ref{1a,,malloc} have
to allocate all @ref{185,,blocks} at the largest
alignment that the processor architecture requires. Other
reasons for aligning objects include using the least
significant bits of the address for a @ref{88,,tag}.

@ref{15cb,,unaligned}.


@subsubheading See also


@ref{70,,natural alignment}.


An alignment is represented by the unsigned integral type
@ref{128,,mps_align_t}. It must be a power of 2. The
alignment of objects allocated in a @ref{18,,pool} may be
specified by passing the @code{MPS_KEY_ALIGN}
@ref{53,,keyword argument} when calling
@ref{166,,mps_pool_create_k()}.
@anchor{glossary/a term-alive}@anchor{15cc}
@geindex alive

@item alive

@ref{78,,live}.
@anchor{glossary/a term-allocate}@anchor{15ca}
@geindex allocate

@item allocate

`cons'.

`Allocation' is the process of assigning resources. When
requested to by the program, an application @ref{15cd,,memory manager} or @ref{15ce,,allocator} `allocates' a @ref{185,,block} of
@ref{194,,memory (2)} for the program to store its data in.
Allocation is also known as `consing', from @ref{15cf,,cons (1)}.

When faced with a request for memory from the program, a
memory manager must choose a suitable block and hand it over,
or fail. The choices made by the memory manager at this point
can have a significant effect on the future efficiency of the
program.

Allocation is rarely a simple issue. For example, programs
usually allocate @ref{15ac,,activation records} (@ref{15d0,,automatic variables}, and so on) for
functions from a processor @ref{15bc,,stack} simply by subtracting
a number from their stack @ref{15b8,,pointer}. However, in a
@ref{51,,virtual memory} system, this may extend the stack onto
a previously unused @ref{92,,page}, in which case the operating
system memory manager must carry out some quite complex
operations in order to supply the program with @ref{15d1,,backing store} for the stack so that the program can continue.

The term `reserved' was often used to mean “allocated”.

@ref{1a,,malloc}.

@ref{15d2,,free (1)}.


@subsubheading See also


@ref{15d3,,constructor (1)}.


@ref{157a,,Wilson et al. (1995)}.

See @ref{2b,,Allocation}.
@anchor{glossary/a term-allocation-frame}@anchor{27d}
@geindex allocation frame

@item allocation frame

An allocation frame is a marker that can pushed onto an
@ref{63,,allocation point} by calling
@ref{16e,,mps_ap_frame_push()}, and then popped by calling
@ref{16d,,mps_ap_frame_pop()} to indicate that all blocks
allocated on the allocation point are @ref{49,,dead} (in the
case of @ref{8,,manual} pools), or
very likely dead (in the case of @ref{9,,automatic} pools). Allocation frames can
be used by the @ref{d0,,client program} to efficiently
implement stack-like patterns of allocation.
@anchor{glossary/a term-allocation-mechanism}@anchor{15d4}
@geindex allocation mechanism

@item allocation mechanism

The algorithm by which an @ref{15ce,,allocator} chooses a
@ref{15bf,,free block} from which to satisfy an allocation
request. An allocation mechanism is the implementation of an
@ref{380,,allocation policy}.

A common mechanism is “@ref{37f,,first fit} on an address-ordered
@ref{15c0,,free block chain}, with eager @ref{38c,,coalescing}”. This implements the @ref{384,,address-ordered first fit} policy, and commonly inherits that name, although there
are many other mechanisms for implementing that policy, for
example, “leftmost fit on a balanced tree of free blocks
ordered by address”.

@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/a term-allocation-pattern}@anchor{272}
@geindex allocation pattern

@item allocation pattern

A hint to the MPS to expect a particular pattern of
allocation on an @ref{63,,allocation point}. The MPS may use
this hint to schedule its decisions as to when and what to
collect. See @ref{26e,,Allocation patterns}.
@anchor{glossary/a term-allocation-point}@anchor{63}
@geindex allocation point

@item allocation point

An allocation point is an interface to a @ref{18,,pool}
which provides fast @ref{1cb,,buffered} allocation, and
defers the need for synchronization in a multi-threaded
environment. Allocation points belong to the type
@ref{1c0,,mps_ap_t}.
@anchor{glossary/a term-allocation-point-protocol}@anchor{2a}
@geindex allocation point protocol

@item allocation point protocol

The protocol that ensures safe inline allocation on an
@ref{63,,allocation point}. See
@ref{ae,,Allocation point protocol}.
@anchor{glossary/a term-allocation-policy}@anchor{380}
@geindex allocation policy

@item allocation policy

`placement policy'.

The concrete policy used by an @ref{15ce,,allocator} for choosing
a @ref{15bf,,free block} to satisfy an @ref{15ca,,allocation} request.

For instance, “always allocate from the largest free block”
(@ref{386,,worst fit}) or “use the most recently freed block
suitable” (@ref{15c1,,LIFO-ordered first fit}).

Each allocation policy is motivated by an @ref{15d5,,allocation strategy} and implemented by an @ref{15d4,,allocation mechanism}.


@subsubheading See also


@ref{384,,address-ordered first fit}, @ref{382,,best fit}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/a term-allocation-strategy}@anchor{15d5}
@geindex allocation strategy

@item allocation strategy

The high-level design motivation or strategy, of an
@ref{15ce,,allocator}, which uses observations or theories about
patterns of allocation requests to justify an
@ref{380,,allocation policy}.

For instance, “do not allow small long-lived @ref{1ab,,objects}
to fragment large @ref{15d6,,free (3)} areas”, “allocate
consecutive objects close together”, and so on. The allocation
strategy motivates an @ref{380,,allocation policy}, which is
implemented by an @ref{15d4,,allocation mechanism}.

@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/a term-allocator}@anchor{15ce}
@geindex allocator

@item allocator

The term `allocator' is often used to refer to the
@ref{15cd,,memory manager}, usually when it is a simple manual
one.

@ref{15cd,,memory manager}.


@subsubheading See also


@ref{15ca,,allocation}.

@anchor{glossary/a term-ambiguous-reference}@anchor{9f}
@geindex ambiguous reference

@item ambiguous reference

`unsure reference'.

An ambiguous or unsure @ref{24,,reference} is a value that is
potentially a reference, but the @ref{15d7,,collector (1)} cannot
prove that it is.

The presence of ambiguous references in a
@ref{f,,garbage-collected} system requires
the use of @ref{349,,conservative garbage collection}.

@ref{61,,exact reference}.


@subsubheading See also


@ref{15d8,,floating garbage}.

@anchor{glossary/a term-ambiguous-root}@anchor{1c4}
@geindex ambiguous root

@item ambiguous root

An ambiguous root is a @ref{97,,root} containing
@ref{9f,,ambiguous references}.

@ref{20b,,exact root}.

An ambiguous root has @ref{9e,,rank}
@ref{20a,,mps_rank_ambig()}.
@anchor{glossary/a term-arena}@anchor{16}
@geindex arena

@item arena

The area of @ref{194,,memory (2)} used by @ref{1a,,malloc} for
allocation.

So named from a semi-mythical “malloc: corrupted arena”
message supposedly emitted when some early versions became
terminally confused.


@subsubheading See also


@ref{15d9,,brk}.


An arena is the data structure responsible for requesting
@ref{17,,memory (3)} from the operating system, making it
available to @ref{18,,pools}, and for @ref{f,,garbage collection}. Arenas belong to the type
@ref{11e,,mps_arena_t}. See @ref{19,,Arenas}.
@anchor{glossary/a term-arena-class}@anchor{11a}
@geindex arena class

@item arena class

A value of type @ref{17a,,mps_arena_class_t} describing a
class of @ref{16,,arenas}. Arena classes include
@ref{4d,,client arenas} and @ref{4f,,virtual memory arenas}.
@anchor{glossary/a term-ASLR}@anchor{15da}
@geindex ASLR

@item ASLR

@ref{cc,,address space layout randomization}.
@anchor{glossary/a term-assertion}@anchor{284}
@geindex assertion

@item assertion

A declaration in a program of a condition that is expected
always to be true, or which must be true in order for the
program to continue to execute correctly.

Memory management mistakes often lead to
@ref{c5,,overwriting errors} that
corrupt the data structures used by the memory manager to
maintain memory. Except in the @ref{163,,rash}
@ref{c9,,variety}, most MPS functions assert the validity of
the data structures they operate on. This means that
memory management mistakes are detected as early as
possible, when there may still be enough evidence in the
@ref{47,,heap} to debug them. See @ref{5b,,Error handing}.
@anchor{glossary/a term-asynchronous-garbage-collector}@anchor{a1}
@geindex asynchronous garbage collector

@item asynchronous garbage collector

A @ref{15ae,,collector (2)} is asynchronous with respect to the
@ref{30c,,mutator} if it cannot be (easily) predicted when the
collector will run.

This means that the mutator must ensure that @ref{23,,formatted objects} are always @ref{65,,scannable}.

@ref{c1,,synchronous garbage collector}.
@anchor{glossary/a term-ATC}@anchor{15db}
@geindex ATC

@item ATC

@ref{15be,,translation lookaside buffer}.
@anchor{glossary/a term-atomic-object}@anchor{15dc}
@geindex atomic object

@item atomic object

@ref{107,,leaf object}.
@anchor{glossary/a term-automatic-memory-management}@anchor{9}
@geindex automatic memory management

@item automatic memory management

Automatic @ref{15dd,,memory management} is a general term for
techniques that automatically @ref{15de,,recycle} unused
@ref{194,,memory (2)}.

It is not possible, in general, to automatically determine
which @ref{1ab,,objects} are still @ref{78,,live}. Even if
it didn’t depend on future input, there can be no general
algorithm to prove that an object is live (cf. the Halting
Problem). However, effective approximations are possible.

In @ref{15df,,tracing garbage collection}, the approximation is
that an object can’t be live unless it is @ref{96,,reachable}.
In @ref{15e0,,reference counting}, the approximation is that an
object can’t be live unless it is @ref{24,,referenced}. Analysis
of the program text can reveal where objects @ref{49,,die}; A notable technique in this vein is @ref{15e1,,region inference}.

Hybrid algorithms are also possible.

@ref{f,,garbage collection}.

@ref{8,,manual memory management}.

The MPS provides automatic memory management through
@ref{10,,pool classes} such as @ref{62,,AMC (Automatic Mostly-Copying)},
@ref{16c,,AMS (Automatic Mark and Sweep)}, and @ref{fe,,AWL (Automatic Weak Linked)}.
@anchor{glossary/a term-automatic-storage-duration}@anchor{15d0}
@geindex automatic storage duration

@item automatic storage duration

In @ref{1c,,C}, @ref{1ab,,objects} that are declared with
`automatic storage duration' are @ref{78,,live} for the duration
of a block of code.

In most implementations of C, objects with automatic storage
duration are @ref{15ca,,allocated} on the @ref{15bc,,stack} when a
function is entered, and @ref{15d2,,deallocated} when
it returns.

@ref{24a,,dynamic extent}, @ref{15e2,,stack allocation}.

@ref{15e3,,static storage duration}.
@end table

@node Memory Management Glossary B,Memory Management Glossary C,Memory Management Glossary A,Memory Management Glossary
@anchor{glossary/b doc}@anchor{15e4}@anchor{glossary/b glossary-b}@anchor{1591}@anchor{glossary/b memory-management-glossary-b}@anchor{15e5}
@section Memory Management Glossary: B


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/b term-backing-store}@anchor{15d1}
@geindex backing store

@item backing store

Backing @ref{15e6,,store (2)} is typically part of a hard disk
that is used by a @ref{15e7,,paging} or @ref{15e8,,swapping} system to
store information not currently in @ref{311,,main memory}.
Backing store is slower and cheaper than main memory.

Other @ref{15b0,,storage} may, less commonly, be used
in place of a hard disk (for instance, magnetic tape, floppy
disk, or historically, magnetic drum).

In general, backing store may mean any locations used to store
information when its preferred or natural location is
otherwise being used: for example, memory used by a graphical
interface to keep a copy of the contents of obscured windows.

@ref{15e9,,swap space}.
@anchor{glossary/b term-barrier-1}@anchor{60}
@geindex barrier (1)

@item barrier@w{^(1)}

A barrier is a block on reading from or writing to certain
@ref{194,,memory (2)} @ref{15b4,,locations} by
certain threads or processes.

Barriers can be implemented in either software or hardware.
Software barriers involve additional instructions around
@ref{15ea,,load} or @ref{15eb,,store (1)} operations, which would
typically be added by a cooperative compiler. Hardware
barriers don’t require compiler support, and may be
implemented on common operating systems by using @ref{15ec,,memory protection}.

Barriers are used for @ref{d,,incremental} or @ref{15ed,,concurrent} @ref{f,,garbage collection}.


@subsubheading See also


@ref{1d6,,read barrier}, @ref{214,,write barrier}.


@ref{1555,,Pirinen (1998)}, @ref{1588,,Zorn (1990)}.
@anchor{glossary/b term-barrier-2}@anchor{15ee}
@geindex barrier (2)

@item barrier@w{^(2)}

A memory barrier is an instruction on certain processor
architectures that will ensure certain guarantees about the
order of accesses to memory.

Some processor architectures make very few guarantees about
the relative orders of @ref{15ea,,load} and @ref{15eb,,store (1)}
operations in the instruction stream and the actual order of
accesses to @ref{311,,main memory}. These architectures will
often have special instructions that make stronger guarantees.

For example, the ARM has the @code{DMB} (Data Memory Barrier)
instruction:

@quotation

It ensures that all explicit memory accesses that appear
in program order before the DMB instruction are observed
before any explicit memory accesses that appear in program
order after the DMB instruction.
@end quotation

These instructions are vital for certain synchronization
operations.
@anchor{glossary/b term-barrier-hit}@anchor{15ef}
@geindex barrier hit

@item barrier hit

@ref{1d7,,protection fault}.
@anchor{glossary/b term-base-pointer}@anchor{1aa}
@geindex base pointer

@item base pointer

A `base pointer' is a @ref{15b8,,pointer} to the base or start of
an @ref{1ab,,object}.

This term is commonly used in opposition to @ref{15f0,,derived pointer}.

Note that @ref{14f8,,Boehm & Chase (1992)} define “base
pointer” to be “any pointer value directly recognizable by the
@ref{15d7,,collector (1)}”, and this may well include
@ref{1ac,,interior pointers}.

@ref{15f0,,derived pointer}.

For objects with @ref{1d1,,in-band headers}, the MPS
distinguishes between the base pointer, which points to
the start of the header, and the @ref{1d4,,client pointer},
which points to the first word after the end of the
header.
@anchor{glossary/b term-best-fit}@anchor{382}
@geindex best fit

@item best fit

The @ref{380,,allocation policy} that always allocates from the
smallest suitable @ref{15bf,,free block}. Suitable
@ref{15d4,,allocation mechanisms} include @ref{15f1,,sequential fit}
searching for a @ref{15f2,,perfect fit}, @ref{37f,,first fit} on a
size-ordered @ref{15c0,,free block chain}, @ref{15f3,,segregated fits}, and @ref{15f4,,indexed fits}. Many @ref{15f5,,good fit}
allocators are also described as @ref{382,,best fit}.

In theory, best fit may exhibit bad @ref{17e,,fragmentation}, but
in practice this is not commonly observed.


@subsubheading See also


@ref{380,,allocation policy}, @ref{37f,,first fit}, @ref{15f1,,sequential fit}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/b term-BIBOP}@anchor{15f6}
@geindex BIBOP

@item BIBOP

`big bag of pages'.

BIBOP, or `BIg Bag Of Pages', is a technique that encodes
@ref{1ab,,object} type in the high-order bits of their
@ref{126,,address}, by using a lookup table that maps from those
bits to a type.

Despite the name, the blocks involved need not be the size of
a @ref{92,,page}.

BIBOP requires storing only objects of the same type in a
block, but this has the same advantages as @ref{15f3,,segregated fits} in general.

This technique was invented for the PDP-10 MACLISP by JonL
White and Stavros Macrakis. It was an advance on earlier
techniques that divided the @ref{54,,address space} into
contiguous blocks for each type.

@ref{14e2,,Baker (1979)}, @ref{156c,,Steele (1977)}.
@anchor{glossary/b term-big-bag-of-pages}@anchor{15f7}
@geindex big bag of pages

@item big bag of pages

@ref{15f6,,BIBOP}.
@anchor{glossary/b term-binary-buddies}@anchor{15f8}
@geindex binary buddies

@item binary buddies

The most common @ref{15f9,,buddy system} @ref{15d4,,allocation mechanism}, in which all block sizes are a power of two.
Finding a block’s buddy is then a matter of flipping the
appropriate bit in the block’s address.

@ref{379,,Internal fragmentation} is usually high, because
objects are often not a good fit for power-of-two sized
blocks.


@subsubheading See also


@ref{15d4,,allocation mechanism}, @ref{15f9,,buddy system}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/b term-bit-array}@anchor{15fa}
@geindex bit array

@item bit array

@ref{298,,bitmap}.
@anchor{glossary/b term-bit-table}@anchor{15fb}
@geindex bit table

@item bit table

@ref{298,,bitmap}.
@anchor{glossary/b term-bit-vector}@anchor{15fc}
@geindex bit vector

@item bit vector

@ref{298,,bitmap}.
@anchor{glossary/b term-bitmap}@anchor{298}
@geindex bitmap

@item bitmap

`bit array', `bit table', `bit vector', `bitset'.

A table of bits.

Bitmaps are sometimes used to represent the marks in a
@ref{15fd,,mark-sweep} collector (see @ref{15fe,,bitmap marking}),
or the used memory in a @ref{15ff,,bitmapped fits}
@ref{15ce,,allocator}.
@anchor{glossary/b term-bitmap-marking}@anchor{15fe}
@geindex bitmap marking

@item bitmap marking

In @ref{15fd,,mark-sweep} collectors, bitmap marking is a
technique for @ref{1600,,marking} objects that stores the mark
bits for the objects in a contiguous range of memory in a
separate @ref{298,,bitmap}. This improves the collector’s
@ref{1601,,locality of reference} and cache performance, because
it avoids setting the @ref{1602,,dirty bit} on the @ref{92,,pages}
containing the marked objects.

@ref{1586,,Zorn (1989)}.
@anchor{glossary/b term-bitmapped-fit}@anchor{15ff}
@geindex bitmapped fit

@item bitmapped fit

A class of @ref{15d4,,allocation mechanisms} that use a
@ref{298,,bitmap} to represent the usage of the @ref{47,,heap}.
Each bit in the map corresponds to a part of the heap,
typically a @ref{37c,,word}, and is set if that part is in use.
Allocation is done by searching the bitmap for a run of clear
bits.

Bitmapped fit mechanisms have good @ref{1601,,locality of reference}, as they avoid examining @ref{1d1,,in-band headers}
when allocating.


@subsubheading See also


@ref{15d4,,allocation mechanism}, @ref{15f4,,indexed fit}, @ref{15f1,,sequential fit}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/b term-bitmask}@anchor{218}
@geindex bitmask

@item bitmask

A @ref{298,,bitmap} used to select or exclude a set of bits in
another bitmap.
@anchor{glossary/b term-bitset}@anchor{1603}
@geindex bitset

@item bitset

@ref{298,,bitmap}.
@anchor{glossary/b term-black}@anchor{1604}
@geindex black

@item black

In a @ref{1605,,tri-color marking} scheme, black @ref{1ab,,objects}
are objects that have been @ref{65,,scanned}.

More precisely, black objects have been noted
@ref{96,,reachable} and the @ref{15ae,,collector (2)} has finished
with them and need not visit them again (for the purposes of
@ref{4b,,tracing}).

@ref{1606,,gray}, @ref{1607,,white}.
@anchor{glossary/b term-blacklisting}@anchor{1608}
@geindex blacklisting

@item blacklisting@anchor{glossary/b term-black-listing}@anchor{1609}
@geindex black-listing

@itemx black-listing

A @ref{349,,conservative garbage collector} can be made more effective by `blacklisting'
values which resemble @ref{126,,addresses} that may be
@ref{15ca,,allocated} at in the future, but are known not to be
@ref{15b8,,pointers} . This list is then used to avoid allocation
at those addresses.

For example, such values can be gathered by scanning the
@ref{97,,roots} before any @ref{1ab,,objects} have been allocated.

@ref{14f9,,Boehm (1993)}.
@anchor{glossary/b term-block}@anchor{185}
@geindex block

@item block

Block is a vague term for an (often contiguous) area of
@ref{15b0,,memory (1)}. Often used to describe @ref{194,,memory (2)}
@ref{15ca,,allocated} by an @ref{15ce,,allocator} such as
@ref{1a,,malloc}.

The term `block' is used as a general term for a unit of
allocation, with `object' being reserved for
@ref{23,,formatted objects}.
@anchor{glossary/b term-bounds-error}@anchor{160a}
@geindex bounds error

@item bounds error

@ref{c5,,overwriting error}.
@anchor{glossary/b term-boxed}@anchor{160b}
@geindex boxed

@item boxed

Boxed @ref{1ab,,objects} are represented by a @ref{15b8,,pointer} to
a @ref{185,,block} of @ref{194,,memory (2)} that contains the object
data. Sometimes the pointer is @ref{88,,tagged} to
distinguish it from an @ref{48,,unboxed} object, or to represent
its type. Only the pointer is duplicated when the object is
passed around, so updates to the object are reflected
everywhere.

@ref{48,,unboxed}.


@subsubheading See also


@ref{15f6,,BIBOP}, @ref{88,,tag}.


@ref{1527,,Gudeman (1993)}.
@anchor{glossary/b term-break-table}@anchor{160c}
@geindex break-table

@item break-table

A break-table is a data structure used by a
@ref{160d,,mark-compact} collector to store the @ref{160e,,relocation}
information.


@subsubheading See also


@ref{160d,,mark-compact}.

@anchor{glossary/b term-brk}@anchor{15d9}
@geindex brk

@item brk

@code{brk} is a Unix system call that sets the limit of the data
segment. This limit is known as the `break'.

@code{brk} and its companion @ref{160f,,sbrk} are obsolete on Unix
systems that support @ref{51,,virtual memory} and the @code{mmap}
system call.

The @ref{1c,,C} library implementation of @ref{1a,,malloc}
formerly @ref{15ca,,allocated} @ref{194,,memory (2)} for the
@ref{47,,heap} by extending the data segment using @code{brk} or
@code{sbrk}. The data segment resided immediately above the
program code and @ref{1610,,static data} (the
“text segment”) in the @ref{54,,address space}.


@float Figure

@image{MemoryPoolSystem-figures/brk,,,Diagram: A simplified view of the address space of a Unix process.,svg}

@caption{A simplified view of the address space of a Unix process.}

@end float


More modern Unix systems use @ref{cc,,address space layout randomization} to place these segments at randomized locations
in @ref{54,,address space}, so that the @ref{47,,heap} is no
longer adjacent to the static data.
@anchor{glossary/b term-broken-heart}@anchor{1611}
@geindex broken heart

@item broken heart

@ref{e3,,Copying garbage collectors} @ref{5d,,move}
@ref{96,,reachable} @ref{1ab,,objects} into another
@ref{1612,,semi-space}. They leave a @ref{87,,forwarding pointer} in
the old @ref{15b4,,location}, pointing to the
new. The object at the old location is known as a broken
heart.

@ref{87,,forwarding pointer}.
@anchor{glossary/b term-bucket}@anchor{15c3}
@geindex bucket

@item bucket

In a @ref{e,,generational garbage collector}, it is often desirable to divide
@ref{e1,,generations} by the age of the
@ref{1ab,,object}. These divisions are known as buckets.


@subsubheading See also


@ref{15c2,,aging space}, @ref{15c4,,creation space}, @ref{e,,generational garbage collection}.

@anchor{glossary/b term-buddy-system}@anchor{15f9}
@geindex buddy system

@item buddy system

Buddy systems are a subclass of @ref{1613,,strict segregated fit}
@ref{15d4,,allocation mechanisms} which
make @ref{1614,,splitting} and @ref{38c,,coalescing} fast by pairing each block with a unique adjacent
`buddy' block.

There is an array of @ref{268,,free lists}, one for
each allowable block size. Allocation rounds up the requested
size to an allowable size and allocates from the corresponding
free list. If the free list is empty, a larger block is
selected and split. A block may only be split into a pair of
buddies.

A block may only be coalesced with its buddy, and this is only
possible if the buddy has not been split into smaller blocks.

The advantage of buddy systems is that the buddy of a block
being freed can be quickly found by a simple address
computation. The disadvantage of buddy systems is that the
restricted set of block sizes leads to high @ref{379,,internal fragmentation}, as does the limited ability to coalesce.

Different sorts of buddy system are distinguished by the
available block sizes and the method of splitting. They
include @ref{15f8,,binary buddies} (the most common),
@ref{1615,,Fibonacci buddies}, @ref{1616,,weighted buddies}, and
@ref{1617,,double buddies}.


@subsubheading See also


@ref{15d4,,allocation mechanism}, @ref{15f3,,segregated fit}, @ref{25c,,segregated free lists}, @ref{1613,,strict segregated fit}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/b term-buffer}@anchor{1cb}
@geindex buffer

@item buffer

A `buffer' is a large @ref{185,,block} of @ref{194,,memory (2)} from
which blocks are @ref{15ca,,allocated} contiguously, as a simple
technique for fast @ref{15ca,,allocation}.

By keeping only a `high-water' mark (that is, a
@ref{15b8,,pointer} to the start of unused memory), the buffer
technique avoids expensive @ref{1d1,,in-band headers} and the
searching of @ref{15c0,,free block chains}. Buffers tend to,
however, lead to @ref{383,,external fragmentation}.

@ref{14db,,Appel et al. (1988)}.

Buffers are implemented using @ref{63,,allocation points}
attached to @ref{18,,pools}.
@anchor{glossary/b term-bus-error}@anchor{15c9}
@geindex bus error

@item bus error

Strictly speaking, `a bus error' is a fault on a hardware bus,
such as when an invalid @ref{126,,address} is issued.

Generally, any hardware exception caused by a @ref{194,,memory (2)} access (for example, @ref{15ea,,loading} an
@ref{15cb,,unaligned} @ref{37c,,word}) is termed a `bus error'. The
term is often used more loosely as a synonym for any memory
access error.


@subsubheading See also


@ref{1618,,segmentation violation}.

@anchor{glossary/b term-byte-1}@anchor{17c}
@geindex byte (1)

@item byte@w{^(1)}

A unit of storage measurement, equal to 8 bits.

It does not matter how the bits are arranged: a byte is just a
quantity.

This is the sense of byte used in the terms @ref{188,,kilobyte},
@ref{186,,megabyte}, @ref{1619,,gigabyte}, @ref{161a,,terabyte}, etc. The
prefixes in these terms derive from the SI prefixes for powers
of 1000, but since powers of two are much more common in
binary computers, they are used to denote powers of 1024 (2@w{^10}).


@subsubheading See also


@ref{37c,,word}.

@anchor{glossary/b term-byte-2}@anchor{15c8}
@geindex byte (2)

@item byte@w{^(2)}

A data type defined by a processor architecture.

For example, the smallest @ref{126,,addressable}
@ref{15b4,,memory location} on the Intel x86 family is the 8-bit
byte.

The PDP-10 had 36-bit @ref{37c,,words}, and defined “byte” to
be a general sub-@ref{37c,,word} bit-field: compare
@ref{161b,,byte (3)}. On this machine it was commonplace for
characters to be packed four or five to a word using 9- or
7-bit bytes respectively.


@subsubheading See also


@ref{37c,,word}.

@anchor{glossary/b term-byte-3}@anchor{161b}
@geindex byte (3)

@item byte@w{^(3)}

A contiguous set of bits used to represent a range of values
compactly.

The number of bits in a byte is a measure of the information
content of the byte. An `n'-bit byte can represent 2@w{^n}
distinct values.

Bytes may be packed into (or otherwise stored in bit-fields
of) integers, words, or other aligned values for space
efficiency.
@anchor{glossary/b term-byte-4}@anchor{161c}
@geindex byte (4)

@item byte@w{^(4)}

A data type or storage unit defined by a programming language.

In ANSI/ISO @ref{1c,,C}, “the unit of data storage large enough
to hold the basic character set of the execution environment”.
In this sense, it is often used synonymously with the C type
@code{char}. C defines @code{sizeof(char)} to be 1. Many
architectures that run C programs equate this sense of byte
and @ref{15c8,,byte (2)}.
@end table

@node Memory Management Glossary C,Memory Management Glossary D,Memory Management Glossary B,Memory Management Glossary
@anchor{glossary/c doc}@anchor{161d}@anchor{glossary/c glossary-c}@anchor{1592}@anchor{glossary/c memory-management-glossary-c}@anchor{161e}
@section Memory Management Glossary: C


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/c term-C89}@anchor{161f}
@geindex C89

@item C89

@ref{1620,,C90}.
@anchor{glossary/c term-C90}@anchor{1620}
@geindex C90

@item C90

`C89'.

A revision of the ANSI/ISO Standard for the @ref{1c,,C}
programming language. Although more than twenty years old, it
remains the only form of Standard C that is supported by all
the major compilers, including Microsoft Visual C.

The public interface conforms to this standard. See
@ref{112,,Interface conventions}.

@ref{118,,ISO/IEC 9899;1990}.
@anchor{glossary/c term-C99}@anchor{1621}
@geindex C99

@item C99

A revision of the ANSI/ISO Standard for C the @ref{1c,,C}
programming language.

@ref{53,,Keyword arguments} can be conveniently passed to
functions using C99’s compound literal syntax. See
@ref{57,,Keyword arguments}.

@ref{9d6,,ISO/IEC 9899;1999}.
@anchor{glossary/c term-cache-1}@anchor{1622}
@geindex cache (1)

@item cache@w{^(1)}

`cache memory', `memory cache'.

A processor’s memory cache is a small piece of fast, but more
expensive memory, usually @ref{1623,,static memory (1)}, used for
copies of parts of @ref{311,,main memory}. The cache is
automatically used by the processor for fast access to any
data currently @ref{1624,,resident} there. Access to the cache
typically takes only a few processor clock cycles, whereas
access to @ref{311,,main memory} may take tens or even hundreds
of cycles.

What part of main memory is resident in a cache, and the
mechanisms by which it is kept consistent, are quite varied.
See @ref{1625,,cache policy}.

Some systems have more than one level of cache. “Level 1
cache” is the fastest, smallest @ref{1626,,storage level}, “level
2” the next fastest, and so on.


@subsubheading See also


@ref{1627,,cache (2)}, @ref{1628,,storage hierarchy}.

@anchor{glossary/c term-cache-2}@anchor{1627}
@geindex cache (2)

@item cache@w{^(2)}

A cache is any small, fast piece of @ref{15b0,,memory (1)}, used
for copies of data that normally reside in a larger, slower
piece of storage. The cache is used to speed up access to data
@ref{1624,,resident} in the slower storage.

In a typical cache, recently used data is @ref{1624,,resident} in
the cache (although the details of this depend on the
@ref{1625,,cache policy}). A @ref{1622,,cache (1)} is the most common
example of a cache(2).


@subsubheading See also


@ref{1628,,storage hierarchy}.

@anchor{glossary/c term-cache-memory}@anchor{1629}
@geindex cache memory

@item cache memory

@ref{1622,,cache (1)}.
@anchor{glossary/c term-cache-policy}@anchor{1625}
@geindex cache policy

@item cache policy

Any @ref{162a,,cache (3)} uses a `cache policy' to
decide which data to store. A cache policy is an attempt to
predict the future, so that the cache will provide swift
responses to future requests.

Cache policy may be implemented in hardware, software, or a
combination of both. Some systems allow programs to influence
cache policy, by giving hints or directions about future use
of data.

There are three main aspects of cache behavior which the cache
policy can affect:


@enumerate 

@item 
Fetch policy. This determines which data is fetched into
the cache, usually as a result of receiving a request for
data that isn’t cached.

@item 
Eviction policy. This determines which data is discarded
from the cache to provide space for newly fetched data.

@item 
Write policy This determines how and when modifications to
cached data are synchronized with the underlying storage.
@end enumerate


@subsubheading See also


@ref{1622,,cache (1)}, @ref{1627,,cache (2)}, @ref{162a,,cache (3)}.


@ref{14e3,,Baker (1991)}, @ref{1577,,Wilson et al. (1992)}, @ref{1589,,Zorn (1991)}.
@anchor{glossary/c term-caching-3}@anchor{162a}
@geindex caching (3)

@item caching@w{^(3)}

`memoization', `tabling'.

`Caching' is a heuristic that stores answers to questions
asked in the past in a `cache' or a `table', in order that
they may be more quickly answered in the future. This process
is also called memoization and tabling (by the @ref{162b,,Prolog}
community).

A “look-ahead cache” attempts to store answers to questions
that will be asked soon. A @ref{1627,,cache (2)} is a common
example of a cache(3).
@anchor{glossary/c term-cactus-stack}@anchor{162c}
@geindex cactus stack

@item cactus stack

`spaghetti stack'.

A cactus stack is a @ref{15bc,,stack} with branches. When
diagrammed, its shape resembles that of a saguaro cactus@footnote{https://en.wikipedia.org/wiki/Saguaro}.

In languages that support @ref{15ad,,continuations},
@ref{15ac,,activation records} can have @ref{15af,,indefinite extent}.
One technique for implementing continuations is not to copy
the activation records that are captured, but rather to create
a fork in the stack below the captured @ref{15b1,,stack frames},
so that new frames appear as a parallel branch. Often the
process of forking is done lazily: captured frames are only
duplicated if they are modified.
@anchor{glossary/c term-card}@anchor{162d}
@geindex card

@item card

A card is a division of memory, all cards being of equal size
(in a particular area of discourse). A card is usually bigger
than a @ref{37c,,word} and smaller than a @ref{92,,page}. Cards are
used in a technique called @ref{162e,,card marking} whereby
@ref{1602,,dirty bits} (which record which portions of old
generations have been written into) are maintained for each
card. Often the use of cards will also entail the use of a
@ref{162f,,crossing map}.
@anchor{glossary/c term-card-marking}@anchor{162e}
@geindex card marking

@item card marking

A technique for managing @ref{15b8,,pointer} @ref{15eb,,stores (1)}
into old @ref{e1,,generations} (which in turn is used to track
@ref{1630,,inter-generational pointers}). Each generation is
divided into a number of equal-sized @ref{162d,,cards}, and when a
generation is written into, the particular card written to is
recorded (often by using a @ref{298,,bitmap}). Subsequently, when
@ref{65,,scanning} an older generation in order to
collect a younger generation, only the recorded cards (in the
old generation) need to be scanned.


@subsubheading See also


@ref{e,,generational garbage collection}.


@ref{14df,,Azagury et al. (1998)}, @ref{152e,,Hosking & Hudson (1993)}, @ref{1569,,Sobalvarro (1988)}.
@anchor{glossary/c term-cell}@anchor{1631}
@geindex cell

@item cell

@ref{1ab,,object}.
@anchor{glossary/c term-Cheney-collector}@anchor{1632}
@geindex Cheney collector

@item Cheney collector

`Cheney scan'.

A Cheney collector uses the @ref{1633,,tospace} of a
@ref{1634,,two-space collector} as a queue of objects remaining to
be @ref{65,,scanned}, thus eliminating the need for
recursion when @ref{4b,,tracing} the @ref{1635,,graph} of
@ref{1ab,,objects}.

@ref{1503,,Cheney (1970)}.
@anchor{glossary/c term-Cheney-scan}@anchor{1636}
@geindex Cheney scan

@item Cheney scan

@ref{1632,,Cheney collector}.
@anchor{glossary/c term-clamped-state}@anchor{19f}
@geindex clamped state

@item clamped state

One of the four states an @ref{16,,arena} can be in (the
others being the @ref{192,,unclamped state}, the
@ref{b8,,parked state}, and the @ref{d5,,postmortem state}).
In the clamped state, no object motion occurs and the
staleness of @ref{19a,,location dependencies} does not
change. However, a @ref{f,,garbage collection} may be in
progress. Call @ref{19d,,mps_arena_clamp()} to put an arena
into the clamped state.
@anchor{glossary/c term-client-arena}@anchor{4d}
@geindex client arena

@item client arena

An @ref{11a,,arena class} that gets its @ref{194,,memory (2)}
from the @ref{d0,,client program}. See
@ref{178,,Client arenas}.
@anchor{glossary/c term-client-object}@anchor{325}
@geindex client object

@item client object

A @ref{23,,formatted object} that contains data from the
@ref{d0,,client program}. One of three types of formatted
objects, the other two being @ref{66,,forwarding objects}
and @ref{67,,padding objects}.
@anchor{glossary/c term-client-pointer}@anchor{1d4}
@geindex client pointer

@item client pointer

A pointer to the first word in an object that’s not part
of the @ref{1d1,,in-band header}. See
@ref{1d2,,In-band headers}.


@subsubheading See also


@ref{1aa,,base pointer}.

@anchor{glossary/c term-client-program}@anchor{d0}
@geindex client program

@item client program

@ref{30c,,mutator}
@anchor{glossary/c term-closure}@anchor{1ee}
@geindex closure

@item closure

A closure is a function or procedure that is saved along with
the current bindings from enclosing blocks for later
invocation.

Some programming languages, such as @ref{1637,,ALGOL}, permit
nested blocks to access the local variables of enclosing
blocks. @ref{28a,,Lisp}-like languages further permit such an
inner block (in particular a function or procedure) to be
saved for later invocation. The act of saving such an inner
block along with the current bindings of variables in the
enclosing blocks that are referenced by the inner block, is
called `closing over' or `capturing' those variables. The
object created is termed `a closure'. A closure is invoked
just like the function from which it was built, passing
whatever parameters the function accepts, but when the
function executes, the variables that belong to enclosing
blocks will have the bindings that were in effect when the
closure was created.

A closure is typically implemented by saving both the
function and any @ref{15ac,,activation records} that contain
variables referenced by the function. The closure creates
additional implicit @ref{24,,references} to the bindings
closed over and hence must be accounted for in any memory
management scheme. The closure itself is an object that
must be managed and may have either @ref{24a,,dynamic extent}
or @ref{15af,,indefinite extent} depending on whether it is
only used by inner blocks of the creating block or passed
out of the creating block.


@subsubheading See also


@ref{15ad,,continuation}.

@anchor{glossary/c term-coalesce}@anchor{38c}
@geindex coalesce

@item coalesce

Coalescing is the act of merging two adjacent @ref{15bf,,free blocks}.

Coalescing reduces @ref{383,,external fragmentation}, but is not
totally effective.

Coalescing can be done as soon as blocks are freed, or it can
be deferred until some time later (known as @ref{1638,,deferred coalescing}), or it might not be done at all.

@ref{157a,,Wilson et al. (1995)} has details about
fragmentation, and which coalescing strategies are effective
under what circumstances.
@anchor{glossary/c term-cold-end}@anchor{aa}
@geindex cold end

@item cold end

A @ref{27,,control stack} has two ends: the oldest items are at
the `cold end' and the newest items are at the `hot end'.
Sometimes the cold end is called the “bottom” of the stack,
but that is misleading when the stack grows downwards, as it
does on common computing platforms.

In order for the MPS to be able to @ref{65,,scan}
@ref{24,,references} on the stack, the @ref{d0,,client program} must pass the location of the cold end of the
stack (or the part of the stack that might contain
references to memory managed by the MPS) to
@ref{a9,,mps_root_create_thread()}.

@ref{1639,,hot end}
@anchor{glossary/c term-collect}@anchor{163a}
@geindex collect

@item collect

An @ref{1ab,,object} is collected when it is @ref{4a,,reclaimed} by
a @ref{20,,garbage collector}.

@ref{4a,,reclaim}.
@anchor{glossary/c term-collection}@anchor{163b}
@geindex collection

@item collection

@ref{1a2,,collection cycle}.
@anchor{glossary/c term-collection-cycle}@anchor{1a2}
@geindex collection cycle

@item collection cycle

`collection'.

A collection cycle is a single complete execution of a
@ref{15df,,tracing garbage collection} algorithm.

Each collection cycle includes (not necessarily in strict
order) choosing a @ref{221,,condemned set}; @ref{65,,scanning} @ref{97,,roots} and @ref{1ab,,objects} that have not been
condemned; @ref{4b,,tracing} the object graph to find
all condemned objects that are @ref{96,,reachable}; and
@ref{4a,,reclaiming} those that were not reachable.

In non-incremental garbage collection, the @ref{30c,,mutator}
pauses at the start of a collection cycle and cannot continue
until it is complete. In @ref{d,,incremental} and @ref{15ed,,parallel} garbage collection, a collection cycle can be
interleaved with, or simultaneous to, mutator activity.
@anchor{glossary/c term-collector-1}@anchor{15d7}
@geindex collector (1)

@item collector@w{^(1)}

@ref{20,,garbage collector}.
@anchor{glossary/c term-collector-2}@anchor{15ae}
@geindex collector (2)

@item collector@w{^(2)}

In a @ref{f,,garbage-collected} system,
the part that executes the garbage collection code, which
discovers unused @ref{15b0,,memory (1)} and @ref{4a,,reclaims} it.

For purposes of describing @ref{d,,incremental garbage collection}, the system is divided into the @ref{30c,,mutator}
and the `collector'. These can be separate threads of
computation, or interleaved within the same thread.

This term is due to @ref{1515,,Dijkstra et al. (1976)}.

@ref{30c,,mutator}.
@anchor{glossary/c term-color}@anchor{163c}
@geindex color

@item color@anchor{glossary/c term-colour}@anchor{163d}
@geindex colour

@itemx colour

In a @ref{1605,,tri-color marking} scheme, each @ref{163e,,node} has a
one of three colors: @ref{1604,,black}, @ref{1607,,white}, or
@ref{1606,,gray}. In a @ref{163f,,treadmill}, nodes may also be
colored @ref{1640,,off-white}.
@anchor{glossary/c term-commit-limit}@anchor{156}
@geindex commit limit

@item commit limit

The commit limit is a limit on the @ref{190,,committed} @ref{194,,memory (2)} that the @ref{16,,arena} will
obtain from the operating system. It can be changed by
calling @ref{15a,,mps_arena_commit_limit_set()}.
@anchor{glossary/c term-committed-1}@anchor{1641}
@geindex committed (1)

@item committed@w{^(1)}

@ref{190,,mapped}.
@anchor{glossary/c term-committed-2}@anchor{b1}
@geindex committed (2)

@item committed@w{^(2)}

A block has been `committed' if it is fully initialized
and is under the management of the MPS, as opposed to a
block that is merely `reserved'. See
@ref{ae,,Allocation point protocol}.
@anchor{glossary/c term-compactifying}@anchor{1642}
@geindex compactifying

@item compactifying

@ref{1643,,compaction}.
@anchor{glossary/c term-compaction}@anchor{1643}
@geindex compaction

@item compaction

`compactifying'.

Compaction is the process of @ref{5d,,moving} @ref{78,,live} @ref{1ab,,objects} to eliminate
@ref{49,,dead} space between them. Some people call this
`compactifying', to distinguish it from techniques for
compressing data structures.

Compaction is used to avoid @ref{383,,external fragmentation} and
to increase @ref{1601,,locality of reference}.
@anchor{glossary/c term-composite-object}@anchor{1644}
@geindex composite object

@item composite object

In the @ref{1645,,PostScript} language, `composite objects' are
the @ref{160b,,boxed} objects.

Unlike a @ref{1646,,simple object}, the main data (what PostScript
calls `the value') in a composite object are stored
separately, in @ref{1647,,VM (2)}. Several composite objects can
share the same value.

@ref{160b,,boxed}.

@ref{1646,,simple object}.
@anchor{glossary/c term-comprehensive}@anchor{1648}
@geindex comprehensive

@item comprehensive

A @ref{15d7,,collector (1)} is `comprehensive' if all
@ref{1649,,garbage} (or, all @ref{21,,unreachable} @ref{1ab,,objects})
is @ref{4a,,reclaimed} in one @ref{1a2,,collection cycle}.


@subsubheading See also


@ref{f,,garbage collection}.

@anchor{glossary/c term-concurrent-garbage-collection}@anchor{164a}
@geindex concurrent garbage collection

@item concurrent garbage collection

@ref{15ed,,parallel garbage collection}.
@anchor{glossary/c term-condemned-set}@anchor{221}
@geindex condemned set

@item condemned set

`threatened set'.

`Condemned' @ref{1ab,,objects} are those which are
candidates for @ref{15de,,recycling} within a
@ref{1a2,,collection cycle}.

At the start of a collection cycle, the @ref{15d7,,collector (1)}
may choose to condemn some objects (the `condemned set' or
`threatened set') but not to condemn others (the @ref{164b,,immune set}). Objects that are not condemned are assumed to be
@ref{78,,live} and behave as @ref{97,,roots} for the
purposes of that collection cycle.

Many simple @ref{15df,,tracing garbage collection} algorithms
begin by condemning all objects, but @ref{e,,generational garbage collectors} will
condemn individual @ref{e1,,generations} or
combinations of generations. Often young generations are
condemned but older ones are not, because objects in older
generations are less likely to have become
@ref{21,,unreachable}.

In collectors using @ref{1605,,tri-color marking}, at the start of
a collection cycle the condemned set is exactly the set of
objects that the collector colors @ref{1607,,white}.

@ref{164b,,immune set}.
@anchor{glossary/c term-connected}@anchor{164c}
@geindex connected

@item connected

@ref{1ab,,Objects} are connected if and only if one
contains a @ref{24,,reference} to the other.


@subsubheading See also


@ref{1635,,graph}.

@anchor{glossary/c term-cons-1}@anchor{15cf}
@geindex cons (1)

@item cons@w{^(1)}

In @ref{28a,,Lisp}, @code{cons} is a primitive operation creating a
list element (from English “CONStruct”). By extension, a
`cons' is the element created.

Function CONS in the Common Lisp HyperSpec@footnote{http://www.lispworks.com/documentation/lw60/CLHS/Body/f_cons.htm}.
@anchor{glossary/c term-cons-2}@anchor{164d}
@geindex cons (2)

@item cons@w{^(2)}

@ref{15ca,,allocate}.
@anchor{glossary/c term-conservative-garbage-collection}@anchor{349}
@geindex conservative garbage collection

@item conservative garbage collection

In conservative @ref{f,,garbage collection}, the layout of
@ref{1ab,,objects} and @ref{97,,roots} is not
known, instead the @ref{15d7,,collector (1)} assumes that any
field that looks like a @ref{15b8,,pointer} `might' be a
@ref{24,,reference}.

Conservative collectors can work with programs where
information about the @ref{194,,memory (2)} layout is not
available, because, for example, the language doesn’t support
@ref{f,,garbage collection}.

A conservative collector doesn’t need to know the
@ref{164e,,format} of the objects, it just needs some idea of
where the object boundaries are. It regards any field value
that looks like a pointer to an object (or, sometimes, into
the middle of one), as preventing the @ref{15de,,recycling} of that object. It can’t @ref{5d,,move} objects, because then the references to
the moved objects would need to be updated, and such
@ref{9f,,ambiguous references} must not be modified, in case
they weren’t pointers after all. Therefore, conservative
collectors are usually @ref{15fd,,mark-sweep collectors}.

Because references are ambiguous, some objects may be retained
despite being actually @ref{21,,unreachable}. In practice, this
happens rarely, and refinements such as @ref{1608,,black-listing} can further reduce the odds.

@ref{164f,,exact garbage collection}.


@subsubheading See also


@ref{1c4,,ambiguous root}, @ref{1ac,,interior pointer}, @ref{348,,semi-conservative garbage collection}.


@ref{14f6,,Boehm & Weiser (1988)}, @ref{14f9,,Boehm (1993)}.
@anchor{glossary/c term-constant-root}@anchor{215}
@geindex constant root

@item constant root

A @ref{97,,root} that the @ref{d0,,client program} promises
not change after it is registered, by specifying the
@ref{a0,,root mode} @ref{210,,MPS_RM_CONST} when calling a
registration function such as @ref{9c,,mps_root_create()}.
@anchor{glossary/c term-constructor-1}@anchor{15d3}
@geindex constructor (1)

@item constructor@w{^(1)}

A constructor is a function or method that @ref{15ca,,allocates} and initializes an @ref{1ab,,object}.

@ref{1650,,destructor (1)}.
@anchor{glossary/c term-constructor-2}@anchor{1651}
@geindex constructor (2)

@item constructor@w{^(2)}

In @ref{1d,,C++}, a `constructor' is a member function that is
used to initialize a newly-@ref{15ca,,allocated} object.

The actual allocation of @ref{194,,memory (2)} is performed by
@code{operator new} or the compiler (for @ref{1610,,static} and @ref{15e2,,stack allocation}), and the new
@ref{185,,block} is then passed to the appropriate constructor.


@subsubheading See also


@ref{1652,,destructor (2)}.

@anchor{glossary/c term-continuation}@anchor{15ad}
@geindex continuation

@item continuation

A continuation is the data required to restore an execution
context after invocation of another context, typically as a
subroutine.

If continuations can be represented as first-class
objects, as in @ref{46,,Scheme}, the execution contexts can
no longer be stored on a @ref{15bc,,stack}, instead, (at least
some) @ref{15ac,,activation records} have
to be @ref{1653,,heap-allocated}.


@subsubheading See also


@ref{1ee,,closure}.

@anchor{glossary/c term-control-stack}@anchor{27}
@geindex control stack

@item control stack

`activation stack', `execution stack'.

A @ref{15bc,,stack} that stores @ref{15ac,,activation records}, particularly subroutine return
information, is known as a `control stack'.

Typically the control stack is supported and used by the
hardware architecture and the operating system, limiting the
types and sizes of @ref{1ab,,objects} that can be stored
on it. Often, only one type of object, a @ref{15b1,,stack frame},
is permitted, and the layout of that is defined by the
hardware architecture.

Theoretically, a control stack is simply an array of
activation records, and hence just another object managed
by the @ref{15cd,,memory manager}. In practice, the control
stack is central to the performance of the hardware
architecture and may require special treatment. In
particular, it may not be accessible as ordinary
@ref{194,,memory (2)}, or it may have its own @ref{1627,,cache (2)} with specific updating requirements.

@ref{15bc,,stack}.


@subsubheading See also


@ref{aa,,cold end}, @ref{1654,,data stack}, @ref{1639,,hot end}.

@anchor{glossary/c term-cool}@anchor{c8}
@geindex cool

@item cool

A @ref{c9,,variety} in which most MPS functions
@ref{284,,assert} that their data structures are
valid, even functions on the @ref{7c,,critical path}. See
@ref{14,,Building the Memory Pool System}. Compare @ref{162,,hot} and @ref{163,,rash}.
@anchor{glossary/c term-copying-garbage-collection}@anchor{e3}
@geindex copying garbage collection

@item copying garbage collection

`scavenging garbage collection'.

Copying garbage collection is a kind of @ref{15df,,tracing garbage collection} that operates by @ref{160e,,relocating}
@ref{96,,reachable} @ref{1ab,,objects} (this is sometimes called
`scavenging') and then @ref{4a,,reclaiming} objects
that are left behind, which must be @ref{21,,unreachable} and
therefore @ref{49,,dead}.

A copying garbage collection relies on being able to find and
correct all @ref{24,,references} to copied objects.


@float Figure

@image{MemoryPoolSystem-figures/copying,,,Diagram: Copying garbage collection.,svg}

@caption{Copying garbage collection.}

@end float


@ref{5d,,moving}.


@subsubheading See also


@ref{1611,,broken heart}, @ref{87,,forwarding pointer}, @ref{1634,,two-space collector}.


The @ref{62,,AMC (Automatic Mostly-Copying)} pool class implements copying garbage
collection (more precisely, @ref{1655,,mostly-copying garbage collection}).
@anchor{glossary/c term-core}@anchor{1656}
@geindex core

@item core

A historical synonym for @ref{311,,main memory}, deriving from
the `cores' or ferrite rings which were once the main
technology used to implement it.

@ref{311,,main memory}.
@anchor{glossary/c term-creation-space}@anchor{15c4}
@geindex creation space

@item creation space

In @ref{e,,generational garbage collection}, when
@ref{e1,,generations} are divided into
@ref{15c3,,buckets}, the creation space is where new
@ref{1ab,,objects} are created in each generation.

This term is sometimes used as a synonym for @ref{35f,,nursery space}.

@ref{15c2,,aging space}.


@subsubheading See also


@ref{e,,generational garbage collection}.

@anchor{glossary/c term-critical-path}@anchor{7c}
@geindex critical path

@item critical path

The sequence of operations on which the MPS spends the
majority of its time, consisting of @ref{65,,scanning}, @ref{b4,,fixing}, @ref{1600,,marking} and
@ref{e3,,copying}. See
@ref{1e3,,The critical path through the MPS}.
@anchor{glossary/c term-crossing-map}@anchor{162f}
@geindex crossing map

@item crossing map

Where @ref{194,,memory (2)} has already been divided into some
fixed-sized unit (for example, @ref{92,,pages} or
@ref{162d,,cards}), a crossing map records where
@ref{1ab,,objects} lie across the boundaries of the
fixed-sized units. In other words, which fixed-sized units do
not start with the beginning of an object.

A system which implements @ref{213,,remembered sets} by
@ref{1657,,page marking} or @ref{162e,,card marking} needs to scan all
the @ref{15b8,,pointers} in the page or card. If the system can
not @ref{65,,scan} partial objects (or requires information in
the object @ref{1d1,,header} in order to scan a
partial object), a crossing map is necessary to find the
beginning of the first object in the unit.

In a sense, a crossing map is an optimization of
@ref{1658,,tagged architecture}. It represents the minimum
information necessary to determine how to interpret any
word of memory.
@anchor{glossary/c term-cyclic-data-structure}@anchor{1659}
@geindex cyclic data structure

@item cyclic data structure

A data structure is cyclic if some of its @ref{24,,references}
form a loop; that is, there’s an @ref{1ab,,object} that can be
reached by following references from itself.
@end table

@node Memory Management Glossary D,Memory Management Glossary E,Memory Management Glossary C,Memory Management Glossary
@anchor{glossary/d doc}@anchor{165a}@anchor{glossary/d glossary-d}@anchor{1593}@anchor{glossary/d memory-management-glossary-d}@anchor{165b}
@section Memory Management Glossary: D


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/d term-dangling-pointer}@anchor{281}
@geindex dangling pointer

@item dangling pointer

A dangling @ref{15b8,,pointer} is a surviving @ref{24,,reference} to
an @ref{1ab,,object} that no longer exists at that
@ref{126,,address}.

In @ref{8,,manual memory management}, dangling pointers
typically arise from one of:


@enumerate 

@item 
A @ref{165c,,premature free}, where an object is @ref{15d2,,freed (1)}, but a reference is retained;

@item 
Retaining a reference to a @ref{15e2,,stack-allocated} object, after the relevant @ref{15b1,,stack frame}
has been popped.
@end enumerate

Dangling pointers can occur under @ref{9,,automatic memory management}, because of a @ref{f,,garbage collection} bug (such
as premature collection, or @ref{5d,,moving} without updating all @ref{24,,references}), but this
is much rarer because garbage collection code is usually a
single common core of reused code in which these bugs can be
fixed systematically.
@anchor{glossary/d term-data-stack}@anchor{1654}
@geindex data stack

@item data stack

A @ref{15bc,,stack} used to manage the storage of
@ref{15e2,,stack-allocated} @ref{1ab,,objects},
other than @ref{15ac,,activation records}, often under program
control.

Because of the limitations that may be imposed on the
@ref{27,,control stack}, or to support stack-like semantics for
certain data structures, some language implementations manage
additional data stacks in software for storing objects that
have @ref{24a,,dynamic extent} but that do not fit within the
constraints of the control stack.


@subsubheading See also


@ref{27,,control stack}.

@anchor{glossary/d term-dead}@anchor{49}
@geindex dead

@item dead

An @ref{1ab,,object} is dead if it is not @ref{78,,live}; that is,
when the @ref{30c,,mutator} cannot reach any state in which it
accesses the object.

It is not possible, in general, for @ref{20,,garbage collectors}
to determine exactly which @ref{1ab,,objects} are dead and which
are live. Instead, they use some approximation to detect
objects that are provably dead, such as those that are
@ref{21,,unreachable}.

@ref{78,,live}.


@subsubheading See also


@ref{15d6,,free (3)}, @ref{1649,,garbage}, @ref{165d,,undead}.

@anchor{glossary/d term-deallocate}@anchor{165e}
@geindex deallocate

@item deallocate

@ref{15d2,,free (1)}.
@anchor{glossary/d term-debugging-pool}@anchor{285}
@geindex debugging pool

@item debugging pool

A @ref{18,,pool} that performs extra checking in order to
find errors in the @ref{d0,,client program}. It uses
@ref{283,,fenceposts} to detect
@ref{c5,,overwriting errors} and it
writes patterns over reclaimed blocks in order to detect
@ref{165c,,use after free} or missing
references during @ref{65,,scanning}.
@anchor{glossary/d term-deferred-coalescing}@anchor{1638}
@geindex deferred coalescing

@item deferred coalescing

Deferred coalescing is a policy which @ref{38c,,coalesces}
@ref{15bf,,free blocks} some time after the blocks are freed, as
opposed to coalescing free blocks immediately as they are
freed.

Adjacent free blocks can be coalesced to form larger free
blocks; deferred coalescing is a catch-all for policies which
perform this coalescing sometime after the blocks were freed.

Given this rather flexible definition there are a number of
choices for when to coalesce: as the @ref{268,,free list} is
traversed during allocation, when the allocation cannot be
satisfied from the free list, periodically, and so on. In
addition there are choices to be made regarding how much
coalescing to perform at any one time.
@anchor{glossary/d term-deferred-reference-counting}@anchor{165f}
@geindex deferred reference counting

@item deferred reference counting

Deferred @ref{15e0,,reference counting} reduces the cost of
maintaining reference counts by avoiding adjustments when the
@ref{24,,reference} is stored on the @ref{15bc,,stack}.

On many systems, the majority of stores are made into local
variables, which are kept on the stack. Deferred reference
counting leaves those out and counts only references stored in
@ref{47,,heap} objects. This requires compiler support, but can
lead to substantial performance improvements.

@ref{1ab,,Objects} cannot be @ref{4a,,reclaimed} as soon
as their reference count becomes zero, because there might
still be references to them from the stack. Such objects are
added to a @ref{1660,,zero count table} (ZCT) instead. If a
reference to an object with a count of zero is stored into the
heap, then the object is removed from the ZCT. Periodically
the stack is @ref{65,,scanned}, and any objects in the
ZCT which were not referenced from the stack are reclaimed.

Deferred reference counting has been used successfully with
several languages, notably @ref{1661,,Smalltalk}. However, since
it fails to collect objects with @ref{1659,,cyclic} references, it is often used alongside a
@ref{15df,,tracing garbage collector}.

@ref{1514,,Deutsch & Bobrow (1976)}.
@anchor{glossary/d term-dependent-object}@anchor{ff}
@geindex dependent object

@item dependent object

In @ref{fe,,AWL (Automatic Weak Linked)}, each object in the pool can have a
`dependent object'. While scanning an object, the MPS
ensures that the dependent object is unprotected so that
it can be updated. This feature supports the
implementation of @ref{fb,,weak-key}
and @ref{fc,,weak-value hash tables}. See
@ref{100,,Dependent objects}.
@anchor{glossary/d term-derived-pointer}@anchor{15f0}
@geindex derived pointer

@item derived pointer

@ref{1ac,,interior pointer}.
@anchor{glossary/d term-destructor-1}@anchor{1650}
@geindex destructor (1)

@item destructor@w{^(1)}

A destructor is a function or a method that performs the
explicit @ref{15d2,,deallocation} of an @ref{1ab,,object}.
It may also perform clean-up actions.

@ref{15d3,,constructor (1)}.
@anchor{glossary/d term-destructor-2}@anchor{1652}
@geindex destructor (2)

@item destructor@w{^(2)}

In @ref{1d,,C++}, a `destructor' is a member function that is
used to clean up when an object is being @ref{15d2,,deallocated}.

When an object is being destroyed (by @code{delete} or
automatically), the appropriate destructor is called, and then
the actual deallocation of @ref{194,,memory (2)} is performed by
@code{operator delete} or the run-time system (for @ref{1610,,static} and @ref{15e2,,stack allocation}).


@subsubheading See also


@ref{1651,,constructor (2)}.

@anchor{glossary/d term-DGC}@anchor{1662}
@geindex DGC

@item DGC

@ref{1663,,distributed garbage collection}.
@anchor{glossary/d term-direct-method}@anchor{1664}
@geindex direct method

@item direct method

Direct methods of @ref{9,,automatic memory management} maintain
information about the @ref{78,,liveness} of each
@ref{1ab,,object}, detecting @ref{1649,,garbage} directly.

Such bits of information, for example, @ref{15e0,,reference counts}, are typically stored within the objects
themselves.

Direct @ref{f,,garbage collection} can allow @ref{194,,memory (2)}
to be @ref{4a,,reclaimed} as soon as it becomes
@ref{21,,unreachable}. However, the stored information must be
updated as the @ref{1635,,graph} of objects changes; this may be
an expensive operation, especially in @ref{1663,,distributed garbage collection} where it can lead to intensive
communication between processors, and make garbage collection
less robust to network failures.

@ref{1665,,indirect method}.

@ref{1538,,Jones et al. (2012)}.
@anchor{glossary/d term-dirty-bit}@anchor{1602}
@geindex dirty bit

@item dirty bit

A dirty bit is a flag indicating that a @ref{92,,page} (or
similar) has been written to since it was last examined.

Dirty bits are used by @ref{1627,,cache (2)} to determine which
pages must be written out, and by garbage collectors in
conjunction with @ref{214,,write barriers}.
@anchor{glossary/d term-distributed-garbage-collection}@anchor{1663}
@geindex distributed garbage collection

@item distributed garbage collection

`DGC'.

Distributed garbage collection is @ref{f,,garbage collection}
in a system where @ref{1ab,,objects} might not reside in the same
@ref{54,,address space} or even on the same machine.

Distributed garbage collection is difficult to achieve in
widely-distributed systems (over wide-area networks) because
of the costs of synchronization and communication between
processes. These costs are particularly high for a
@ref{15df,,tracing garbage collector}, so other techniques, including @ref{1666,,weighted reference counting}, are commonly used instead.
@anchor{glossary/d term-double-buddies}@anchor{1617}
@geindex double buddies

@item double buddies

A @ref{15f9,,buddy system} @ref{15d4,,allocation mechanism} using a
pair of @ref{15f8,,binary buddy} systems with
staggered size classes.

One system is a pure binary buddy, with powers-of-two classes
(2, 4, 8, …). The other uses some fixed multiple of
powers-of-two (for example, 3, 6, 12, …). This resembles
@ref{1616,,weighted buddies}, but the two buddy systems are
treated independently: blocks cannot be @ref{1614,,split} or
@ref{38c,,coalesced} from one to the other.

@ref{157b,,Wise (1978)}.
@anchor{glossary/d term-double-free}@anchor{26b}
@geindex double free

@item double free

A double free is when an attempt is made to @ref{15d2,,free (1)} a
@ref{194,,memory (2)} @ref{185,,block} that has already been freed.

This usually occurs in @ref{8,,manual memory management} when
two parts of a program believe they are responsible for the
management of the same block.

Many manual @ref{15cd,,memory managers} have great trouble with
double frees, because they cannot cheaply determine that
@ref{15d2,,deallocated} blocks were already free.
Instead, they corrupt their @ref{15c0,,free block chain}, which
leads to mysterious problems when the same block is
subsequently @ref{15ca,,allocated}.


@subsubheading See also


@ref{165c,,premature free}.

@anchor{glossary/d term-doubleword}@anchor{1667}
@geindex doubleword

@item doubleword

`longword'.

A `doubleword' is a unit of memory consisting of two adjacent
@ref{37c,,words}.

On the Intel 80386, 80486, and Pentium processors, the
doubleword of 32 bits is actually the `natural word size',
but the term `word' is still used for the 16-bit unit, as
it was on earlier processors of this series.


@subsubheading See also


@ref{1668,,quadword}.

@anchor{glossary/d term-doubly-weak-hash-table}@anchor{fd}
@geindex doubly weak hash table

@item doubly weak hash table

A hash table that is both @ref{fb,,weak-key} and @ref{fc,,weak-value}.
@anchor{glossary/d term-DRAM}@anchor{1669}
@geindex DRAM

@item DRAM

@ref{166a,,dynamic memory}.
@anchor{glossary/d term-dynamic-allocation}@anchor{166b}
@geindex dynamic allocation

@item dynamic allocation

@ref{1653,,heap allocation}.
@anchor{glossary/d term-dynamic-extent}@anchor{24a}
@geindex dynamic extent

@item dynamic extent

An @ref{1ab,,object} has `dynamic extent' if its @ref{b5,,lifetime}
is bounded by the execution of a function or some other block
construct.

Objects of dynamic extent are usually @ref{15e2,,stack-allocated}.

@ref{15d0,,automatic storage duration}.

@ref{15af,,indefinite extent}.
@anchor{glossary/d term-dynamic-memory}@anchor{166a}
@geindex dynamic memory

@item dynamic memory

`DRAM', `dynamic RAM'.

Dynamic memory, or dynamic RAM (DRAM, pronounced “dee ram”),
is a type of @ref{55,,RAM}.

Dynamic memory requires periodic refreshing to avoid losing
its contents (as opposed to @ref{1623,,static memory (1)}, the
contents of which are preserved without any need for
refreshing). The refreshing is performed by additional
“refresh hardware” usually external to the dynamic memory
package itself, sometimes by the main CPU. Dynamic memory is
cheap and compact and is the choice for large amounts of
relatively fast memory, such as the @ref{311,,main memory} of
PCs. Dynamic memory often comes packaged in SIMMs or DIMMs.


@subsubheading See also


@ref{166c,,SDRAM}, @ref{1623,,static memory (1)}.

@anchor{glossary/d term-dynamic-RAM}@anchor{166d}
@geindex dynamic RAM

@item dynamic RAM

@ref{166a,,dynamic memory}.
@end table

@node Memory Management Glossary E,Memory Management Glossary F,Memory Management Glossary D,Memory Management Glossary
@anchor{glossary/e doc}@anchor{166e}@anchor{glossary/e glossary-e}@anchor{1594}@anchor{glossary/e memory-management-glossary-e}@anchor{166f}
@section Memory Management Glossary: E


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/e term-ecru}@anchor{1670}
@geindex ecru

@item ecru

@ref{1640,,off-white}.
@anchor{glossary/e term-edge}@anchor{1671}
@geindex edge

@item edge

In a @ref{1635,,graph}, an edge is a connection between two
@ref{163e,,nodes}.

In a directed graph (digraph), edges have a direction;
otherwise the start and end nodes are interchangeable. By
convention, two directed edges between the same two nodes, but
in different directions, are depicted as a bi-directional
edge.

Typically an edge represents some relation between nodes.

In memory management, edges normally represent the fact
that an @ref{1ab,,object} holds a @ref{24,,reference} to
another object.


@subsubheading See also


@ref{1635,,graph}.

@anchor{glossary/e term-entry-table-1}@anchor{1672}
@geindex entry table (1)

@item entry table@w{^(1)}

An entry table is a table of @ref{24,,references}
into a set of @ref{1ab,,objects} used to indirect
references from the outside.

The Lieberman-Hewitt @ref{15d7,,collector (1)} represented
references from older @ref{e1,,generations} to younger ones by
indirect pointers through an entry table in the younger
generation that contained the actual @ref{126,,address} of the
young object. This is fairly expensive without special
hardware; other @ref{e,,generational} collectors generally use @ref{213,,remembered sets}.


@subsubheading See also


@ref{1673,,exit table}, @ref{e,,generational garbage collection}.


@ref{153f,,Lieberman & Hewitt (1983)}.
@anchor{glossary/e term-entry-table-2}@anchor{1674}
@geindex entry table (2)

@item entry table@w{^(2)}

An entry table is an implementation of a @ref{213,,remembered set}, where, for a given @ref{e1,,generation}, there is a list
of @ref{1ab,,objects} in older generations which contain
@ref{24,,references} into that generation.

One could also store the actual @ref{15b4,,locations} of the references, which would save time when
@ref{65,,scanning}, but incur other costs.

@ref{213,,remembered set}.


@subsubheading See also


@ref{1673,,exit table}, @ref{e,,generational garbage collection}.

@anchor{glossary/e term-exact-garbage-collection}@anchor{164f}
@geindex exact garbage collection

@item exact garbage collection

`precise garbage collection', `type-accurate garbage collection'.

@ref{f,,Garbage collection} is exact (or precise) if it deals
only with @ref{61,,exact references}.

An exact @ref{15d7,,collector (1)} needs to know the
@ref{164e,,format} of the @ref{1ab,,objects} and the
@ref{97,,roots}, so that it can tell which fields are
references.

@ref{349,,conservative garbage collection}.
@anchor{glossary/e term-exact-reference}@anchor{61}
@geindex exact reference

@item exact reference

`precise reference', `sure reference'.

An exact or precise or sure reference is a value the
@ref{15d7,,collector (1)} knows is a @ref{24,,reference}.

This is the usual sort of reference. The term is used to draw
a contrast with @ref{9f,,ambiguous reference}.

@ref{9f,,ambiguous reference}.
@anchor{glossary/e term-exact-root}@anchor{20b}
@geindex exact root

@item exact root

`precise root'.

An exact or precise root is a @ref{97,,root} that contains only
@ref{61,,exact references}.

@ref{1c4,,ambiguous root}.


@subsubheading See also


@ref{61,,exact reference}.


An exact root has @ref{9e,,rank} @ref{9d,,mps_rank_exact()}.
@anchor{glossary/e term-exact-segregated-fit}@anchor{1675}
@geindex exact segregated fit

@item exact segregated fit

A @ref{15f3,,segregated fit} @ref{15d4,,allocation mechanism} which
has a separate @ref{268,,free list} for each possible block size.
The array of free lists may be represented sparsely. Large
blocks may be treated separately.


@subsubheading See also


@ref{15d4,,allocation mechanism}, @ref{15f3,,segregated fit}, @ref{25c,,segregated free list}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/e term-execution-stack}@anchor{1676}
@geindex execution stack

@item execution stack

@ref{27,,control stack}.
@anchor{glossary/e term-exit-table}@anchor{1673}
@geindex exit table

@item exit table

An exit table is a table of all @ref{24,,references}
from a set of @ref{1ab,,objects} to objects outside the
set.


@subsubheading See also


@ref{1672,,entry table (1)}, @ref{1674,,entry table (2)}.


@ref{153f,,Lieberman & Hewitt (1983)}.
@anchor{glossary/e term-extent}@anchor{1677}
@geindex extent

@item extent

@ref{b5,,lifetime}.
@anchor{glossary/e term-external-fragmentation}@anchor{383}
@geindex external fragmentation

@item external fragmentation

External @ref{17e,,fragmentation} is the inability to use
@ref{15b0,,memory (1)} because @ref{15d6,,free (3)} memory is divided
into many small @ref{185,,blocks}.

If @ref{78,,live} @ref{1ab,,objects} are scattered, the
free blocks cannot be @ref{38c,,coalesced}, and hence
no large blocks can be @ref{15ca,,allocated}.

Common solutions to external fragmentation include:


@enumerate 

@item 
@ref{5d,,Moving garbage collection};

@item 
@ref{1678,,Handles};

@item 
Making all your objects the same size.
@end enumerate


@subsubheading See also


@ref{379,,internal fragmentation}.


@ref{1533,,Johnstone & Wilson (1998)}.
@end table

@node Memory Management Glossary F,Memory Management Glossary G,Memory Management Glossary E,Memory Management Glossary
@anchor{glossary/f doc}@anchor{1679}@anchor{glossary/f glossary-f}@anchor{1595}@anchor{glossary/f memory-management-glossary-f}@anchor{167a}
@section Memory Management Glossary: F


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/f term-fencepost}@anchor{283}
@geindex fencepost

@item fencepost@anchor{glossary/f term-fence-post}@anchor{167b}
@geindex fence post

@itemx fence post

A fencepost is spare @ref{15b0,,memory (1)} between
@ref{15ca,,allocated} @ref{185,,blocks} for checking purposes.

Some @ref{15dd,,memory management} systems leave spare memory
between allocated blocks and store special values in it. If a
checking routine finds that these memory @ref{15b4,,locations} have been modified, this probably indicates
an @ref{c5,,overwriting error} in the application that was
allocated the adjacent block.

Such checking can help application programmers to find bugs
that would otherwise be difficult to reproduce and track down.

@ref{1d1,,in-band header}.

@ref{285,,Debugging pools} use fenceposts. See
@ref{10d,,Debugging pools}.
@anchor{glossary/f term-fencepost-error}@anchor{167c}
@geindex fencepost error

@item fencepost error@anchor{glossary/f term-fence-post-error}@anchor{167d}
@geindex fence post error

@itemx fence post error

The term `fencepost error' refers to errors arising from the
fact that, to enclose `n' consecutive intervals, you need
`n' + 1 end-points, from the number of posts required to
support fence rails.

An example of a fencepost error would be, in @ref{1c,,C}:

@example
void f(void)
@{
  int i;
  int a[10];
  for(i = 0; i <= 10; i++)
    a[i] = 0;
@}
@end example

because the declaration @code{int a[10];} creates an array of ten
integers, with indices from 0 to 9, but the @code{for} loop index
@code{i} runs from 0 to 10.
@anchor{glossary/f term-Fibonacci-buddies}@anchor{1615}
@geindex Fibonacci buddies

@item Fibonacci buddies

A common @ref{15f9,,buddy system} @ref{15d4,,allocation mechanism}, in
which block sizes form a Fibonacci series (each block size is
the sum of the two previous sizes). Each block can therefore
be @ref{1614,,split} to form two blocks of valid sizes, and the
sizes are more closely spaced than in @ref{15f8,,binary buddies}.
However, if the same size is allocated repeatedly, performance
may suffer as the remainder blocks may have to be split again
(or become fragments).


@subsubheading See also


@ref{15d4,,allocation mechanism}, @ref{15f9,,buddy system}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/f term-FIFO-ordered-first-fit}@anchor{385}
@geindex FIFO-ordered first fit

@item FIFO-ordered first fit

The @ref{380,,allocation policy} that always uses the
least-recently @ref{15d2,,freed (1)} suitable @ref{15bf,,free block}. Commonly implemented by adding freed blocks to the end
of a @ref{15c0,,free block chain}, and then using @ref{37f,,first fit} allocation on this chain. @ref{15d2,,free (1)} can be very
quick, depending on the @ref{38c,,coalescing} policy.

According to @ref{157a,,Wilson et al. (1995)}, this policy
controls fragmentation quite well, better than
@ref{15c1,,LIFO-ordered first fit} and as well as
@ref{384,,address-ordered first fit} in some cases, although
@ref{1601,,locality} may be worse.
@anchor{glossary/f term-file-mapping}@anchor{167e}
@geindex file mapping

@item file mapping

@ref{15b7,,memory mapping}.
@anchor{glossary/f term-finalization}@anchor{b}
@geindex finalization

@item finalization

`termination'.

In @ref{f,,garbage-collected} languages,
it is often necessary to perform actions on some
@ref{1ab,,objects} after they are no longer in use and
before their @ref{194,,memory (2)} can be @ref{15de,,recycled}. These actions are known as `finalization' or
`termination'.

A common use of finalization is to release resources when the
corresponding “proxy” object dies. For example, an open file
might be represented by a stream object. When this object has
been proven @ref{49,,dead} by the @ref{15d7,,collector (1)}, it is
certain that the file is no longer in use by the program, and
it can and should be closed before the stream is recycled.

Note that finalization is not, in general, guaranteed to be
prompt, and this can cause problems if it is used to manage
scarce operating system resources such as file descriptors.

Many object-oriented languages provide support for
finalization, for example, Cedar, @ref{167f,,Java}, @ref{1680,,Perl}
5, and @ref{1661,,Smalltalk}.

The term `finalization' is sometimes used to refer to the use
of @ref{1650,,destructors (1)}, for example in Ada.

See @ref{f0,,Finalization}.
@anchor{glossary/f term-finalized-block}@anchor{23d}
@geindex finalized block

@item finalized block

A @ref{185,,block} that has been registered for finalization
using @ref{e8,,mps_finalize()}, and which the MPS has
determined is @ref{49,,dead}, but whose finalization message
has not been discarded. See
@ref{236,,mps_message_type_finalization()}.
@anchor{glossary/f term-first-fit}@anchor{37f}
@geindex first fit

@item first fit

First fit is a @ref{15f1,,sequential fit} @ref{15d4,,allocation mechanism}.

To quote @ref{157a,,Wilson et al. (1995)}:

@quotation

First fit simply searches the @ref{268,,free list} from the
beginning, and uses the first @ref{15bf,,free block} large
enough to satisfy the request. If the block is larger than
necessary, it is split and the remainder is put on the
free list.
@end quotation

The first fit mechanism provides a class of first fit
@ref{380,,allocation policies}, depending on the order in which
the free list is stored. @ref{384,,Address-ordered first fit}
stores the list in order of (usually increasing) address.
@ref{15c1,,LIFO-ordered first fit} puts blocks on the front of the
free list when they are @ref{15d2,,freed (1)}. @ref{385,,FIFO-ordered first fit} puts blocks on the end of the free list when they
are @ref{15d2,,freed (1)}.


@subsubheading See also


@ref{384,,address-ordered first fit}, @ref{382,,best fit}, @ref{385,,FIFO-ordered first fit}, @ref{15c1,,LIFO-ordered first fit}, @ref{1681,,next fit}, @ref{15f1,,sequential fit}, @ref{386,,worst fit}.

@anchor{glossary/f term-fix}@anchor{b4}
@geindex fix

@item fix

To `fix' a @ref{24,,reference} from one @ref{185,,block} to
another is to declare it to the MPS by calling
@ref{75,,MPS_FIX1()} and @ref{76,,MPS_FIX2()} within a
@ref{73,,scan method}. In a @ref{5d,,moving} @ref{18,,pool}, fixing a reference may also
update it to point to the new location of the block. See
@ref{25,,Scanning}.
@anchor{glossary/f term-flip}@anchor{18c}
@geindex flip

@item flip

The instant in a @ref{1634,,two-space collector} when the roles of
the two @ref{1612,,semi-spaces} are reversed. What
was the @ref{1633,,tospace} is now marked as @ref{1682,,fromspace} and
@ref{221,,condemned}. What was the fromspace
becomes the site for all new @ref{15ca,,allocations}. Also used in a more general sense to mean the
initiation of a new @ref{1a2,,collection cycle}.


@float Figure

@image{MemoryPoolSystem-figures/two-space,,,Diagram: In a two-space collector@comma{} the *flip* occurs just before the fromspace is condemned and copying starts.,svg}

@caption{In a two-space collector, the `flip' occurs just before the
fromspace is condemned and copying starts.}

@end float

@anchor{glossary/f term-floating-garbage}@anchor{15d8}
@geindex floating garbage

@item floating garbage

Floating garbage is @ref{1649,,garbage} that is not
@ref{15de,,recycled} promptly due to some approximation
or optimization in the @ref{20,,garbage collector}.

Floating garbage results from conservatively estimating an
@ref{1ab,,object} that is really @ref{21,,unreachable} to be
@ref{96,,reachable} for the purposes of a particular
@ref{1a2,,collection cycle}. Using estimates can have
considerable performance benefits but also result in higher
@ref{194,,memory (2)} consumption.

Typical estimates that cause floating garbage are:


@enumerate 

@item 
Every register or @ref{15ab,,activation frame} slot holds a
reachable value: this is not always true, as objects stored
in dead registers or slots may be otherwise unreachable.
This estimate can simplify the compiler as well as the
interface between the compiler and the garbage collector.

@item 
Every object in a @ref{213,,remembered set} is reachable: this
is not always true, because remembered objects can have
become unreachable since they were added to the remembered
set. This estimate allows remembered sets to be effective;
the alternative—determining whether each remembered object
is reachable—is equivalent to a full garbage collection.

@item 
Anything that looks like a @ref{24,,reference} is one: this
is not generally true, because random data can have the
same bit pattern as a pointer. @ref{349,,Conservative garbage collectors} use this
estimate.

@item 
Any object referenced from another is reachable: this is
not generally true, because garbage can reference other
garbage. @ref{15e0,,Reference counting} collectors use this
estimate, resulting in their not being able to reclaim
self-referential structures.

@item 
Any object reached during collection remains live until the
next collection: this may not be true when the garbage
collector runs interleaved with the mutator, as do
@ref{d,,incremental} and
@ref{15ed,,concurrent}
collectors.
@end enumerate

A more subtle kind of floating garbage is an unreachable data
structure that spans multiple regions that are never
@ref{221,,condemned} together.
@anchor{glossary/f term-foreign-code}@anchor{10b}
@geindex foreign code

@item foreign code

From the point of view of the @ref{d0,,client program},
`foreign code' is external code (not part of the client
program, or the MPS), which is not aware of and does not
co-operate with the MPS. The client program must take care
when passing the address of a block in a @ref{1ad,,moving} @ref{18,,pool} to foreign code.

The @ref{353,,LO (Leaf Object)} @ref{10,,pool class} is designed for this
use case: blocks allocated from this pool do not move and
are never protected, and so may be passed safely to
foreign code.
@anchor{glossary/f term-format}@anchor{164e}
@geindex format

@item format

A format describes the representation of an @ref{1ab,,object};
that is, how the object is laid out in memory.

A format usually specifies where the fields of the objects are
located and what their type is.

If formats are provided by a language or the application
program, @ref{164f,,exact garbage collection} can be used,
because the @ref{15d7,,collector (1)} can determine which
fields are @ref{24,,references}.


@subsubheading See also


@ref{349,,conservative garbage collection}.

@anchor{glossary/f term-format-method}@anchor{69}
@geindex format method

@item format method

One of the methods in an @ref{39,,object format}, defined by
the @ref{d0,,client program} in order to describe its
objects to the MPS. May be a @ref{73,,scan method},
@ref{81,,skip method}, @ref{85,,forward method},
@ref{8c,,is-forwarded method}, or @ref{90,,padding method}.
@anchor{glossary/f term-formatted-object}@anchor{23}
@geindex formatted object

@item formatted object

An allocated @ref{185,,block} that belongs to an
@ref{39,,object format} and may be @ref{65,,scanned} by
the @ref{20,,garbage collector}. See @ref{6a,,Object formats}.
@anchor{glossary/f term-forward-method}@anchor{85}
@geindex forward method

@item forward method

A @ref{69,,format method} that is called by a @ref{5d,,moving} @ref{18,,pool} when it
has moved an object. The forward method replaces the old
object with a @ref{1db,,forwarding marker} that points to the
new location of the object. See @ref{86,,mps_fmt_fwd_t}.
@anchor{glossary/f term-forwarding-marker}@anchor{1db}
@geindex forwarding marker

@item forwarding marker@anchor{glossary/f term-forwarding-object}@anchor{66}
@geindex forwarding object

@itemx forwarding object@anchor{glossary/f term-forwarding-pointer}@anchor{87}
@geindex forwarding pointer

@itemx forwarding pointer

Some @ref{20,,garbage collectors}
@ref{5d,,move} @ref{96,,reachable}
@ref{1ab,,objects} into another space. They leave a
forwarding pointer, a special @ref{24,,reference} pointing to
the new @ref{15b4,,location}, in the old
location.

@ref{1611,,broken heart}.


@subsubheading See also


@ref{e3,,copying garbage collection}, @ref{1634,,two-space collector}.


The term `forwarding object' is used. This is a
@ref{23,,formatted object} that has been replaced by a
@ref{1db,,forwarding marker}. One of three types of formatted
objects, the other two being @ref{325,,client objects} and
@ref{67,,padding objects}.
@anchor{glossary/f term-fragmentation}@anchor{17e}
@geindex fragmentation

@item fragmentation

Fragmentation is the inability to use @ref{15b0,,memory (1)}
because of the arrangement of memory already in use. It is
usually divided into @ref{383,,external fragmentation} and
@ref{379,,internal fragmentation}.

@ref{1533,,Johnstone & Wilson (1998)}.
@anchor{glossary/f term-frame}@anchor{1683}
@geindex frame

@item frame

@ref{1d1,,in-band header}.
@anchor{glossary/f term-free-1}@anchor{15d2}
@geindex free (1)

@item free@w{^(1)}

`deallocate'.

In @ref{8,,manual memory management}, to free or deallocate an
@ref{1ab,,object} is to tell the @ref{15cd,,memory manager} that it
is no longer needed. The @ref{15b0,,memory (1)} may then be
@ref{15de,,recycled} by being used for subsequent
@ref{15ca,,allocation}, or by being returned to the
operating system.

@ref{15ca,,allocate}.


@subsubheading See also


@ref{1650,,destructor (1)}, @ref{1b,,free (2)}.

@anchor{glossary/f term-free-2}@anchor{1b}
@geindex free (2)

@item free@w{^(2)}

In @ref{1c,,C}, the system function used for explicit
@ref{15d2,,deallocation} is called @code{free}.
@anchor{glossary/f term-free-3}@anchor{15d6}
@geindex free (3)

@item free@w{^(3)}

@ref{194,,Memory (2)} is `free' if it is not currently
@ref{15ca,,allocated}.

The term `available' was commonly used to mean “free”.

@ref{15ca,,allocated}.


@subsubheading See also


@ref{15d2,,free (1)}.

@anchor{glossary/f term-free-4}@anchor{1684}
@geindex free (4)

@item free@w{^(4)}

@ref{1685,,unmapped}.
@anchor{glossary/f term-free-block}@anchor{15bf}
@geindex free block

@item free block

A single contiguous area of @ref{194,,memory (2)} available to
satisfy an @ref{15ca,,allocation} request.

For the purpose of discussing @ref{15d4,,allocation mechanisms},
two adjacent free blocks are not considered to be a single
free block, until they are @ref{38c,,coalesced}. Free blocks may
be @ref{1614,,split}.


@subsubheading See also


@ref{15d4,,allocation mechanism}, @ref{268,,free list}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/f term-free-block-chain}@anchor{15c0}
@geindex free block chain

@item free block chain

Some systems store the @ref{268,,free list} as a linked list, or
chain.

Usually the links are stored within the @ref{15d6,,free (3)}
@ref{185,,blocks}. This means that all @ref{15ca,,allocated} blocks
must be large enough to store these, and implies a minimum
size.

Sometimes, the free block chain is ordered by @ref{126,,address}.
This makes @ref{38c,,coalescence} considerably
cheaper, but @ref{15d2,,deallocation} more expensive.


@subsubheading See also


@ref{268,,free list}.

@anchor{glossary/f term-free-list}@anchor{268}
@geindex free list

@item free list

The free list is the set of @ref{15bf,,free blocks}.

Originally this term meant the single linked list of all free
blocks, but as @ref{15d4,,allocation mechanisms} have become more
varied, it has become more generic, and now may be implemented
as a tree or other data structure rather than a linked list.
If the implementation actually is a linked list of free
blocks, this is called a @ref{15c0,,free block chain} to
distinguish it from the abstract term.

There may be several free lists, classed by size or other
characteristic. For instance, @ref{25c,,segregated free list}
systems classify free lists by block size.


@subsubheading See also


@ref{15bf,,free block}, @ref{15c0,,free block chain}.

@anchor{glossary/f term-freestanding}@anchor{14e}
@geindex freestanding

@item freestanding

In the @ref{1c,,C} programming language as defined by
@ref{1620,,C90}, a freestanding implementation “accepts any
strictly conforming program in which the use of the features
specified in the library section is confined to the contents
of the standard headers @code{<float.h>}, @code{<limits.h>},
@code{<stdarg.h>}, and @code{<stddef.h>}.” The @ref{1621,,C99} standard
adds @code{<iso646.h>}, @code{<stdbool.h>}, and @code{<stdint.h>} to
this list.

In particular, a freestanding implementation need not provide
the other features of the standard C library, including I/O,
time, and string operations.

@ref{1686,,hosted}.

The MPS is designed to be portable to a freestanding
implementation, by restricting the use of other features
either to @ref{12f,,platform}-specific modules or to the
replaceable @ref{160,,plinth} modules.

@ref{118,,ISO/IEC 9899;1990}, @ref{9d6,,ISO/IEC 9899;1999}.
@anchor{glossary/f term-free-store}@anchor{1687}
@geindex free store

@item free store@anchor{glossary/f term-freestore}@anchor{1688}
@geindex freestore

@itemx freestore

@ref{47,,heap}.
@anchor{glossary/f term-from-space}@anchor{1689}
@geindex from space

@item from space@anchor{glossary/f term-fromspace}@anchor{1682}
@geindex fromspace

@itemx fromspace

`old space', `oldspace'.

In @ref{e3,,copying garbage collection}, the space containing a
mixture of @ref{78,,live} and @ref{49,,dead} objects, out of which
the former are copied.

@ref{1633,,tospace}.
@anchor{glossary/f term-function-pointer}@anchor{168a}
@geindex function pointer

@item function pointer

In the @ref{1c,,C} programming language, a @ref{15b8,,pointer} to an
function, as distinct from a @ref{6e,,object pointer}. The C
programming language does not guarantee that function and
object pointers are the same size, or that a pointer of one
type can be cast to a pointer of the other type without
losing information (but on every mainstream C implementation,
including all those supported by the MPS, they are in fact the
same).

@ref{6e,,object pointer}.
@anchor{glossary/f term-function-record}@anchor{168b}
@geindex function record

@item function record

@ref{15ac,,activation record}.
@end table

@node Memory Management Glossary G,Memory Management Glossary H,Memory Management Glossary F,Memory Management Glossary
@anchor{glossary/g doc}@anchor{168c}@anchor{glossary/g glossary-g}@anchor{1596}@anchor{glossary/g memory-management-glossary-g}@anchor{168d}
@section Memory Management Glossary: G


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/g term-garbage}@anchor{1649}
@geindex garbage

@item garbage

Garbage consists of @ref{1ab,,objects} that are
@ref{49,,dead}.

In @ref{15df,,tracing garbage collection}, the term is sometimes
used to mean objects that are known to be dead; that is,
objects that are @ref{21,,unreachable}.
@anchor{glossary/g term-garbage-collection}@anchor{f}
@geindex garbage collection

@item garbage collection

`GC'.

Garbage collection (GC), also known as `automatic memory
management', is the automatic @ref{15de,,recycling} of
@ref{1653,,dynamically allocated} @ref{194,,memory (2)}. Garbage collection is performed by a @ref{20,,garbage collector} which recycles memory that it can prove will never
be used again. Systems and languages which use garbage
collection can be described as `garbage-collected'.

Garbage collection is a tried and tested memory management
technique that has been in use since its invention in the
1950s. It avoids the need for the programmer to
@ref{15d2,,deallocate} memory @ref{185,,blocks}
explicitly, thus avoiding a number of problems: @ref{234,,memory leaks}, @ref{26b,,double frees}, and @ref{165c,,premature frees}. The
burden on the programmer is reduced by not having to
investigate such problems, thereby increasing productivity.

Garbage collection can also dramatically simplify programs,
chiefly by allowing modules to present cleaner interfaces to
each other: the management of object storage between modules
is unnecessary.

It is not possible, in general, for a @ref{20,,garbage collector} to determine exactly which @ref{1ab,,objects} are
still @ref{78,,live}. Even if it didn’t depend on future input,
there can be no general algorithm to prove that an object is
live (cf. the Halting Problem). All garbage collectors use
some efficient approximation to liveness. In @ref{15df,,tracing garbage collection}, the approximation is that an object can’t
be live unless it is @ref{96,,reachable}. In @ref{15e0,,reference counting}, the approximation is that an object can’t be live
unless it is @ref{24,,referenced}. Hybrid algorithms are also
possible. Often the term `garbage collection' is used narrowly
to mean only tracing garbage collection.

There is a large body of published work on particular and
general garbage collection algorithms.

Garbage collection was first invented by John McCarthy in
1958 as part of the implementation of @ref{28a,,Lisp}.

Other significant languages offering garbage collection
include @ref{167f,,Java}, @ref{168e,,ML}, @ref{168f,,Modula-3},
@ref{1680,,Perl}, @ref{162b,,Prolog}, and @ref{1661,,Smalltalk}. Major
applications using garbage collection include Emacs and
AutoCAD; usually, you can’t tell whether an application does
or not, but these have extension languages that expose the
fact.

@ref{9,,automatic memory management}.

@ref{8,,manual memory management}.


@subsubheading See also


@ref{349,,conservative garbage collection}, @ref{e3,,copying garbage collection}, @ref{1663,,distributed garbage collection}, @ref{e,,generational garbage collection}, @ref{d,,incremental garbage collection}, @ref{15ed,,parallel garbage collection}.


@ref{1541,,McCarthy (1960)}.
@anchor{glossary/g term-garbage-collector}@anchor{20}
@geindex garbage collector

@item garbage collector

`collector'.

A (garbage) collector is (an implementation of) a
@ref{f,,garbage collection} algorithm.

This term is often used when referring to particular
implementations or algorithms, for example, “the
Boehm–Demers–Weiser `collector'”.
@anchor{glossary/g term-GB}@anchor{1690}
@geindex GB

@item GB

@ref{1619,,gigabyte}.
@anchor{glossary/g term-GC}@anchor{1691}
@geindex GC

@item GC

@ref{f,,garbage collection}.
@anchor{glossary/g term-General-Protection-Fault}@anchor{1692}
@geindex General Protection Fault

@item General Protection Fault

`GPF'.

A General Protection Fault on the Windows platforms is the
equivalent of a @ref{1618,,segmentation violation} on Unix.
@anchor{glossary/g term-generation}@anchor{e1}
@geindex generation

@item generation

A generation is a set of @ref{1ab,,objects} of similar
`age'.

A @ref{e,,generational garbage collector} will typically divide the set of all objects into
generations, and @ref{221,,condemn} all the
objects in a generation together. Rather than allowing whole
generations to age, the @ref{15d7,,collector (1)} can
@ref{223,,promote} objects into older generations as
they survive successive @ref{1a2,,collection cycles}.

New objects are usually allocated in the youngest or
@ref{222,,nursery generation}, but if we know that particular
objects will be long-lived, we might want to allocate them
directly in an older generation. Thus, more loosely, a
generation is a set of objects which have similar expected
@ref{b5,,lifetimes}.


@subsubheading See also


@ref{15c3,,bucket}.


The @ref{d0,,client program} specifies the generational
structure of a @ref{18,,pool} (or group of pools) using a
@ref{e2,,generation chain}. See @ref{2c,,Garbage collection}.
@anchor{glossary/g term-generation-chain}@anchor{e2}
@geindex generation chain

@item generation chain

A data structure that specifies the structure of the
@ref{e1,,generations} in a @ref{18,,pool} (or group of pools).
See @ref{2c,,Garbage collection}.
@anchor{glossary/g term-generation-scavenging}@anchor{1693}
@geindex generation scavenging

@item generation scavenging

@ref{e,,generational garbage collection}.
@anchor{glossary/g term-generational-garbage-collection}@anchor{e}
@geindex generational garbage collection

@item generational garbage collection

`generation scavenging'.

Generational garbage collection is @ref{15df,,tracing garbage collection} that makes use of the @ref{35b,,generational hypothesis}. @ref{1ab,,Objects} are gathered together in
@ref{e1,,generations}. New objects are allocated in
the `youngest' or `nursery' generation, and @ref{223,,promoted} to `older' generations if they survive. Objects
in older generations are @ref{221,,condemned}
less frequently, saving CPU time.

It is typically rare for an object to refer to a younger
object. Hence, objects in one generation typically have few
@ref{24,,references} to objects in younger
generations. This means that the @ref{65,,scanning} of
old generations in the course of collecting younger
generations can be done more efficiently by means of
@ref{213,,remembered sets}.

In some purely functional languages (that is, without update),
all references are backwards in time, in which case remembered
sets are unnecessary.


@subsubheading See also


@ref{213,,remembered set}.


The @ref{62,,AMC (Automatic Mostly-Copying)} and @ref{89,,AMCZ (Automatic Mostly-Copying Zero-rank)} pool classes
support generational garbage collection.
@anchor{glossary/g term-generational-hypothesis}@anchor{35b}
@geindex generational hypothesis

@item generational hypothesis

`infant mortality'.

`Infant mortality' or `the generational hypothesis' is the
observation that, in most cases, young @ref{1ab,,objects} are
much more likely to @ref{49,,die} than old objects.

Strictly, the hypothesis is that the probability of death as a
function of age falls faster than exponential decay (inverse
hyper-exponential), but this strict condition is not always
required for techniques such as @ref{e,,generational garbage collection} to be useful.
@anchor{glossary/g term-gigabyte}@anchor{1619}
@geindex gigabyte

@item gigabyte

`GB'.

A gigabyte is 1024 @ref{186,,megabytes}, or 1073741824
@ref{17c,,bytes (1)}.

See @ref{17c,,byte (1)} for general information on this and
related quantities.
@anchor{glossary/g term-good-fit}@anchor{15f5}
@geindex good fit

@item good fit

The class of @ref{380,,allocation policies} which approximate
@ref{382,,best fit}. Strict best fit may be costly to implement
(depending on the details of the @ref{15d4,,allocation mechanism}), so some implementors approximate it, choosing a
block which is close in size to the allocation request.


@subsubheading See also


@ref{380,,allocation policy}, @ref{382,,best fit}, @ref{1681,,next fit}, @ref{386,,worst fit}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/g term-GPF}@anchor{1694}
@geindex GPF

@item GPF

@ref{1692,,General Protection Fault}.
@anchor{glossary/g term-grain}@anchor{1695}
@geindex grain

@item grain

The grain of a platform is the smallest @ref{68,,alignment} that
is sufficient to accommodate all data accesses on that
platform. Often this is a @ref{37c,,word} or a small multiple of
a word. Double precision floating point numbers often have the
strictest alignment requirements.


@subsubheading See also


@ref{68,,alignment}, @ref{37c,,word}.

@anchor{glossary/g term-graph}@anchor{1635}
@geindex graph

@item graph

A graph is a set of @ref{163e,,nodes} together with a set
of @ref{1671,,edges} connecting nodes.

If the edges have direction like arrows (for example,
@ref{24,,references} in a graph of @ref{1ab,,objects}), then the
graph is said to be a `directed graph'.


@float Figure

@image{MemoryPoolSystem-figures/graph,,,Ten white circles (the nodes of this graph)@comma{} some of them joined by arrows (the edges of the graph). Most of the edges point in one direction@comma{} but one edge points both ways. Seven of the nodes are connected in one component@comma{} and three in another.,svg}

@caption{Directed graph.}

@end float


Graphs are used to model @ref{96,,reachability}
for @ref{15df,,tracing garbage collection}. The
@ref{1ab,,objects} are considered to form a graph, with the
nodes of the graph being the objects and the edges of the
graph being the references from one object to another.
Usually, there is a single, distinguished @ref{97,,root} to
which the @ref{30c,,mutator} has `direct' access, and the
nodes strongly connected to it are the reachable modes.
@anchor{glossary/g term-gray}@anchor{1606}
@geindex gray

@item gray@anchor{glossary/g term-grey}@anchor{1696}
@geindex grey

@itemx grey

In a @ref{1605,,tri-color marking} scheme, gray @ref{1ab,,objects}
are objects that are proved or assumed (see
@ref{e,,generational} and
@ref{221,,condemn}) to be @ref{96,,reachable}, but
have not yet been @ref{65,,scanned}.

More precisely, gray objects have been noted reachable, but
must still be visited by the @ref{15ae,,collector (2)} in order to
process their children.

@ref{1697,,gray list}.

@ref{1604,,black}, @ref{1607,,white}.
@anchor{glossary/g term-gray-list}@anchor{1697}
@geindex gray list

@item gray list@anchor{glossary/g term-grey-list}@anchor{1698}
@geindex grey list

@itemx grey list

The gray list is the set of @ref{1ab,,objects} that a
@ref{15df,,tracing garbage collector}
has noted @ref{96,,reachable}, but hasn’t @ref{65,,scanned}
yet.

The gray list is so called because it corresponds to the set
of @ref{1606,,gray} objects in the @ref{1605,,tri-color marking} model
of graph tracing. The gray list changes as the garbage
collector progresses.

Each gray object is @ref{65,,scanned}, and all
@ref{1607,,white} objects referred to by it become gray and are
added to the list. Scanning a gray object turns it
@ref{1604,,black}. When the gray list is empty, the tracing is
finished, and white objects may be @ref{4a,,reclaimed}.

The representation of the gray list is a key part of garbage
collector design. The size of the list is potentially
proportional to the size of the @ref{47,,heap}, and the
operation of finding the next gray object to scan must be
cheap.


@subsubheading See also


@ref{1636,,Cheney scan}.

@end table

@node Memory Management Glossary H,Memory Management Glossary I,Memory Management Glossary G,Memory Management Glossary
@anchor{glossary/h doc}@anchor{1699}@anchor{glossary/h glossary-h}@anchor{1597}@anchor{glossary/h memory-management-glossary-h}@anchor{169a}
@section Memory Management Glossary: H


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/h term-handle}@anchor{1678}
@geindex handle

@item handle

A handle is an object that represents a resource.

Handles are used when the resource cannot be represented
directly. For example, a file handle is an object passed
between a process and the OS in order to access a file,
because the file itself cannot be represented.

In memory management, a handle is an object that
represents another @ref{1ab,,object}. Handles are usually
used because the object itself needs to be @ref{5d,,moved} in @ref{194,,memory (2)}, or even
@ref{169b,,swapped out} to disk. The program therefore cannot
know the @ref{126,,address} of the object.

For example, Apple’s Classic Mac OS made extensive use of
handles in its heap management@footnote{http://web.archive.org/web/200012120034/http://developer.apple.com/techpubs/mac/Memory/Memory-11.html}
to avoid problems due to @ref{17e,,fragmentation}. If the Classic
Mac OS Memory Manager could not satisfy a request for memory,
it tried @ref{1643,,compacting} the @ref{47,,heap}:
moving all the @ref{160e,,relocatable} objects
together to squeeze out gaps. It could do this because the
program only had handles on the objects, and not their actual
addresses.


@float Figure

@image{MemoryPoolSystem-figures/handle,,,Diagram: Handle-based heap.,svg}

@caption{Handle-based heap.}

@end float


@ref{15b8,,pointer}.
@anchor{glossary/h term-header}@anchor{169c}
@geindex header

@item header

@ref{1d1,,in-band header}.
@anchor{glossary/h term-heap}@anchor{47}
@geindex heap

@item heap

`free store', `freestore'.

The `heap' or `free store' is the @ref{194,,memory (2)} area
managed by @ref{166b,,dynamic allocation}.

This use of `heap' is unconnected with the data structure used
by the heapsort algorithm.
@anchor{glossary/h term-heap-allocation}@anchor{1653}
@geindex heap allocation

@item heap allocation

`dynamic allocation'.

`Heap allocation' or `dynamic allocation' means run-time
@ref{15ca,,allocation} and @ref{15d2,,deallocation} of @ref{15b0,,memory (1)} in arbitrary order.

Dynamic allocation is usually for @ref{1ab,,objects}
whose size, quantity, or @ref{b5,,lifetime} could not be
determined at compile-time. It is necessary to implement
modern data structures, such as recursive trees and full
@ref{1ee,,closures}.

Objects on the @ref{47,,heap} can be managed @ref{8,,manually}, as in @ref{1c,,C}, or
@ref{9,,automatically}, as in
@ref{28a,,Lisp} and @ref{167f,,Java}.

@ref{15e2,,stack allocation}, @ref{1610,,static allocation}.


@subsubheading See also


@ref{15af,,indefinite extent}.

@anchor{glossary/h term-hit}@anchor{169d}
@geindex hit

@item hit

A hit is a successful lookup in any form of @ref{162a,,cache (3)}, most commonly at some level of a
@ref{1628,,storage hierarchy}, such as a @ref{1622,,cache (1)} or
@ref{51,,virtual memory} system.

@ref{169e,,miss}.
@anchor{glossary/h term-hit-rate}@anchor{169f}
@geindex hit rate

@item hit rate

At any level of a @ref{1628,,storage hierarchy}, the hit rate is
the proportion of accesses which @ref{169d,,hit}.

@ref{16a0,,miss rate}.
@anchor{glossary/h term-hosted}@anchor{1686}
@geindex hosted

@item hosted

In the @ref{1c,,C} programming language, a hosted implementation
is one that provides all the features of the standard C
library.

@ref{14e,,freestanding}.

@ref{118,,ISO/IEC 9899;1990}, @ref{9d6,,ISO/IEC 9899;1999}.
@anchor{glossary/h term-hot}@anchor{162}
@geindex hot

@item hot

A @ref{c9,,variety} in which many MPS functions
@ref{284,,assert} that their data structures are
valid, but functions on the @ref{7c,,critical path} do not.
Select it by defining @ref{172,,CONFIG_VAR_HOT}. Compare
@ref{c8,,cool} and @ref{163,,rash}.
@anchor{glossary/h term-hot-end}@anchor{1639}
@geindex hot end

@item hot end

A @ref{27,,control stack} has two ends: the oldest items are at
the `cold end' and the newest items are at the `hot end'.
Sometimes the hot end is called the “top” of the stack, but
that is misleading when the stack grows downwards, as it does
on common computing platforms.

@ref{aa,,cold end}
@anchor{glossary/h term-huge-page}@anchor{16a1}
@geindex huge page

@item huge page

`large page', `superpage'.

Some processor architectures support multiple @ref{92,,page}
sizes. This allows operating systems to better match the page
size to the granularity of memory usage and so reduce the size
of the @ref{16a2,,page table}.
@end table

@node Memory Management Glossary I,Memory Management Glossary K,Memory Management Glossary H,Memory Management Glossary
@anchor{glossary/i doc}@anchor{16a3}@anchor{glossary/i glossary-i}@anchor{1598}@anchor{glossary/i memory-management-glossary-i}@anchor{16a4}
@section Memory Management Glossary: I


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/i term-immediate-data}@anchor{16a5}
@geindex immediate data

@item immediate data

Immediate data is the representation of a @ref{16a6,,value object}
as one or more machine @ref{37c,,words}, as a register, or
as a field in an instruction.

Immediate data takes its name from the value of the object
being immediately available, rather than requiring a
@ref{15ea,,load} or indirection through a @ref{24,,reference}.

@ref{48,,unboxed}.

@ref{160b,,boxed}, @ref{15b8,,pointer}, @ref{24,,reference}.
@anchor{glossary/i term-immune-set}@anchor{164b}
@geindex immune set

@item immune set

The set of @ref{1ab,,objects} which are not
@ref{221,,condemned}.

@ref{221,,condemned set}.
@anchor{glossary/i term-immutable}@anchor{16a7}
@geindex immutable

@item immutable

In some programming languages, @ref{1ab,,objects} of
some types are immutable, that is, they cannot be modified.
For example, in Standard @ref{168e,,ML}, only arrays and refs are
mutable; all other objects are immutable.

This property can be very useful for @ref{f,,garbage collection}. For instance, no immutable object may contain a
@ref{24,,reference} to an object younger than itself, and no
immutable object will appear in a @ref{213,,remembered set}.
Garbage collectors for these languages often take advantage of
this property.

In lazy languages, the evaluation of an expression may require
an object of a different size, and adjustment of references
may take place. This means that, although objects might be
immutable at the language level, they are not immutable at the
implementation level, and may contain references to younger
objects.

@ref{16a8,,mutable}.


@subsubheading See also


@ref{e,,generational garbage collection}.

@anchor{glossary/i term-immutable-object}@anchor{16a9}
@geindex immutable object

@item immutable object

@ref{16a6,,value object}.
@anchor{glossary/i term-in-band-header}@anchor{1d1}
@geindex in-band header

@item in-band header

`frame', `header'.

Some @ref{15cd,,memory managers} @ref{15ca,,allocate}
a fixed amount more than is necessary for each @ref{185,,block}
and use it to store information such as the size of the block
or a @ref{88,,tag}. This extra memory is known as an `in-band
header' or a `frame'.

This is a form of @ref{379,,internal fragmentation}, although
sometimes, @ref{68,,alignment} requirements result in free space
for the header.

Storing control information `in-band' often results in bad
@ref{1601,,locality}, particularly for
@ref{15d2,,deallocation}.

@ref{16aa,,out-of-band header}.


@subsubheading See also


@ref{15ab,,activation frame}, @ref{15b1,,stack frame}.


In-band headers are supported by some @ref{10,,pool classes}
and the size of the header is specified by passing the
@code{MPS_KEY_FMT_HEADER_SIZE} @ref{53,,keyword argument} to @ref{13f,,mps_fmt_create_k()}.

A pointer to the first word after the in-band header is
called a @ref{1d4,,client pointer}.
@anchor{glossary/i term-in-parameter}@anchor{16ab}
@geindex in parameter

@item in parameter

A function parameter that supplies data from the caller to the
function. (The usual case in @ref{1c,,C}.)

@ref{58,,out parameter}.
@anchor{glossary/i term-in-out-parameter}@anchor{120}
@geindex in/out parameter

@item in/out parameter

A function parameter that is both an @ref{16ab,,in parameter} an
@ref{58,,out parameter}.

In/out parameters are given names ending with @code{_io}. See
@ref{112,,Interface conventions}.
@anchor{glossary/i term-incremental-garbage-collection}@anchor{d}
@geindex incremental garbage collection

@item incremental garbage collection

Some @ref{15df,,tracing garbage collection} algorithms can pause
in the middle of a @ref{1a2,,collection cycle} while the
@ref{30c,,mutator} continues, without ending up with inconsistent
data. Such collectors can operate incrementally and are
suitable for use in an interactive system.

Primitive garbage @ref{20,,collectors (1)},
once they start a @ref{1a2,,collection cycle}, must either finish
the task, or abandon all their work so far. This is often an
appropriate restriction, but is unacceptable when the system
must guarantee response times; for example, in systems with a
user interface and in real-time hardware control systems. Such
systems might use incremental garbage collection so that the
time-critical processing and the garbage collection can
proceed effectively in parallel, without wasted effort.

@ref{15ed,,parallel garbage collection}.

@ref{16ac,,stop-and-copy collection}.


@subsubheading See also


@ref{60,,barrier (1)}, @ref{1605,,tri-color marking}.


@ref{14db,,Appel et al. (1988)}, @ref{14f7,,Boehm et al. (1991)}.

The MPS uses incremental collection, except for
collections started by calling
@ref{ce,,mps_arena_collect()}.
@anchor{glossary/i term-incremental-update}@anchor{16ad}
@geindex incremental update

@item incremental update

Incremental-update algorithms for @ref{4b,,tracing},
@ref{d,,incremental garbage collection} note changes made by
the @ref{30c,,mutator} to the @ref{1635,,graph} of @ref{1ab,,objects}
and update the @ref{15ae,,collector (2)} state to make it
correctly trace the new graph.

In order for the collector to miss a @ref{96,,reachable}
@ref{1ab,,object}, the following two conditions need to hold at
some point during tracing:


@enumerate 

@item 
The mutator stores a @ref{24,,reference} to a @ref{1607,,white}
object into a @ref{1604,,black} object.

@item 
All paths from any @ref{1606,,gray} objects to that white
object are destroyed.
@end enumerate

Incremental-update algorithms ensure the first condition
cannot occur, by painting either the black or the white object
gray (see @ref{1555,,Pirinen (1998)} for details).

They are so called because they incrementally update the
collector’s view of the graph to track changes made by the
mutator.

This distinction between incremental update and
snapshot at the beginning was first introduced for
write-barrier algorithms, but it applies to any type of
tracing algorithm.

@ref{16ae,,snapshot at the beginning}.


@subsubheading See also


@ref{60,,barrier (1)}, @ref{16af,,strong tri-color invariant}, @ref{1605,,tri-color marking}.


@ref{1579,,Wilson (1994)}, @ref{1555,,Pirinen (1998)}.
@anchor{glossary/i term-indefinite-extent}@anchor{15af}
@geindex indefinite extent

@item indefinite extent

An @ref{1ab,,object} has indefinite extent if its
@ref{b5,,lifetime} is independent of the block or function-call
structure of the program.

The @ref{b5,,lifetime} of such an object can sometimes be
determined by the programmer, and specified by @ref{15d2,,freeing} the object explicitly. This becomes harder to do
correctly as the program becomes more complex, especially if
objects are passed across module boundaries, or if
higher-order functions are used. In some languages it is
impossible to determine the extent at compile-time. In these
situations, a @ref{20,,garbage collector} can be used to
@ref{15de,,recycle} objects whose @ref{b5,,lifetime} has come to an
end.

@ref{24a,,dynamic extent}.
@anchor{glossary/i term-indexed-fit}@anchor{15f4}
@geindex indexed fit

@item indexed fit

A class of @ref{15d4,,allocation mechanisms} that use an indexing
data structure, such as a tree or hash table, to identify
suitable @ref{15bf,,free blocks}, according to the
@ref{380,,allocation policy}. For instance, a tree ordered by
block size may be used to implement the @ref{382,,best fit}
policy.


@subsubheading See also


@ref{15d4,,allocation mechanism}, @ref{380,,allocation policy}, @ref{15ff,,bitmapped fit}, @ref{15f1,,sequential fit}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/i term-indirect-method}@anchor{1665}
@geindex indirect method

@item indirect method

Indirect methods of @ref{9,,automatic memory management} are
those in which the information necessary to determine whether
an @ref{1ab,,object} can be @ref{4a,,reclaimed} is not
stored in or associated with that object, but is derived from
other objects.

Indirect methods detect @ref{1649,,garbage} by @ref{4b,,tracing} @ref{96,,reachable} objects.

Indirect methods cannot always reclaim @ref{194,,memory (2)} as
soon as it becomes @ref{49,,dead}, because it may be necessary
to inspect many other objects to determine this. However, not
having to store and update information on each object may
reduce the overhead for the @ref{15d7,,collector (1)}. In
@ref{1663,,distributed garbage collection}, this can reduce the
amount of communication between processors.

@ref{15df,,tracing garbage collection}.

@ref{1664,,direct method}.

@ref{1538,,Jones et al. (2012)}.
@anchor{glossary/i term-infant-mortality}@anchor{16b0}
@geindex infant mortality

@item infant mortality

@ref{35b,,generational hypothesis}.
@anchor{glossary/i term-inline-allocation-1}@anchor{a}
@geindex inline allocation (1)

@item inline allocation@w{^(1)}

Allocation of objects by inline code, that is, without calling
an allocation function. This is vital for performance in
languages that allocate many small objects.

This is achieved by the
@ref{ae,,Allocation point protocol}.
@anchor{glossary/i term-inline-allocation-2}@anchor{16b1}
@geindex inline allocation (2)

@item inline allocation@w{^(2)}

Allocation of child objects inside their parent, as opposed
to allocating child objects on the @ref{47,,heap} and storing
@ref{15b8,,pointers} to them in the parent.
@anchor{glossary/i term-inter-generational-pointer}@anchor{1630}
@geindex inter-generational pointer

@item inter-generational pointer

An inter-generational pointer is a @ref{24,,reference} that is
stored in an @ref{1ab,,object} in one @ref{e1,,generation} and
references an object in another generation.

If the referent’s generation is @ref{221,,condemned} and the referrer’s generation is not, then the reference
is important in two ways. First, the reference keeps the
referent @ref{78,,alive}, so the referrer must be
@ref{65,,scanned} during the @ref{1a2,,collection cycle}.
Second, the reference must always refer to the referent, so if
the referent is moved, then the referrer must be updated.

During a collection, the only objects in non-condemned areas
that must be scanned are the ones that contain
inter-generational pointers. @ref{e,,Generational garbage collectors} make use of
@ref{214,,write barriers} and data structures like @ref{1674,,entry tables (2)}, @ref{1673,,exit tables}, and @ref{213,,remembered sets}
to track those objects at run-time.

Inter-generational pointers can cause @ref{15d8,,floating garbage}: even if both referrer and referent die, the
inter-generational pointer will stop the referent from being
reclaimed until the referrer’s generation is condemned.
@anchor{glossary/i term-interior-pointer}@anchor{1ac}
@geindex interior pointer

@item interior pointer

`derived pointer'.

An `interior pointer' is a pointer to @ref{194,,memory (2)}
occupied by an @ref{1ab,,object} which does not point to the
start location. Also called a `derived pointer' when it’s
derived from a @ref{1aa,,base pointer}.

A @ref{15b8,,pointer} to an object will usually take as its value
the @ref{126,,address} of the start of that object.

It is common to have interior pointers into string buffers or
to embedded structures. A @ref{16b2,,suballocator} may place a
@ref{1d1,,header} at the start of each object
and pass on an interior pointer.

In a system where interior pointers are used, the
@ref{20,,garbage collector} must be able to @ref{1600,,mark} an object as @ref{96,,reachable} without being
told the start of the object. In a system where interior
pointers are not used, the collector should either ignore
them (in particular, if it is @ref{65,,scanning}
@ref{349,,conservatively})
and not retain @ref{1649,,garbage} because of them, or
possibly report them as bugs.

@ref{1aa,,base pointer}.
@anchor{glossary/i term-internal-fragmentation}@anchor{379}
@geindex internal fragmentation

@item internal fragmentation

Internal @ref{17e,,fragmentation} is where the @ref{15cd,,memory manager} @ref{15ca,,allocates} more for each allocation
than is actually requested. There are three reasons for this:
@ref{16b3,,padding}; @ref{15f9,,buddy system}; @ref{1d1,,in-band headers}.


@subsubheading See also


@ref{383,,external fragmentation}.

@anchor{glossary/i term-invalid-page-fault}@anchor{16b4}
@geindex invalid page fault

@item invalid page fault

An exception when using @ref{51,,virtual memory} resulting
from an access to a virtual memory location for which no
translation is defined.

This is usually an error, often, anachronistically, known as a
@ref{1618,,segmentation violation}.

@ref{15c9,,bus error}.


@subsubheading See also


@ref{16b5,,page fault}.

@anchor{glossary/i term-inverted-page-table}@anchor{16b6}
@geindex inverted page table

@item inverted page table@anchor{glossary/i term-0}@anchor{16b7}
@geindex inverted page-table

@itemx inverted page-table

In a @ref{51,,virtual memory} system, conventional
@ref{16a2,,page tables} have an entry for every
@ref{92,,page} in the @ref{15bb,,virtual address space}. An
`inverted page table' has only as many entries as there are
pages in @ref{16b8,,physical memory (1)}, and uses a hash lookup
to translate @ref{16b9,,virtual addresses} to
@ref{15aa,,physical addresses} in nearly
constant time.

The entire virtual address space of each process is described
in an auxiliary structure, typically a B*-tree, that can
efficiently store contiguous, sparse, or large @ref{54,,address space} descriptions. This auxiliary structure may itself be
paged to avoid permanently consuming @ref{16b8,,physical memory (1)} resources.

Inverted page tables are ideal for schemes that store
information about @ref{1ab,,objects} in the high-order
bits of their @ref{126,,address}. Such schemes may perform poorly
with conventional page tables as the sparse address space may
cause the page table structures to become so large as to
compete with the program @ref{16ba,,working set} for
@ref{16b8,,physical memory (1)}.

The @ref{16bb,,Lisp Machine} was an early workstation that
used an inverted page table with hardware lookup. The
UltraSPARC, PowerPC, and IA-64 architectures all include
inverted page tables. Some implementations of these
architectures have hardware-assisted lookup.
@anchor{glossary/i term-is-forwarded-method}@anchor{8c}
@geindex is-forwarded method

@item is-forwarded method

A @ref{69,,format method} that is called by a @ref{5d,,moving} @ref{18,,pool} to determine if a
@ref{23,,formatted object} is a @ref{66,,forwarding object},
and if so, to return the address where the object was
moved to. See @ref{8d,,mps_fmt_isfwd_t}.
@end table

@node Memory Management Glossary K,Memory Management Glossary L,Memory Management Glossary I,Memory Management Glossary
@anchor{glossary/k doc}@anchor{16bc}@anchor{glossary/k glossary-k}@anchor{1599}@anchor{glossary/k memory-management-glossary-k}@anchor{16bd}
@section Memory Management Glossary: K


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/k term-kB}@anchor{16be}
@geindex kB

@item kB

@ref{188,,kilobyte}.
@anchor{glossary/k term-keyword-argument}@anchor{53}
@geindex keyword argument

@item keyword argument

An argument to a function call that’s identified by an
associated keyword rather than by its position in the argument
list.

Keyword arguments are passed to functions in the MPS
interface as arrays of structures of type
@ref{56,,mps_arg_s}. See @ref{57,,Keyword arguments}.
@anchor{glossary/k term-kilobyte}@anchor{188}
@geindex kilobyte

@item kilobyte

`kB'.

A kilobyte is 1024 @ref{17c,,bytes (1)}.

See @ref{17c,,byte (1)} for general information on this and
related quantities.

The standard abbreviation is “kB”, but “KB” is often used by
people unfamiliar with the metric system.
@end table

@node Memory Management Glossary L,Memory Management Glossary M,Memory Management Glossary K,Memory Management Glossary
@anchor{glossary/l doc}@anchor{16bf}@anchor{glossary/l glossary-l}@anchor{159a}@anchor{glossary/l memory-management-glossary-l}@anchor{16c0}
@section Memory Management Glossary: L


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/l term-large-object-area}@anchor{16c1}
@geindex large object area

@item large object area

An @ref{15d4,,allocation mechanism} designed to optimize the
management of large @ref{1ab,,objects} by separating
them from small ones.

Large objects, typically objects one or more orders of
magnitude larger than the @ref{51,,virtual memory}
@ref{92,,page} of a platform, can be costly to @ref{15ca,,allocate},
initialize, and @ref{15de,,recycle}. By segregating those objects
into a separate area, they can be managed using specific
mechanisms that would be inefficient for smaller objects but
which can reduce the cost of manipulating large ones.

Some example mechanisms:


@enumerate 

@item 
In a @ref{e3,,copying collector}
large objects can be managed separately using a
@ref{15fd,,mark-and-sweep collector} to avoid
copying costs. See @ref{1574,,Ungar (1988)}.

@item 
By aligning large objects on page boundaries, they can be
@ref{1643,,compacted} or copied by adjusting their
@ref{310,,mapping} in @ref{51,,virtual memory}. See
@ref{1582,,Withington (1991)}.

@item 
Large objects may be split into a header and a body, where
the header is fixed size and the bulk of the object is in
the body. See @ref{1574,,Ungar (1988)}.

@item 
By using a page-based @ref{1d6,,read barrier}, large objects
can be initialized incrementally. For example, each page of
the large object is initialized to zero when it is first
read, rather than all at once at creation time.

@item 
In a copying collector, large objects can be copied
incrementally using a similar technique (the new copy is
initialized from the old copy). See @ref{14e1,,Baker (1978)}.

@item 
Large objects are often @ref{107,,leaf objects},
so do not need to be @ref{65,,scanned}, or are known
to have a fixed @ref{164e,,format} with only a few
@ref{24,,references} so they can be scanned more
efficiently by a specialized scanner.

@item 
Large objects often have longer than average
@ref{b5,,lifetimes}, so are not allocated in a
@ref{35f,,nursery space} of a @ref{e,,generational garbage collector}.
@end enumerate
@anchor{glossary/l term-large-page}@anchor{16c2}
@geindex large page

@item large page

@ref{16a1,,huge page}.
@anchor{glossary/l term-leaf-object}@anchor{107}
@geindex leaf object

@item leaf object

`atomic object'.

A leaf object is an @ref{1ab,,object} that does not
@ref{24,,reference} any other objects.

In a typed language, the compiler can often determine at
compile time that certain types can be represented as leaf
objects. Usually these types are either a @ref{15c6,,scalar data type} or a @ref{15c7,,vector data type} of scalars with bounded
magnitude.

If leaf objects can be identified, a @ref{20,,garbage collector} can make certain optimizations: leaf objects do
not have to be @ref{65,,scanned} for references nor
are @ref{60,,barriers (1)} needed to detect
and maintain references in the object.

The @ref{89,,AMCZ (Automatic Mostly-Copying Zero-rank)} and @ref{353,,LO (Leaf Object)} pool classes are
designed for the storage of leaf objects.
@anchor{glossary/l term-leak}@anchor{16c3}
@geindex leak

@item leak

@ref{234,,memory leak}.
@anchor{glossary/l term-life}@anchor{16c4}
@geindex life

@item life

@ref{b5,,lifetime}.
@anchor{glossary/l term-lifetime}@anchor{b5}
@geindex lifetime

@item lifetime

`extent', `life'.

The lifetime or extent of an @ref{1ab,,object} is the time for
which the object is @ref{78,,live}.


@subsubheading See also


@ref{24a,,dynamic extent}, @ref{15af,,indefinite extent}.

@anchor{glossary/l term-LIFO-ordered-first-fit}@anchor{15c1}
@geindex LIFO-ordered first fit

@item LIFO-ordered first fit

The @ref{380,,allocation policy} that always uses the
most-recently @ref{15d2,,freed (1)} suitable @ref{15bf,,free block}.
Commonly implemented by pushing freed blocks on the front of a
@ref{15c0,,free block chain}, and then using @ref{37f,,first fit}
allocation on this chain. @ref{15d2,,free (1)} can be very quick,
depending on the @ref{38c,,coalescing} policy.

This policy may suffer from severe @ref{17e,,fragmentation} in
the presence of short-lived large objects of a single size. As
smaller objects are allocated, the free block chain fills up
with fragments a little smaller than the large object size.


@subsubheading See also


@ref{384,,address-ordered first fit}, @ref{385,,FIFO-ordered first fit}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/l term-limited-field-reference-count}@anchor{16c5}
@geindex limited-field reference count

@item limited-field reference count

`sticky reference count'.

A @ref{15e0,,reference counting} technique whereby the field used
to store the number of @ref{24,,references} to an
@ref{1ab,,object} has a limited size. In particular, the field is
not large enough to represent the maximum possible number of
references to an object.

Using the observation that most objects are not referenced a
great number of times, some systems that use reference counts
only store the count accurately up to a certain maximum value.
If an object has more references than the maximum then the
count “sticks” at the maximum and is never decremented. Such
objects are expected to be rare, but their @ref{15b0,,memory (1)}
can never be @ref{4a,,reclaimed} using reference counting. A
separate (infrequently run) @ref{15df,,tracing garbage collector} is often employed to reclaim
this storage.

A degenerate form of limited-field reference counting is
@ref{16c6,,one-bit reference counting}
where an object is considered to be referenced either exactly
once or many times.
@anchor{glossary/l term-linear-addressing}@anchor{16c7}
@geindex linear addressing

@item linear addressing

In linear addressing, @ref{126,,addresses} form a
single, continuous @ref{54,,address space}. This term is used
mostly in opposition to @ref{15b9,,segmented addressing}.

@ref{15b9,,segmented addressing}.
@anchor{glossary/l term-live}@anchor{78}
@geindex live

@item live

`active', `alive'.

@ref{194,,Memory (2)} or an @ref{1ab,,object} is live if the program
will read from it in future. The term is often used more
broadly to mean @ref{96,,reachable}.

It is not possible, in general, for @ref{20,,garbage collectors}
to determine exactly which @ref{1ab,,objects} are still live.
Instead, they use some approximation to detect objects that
are provably @ref{49,,dead}, such as those that are not
@ref{96,,reachable}.

@ref{96,,reachable}.

@ref{49,,dead}.


@subsubheading See also


@ref{165d,,undead}.

@anchor{glossary/l term-load}@anchor{15ea}
@geindex load

@item load

To transfer data from @ref{194,,memory (2)} to a processor’s
@ref{26,,registers}.

Load can also be used in the more general sense of moving data
from a part of the @ref{16c8,,memory hierarchy} that is slow to
access to one that is fast to access (For example, “it takes
about 3 ms for the @ref{51,,virtual memory} system to load a
@ref{92,,page} from disk on this system”). When used in this
sense, the qualified term @ref{1627,,cache (2)} load is common.

@code{LOAD} (or an abbreviation) is also commonly used in many
processor architectures as the mnemonic name for the machine
code instructions that are used primarily to make data
accessible to the CPU (by loading the data into registers
usually). In RISC architectures it is common for the load
instructions to be the only means of making data accessible to
the CPU; in CISC architectures it is common for a wide variety
of instructions to implicitly or explicitly load data from
memory.

@ref{15eb,,store (1)}.
@anchor{glossary/l term-locality-of-reference}@anchor{1601}
@geindex locality of reference

@item locality of reference

Locality of reference is the extent to which successive
accesses of nearby @ref{15b0,,memory (1)} @ref{15b4,,locations} are nearby in time; for example, a program that
reads all the elements of a contiguous array in turn or that
repeatedly uses the same memory variable has good locality of
reference.

Good locality of reference interacts well with @ref{51,,virtual memory} and @ref{1622,,memory caches}, as it reduces
the @ref{16ba,,working set} and improves the @ref{169f,,hit rate}.

There are a number of specialized senses of locality of
reference in certain fields such as distributed systems; these
are not covered in depth here.

A @ref{30c,,mutator} may exhibit predictable properties such
as accessing in turn @ref{1ab,,objects} which were
@ref{15ca,,allocated} in turn, or accessing in turn objects
which have @ref{24,,references} to each other. An
intelligent @ref{15ce,,allocator} or @ref{e3,,copying garbage collector} can use this
observation to improve locality of reference.

@ref{1525,,Grunwald et al. (1993)}, @ref{1577,,Wilson et al. (1992)}.
@anchor{glossary/l term-location}@anchor{16c9}
@geindex location

@item location

@ref{15b4,,memory location}.
@anchor{glossary/l term-location-dependency}@anchor{19a}
@geindex location dependency

@item location dependency

A `location dependency' records the fact that the
@ref{d0,,client program} depends on the bit patterns of some
@ref{24,,references} (and not merely on the
identity of the @ref{185,,block} to which the reference
refers), and provides a function
(@ref{f7,,mps_ld_isstale()}) to find out whether a
reference might have been changed because a block has
been @ref{5d,,moved}. See
@ref{f8,,Location dependency}.
@anchor{glossary/l term-lock-free}@anchor{1bf}
@geindex lock free

@item lock free

A multi-threaded program is `lock free' if all schedules for
the threads make progress: in particular, no schedule leads to
deadlock. This is most easily implemented by avoiding taking
locks.
@anchor{glossary/l term-logical-address}@anchor{16ca}
@geindex logical address

@item logical address

@ref{16b9,,virtual address}.
@anchor{glossary/l term-longword}@anchor{16cb}
@geindex longword

@item longword

@ref{1667,,doubleword}.
@end table

@node Memory Management Glossary M,Memory Management Glossary N,Memory Management Glossary L,Memory Management Glossary
@anchor{glossary/m doc}@anchor{16cc}@anchor{glossary/m glossary-m}@anchor{159b}@anchor{glossary/m memory-management-glossary-m}@anchor{16cd}
@section Memory Management Glossary: M


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/m term-machine-word}@anchor{15b5}
@geindex machine word

@item machine word

@ref{37c,,word}.
@anchor{glossary/m term-main-memory}@anchor{311}
@geindex main memory

@item main memory

`memory', `primary storage'.

The `main memory' (or `primary storage') of a computer is
@ref{15b0,,memory (1)} that is wired directly to the processor,
consisting of @ref{55,,RAM} and possibly @ref{16ce,,ROM}.

These terms are used in contrast to mass storage devices and
@ref{1629,,cache memory} (although we may note that when a program
accesses main memory, it is often actually interacting with a
cache).

Main memory is the middle level of the @ref{16c8,,memory hierarchy}: it is slower and cheaper than @ref{1622,,caches (1)},
but faster and more expensive than @ref{15d1,,backing store}.

It is common to refer only to the main memory of a computer;
for example, “This server has 128 GB of memory” and “macOS
High Sierra requires at least 2 GB of memory”.

Main memory used to be called @ref{1656,,core}, and is now
likewise often called @ref{55,,RAM}.

@ref{1656,,core}, @ref{16b8,,physical memory (1)}, @ref{55,,RAM}.
@anchor{glossary/m term-malloc}@anchor{1a}
@geindex malloc

@item malloc

A function in the standard @ref{1c,,C} library that performs
@ref{166b,,dynamic allocation} of @ref{194,,memory (2)}.

Many people use “malloc” as a verb to mean “allocate
dynamically”.

@ref{15ca,,allocate}.

@ref{1b,,free (2)}.
@anchor{glossary/m term-manual-memory-management}@anchor{8}
@geindex manual memory management

@item manual memory management

In some systems or languages, it is up to the application
program to manage all the bookkeeping details of
@ref{15ca,,allocating} @ref{194,,memory (2)} from the
@ref{47,,heap} and @ref{15d2,,freeing} it when no longer
required; this is known as manual @ref{15dd,,memory management}.

Manual memory management may be appropriate for small
programs, but it does not scale well in general, nor does it
encourage modular or object-oriented programming.

To quote @ref{1539,,Joyner (1996)}:

@quotation

In C++ the programmer must manually manage storage due to
the lack of @ref{f,,garbage collection}. This is the most
difficult bookkeeping task C++ programmers face, that
leads to two opposite problems: firstly, an object can be
@ref{15d2,,deallocated} prematurely, while valid
@ref{24,,references} still exist (@ref{281,,dangling pointers}); secondly, @ref{49,,dead} objects might not be
deallocated, leading to memory filling up with dead
objects (@ref{234,,memory leaks}). Attempts to correct either
problem can lead to overcompensation and the opposite
problem occurring. A correct system is a fine balance.
@end quotation

Manual memory management was common in early languages,
but @ref{f,,garbage collection} has been around since the
late 1950s, in languages like @ref{28a,,Lisp}. Most modern
languages use @ref{9,,automatic memory management}, and
some older languages have @ref{349,,conservative garbage collection} extensions.

@ref{9,,automatic memory management}.

Manual memory management can be used with @ref{18,,pools}
such as @ref{10c,,MVFF (Manual Variable First Fit)} via the functions
@ref{ad,,mps_alloc()} and @ref{1f,,mps_free()}.
@anchor{glossary/m term-mapped}@anchor{190}
@geindex mapped

@item mapped

`committed'.

A range of @ref{16b9,,virtual addresses} is said
to be `mapped' (`committed' on Windows) if there is
@ref{15b6,,physical memory (2)} associated with the range.

Note that, in some circumstances, the @ref{51,,virtual memory}
system could actually @ref{16cf,,overcommit} mapped memory.

@ref{1685,,unmapped}.


@subsubheading See also


@ref{310,,mapping}, @ref{15b7,,memory mapping}, @ref{16d0,,mmap}.


The term `committed' is used. The function
@ref{18e,,mps_arena_committed()} returns the total committed
memory for an @ref{16,,arena}.
@anchor{glossary/m term-mapping}@anchor{310}
@geindex mapping

@item mapping

A `mapping' is a correspondence between a range of
@ref{16b9,,virtual addresses} and some
@ref{15b0,,memory (1)} (or a @ref{15b7,,memory-mapped} object). The physical location of the memory will be
managed by the @ref{51,,virtual memory} system.

Each @ref{92,,page} in a mapping could be @ref{16d1,,paged out} or
@ref{195,,paged in}, and the locations it occupies in @ref{311,,main memory} and/or @ref{15e9,,swap space} might change over time.

The @ref{15bb,,virtual address space} can contain of a complex set
of mappings. Typically, parts of the address space are
@ref{190,,mapped} (have a mapping assigned), others are
@ref{16d2,,reserved} but unmapped, and most of it is entirely
@ref{1685,,unmapped}.


@float Figure

@image{MemoryPoolSystem-figures/mapped,,,Diagram: Virtual memory with different kinds of mappings.,svg}

@caption{Virtual memory with different kinds of mappings.}

@end float



@subsubheading See also


@ref{15d1,,backing store}.

@anchor{glossary/m term-mark-compact}@anchor{160d}
@geindex mark-compact

@item mark-compact

Mark-compact collection is a kind of @ref{15df,,tracing garbage collection} that operates by @ref{1600,,marking} @ref{96,,reachable}
@ref{1ab,,objects}, then @ref{1643,,compacting}
the marked objects (which must include all the @ref{78,,live}
objects).

The mark phase follows @ref{24,,reference} chains to mark all
reachable objects; the compaction phase typically performs a
number of sequential passes over @ref{194,,memory (2)} to move
objects and update references. As a result of compaction, all
the marked objects are moved into a single contiguous
@ref{185,,block} of memory (or a small number of such blocks);
the memory left unused after compaction is @ref{15de,,recycled}.

Mark-compact collection can be regarded as a variation of
@ref{15fd,,mark-sweep collection}, with extra effort
spent to eliminate the resulting @ref{17e,,fragmentation}.
Compaction also allows the use of more efficient
@ref{15d4,,allocation mechanisms}, by
making large free blocks available.

@ref{151e,,Edwards}.
@anchor{glossary/m term-mark-sweep}@anchor{15fd}
@geindex mark-sweep

@item mark-sweep@anchor{glossary/m term-mark-and-sweep}@anchor{16d3}
@geindex mark-and-sweep

@itemx mark-and-sweep

Mark-sweep collection is a kind of @ref{15df,,tracing garbage collection} that operates by @ref{1600,,marking} @ref{96,,reachable}
@ref{1ab,,objects}, then @ref{16d4,,sweeping} over
@ref{194,,memory (2)} and @ref{15de,,recycling} objects
that are unmarked (which must be @ref{21,,unreachable}), putting
them on a @ref{268,,free list}.

The mark phase follows @ref{24,,reference} chains to mark all
reachable objects; the sweep phase performs a sequential
(@ref{126,,address}-order) pass over memory to recycle all
unmarked objects. A mark-sweep @ref{15d7,,collector (1)} doesn’t
move objects.

This was the first garbage collection algorithm, devised
by John McCarthy for @ref{28a,,Lisp}.


@subsubheading See also


@ref{160d,,mark-compact}.


@ref{1541,,McCarthy (1960)}.
@anchor{glossary/m term-marking}@anchor{1600}
@geindex marking

@item marking

Marking is the first phase (“the mark phase”) of the
@ref{15fd,,mark-sweep} algorithm or @ref{160d,,mark-compact}
algorithm. It follows all @ref{24,,references} from
a set of @ref{97,,roots} to mark all the
@ref{96,,reachable} @ref{1ab,,objects}.

Marking follows @ref{24,,reference} chains and makes some sort
of mark for each object it reaches.

Marking is often achieved by setting a bit in the object,
though any conservative representation of a predicate on the
@ref{15b4,,memory location} of the object can be used. In
particular, storing the mark bit within the object can lead to
poor @ref{1601,,locality of reference} and to poor cache
performance, because the marking phases ends up setting the
@ref{1602,,dirty bit} on all @ref{92,,pages} in the @ref{16ba,,working set}. An alternative is to store the mark bits separately:
see @ref{15fe,,bitmap marking}.


@subsubheading See also


@ref{1643,,compact}, @ref{16d4,,sweep}.

@anchor{glossary/m term-MB}@anchor{16d5}
@geindex MB

@item MB

@ref{186,,megabyte}.
@anchor{glossary/m term-megabyte}@anchor{186}
@geindex megabyte

@item megabyte

`MB'.

A megabyte is 1024 @ref{188,,kilobytes}, or 1048576
@ref{17c,,byte (1)}.

See @ref{17c,,byte (1)} for general information on this and
related quantities.
@anchor{glossary/m term-memoization}@anchor{16d6}
@geindex memoization

@item memoization

@ref{162a,,caching (3)}.
@anchor{glossary/m term-memory-1}@anchor{15b0}
@geindex memory (1)

@item memory@w{^(1)}

`storage', `store'.

`memory' or `storage' (or `store') is where data and
instructions are stored. For example, @ref{1622,,caches (1)}, @ref{311,,main memory}, floppy and hard disks are
all storage devices.

These terms are also used for the capacity of a system to
store data, and may be applied to the sum total of all the
storage devices attached to a computer.

“Store” is old-fashioned, but survives in expressions such
as “@ref{15d1,,backing store}”.
@anchor{glossary/m term-memory-2}@anchor{194}
@geindex memory (2)

@item memory@w{^(2)}

`Memory' refers to @ref{15b0,,memory (1)} that can be accessed by
the processor directly (using memory addressing instructions).

This could be @ref{16d7,,real memory (1)} or @ref{51,,virtual memory}.
@anchor{glossary/m term-memory-3}@anchor{17}
@geindex memory (3)

@item memory@w{^(3)}

@ref{311,,main memory}.
@anchor{glossary/m term-memory-4}@anchor{16d8}
@geindex memory (4)

@item memory@w{^(4)}

A @ref{15b4,,memory location}; for example, “My digital watch has
256 memories.”
@anchor{glossary/m term-memory-bandwidth}@anchor{16d9}
@geindex memory bandwidth

@item memory bandwidth

Memory bandwidth (by analogy with the term `bandwidth' from
communication theory) is a measure of how quickly information
(expressed in terms of bits) can be transferred between two
places in a computer system.

Often the term is applied to a measure of how quickly the
processor can obtain information from the @ref{311,,main memory}
(for example, “My new bus design has a bandwidth of over 400
Megabytes per second”).
@anchor{glossary/m term-memory-cache}@anchor{16da}
@geindex memory cache

@item memory cache

@ref{1622,,cache (1)}.
@anchor{glossary/m term-memory-hierarchy}@anchor{16c8}
@geindex memory hierarchy

@item memory hierarchy

@ref{1628,,storage hierarchy}.
@anchor{glossary/m term-memory-leak}@anchor{234}
@geindex memory leak

@item memory leak

`leak', `space leak', `space-leak'.

A memory leak is where @ref{15ca,,allocated} @ref{194,,memory (2)} is
not @ref{15d2,,freed (1)} although it is never used again.

In @ref{8,,manual memory management}, this usually occurs
because @ref{1ab,,objects} become @ref{21,,unreachable} without
being @ref{15d2,,freed (1)}.

In @ref{15df,,tracing garbage collection}, this happens when
objects are @ref{96,,reachable} but not @ref{78,,live}.

In @ref{15e0,,reference counting}, this happens when objects are
@ref{24,,referenced} but not @ref{78,,live}. (Such objects may or
may not be @ref{96,,reachable}.)

Repeated memory leaks cause the memory usage of a process to
grow without bound.
@anchor{glossary/m term-memory-location}@anchor{15b4}
@geindex memory location

@item memory location

`location'.

Each separately-@ref{126,,addressable} unit of
@ref{194,,memory (2)} in which data can be stored is called a
`memory location'. Usually, these hold a @ref{15c8,,byte (2)}, but
the term can refer to @ref{37c,,words}.
@anchor{glossary/m term-memory-management}@anchor{15dd}
@geindex memory management

@item memory management

`storage management'.

Memory management is the art and the process of coordinating
and controlling the use of @ref{15b0,,memory (1)} in a computer
system.

Memory management can be divided into three areas:


@enumerate 

@item 
Memory management hardware (@ref{16db,,MMUs},
@ref{55,,RAM}, etc.);

@item 
Operating system memory management (@ref{51,,virtual memory},
@ref{1fd,,protection});

@item 
Application memory management (@ref{15ca,,allocation}, @ref{15d2,,deallocation}, @ref{f,,garbage collection}).
@end enumerate

Memory management hardware consists of the electronic devices
and associated circuitry that store the state of a computer.
These devices include RAM, MMUs (memory management units),
@ref{1622,,cache (1)}, disks, and processor
@ref{26,,registers}. The design of memory hardware is
critical to the performance of modern computer systems. In
fact, @ref{16d9,,memory bandwidth} is perhaps the main limiting
factor on system performance.

Operating system memory management is concerned with using the
memory management hardware to manage the resources of the
@ref{1628,,storage hierarchy} and allocating them to the various
activities running on a computer. The most significant part of
this on many systems is @ref{51,,virtual memory}, which
creates the illusion that every process has more memory than
is actually available. OS memory management is also concerned
with @ref{15ec,,memory protection} and security, which help to
maintain the integrity of the operating system against
accidental damage or deliberate attack. It also protects user
programs from errors in other programs.

Application memory management involves obtaining @ref{194,,memory (2)} from the operating system, and managing its use by an
application program. Application programs have dynamically
changing storage requirements. The application @ref{15cd,,memory manager} must cope with this while minimizing the total CPU
overhead, interactive pause times, and the total memory used.

While the operating system may create the illusion of nearly
infinite memory, it is a complex task to manage application
memory so that the application can run most efficiently.
Ideally, these problems should be solved by tried and tested
tools, tuned to a specific application.

The Memory Management Reference is mostly concerned with
application memory management.


@subsubheading See also


@ref{9,,automatic memory management}, @ref{8,,manual memory management}.

@anchor{glossary/m term-Memory-Management-Unit}@anchor{16dc}
@geindex Memory Management Unit

@item Memory Management Unit

@ref{16db,,MMU}.
@anchor{glossary/m term-memory-manager}@anchor{15cd}
@geindex memory manager

@item memory manager

The memory manager is that part of the system that manages
@ref{194,,memory (2)}, servicing @ref{15ca,,allocation}
requests, and @ref{15de,,recycling} memory, either
@ref{8,,manually} or
@ref{9,,automatically}.

The memory manager can have a significant effect on the
efficiency of the program; it is not unusual for a program to
spend 20% of its time managing memory.

@ref{15ce,,allocator}, @ref{15d7,,collector (1)}.


@subsubheading See also


@ref{15dd,,memory management}.

@anchor{glossary/m term-memory-mapping}@anchor{15b7}
@geindex memory mapping

@item memory mapping

`file mapping'.

`Memory mapping' is the technique of making a part of the
@ref{54,,address space} appear to contain an “object”, such as a
file or device, so that ordinary @ref{194,,memory (2)} accesses
act on that object.

The object is said to be `mapped' to that range of addresses.
(The term “object” does not mean a program @ref{1ab,,object}. It
comes from Unix terminology on the @ref{16d0,,mmap} man page.)


@float Figure

@image{MemoryPoolSystem-figures/mapping,,,Diagram: An address space with a range mapped to part of an object.,svg}

@caption{An address space with a range mapped to part of an object.}

@end float


Memory mapping uses the same mechanism as @ref{51,,virtual memory} to “trap” accesses to parts of the @ref{54,,address space}, so that data from the file or device can be
@ref{195,,paged in} (and other parts @ref{16d1,,paged out}) before
the access is completed.

File mapping is available on most modern Unix and Windows
systems. However, it has a much longer history. In
Multics, it was the primary way of accessing files.


@subsubheading See also


@ref{190,,mapped}.

@anchor{glossary/m term-memory-protection}@anchor{15ec}
@geindex memory protection

@item memory protection

@ref{1fd,,protection}.
@anchor{glossary/m term-message}@anchor{e9}
@geindex message

@item message

A data structure which the MPS uses to communicate with
the @ref{d0,,client program}. See @ref{f1,,Messages}.
@anchor{glossary/m term-message-queue}@anchor{ea}
@geindex message queue

@item message queue

A queue of @ref{e9,,messages} posted by an
@ref{16,,arena}. It can be queried by calling
@ref{240,,mps_message_poll()},
@ref{241,,mps_message_queue_type()}, or
@ref{ec,,mps_message_get()}. See @ref{f1,,Messages}.
@anchor{glossary/m term-message-type}@anchor{22c}
@geindex message type

@item message type

A value of type @ref{22b,,mps_message_type_t} describing
the type of a @ref{e9,,message}. There are three message
types: @ref{236,,mps_message_type_finalization()},
@ref{18d,,mps_message_type_gc()}, and
@ref{22a,,mps_message_type_gc_start()}. See
@ref{f1,,Messages}.
@anchor{glossary/m term-misaligned}@anchor{16dd}
@geindex misaligned

@item misaligned

@ref{15cb,,unaligned}.
@anchor{glossary/m term-miss}@anchor{169e}
@geindex miss

@item miss

A miss is a lookup failure in any form of @ref{162a,,cache (3)}, most commonly at some level of a
@ref{1628,,storage hierarchy}, such as a @ref{1622,,cache (1)} or
@ref{51,,virtual memory} system.

The cost of a miss in a virtual memory system is considerable:
it may be five orders of magnitude more costly than a hit. In
some systems, such as multi-process operating systems, other
work may be done while a miss is serviced.

@ref{169d,,hit}.


@subsubheading See also


@ref{16a0,,miss rate}.

@anchor{glossary/m term-miss-rate}@anchor{16a0}
@geindex miss rate

@item miss rate

At any level of a @ref{1628,,storage hierarchy}, the miss rate is
the proportion of accesses which @ref{169e,,miss}.

Because misses are very costly, each level is designed to
minimize the miss rate. For instance, in @ref{1622,,caches (1)},
miss rates of about 0.01 may be acceptable, whereas in
@ref{51,,virtual memory} systems, acceptable miss rates are much
lower (say 0.00005). If a system has a miss rate which is too
high, it will spend most of its time servicing the misses, and
is said to @ref{16de,,thrash}.

Miss rates may also be given as a number of misses per unit
time, or per instruction.

@ref{169f,,hit rate}.
@anchor{glossary/m term-mmap}@anchor{16d0}
@geindex mmap

@item mmap

@code{mmap} is a system call provided on many Unix systems to
create a @ref{310,,mapping} for a range of @ref{16b9,,virtual addresses}.
@anchor{glossary/m term-MMU}@anchor{16db}
@geindex MMU

@item MMU

`Memory Management Unit'.

The MMU (Memory Management Unit) is a hardware device
responsible for handling @ref{194,,memory (2)} accesses requested
by the main processor.

This typically involves translation of @ref{16b9,,virtual addresses} to @ref{15aa,,physical addresses}, @ref{1622,,cache (1)}
control, bus arbitration, @ref{15ec,,memory protection}, and the
generation of various exceptions. Not all processors have an
MMU.


@subsubheading See also


@ref{16b5,,page fault}, @ref{1618,,segmentation violation}, @ref{51,,virtual memory}.

@anchor{glossary/m term-mostly-copying-garbage-collection}@anchor{1655}
@geindex mostly-copying garbage collection

@item mostly-copying garbage collection

A type of @ref{348,,semi-conservative} @ref{15df,,tracing garbage collection} which permits
@ref{1ab,,objects} to @ref{5d,,move} if
no @ref{9f,,ambiguous references} point to them.

The techniques used are a hybrid of @ref{e3,,copying garbage collection} and @ref{15fd,,mark-sweep}.

Mostly-copying garbage collectors share many of the benefits
of copying collectors, including @ref{1643,,compaction}. Since
they support ambiguous references they are additionally
suitable for use with uncooperative compilers, and may be an
efficient choice for multi-threaded systems.

@ref{14f2,,Bartlett (1989)}, @ref{1583,,Yip (1991)}.

The @ref{62,,AMC (Automatic Mostly-Copying)} pool class implements mostly-copying
garbage collection.
@anchor{glossary/m term-mostly-exact-garbage-collection}@anchor{16df}
@geindex mostly-exact garbage collection

@item mostly-exact garbage collection

@ref{348,,semi-conservative garbage collection}.
@anchor{glossary/m term-mostly-precise-garbage-collection}@anchor{16e0}
@geindex mostly-precise garbage collection

@item mostly-precise garbage collection

@ref{348,,semi-conservative garbage collection}.
@anchor{glossary/m term-moving-garbage-collector}@anchor{5d}
@geindex moving garbage collector

@item moving garbage collector@anchor{glossary/m term-moving-memory-manager}@anchor{1ad}
@geindex moving memory manager

@itemx moving memory manager

A memory manager (often a @ref{20,,garbage collector}) is said
to be `moving' if @ref{15ca,,allocated} @ref{1ab,,objects} can move
during their lifetimes.

In the garbage collecting world this will apply to
@ref{e3,,copying} collectors
and to @ref{160d,,mark-compact} collectors. It may also refer
to @ref{16e1,,replicating}
collectors.

@ref{e3,,copying garbage collection}.

@ref{5e,,non-moving garbage collector}.
@anchor{glossary/m term-mutable}@anchor{16a8}
@geindex mutable

@item mutable

Any @ref{1ab,,object} which may be changed by a program is
`mutable'.

@ref{16a7,,immutable}.
@anchor{glossary/m term-mutator}@anchor{30c}
@geindex mutator

@item mutator

`client program'.

In a @ref{f,,garbage-collected} system,
the part that executes the user code, which @ref{15ca,,allocates} @ref{1ab,,objects} and modifies, or
`mutates', them.

For purposes of describing @ref{d,,incremental garbage collection}, the system is divided into the `mutator' and the
@ref{15ae,,collector (2)}. These can be separate threads of
computation, or interleaved within the same thread.

The user code issues allocation requests, but the allocator
code is usually considered part of the collector. Indeed, one
of the major ways of scheduling the other work of the
collector is to perform a little of it at every allocation.

While the mutator mutates, it implicitly @ref{15d2,,frees} @ref{15b0,,memory (1)} by overwriting @ref{24,,references}.

This term is due to @ref{1515,,Dijkstra et al. (1976)}.

@ref{15ae,,collector (2)}.

The MPS documentation uses the term @ref{d0,,client program}
to refer to the mutator.
@end table

@node Memory Management Glossary N,Memory Management Glossary O,Memory Management Glossary M,Memory Management Glossary
@anchor{glossary/n doc}@anchor{16e2}@anchor{glossary/n glossary-n}@anchor{159c}@anchor{glossary/n memory-management-glossary-n}@anchor{16e3}
@section Memory Management Glossary: N


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/n term-nailing}@anchor{16e4}
@geindex nailing

@item nailing

@ref{1e5,,pinning}.
@anchor{glossary/n term-natural-alignment}@anchor{70}
@geindex natural alignment

@item natural alignment

Natural alignment is an @ref{68,,alignment} constraint such that
all @ref{1ab,,objects} must be aligned to an address
that is a multiple of their size.

Natural alignment is not usually required for objects larger
than a @ref{37c,,word} or @ref{1695,,grain}, which usually only need
to be word- or grain-aligned.


@subsubheading See also


@ref{68,,alignment}, @ref{16b3,,padding}.


The MPS platform interface defines the @ref{1c,,C}
preprocessor macro @ref{6f,,MPS_PF_ALIGN} to be the
natural alignment of the platform.
@anchor{glossary/n term-nepotism}@anchor{16e5}
@geindex nepotism

@item nepotism

In @ref{e,,generational garbage collection} nepotism is the
tendency for @ref{49,,dead} @ref{1ab,,objects} in old
@ref{e1,,generations} to preserve younger dead
objects that are referenced by them. In other words, dead
parents can cause their children to get promoted.

This happens when an object gets @ref{223,,promoted}
to an old generation and dies there, but does not get
@ref{4a,,reclaimed} because the generation it is in does not get
considered for garbage collection very often. The old object
might refer to objects in younger generations that are also
dead; until the old object is reclaimed the younger objects
will be preserved by virtue of the @ref{24,,reference} from the
older, assumed alive, object.

This is a form of @ref{15d8,,floating garbage} introduced by
partitioning the objects into generations.
@anchor{glossary/n term-next-fit}@anchor{1681}
@geindex next fit

@item next fit

A variant of the @ref{37f,,first fit} @ref{15d4,,allocation mechanism} that uses a `roving pointer' on a circular
@ref{15c0,,free block chain}. The pointer is advanced along the
chain when searching for a fit. Thus each allocation begins
looking where the previous one finished. The rationale is to
avoid creating an accumulation of small fragments at the head
of the free block chain, which would have to be examined on
every allocation.

There are several variants, according to the order of blocks
on the free block chain. The most common variant is
address-ordered next fit.

This has a tendency to spread related objects out in memory,
and also gives quite poor @ref{1601,,locality} for the allocator (as the roving pointer rotates
around memory, the free blocks touched are those
least-recently used).


@subsubheading See also


@ref{15d4,,allocation mechanism}, @ref{37f,,first fit}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/n term-new-space}@anchor{16e6}
@geindex new space

@item new space@anchor{glossary/n term-newspace}@anchor{16e7}
@geindex newspace

@itemx newspace

@ref{1633,,tospace}.
@anchor{glossary/n term-node}@anchor{163e}
@geindex node

@item node

In a @ref{1635,,graph}, a node is a representation of an
@ref{1ab,,object} at the junction of zero or more @ref{1671,,edges}.

@ref{1671,,edge}.


@subsubheading See also


@ref{1635,,graph}.

@anchor{glossary/n term-non-moving-garbage-collector}@anchor{5e}
@geindex non-moving garbage collector

@item non-moving garbage collector@anchor{glossary/n term-non-moving-memory-manager}@anchor{1e7}
@geindex non-moving memory manager

@itemx non-moving memory manager

A memory manager is said to be `non-moving' if
@ref{15ca,,allocated} @ref{1ab,,objects} do not move during their
lifetimes.

Non-moving memory management techniques include
@ref{15fd,,mark-sweep} collection, @ref{15e0,,reference counting}, and
most kinds of @ref{8,,manual memory management}.

@ref{5d,,moving garbage collector}.
@anchor{glossary/n term-nursery-generation}@anchor{222}
@geindex nursery generation

@item nursery generation

@ref{35f,,nursery space}.
@anchor{glossary/n term-nursery-space}@anchor{35f}
@geindex nursery space

@item nursery space

`nursery generation'.

In @ref{e,,generational garbage collection}, the `nursery
generation' or `space' is the area used for new
@ref{15ca,,allocation}.

The size of the nursery space must be chosen carefully. Often
it is related to the size of @ref{16b8,,physical memory (1)}.

By default, a garbage-collected @ref{18,,pool} allocates
into the first @ref{e1,,generation} in its @ref{e2,,generation chain}, but this can be altered by setting the
@code{MPS_KEY_GEN} @ref{53,,keyword argument} when
calling @ref{166,,mps_pool_create_k()}.
@end table

@node Memory Management Glossary O,Memory Management Glossary P,Memory Management Glossary N,Memory Management Glossary
@anchor{glossary/o doc}@anchor{16e8}@anchor{glossary/o glossary-o}@anchor{159d}@anchor{glossary/o memory-management-glossary-o}@anchor{16e9}
@section Memory Management Glossary: O


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/o term-object}@anchor{1ab}
@geindex object

@item object

`cell'.

In @ref{15dd,,memory management}, we use the term `object' or
`cell' to mean a contiguous @ref{185,,block} of @ref{194,,memory (2)} forming a single logical structure.

Objects are the units of @ref{15ca,,allocation},
@ref{15d2,,deallocation}, etc. No connection to an
object-oriented system is implied.

The MPS documentation generally reserves the term `object'
for @ref{23,,formatted objects}. For
units of allocation in general, it uses the term
@ref{185,,block}.
@anchor{glossary/o term-object-format}@anchor{39}
@geindex object format

@item object format

A data structure provided by the @ref{d0,,client program}
which describes the format of @ref{23,,objects} allocated in a @ref{18,,pool}. The MPS uses the
@ref{69,,format methods} to find
@ref{24,,references} in an object, replace an
object with @ref{16b3,,padding}, replace an object with a
@ref{1db,,forwarding marker}, and other essential
@ref{f,,garbage collection} tasks. See @ref{6a,,Object formats}.
@anchor{glossary/o term-object-pointer}@anchor{6e}
@geindex object pointer

@item object pointer

In the @ref{1c,,C} programming language, a @ref{15b8,,pointer} to an
@ref{1ab,,object}, as distinct from a @ref{168a,,function pointer}.
The C programming language guarantees that you can cast any
object pointer to @code{void *} and back without losing
information.

@ref{168a,,function pointer}.
@anchor{glossary/o term-off-white}@anchor{1640}
@geindex off-white

@item off-white

`ecru'.

In a @ref{163f,,treadmill} @ref{20,,garbage collector}, the
@ref{163c,,color} off-white is used to describe @ref{1ab,,objects}
which are @ref{15d6,,free (3)}. @ref{14e5,,Baker (1992c)}
used the term `ecru'.

@ref{1604,,black}, @ref{1606,,gray}, @ref{1607,,white}.


@subsubheading See also


@ref{163c,,color}, @ref{163f,,treadmill}.

@anchor{glossary/o term-old-space}@anchor{16ea}
@geindex old space

@item old space@anchor{glossary/o term-oldspace}@anchor{16eb}
@geindex oldspace

@itemx oldspace

@ref{1682,,fromspace}.
@anchor{glossary/o term-one-bit-reference-count}@anchor{16c6}
@geindex one-bit reference count

@item one-bit reference count

The one-bit @ref{15e0,,reference count} is a
heuristic mechanism that lets a program test, at low cost,
whether an @ref{1ab,,object} is @ref{49,,dead}.

The one-bit reference count is a special case of the
@ref{16c5,,limited-field reference count}. A single bit in an
object, called the MRB (Multiple Reference Bit), is cleared
when the object is @ref{15ca,,allocated}. Whenever another
@ref{24,,reference} to the object is created, the bit is set.
Thus, MRB=0 indicates that there is exactly one reference to
the object, and MRB=1 indicates that there may be more than
one reference to the object.

The MRB can be stored in the reference rather than in the
object; doing so reduces the number of memory accesses due to
MRB checking and setting. When a reference is copied, the
copy’s MRB is set. If the MRB in the old reference is 0, it
also needs to be set. Setting the MRB in the old reference
requires that the program knows the location the old reference
came from, and that it can prove that location has not since
been overwritten with other data.

The one-bit reference count is used by a compiler to augment
an object lifetime analysis. When compile-time analysis
predicts that a particular object may be dead (typically
because the variable that references the object is dead), the
compiler can generate code that will check the object’s MRB at
run-time. If the MRB is 0, then the object is dead.

Using a one-bit reference count does have a cost: the MRB uses
space that could sometimes be put to other use, and the MRB
must be set every time the number of references to the object
increases. The one-bit reference count is cheaper than other
kinds of reference counting, however, since the space cost is
only one bit and the reference count is not adjusted when
references are destroyed.

The one-bit reference count was suggested by
@ref{1523,,Friedman & Wise (1977)}. Storing the MRB in
the reference was suggested by @ref{156e,,Stoye@comma{} Clarke@comma{} and Norman (1984)}.

@ref{1538,,Jones et al. (2012)}.
@anchor{glossary/o term-opaque-type}@anchor{16ec}
@geindex opaque type

@item opaque type

In the MPS interface, an `opaque type' is a pointer to an
incomplete structure type. The client programs must not
rely on the details of its implementation. For example,
the type @ref{11e,,mps_arena_t} is an alias for @code{struct
mps_arena_s *}, but the implementation of @code{struct
mps_arena_s} is not public. See @ref{112,,Interface conventions}.

@ref{127,,transparent type}.
@anchor{glossary/o term-out-parameter}@anchor{58}
@geindex out parameter

@item out parameter

A function parameter that points to a location for the caller
to receive data from the function.

@ref{16ab,,in parameter}.

Out parameters are given names ending with @code{_o}. See
@ref{112,,Interface conventions}.
@anchor{glossary/o term-out-of-band-header}@anchor{16aa}
@geindex out-of-band header

@item out-of-band header

In some @ref{15cd,,memory managers}, each @ref{15ca,,allocated}
@ref{185,,block} has additional information (such as the size of
the block or a @ref{88,,tag}) stored in a separate block; this
is called `an out-of-band header'.

@ref{1d1,,in-band header}.
@anchor{glossary/o term-overcommit}@anchor{16cf}
@geindex overcommit

@item overcommit

In some circumstances, although a range of @ref{16b9,,virtual addresses} has been @ref{190,,mapped} as far as the user program
is concerned, the @ref{16ed,,physical storage} might not be
allocated until it is accessed. This is called
`overcommitting'.

Overcommitting shares @ref{15e9,,swap space} resources more
flexibly, especially when crude @ref{16b2,,suballocators} are
involved, but it can lead to an out-of-resource error during a
@ref{194,,memory (2)} access; few environments deal with this
situation gracefully.

Unix systems such as IRIX and AIX can do this on @ref{160f,,sbrk}
and @ref{16d0,,mmap} calls.
@anchor{glossary/o term-overwriting-error}@anchor{c5}
@geindex overwriting error

@item overwriting error

`bounds error'.

An overwriting or bounds error occurs when the programmer
intends his program to write to a particular @ref{185,,block} of
@ref{15b0,,memory (1)}, but a program error causes the program to
write outside the bounds of that block.


@subsubheading See also


@ref{283,,fencepost}.

@end table

@node Memory Management Glossary P,Memory Management Glossary Q,Memory Management Glossary O,Memory Management Glossary
@anchor{glossary/p doc}@anchor{16ee}@anchor{glossary/p glossary-p}@anchor{159e}@anchor{glossary/p memory-management-glossary-p}@anchor{16ef}
@section Memory Management Glossary: P


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/p term-padding}@anchor{16b3}
@geindex padding

@item padding

Padding is redundant @ref{194,,memory (2)} within the memory
@ref{15ca,,allocated} to an @ref{1ab,,object}. It is usually inserted
because of @ref{68,,alignment} restrictions on the fields of the
object or on the object itself.

Padding is a form of @ref{379,,internal fragmentation}.
@anchor{glossary/p term-padding-method}@anchor{90}
@geindex padding method

@item padding method

A @ref{69,,format method} that is called by a @ref{5d,,moving} @ref{18,,pool} to create
a @ref{67,,padding object}. See @ref{91,,mps_fmt_pad_t}.
@anchor{glossary/p term-padding-object}@anchor{67}
@geindex padding object

@item padding object

A @ref{23,,formatted object} that consists of
@ref{16b3,,padding}. One of three types of formatted objects,
the other two being @ref{325,,client objects}
and @ref{66,,forwarding objects}.
@anchor{glossary/p term-page}@anchor{92}
@geindex page

@item page

A @ref{51,,virtual memory} system usually deals with
@ref{15b0,,memory (1)} @ref{185,,blocks} of fixed size as
units for @ref{15e7,,paging}. These are known as `pages'.

Pages are often 4 @ref{188,,kB} or 8 kB in size. This
size is determined by the addressing hardware of the machine.
@anchor{glossary/p term-page-fault}@anchor{16b5}
@geindex page fault

@item page fault

An exception when accessing @ref{51,,virtual memory},
usually resulting in a @ref{92,,page} being fetched from disk.

A page fault is an exception occurring during the translation
of @ref{16b9,,virtual addresses} to
@ref{15aa,,physical addresses}. “Page fault”
usually means an access to a page that has been @ref{16d1,,paged out} and hence requires fetching from disk, but it is
sometimes also used to mean @ref{16b4,,invalid page fault} or
@ref{1d7,,protection fault}.


@subsubheading See also


@ref{195,,paged in}, @ref{16d1,,paged out}, @ref{15e7,,paging}, @ref{16f0,,read fault}, @ref{16f1,,write fault}.

@anchor{glossary/p term-page-marking}@anchor{1657}
@geindex page marking

@item page marking

Page marking is a form of @ref{162e,,card-marking}
where the @ref{162d,,card} is the same size as a @ref{92,,page}
@anchor{glossary/p term-page-protection}@anchor{16f2}
@geindex page protection

@item page protection

@ref{1fd,,protection}.

Many operating systems support protection of @ref{194,,memory (2)} @ref{92,,pages}. Individual pages may be protected
against a combination of read, write or execute accesses by a
process.
@anchor{glossary/p term-page-table}@anchor{16a2}
@geindex page table

@item page table

In a @ref{51,,virtual memory} system, it is common to map
between @ref{16b9,,virtual addresses} and
@ref{15aa,,physical addresses} by means of a
data structure called a `page table'.

The @ref{92,,page} number of an address is usually found from
the most significant bits of the address; the remaining bits
yield the offset of the @ref{15b4,,memory location} within the
page. The page table is normally indexed by page number and
contains information on whether the page is currently in
@ref{311,,main memory}, and where it is in main memory or on
disk.

Conventional page tables are sized to the virtual
@ref{54,,address space} and store the entire virtual address
space description of each process. Because of the need to keep
the virtual-to-physical translation time low, a conventional
page table is structured as a fixed, multi-level hierarchy,
and can be very inefficient at representing a sparse virtual
address space, unless the allocated pages are carefully
aligned to the page table hierarchy.


@subsubheading See also


@ref{16b6,,inverted page table}.

@anchor{glossary/p term-paged-in}@anchor{195}
@geindex paged in

@item paged in

In a @ref{51,,virtual memory} system, @ref{194,,memory (2)} is
described as `paged in' if it is available in @ref{16b8,,physical memory (1)}.

@ref{16f3,,swapped in}.

@ref{16d1,,paged out}.


@subsubheading See also


@ref{15e7,,paging}.

@anchor{glossary/p term-paged-out}@anchor{16d1}
@geindex paged out

@item paged out

In a @ref{51,,virtual memory} system, @ref{194,,memory (2)} is
described as `paged out' if it is not available in
@ref{16b8,,physical memory (1)}.

@ref{169b,,swapped out}.

@ref{195,,paged in}.


@subsubheading See also


@ref{15e7,,paging}.

@anchor{glossary/p term-paging}@anchor{15e7}
@geindex paging

@item paging

In a @ref{51,,virtual memory} system, `paging' is the act of
transferring @ref{92,,pages} between @ref{16b8,,physical memory (1)} and @ref{15d1,,backing store} (usually disk).

When pages need to be paged out, a heuristic is used to select
ones that will not be needed soon; “least recently used” is a
popular one.

@ref{15e8,,swapping}.


@subsubheading See also


@ref{195,,paged in}, @ref{16d1,,paged out}.

@anchor{glossary/p term-palimpsest}@anchor{16f4}
@geindex palimpsest

@item palimpsest

A @ref{185,,block} of @ref{194,,memory (2)} that has been
@ref{15ca,,allocated}, @ref{15d2,,freed (1)} (or @ref{4a,,reclaimed}),
and then allocated again. Such memory may contain data from
the previous use if portions of it remain uninitialised.

This commonly occurs on the @ref{15bc,,stack}, especially if the
compiler allocates large @ref{15b1,,stack frames} in
anticipation of allocating data structures on the stack.

If the palimpsest is being @ref{65,,scanned}
@ref{349,,conservatively}, such
left-over data may cause @ref{21,,unreachable} @ref{1ab,,objects}
to appear @ref{96,,reachable} and thus become @ref{15d8,,floating garbage}. If it is scanned @ref{164f,,precisely}, such left-over data, if treated as
@ref{15b8,,pointers}, is a bug.
@anchor{glossary/p term-parallel-garbage-collection}@anchor{15ed}
@geindex parallel garbage collection

@item parallel garbage collection

`concurrent garbage collection'.

A parallel or concurrent @ref{15ae,,collector (2)} executes
simultaneously with the @ref{30c,,mutator}, usually on a
multi-processor machine.

Concurrent @ref{f,,garbage collection} must cope with the
mutator changing @ref{1ab,,objects} while collection
occurs. The problem is similar to that of @ref{d,,incremental GC}, but harder. The solution
typically involves @ref{60,,barriers (1)}.

@ref{d,,incremental}.


@subsubheading See also


@ref{16e1,,replicating garbage collector}.


@ref{1519,,Doligez & Leroy (1993)}, @ref{151a,,Doligez & Gonthier (1994)}.
@anchor{glossary/p term-parked-state}@anchor{b8}
@geindex parked state

@item parked state

One of the four states an @ref{16,,arena} can be in (the
others being the @ref{19f,,clamped state}, the
@ref{d5,,postmortem state}, and the @ref{192,,unclamped state}). In the parked state, no @ref{f,,garbage collection} is in progress, no object motion occurs and
the staleness of @ref{19a,,location dependencies} does not
change. Call @ref{b9,,mps_arena_park()} or
@ref{ce,,mps_arena_collect()} to put an arena into the
parked state.
@anchor{glossary/p term-perfect-fit}@anchor{15f2}
@geindex perfect fit

@item perfect fit

If an @ref{15ca,,allocation} request is satisfied
exactly from a @ref{15bf,,free block} with no
@ref{17e,,fragmentation}, this is said to be a @ref{15f2,,perfect fit}.


@subsubheading See also


@ref{15d4,,allocation mechanism}, @ref{382,,best fit}, @ref{15bf,,free block}.

@anchor{glossary/p term-phantom-reachable}@anchor{16f5}
@geindex phantom reachable

@item phantom reachable@anchor{glossary/p term-phantomly-reachable}@anchor{16f6}
@geindex phantomly reachable

@itemx phantomly reachable

In @ref{167f,,Java}, an object is `phantom reachable' if it is
neither @ref{16f7,,strongly} nor
@ref{16f8,,softly} nor @ref{16f9,,weakly reachable}
and has been @ref{b,,finalized} and there is a
path from the @ref{97,,roots} to it that contains at
least one @ref{16fa,,phantom reference}.

When the Java @ref{15d7,,collector (1)} determines that an object
is phantom reachable, the @ref{16fb,,reference objects} containing
the phantom references are enqueued.

The Java specification says that the phantom reference is not
cleared when the reference object is enqueued, but actually,
there’s no way in the language to tell whether that has been
done or not. In some implementations, JNI weak global
references are weaker than phantom references, and provide a
way to access phantom reachable objects.


@subsubheading See also


@ref{96,,reachability}.


Class java.lang.ref.PhantomReference@footnote{http://docs.oracle.com/javase/8/docs/api/java/lang/ref/PhantomReference.html}, Reference Objects and Garbage Collection@footnote{http://pawlan.com/monica/articles/refobjs/}.
@anchor{glossary/p term-phantom-reference}@anchor{16fa}
@geindex phantom reference

@item phantom reference

In @ref{167f,,Java} terminology, `phantom reference' is used to
mean a @ref{24,,reference} encapsulated in a @ref{16fb,,reference object} of class @code{PhantomReference}.

Phantom references form one of three kinds of @ref{c,,weak reference (1)} in Java. They are handy for performing
clean-ups after an object has @ref{49,,died} and been
@ref{b,,finalized}.


@subsubheading See also


@ref{16f5,,phantom reachable}.


Class java.lang.ref.PhantomReference@footnote{http://docs.oracle.com/javase/8/docs/api/java/lang/ref/PhantomReference.html}, Reference Objects and Garbage Collection@footnote{http://pawlan.com/monica/articles/refobjs/}.
@anchor{glossary/p term-physical-address}@anchor{15aa}
@geindex physical address

@item physical address

`absolute address'.

Physical @ref{126,,addresses} are used to index into
@ref{16b8,,physical memory (1)}. On some systems, they are called
`absolute addresses'.

In a @ref{51,,virtual memory} system the application program
handles @ref{16b9,,virtual addresses} and these
are translated to physical addresses by the @ref{16db,,MMU}.

@ref{16b9,,virtual address}.
@anchor{glossary/p term-physical-address-space}@anchor{15ba}
@geindex physical address space

@item physical address space

The physical @ref{54,,address space} is the space of
@ref{15aa,,physical addresses}.

@ref{15bb,,virtual address space}.
@anchor{glossary/p term-physical-memory-1}@anchor{16b8}
@geindex physical memory (1)

@item physical memory@w{^(1)}

`real memory'.

Physical memory is @ref{15b0,,memory (1)} that is wired to
directly to the processor, addressable by @ref{15aa,,physical address}.

This term is basically synonymous to @ref{311,,main memory}, but
is used in contrast to @ref{51,,virtual memory} and
@ref{15d1,,backing store}.

While modern computers usually have lots of @ref{51,,virtual memory}, performance is still closely related to the
quantity of physical memory available. If a system has
insufficient physical memory, it may @ref{16de,,thrash}.

@ref{311,,main memory}.
@anchor{glossary/p term-physical-memory-2}@anchor{15b6}
@geindex physical memory (2)

@item physical memory@w{^(2)}

`physical storage'.

Physical memory is @ref{15b0,,memory (1)} on physical storage
devices, such as @ref{55,,RAM} or disks.

This term is often contrasted to @ref{15bb,,virtual address space}
that might not be mapped to any actual storage.

@ref{15b0,,memory (1)}.
@anchor{glossary/p term-physical-storage}@anchor{16ed}
@geindex physical storage

@item physical storage

@ref{15b6,,physical memory (2)}.
@anchor{glossary/p term-pig-in-the-python}@anchor{16fc}
@geindex pig in the python

@item pig in the python

`pig in the snake'.

In a @ref{e,,generational}
collector, when long-lived @ref{1ab,,objects} are
@ref{15ca,,allocated} in @ref{35f,,nursery space}, collection effort
will be wasted as those objects survive and are
@ref{223,,promoted} from @ref{e1,,generation} to
generation. This is especially noticeable in a @ref{e3,,copying collector}, where long-lived
objects will be copied many times. This difficulty is similar
to that of a python which swallows its prey whole and is
somewhat immobilized as it digests it.

Modern collectors permit objects to be allocated directly into
appropriate generations or pools to avoid this problem.
Long-lived objects can be allocated directly into long-term
generations. Large objects can be allocated directly into
pools with special support for large objects (such as copying
by remapping, incremental copying, or not copying at all).


@subsubheading See also


@ref{e,,generational garbage collection}.


A @ref{18,,pool} can be configured to allocate into a
specific @ref{e1,,generation} in its @ref{e2,,generation chain} by setting the @code{MPS_KEY_GEN}
@ref{53,,keyword argument} when calling
@ref{166,,mps_pool_create_k()}.
@anchor{glossary/p term-pig-in-the-snake}@anchor{16fd}
@geindex pig in the snake

@item pig in the snake

@ref{16fc,,pig in the python}.
@anchor{glossary/p term-pinning}@anchor{1e5}
@geindex pinning

@item pinning

`nailing'.

In @ref{e3,,copying garbage collection}, an object may not be
movable because it is the target of an @ref{9f,,ambiguous reference} or because it is referenced by @ref{10b,,foreign code}
that does not co-operate with the collector. Such an object is
said to be `pinned'.
@anchor{glossary/p term-placement-policy}@anchor{16fe}
@geindex placement policy

@item placement policy

@ref{380,,allocation policy}.
@anchor{glossary/p term-platform}@anchor{12f}
@geindex platform

@item platform

The term `platform' is used to refer to the combination of
operating system, processor architecture, and compiler.
See @ref{130,,Platforms}.
@anchor{glossary/p term-plinth}@anchor{160}
@geindex plinth

@item plinth

The plinth is a program module providing the MPS with all
the support functions it needs from the execution
environment. The plinth removes the need for external
libraries, by getting the support from the @ref{d0,,client program}. See @ref{3b,,Plinth}.
@anchor{glossary/p term-pointer}@anchor{15b8}
@geindex pointer

@item pointer

`Pointer' data types represent a reference to an
@ref{1ab,,object} or a @ref{15b4,,location}.

Pointers may be specialized by the type of the object referred
to.

Typically, pointers are represented by an @ref{126,,address}, but
they can be more complicated when they need to carry more
information. For example, when the referent is smaller than a
@ref{37c,,word}, an offset within the word might be needed.

@ref{126,,address}, @ref{24,,reference}.


@subsubheading See also


@ref{88,,tag}.

@anchor{glossary/p term-pool}@anchor{18}
@geindex pool

@item pool

A pool is responsible for requesting memory from the
@ref{16,,arena} and making it available to the @ref{d0,,client program} via @ref{ad,,mps_alloc()} or via an
@ref{63,,allocation point}. Multiple pools can coexist in
one arena. Pools belong to the type
@ref{1b1,,mps_pool_t}. See @ref{1e,,Pools} and the
@ref{22,,Pool reference}.
@anchor{glossary/p term-pool-class}@anchor{10}
@geindex pool class

@item pool class

A value of type @ref{1b4,,mps_pool_class_t} describing a
class of @ref{18,,pools} that manage memory according to
particular policy. See @ref{22,,Pool reference}.
@anchor{glossary/p term-postmortem-state}@anchor{d5}
@geindex postmortem state

@item postmortem state

One of the four states an @ref{16,,arena} can be in (the
others being the @ref{192,,unclamped state}, the
@ref{19f,,clamped state}, and the @ref{b8,,parked state}). In
the postmortem state, objects do not move in memory, the
staleness of @ref{19a,,location dependencies} does not
change, memory occupied by @ref{21,,unreachable} objects is
not recycled, all memory protection is removed, and memory
may be in an inconsistent state. Call
@ref{d6,,mps_arena_postmortem()} to put an arena into the
postmortem state.
@anchor{glossary/p term-precise-garbage-collection}@anchor{16ff}
@geindex precise garbage collection

@item precise garbage collection

@ref{164f,,exact garbage collection}.
@anchor{glossary/p term-precise-reference}@anchor{1700}
@geindex precise reference

@item precise reference

@ref{61,,exact reference}.
@anchor{glossary/p term-precise-root}@anchor{1701}
@geindex precise root

@item precise root

@ref{20b,,exact root}.
@anchor{glossary/p term-premature-free}@anchor{165c}
@geindex premature free

@item premature free

`use after free'.

A `premature free' or `use after free' occurs when
@ref{194,,memory (2)} is @ref{15d2,,deallocated}, but is
later accessed.

Under @ref{8,,manual memory management}, this usually occurs
when one part of a program decides it has finished using a
memory @ref{185,,block}, and is unaware that another part of the
program is still using it. This is rare under @ref{9,,automatic memory management}.


@subsubheading See also


@ref{26b,,double free}.

@anchor{glossary/p term-premature-promotion}@anchor{1702}
@geindex premature promotion

@item premature promotion

@ref{1703,,premature tenuring}.
@anchor{glossary/p term-premature-tenuring}@anchor{1703}
@geindex premature tenuring

@item premature tenuring

`premature promotion'.

When a short-lived @ref{1ab,,object} @ref{15ca,,allocated} in a
@ref{e,,generational garbage collector} is @ref{223,,promoted} (due to poor
timing) into a less-frequently collected @ref{e1,,generation}.
This `prematurely tenured' object may become @ref{1649,,garbage}
very soon after promotion, but will not be @ref{4a,,reclaimed}
for some time because it is now in a less frequently collected
generation.

This problem is essentially due to quantization error: all
objects in a generation are treated as if they have the same
age, even though they range from as old as the previous
promotion cycle to new-born.

Modern @ref{20,,collectors (1)} offer
several remedies for premature tenuring. If the client program
knows that it is entering a phase that will create many
short-lived objects, it can forestall all promotion until it
knows it is done with those objects. Thus no objects will be
prematurely promoted: they will all be seen as garbage.
Another solution is to create @ref{15c3,,buckets} within
generations to more accurately classify objects by age and
only promote those which have reached a certain minimum.
@anchor{glossary/p term-primary-storage}@anchor{1704}
@geindex primary storage

@item primary storage

@ref{311,,main memory}.
@anchor{glossary/p term-promotion}@anchor{223}
@geindex promotion

@item promotion

`tenuring'.

Promotion or tenuring is the act of moving an @ref{1ab,,object}
from its current @ref{e1,,generation} to an `older' one (one
that contains objects that are expected to survive longer).

“Tenuring” is used particularly about promotion to the oldest
generation.


@subsubheading See also


@ref{e,,generational garbage collection}.

@anchor{glossary/p term-protectable-root}@anchor{216}
@geindex protectable root

@item protectable root

A @ref{97,,root} which the MPS may @ref{1fd,,protect} with a @ref{214,,write barrier}. A protectable
root is created by specifying the @ref{a0,,root mode}
@ref{211,,MPS_RM_PROT} when calling a registration
function such as @ref{9c,,mps_root_create()}.
@anchor{glossary/p term-protected}@anchor{d4}
@geindex protected

@item protected

A region of @ref{194,,memory (2)} is said to be protected if
there is a @ref{60,,barrier (1)} on that region.

@ref{1a8,,unprotected}
@anchor{glossary/p term-protection}@anchor{1fd}
@geindex protection

@item protection

`memory protection', `page protection'.

Many operating systems support protection of @ref{194,,memory (2)} @ref{92,,pages}. Individual pages may be protected
against a combination of read, write or execute accesses by a
process.

A process which attempts a protected access will trigger a
@ref{1d7,,protection fault}. Protection is typically implemented
in hardware by the @ref{16db,,MMU} as part of the support for
@ref{51,,virtual memory} .

Pages can be protected for a number of reasons: a
@ref{e,,generational} or
@ref{d,,incremental}
@ref{20,,garbage collector} may want to place @ref{60,,barriers (1)} on pages; an operating system may want to protect pages
for security, or to implement “copy-on-write” or
“demand-zero-filled” pages.


@subsubheading See also


@ref{16f0,,read fault}, @ref{16f1,,write fault}.


@ref{14db,,Appel et al. (1988)}, @ref{1568,,Singhal et al. (1992)}, @ref{152f,,Hosking & Moss (1993)}.
@anchor{glossary/p term-protection-exception}@anchor{1705}
@geindex protection exception

@item protection exception

@ref{1d7,,protection fault}.
@anchor{glossary/p term-protection-fault}@anchor{1d7}
@geindex protection fault

@item protection fault

`barrier hit', `protection exception', `protection violation'.

A protection fault is an exception or trap which occurs when a
process attempts to access @ref{194,,memory (2)} which has been
@ref{1fd,,protected}.

Some @ref{20,,garbage collectors} use handlers for
protection faults to provide @ref{60,,barriers (1)}.


@subsubheading See also


@ref{1692,,General Protection Fault}, @ref{1618,,segmentation violation}.

@anchor{glossary/p term-protection-violation}@anchor{1706}
@geindex protection violation

@item protection violation

@ref{1d7,,protection fault}.
@end table

@node Memory Management Glossary Q,Memory Management Glossary R,Memory Management Glossary P,Memory Management Glossary
@anchor{glossary/q doc}@anchor{1707}@anchor{glossary/q glossary-q}@anchor{159f}@anchor{glossary/q memory-management-glossary-q}@anchor{1708}
@section Memory Management Glossary: Q


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/q term-quadword}@anchor{1668}
@geindex quadword

@item quadword

A `quadword' is a unit of memory consisting of four adjacent
@ref{37c,,words}.

In Digital’s Alpha architecture, a quadword of 64 bits was
actually the natural word size, but the term `word' was
still used for the 16-bit unit, for compatibility with the
PDP-11.


@subsubheading See also


@ref{1667,,doubleword}.

@end table

@node Memory Management Glossary R,Memory Management Glossary S,Memory Management Glossary Q,Memory Management Glossary
@anchor{glossary/r doc}@anchor{1709}@anchor{glossary/r glossary-r}@anchor{15a0}@anchor{glossary/r memory-management-glossary-r}@anchor{170a}
@section Memory Management Glossary: R


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/r term-RAM}@anchor{55}
@geindex RAM

@item RAM

`random access memory'.

RAM (random access memory) is a type of @ref{15b6,,physical memory (2)} that can be read from and written to.

@ref{311,,main memory}.


@subsubheading See also


@ref{166d,,dynamic RAM}, @ref{16ce,,ROM}, @ref{170b,,static RAM}.

@anchor{glossary/r term-random-access-memory}@anchor{170c}
@geindex random access memory

@item random access memory

@ref{55,,RAM}.
@anchor{glossary/r term-ramp-allocation}@anchor{277}
@geindex ramp allocation

@item ramp allocation

An @ref{272,,allocation pattern} indicating to the MPS that
most of the blocks allocated after the call to
@ref{273,,mps_ap_alloc_pattern_begin()} are likely to be
@ref{49,,dead} by the time of the corresponding call to
@ref{274,,mps_ap_alloc_pattern_end()}. See
@ref{228,,Ramp allocation}.
@anchor{glossary/r term-rank}@anchor{9e}
@geindex rank

@item rank

A value of @ref{146,,mps_rank_t} indicating whether a
@ref{24,,reference} is @ref{1c4,,ambiguous}
(@ref{20a,,mps_rank_ambig()}), @ref{20b,,exact}
(@ref{9d,,mps_rank_exact()}) or @ref{20d,,weak}
(@ref{20c,,mps_rank_weak()}).
@anchor{glossary/r term-rash}@anchor{163}
@geindex rash

@item rash

A @ref{c9,,variety} in which no MPS functions @ref{284,,assert} that their data structures are valid. Select
it by defining @ref{173,,CONFIG_VAR_RASH}. Compare
@ref{c8,,cool} and @ref{162,,hot}.
@anchor{glossary/r term-raw}@anchor{170d}
@geindex raw

@item raw

@ref{170e,,unwrapped}.
@anchor{glossary/r term-reachable}@anchor{96}
@geindex reachable

@item reachable

An @ref{1ab,,object} is `reachable' if it is @ref{24,,referred} to by a @ref{97,,root}, or is referred to by a
reachable object; that is, if it can be reached from the roots
by following @ref{24,,references}.

Reachability is used as an approximation to @ref{78,,liveness} in @ref{15df,,tracing garbage collection}.

In @ref{167f,,Java}, the @ref{16fb,,reference objects} together with
ordinary references and @ref{b,,finalization} generate a
hierarchy of reachability that guides the @ref{15d7,,collector (1)} on what to do when an object is about to @ref{49,,die}. There are six strengths:


@enumerate 

@item 
@ref{16f7,,strongly reachable};

@item 
@ref{16f8,,softly reachable};

@item 
@ref{16f9,,weakly reachable};

@item 
@ref{b,,finalizable};

@item 
@ref{16f5,,phantom reachable};

@item 
@ref{21,,unreachable}.
@end enumerate

Basically, an object is only as reachable as the weakest link
in the strongest path from the roots. Note that the Java
specification’s description of the reachabilities is a bit
patchy, but that’s what it intends. It is unspecified where
Java Native Interface’s `weak global references' fit into
this.

@ref{78,,live}.

@ref{21,,unreachable}.

Package java.lang.ref@footnote{http://docs.oracle.com/javase/8/docs/api/java/lang/ref/package-summary.html}, Reference Objects and Garbage Collection@footnote{http://pawlan.com/monica/articles/refobjs/}.
@anchor{glossary/r term-read-barrier}@anchor{1d6}
@geindex read barrier

@item read barrier

A read @ref{60,,barrier (1)} is a block on reading from certain
@ref{194,,memory (2)} @ref{15b4,,locations} by
certain threads or processes.

Read barriers are used for @ref{d,,incremental} or @ref{15ed,,concurrent} @ref{f,,garbage collection}.


@subsubheading See also


@ref{214,,write barrier}.

@anchor{glossary/r term-read-fault}@anchor{16f0}
@geindex read fault

@item read fault

An exception which occurs when reading from an address in
@ref{51,,virtual memory}.

This is probably either a @ref{16b5,,page fault}, an
@ref{16b4,,invalid page fault} or a @ref{1d7,,protection fault}.

@ref{1618,,segmentation violation}.


@subsubheading See also


@ref{16f1,,write fault}.

@anchor{glossary/r term-read-only-memory}@anchor{170f}
@geindex read-only memory

@item read-only memory

@ref{16ce,,ROM}.
@anchor{glossary/r term-real-memory-1}@anchor{16d7}
@geindex real memory (1)

@item real memory@w{^(1)}

A system with no @ref{51,,virtual memory} capability can be
said to have `real memory'.

On older architectures, programs could only directly
access data in real memory. Where this was inefficient,
they had to store data on disk, and sometimes had
alternate portions of program image called `overlays'.

@ref{51,,virtual memory}.
@anchor{glossary/r term-real-memory-2}@anchor{1710}
@geindex real memory (2)

@item real memory@w{^(2)}

@ref{16b8,,physical memory (1)}.
@anchor{glossary/r term-reclaim}@anchor{4a}
@geindex reclaim

@item reclaim

`Reclaiming' an @ref{1ab,,object} or the @ref{15b0,,memory (1)}
occupied by it is making it available for reuse after the
object is no longer needed.

This word is usually used only in connection with
@ref{9,,automatic memory management}.

@ref{15de,,recycle}.
@anchor{glossary/r term-recycle}@anchor{15de}
@geindex recycle

@item recycle

`Recycling' @ref{15b0,,memory (1)} means making it available for
reuse after it has been occupied by an @ref{1ab,,object} that is
no longer needed.

In simple cases, this might simply involve adding a
@ref{194,,memory (2)} @ref{185,,block} to the @ref{268,,free list}.
Another possibility is @ref{1685,,unmapping} memory so
that the @ref{15d1,,backing store} can be allocated to another
process.

@ref{4a,,reclaim}.
@anchor{glossary/r term-reference}@anchor{24}
@geindex reference

@item reference

In memory management, `a reference' is the general term for a
link from one @ref{1ab,,object} to another. Some programming
languages have more specific meanings for the term.

The terms “@ref{15b8,,pointer}” and “reference” are often
interchangeable, but some programming languages differentiate
the two in subtle ways.

@ref{126,,address}, @ref{15b8,,pointer}.

A reference is represented in the @ref{1c,,C} interface by a
value of type @ref{11d,,mps_addr_t} (an alias for @code{void
*}) which points to a @ref{15b4,,memory location} within the
object (typically the base of the object, but for objects
with @ref{1d1,,headers} this may not be the
case). The pointer returned by @ref{ad,,mps_alloc()} and
@ref{b0,,mps_reserve()} is a reference to the object
allocated.

The @ref{d0,,client program} is free to represent references
as it chooses (for example, with @ref{7d,,tags}), provided that during @ref{65,,scanning}
it is able to decode a reference from its representation
into the MPS interface representation and encode a
reference from the MPS into its representation.
@anchor{glossary/r term-reference-counting}@anchor{15e0}
@geindex reference counting

@item reference counting

Reference counting systems perform @ref{9,,automatic memory management} by keeping a count in each @ref{1ab,,object}, usually
in a @ref{1d1,,header}, of how many
@ref{24,,references} there are to the object.
Objects to which there are no references cannot be accessed by
the @ref{30c,,mutator}; they are therefore @ref{49,,dead} and may
be @ref{4a,,reclaimed}.

The reference count is incremented for each new reference, and
is decremented if a reference is overwritten, or if the
referring object is recycled. If a reference count falls to
zero, then the object is no longer required and can be
recycled.

There are four main problems with simple reference counting:


@enumerate 

@item 
The reference count field usually has to have limited size,
and the system therefore breaks down if the number of
possible references to an object is unbounded;

@item 
Reference counting involves an operation on every
modification of a pointer, which increases code size,
increases demand for @ref{16d9,,memory bandwidth}, decreases
@ref{1601,,locality of reference} and can be a serious
performance penalty (especially in multi-threaded
environments where reference count updates require
synchronization);

@item 
Every object needs to be slightly larger in order to store
the reference count;

@item 
If any objects are part of a @ref{1659,,cyclic data structure}
then they will always have a non-zero reference count, and
hence won’t be reclaimed when they are dead.
@end enumerate


@float Figure

@image{MemoryPoolSystem-figures/refloop,,,Diagram: Garbage with non-zero reference counts.,svg}

@caption{Garbage with non-zero reference counts.}

@end float


Reference counting has the advantage that it can reclaim
objects promptly, and for this reason it is often used to
reclaim non-cyclic data structures in file systems, databases
and operating system kernels. When there is a possibility of
cyclic data structures, reference counting is sometimes used
together with a @ref{15df,,tracing garbage collector} that runs infrequently. Such combinations
are generally less efficient than using a tracing collector by
itself, but the promptness of reference counting may be
important.

Pauses due to reference counting are typically fairly short,
and it may be appropriate as a form of @ref{d,,incremental garbage collection}. But removing a single reference may cause
the recycling of a large number of objects at once, so it is
not suited to real-time systems where minimum pause times must
be guaranteed. There are more complex variations of the
technique that address this problem.

Reference counting is often used because it can be implemented
without any support from the language or compiler. In
@ref{1d,,C++} this can be encapsulated in a class, using a
@ref{1711,,smart pointer}. However, it would normally be more
efficient to use a tracing garbage collector instead. The
performance of reference counting can be improved
substantially with compiler support, using refinements such as
@ref{165f,,deferred reference counting}, which has been
successfully used in @ref{1661,,Smalltalk} and other languages.

Despite the problems, reference counting is often used for
@ref{1663,,distributed garbage collection}. This is because
refinements such as @ref{1666,,weighted reference counting}
require less inter-process communication than @ref{4b,,tracing}.


@subsubheading See also


@ref{16c5,,limited-field reference count}, @ref{16c6,,one-bit reference count}.

@anchor{glossary/r term-reference-object}@anchor{16fb}
@geindex reference object

@item reference object

In @ref{167f,,Java}, a `reference object'
(@code{java.lang.ref.Reference}) encapsulates a @ref{24,,reference}
to some other object, in order to make the @ref{20,,garbage collector} handle it specially. In particular, a Java program
can use this to detect when the referent becomes
@ref{21,,unreachable}.

Basically, the encapsulated reference is a @ref{c,,weak reference (1)}; it will be cleared by the @ref{15d7,,collector (1)} when all other references to the referent have
disappeared. However, in order to better control what happens
at the end of an object’s @ref{b5,,lifetime}, Java 1.2 provides
three classes of reference objects, each with its own
peculiarities: @code{SoftReference}, @code{WeakReference}, and
@code{PhantomReference}. Each of these classes has its uses in
managing memory. The reference objects together with ordinary
references and @ref{b,,finalization} generate a hierarchy of
@ref{96,,reachability} that guides the collector on
what to do when an object is about to @ref{49,,die}.

A reference object can be `registered' with a queue, and it
will be enqueued when the collector determines that the
referent is @ref{16f8,,softly}, @ref{16f9,,weakly} or @ref{16f5,,phantom reachable}, as the case
may be. A program can use these queues to perform some action
when an object is dying. This allows finer control than the
older @ref{b,,finalization} mechanism alone.

This feature was introduced in Java 1.2 (confusingly, part
of the Java 2 Platform).


@subsubheading See also


@ref{16fa,,phantom reference}, @ref{1712,,soft reference}, @ref{1713,,weak reference (2)}.


Package java.lang.ref@footnote{http://docs.oracle.com/javase/8/docs/api/java/lang/ref/package-summary.html}, Reference Objects and Garbage Collection@footnote{http://pawlan.com/monica/articles/refobjs/}.

@ref{151b,,Dybvig et al. (1993)}.
@anchor{glossary/r term-region-inference}@anchor{15e1}
@geindex region inference

@item region inference

Region inference is a technique for determining when
@ref{1ab,,objects} become @ref{49,,dead} (even if they are
@ref{96,,reachable}) by a static analysis of the program.

Region inference infers a `region' for each object. When a
region dies, all the objects in it are known to be
@ref{49,,dead}, whether reachable or not. Regions obey a strict
@ref{15bc,,stack} discipline; that is, when a region dies, all
younger regions also die. In this way, region inference
occupies a middle ground between @ref{15e2,,stack allocation} and
@ref{1653,,heap allocation}.

@ref{1572,,Tofte & Talpin (1997)}.
@anchor{glossary/r term-register}@anchor{26}
@geindex register

@item register

A `register' is a small unit of @ref{194,,memory (2)} that is
attached to a processor and accessible very quickly. Registers
typically form the highest level of a computer’s
@ref{1628,,storage hierarchy}.

In some programs (for example, those compiled by typical
@ref{1c,,C} or @ref{1d,,C++} compilers), a subset of the
registers is always accessible by the @ref{30c,,mutator} and
so forms a @ref{97,,root}.

The @ref{73,,scan method} for the root containing the
registers is hard to write (it depends on the operating
system, the processor architecture, and in some cases the
compiler), so the MPS provides (on its supported
platforms) the function @ref{32f,,mps_stack_scan_ambig()}.
@anchor{glossary/r term-register-set-partitioning}@anchor{1714}
@geindex register set partitioning

@item register set partitioning

Run-time systems for @ref{f,,garbage-collected} languages sometimes partition the set of machine
@ref{26,,registers} `a priori' into two categories:
those always @ref{4b,,traced} and updated by the
@ref{20,,garbage collector} and those ignored by it.

The former are always maintained in a format understood by the
collector; the latter are never used to hold
@ref{24,,references} to collectable @ref{1ab,,objects}. More
complicated schemes are also possible.

This partitioning provides a separation of concerns between
the compiler and the @ref{20,,garbage collector}. The compiler
can generate code that produces values the garbage collector
would not be able to handle (say, because they have no
@ref{88,,tags}), as long as those values are kept in the
ignored registers. The garbage collector can trust that the
registers it looks at always contain valid data, and can
perform @ref{164f,,exact garbage collection}.

Register set partitioning increases the demand for registers
(`register pressure'), but may reduce the amount of
@ref{160b,,boxing} needed.
@anchor{glossary/r term-relocation}@anchor{160e}
@geindex relocation

@item relocation

`Relocating' means moving data from one location to another
and updating all @ref{24,,references}.

Relocation is often performed to avoid @ref{383,,external fragmentation}.

Program loading sometimes relocates code and @ref{1610,,static} data.

@ref{5d,,moving}.


@subsubheading See also


@ref{1643,,compaction}, @ref{1ad,,moving memory manager}.

@anchor{glossary/r term-remembered-set}@anchor{213}
@geindex remembered set

@item remembered set

A remembered set is the technique of keeping a separate list
of interesting @ref{24,,references} between two sets
of @ref{1ab,,objects}, so you don’t have to find them by
@ref{65,,scanning}.

Many @ref{15dd,,memory management} algorithms depend on
partitioning the objects and require special handling for
references between partitions. Keeping track of such
references in a remembered set eliminates the need to scan the
originating partition to find them.

A typical use in @ref{e,,generational garbage collection} is
remembering @ref{24,,references} from an older
@ref{e1,,generation} to a younger one.

@ref{1674,,entry table (2)}.

@ref{1573,,Ungar (1984)}, @ref{1538,,Jones et al. (2012)}.
@anchor{glossary/r term-remote-reference}@anchor{35d}
@geindex remote reference

@item remote reference

A @ref{24,,reference} that logically belongs to a
@ref{23,,formatted object} and so must be @ref{b4,,fixed} when
the object is @ref{65,,scanned}, but which is not
stored within the block containing the object. (For
example, in an auxiliary table of some sort.)

The MPS does not generally support remote references
because those references may be @ref{1fd,,protected} and so if @ref{73,,scan method} attempts to
@ref{b4,,fix} them this will hit a @ref{60,,barrier (1)} and
cause a re-entrant call to the MPS.
@anchor{glossary/r term-replicating-garbage-collector}@anchor{16e1}
@geindex replicating garbage collector

@item replicating garbage collector

A variant of @ref{e3,,copying garbage collection}, which does
not destroy the original @ref{1ab,,object} when making a copy.

This is useful in an @ref{d,,incremental} or @ref{15ed,,concurrent} @ref{15d7,,collector (1)}, as no @ref{1d6,,read barrier}
is required; the @ref{30c,,mutator} can continue to use old
objects. The collector uses a @ref{214,,write barrier} to
replicate the writes to the new copies.


@subsubheading See also


@ref{1611,,broken heart}, @ref{e3,,copying garbage collection}.


@ref{154c,,Nettles et al. (1992)}, @ref{154f,,Nettles & O’Toole (1993)}, @ref{154e,,Nettles & O’Toole (1993a)}, @ref{1552,,O’Toole & Nettles (1994)}.
@anchor{glossary/r term-reserved}@anchor{16d2}
@geindex reserved

@item reserved

In a @ref{51,,virtual memory} system, it is usually possible
to hold range of @ref{16b9,,virtual addresses}
`reserved' without making it @ref{190,,mapped}.

Reserving addresses prevents other components of the program
using the same addresses, without consuming @ref{15e9,,swap space}. This technique is often used in @ref{15f6,,BIBOP} schemes,
where one might want to reserve a large amount of
@ref{54,,address space} but only sparsely map it.

On some systems there are special calls for reserving; on
others one can create @ref{310,,mappings} that don’t
need @ref{15d1,,backing store}. For example, on some Unix systems,
@code{mmap /dev/zero} with no access.


@subsubheading See also


@ref{310,,mapping}, @ref{16d0,,mmap}.


The function @ref{196,,mps_arena_reserved()} returns the
total address space reserved by an arena.
@anchor{glossary/r term-resident}@anchor{1624}
@geindex resident

@item resident

In a @ref{1627,,cache (2)} system, that part of the cached storage
which currently has a copy in the cache is called `resident'.
Ideally, the @ref{16ba,,working set} should be resident.


@subsubheading See also


@ref{1627,,cache (2)}, @ref{1715,,resident set}, @ref{1628,,storage hierarchy}.

@anchor{glossary/r term-resident-set}@anchor{1715}
@geindex resident set

@item resident set

In a @ref{51,,virtual memory} system, a process’ resident
set is that part of a process’ @ref{54,,address space} which is
currently in @ref{311,,main memory}. If this does not include all
of the process’ @ref{16ba,,working set}, the system may
@ref{16de,,thrash}.
@anchor{glossary/r term-result-code}@anchor{59}
@geindex result code

@item result code

A value returned from an MPS function, represented by the
type @ref{14d,,mps_res_t}. The result code
@ref{5a,,MPS_RES_OK} indicates success; other values
indicate errors. See @ref{5b,,Error handing}.
@anchor{glossary/r term-resurrection}@anchor{247}
@geindex resurrection

@item resurrection

An object is said to have been `resurrected' if it was
determined to be @ref{b,,finalizable} by the
@ref{20,,garbage collector} (that is, the only thing keeping it
alive was the fact that it required finalization), but then a
new @ref{244,,strong reference} was created to it.

This can happen via a @ref{c,,weak reference (1)} or by the
finalization procedure storing a permanent copy of its
reference to the object.

See @ref{f0,,Finalization}.
@anchor{glossary/r term-retention}@anchor{17f}
@geindex retention

@item retention

The failure to @ref{15de,,recycle} @ref{15d8,,floating garbage}, due
to some approximation or optimization in the @ref{20,,garbage collector}; also the amount of memory thus retained.

@ref{14fb,,Boehm (2001)}.
@anchor{glossary/r term-ROM}@anchor{16ce}
@geindex ROM

@item ROM

`read-only memory'.

ROM (read-only memory) is a type of @ref{15b6,,physical memory (2)} that can be read from, but not written to. The contents
of ROM are usually set in the factory.


@subsubheading See also


@ref{55,,RAM}.

@anchor{glossary/r term-root}@anchor{97}
@geindex root

@item root

In @ref{15df,,tracing garbage collection}, a root holds a
@ref{24,,reference} or set of references to @ref{1ab,,objects} that
are `a priori' @ref{96,,reachable}. The @ref{1716,,root set} is used
as the starting point in determining all reachable data.

Roots basically comprise the references in the state of the
@ref{30c,,mutator}. Typical roots are global variables, other
@ref{1610,,static} data, and the
@ref{27,,control stack}.


@subsubheading See also


@ref{1c4,,ambiguous root}, @ref{20b,,exact root}, @ref{1717,,strong root}, @ref{20d,,weak root}.


See @ref{28,,Roots}.
@anchor{glossary/r term-root-description}@anchor{1718}
@geindex root description

@item root description

The @ref{16,,arena} uses root descriptions to find
@ref{24,,references} within the @ref{d0,,client program’s} @ref{97,,roots}. Root
descriptions belong to the type @ref{98,,mps_root_t}.
@anchor{glossary/r term-root-mode}@anchor{a0}
@geindex root mode

@item root mode

A value of type @ref{20f,,mps_rm_t} describing whether a
@ref{97,,root} is @ref{215,,constant},
@ref{216,,protectable}, or both. The root
mode tells the MPS whether it may place a @ref{60,,barrier (1)} on the root.
@anchor{glossary/r term-root-set}@anchor{1716}
@geindex root set

@item root set

The `root set' is the collection of @ref{97,,roots} that
the @ref{30c,,mutator} declares to the @ref{15ae,,collector (2)}.


@subsubheading See also


@ref{f,,garbage collection}.

@end table

@node Memory Management Glossary S,Memory Management Glossary T,Memory Management Glossary R,Memory Management Glossary
@anchor{glossary/s doc}@anchor{1719}@anchor{glossary/s glossary-s}@anchor{15a1}@anchor{glossary/s memory-management-glossary-s}@anchor{171a}
@section Memory Management Glossary: S


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/s term-sbrk}@anchor{160f}
@geindex sbrk

@item sbrk

@code{sbrk} is a Unix library function that adjusts the limit of
the data segment; this limit is known as the `break'.

@code{sbrk} and its companion @ref{15d9,,brk} are obsolete on Unix
systems that support @ref{51,,virtual memory}.

@code{sbrk} returns the previous value of the break, so
@code{sbrk(0)} was a common idiom for getting the current value.
@anchor{glossary/s term-scalar-data-type}@anchor{15c6}
@geindex scalar data type

@item scalar data type

A scalar data type is a type that is representable in a single
dimension and whose objects have only magnitude as value.

Examples of scalar data types include: integers,
floating-point numbers, enumerations, and characters.

The objects of a scalar data type are @ref{107,,leaf objects}. Scalar data types with bounded magnitude can be
represented compactly using @ref{16a6,,value objects}.

Because compact representation solves many memory
management issues, many older programming languages only
offered bounded scalar data types. For example, the
@code{int} type in @ref{1c,,C} is defined to have a magnitude
that can be represented by a @ref{37c,,word}.


@subsubheading See also


@ref{15c5,,algebraic data type}, @ref{107,,leaf object}, @ref{16a6,,value object}, @ref{15c7,,vector data type}.

@anchor{glossary/s term-scan}@anchor{65}
@geindex scan

@item scan

The examination of an @ref{1ab,,object} or an area of
@ref{194,,memory (2)} to find @ref{24,,references},
typically as part of @ref{4b,,tracing}.

Scanning examines memory that has been decided to be
non-@ref{1649,,garbage}, to find references to objects that have
been @ref{221,,condemned}.

See @ref{25,,Scanning}.
@anchor{glossary/s term-scan-method}@anchor{73}
@geindex scan method

@item scan method

A function that examines a block of memory to find
@ref{24,,references} and indicate them to the
MPS. A scan method forms part of an @ref{39,,object format}.
See @ref{74,,mps_fmt_scan_t}.
@anchor{glossary/s term-scan-state}@anchor{79}
@geindex scan state

@item scan state

A scan state represents the state of the current
@ref{65,,scan}. The MPS passes a scan state to the
@ref{73,,scan method} of an @ref{39,,object format} when it
needs to @ref{65,,scan} for @ref{24,,references}
within a region of memory. Scan states belong to the type
@ref{1dc,,mps_ss_t}.
@anchor{glossary/s term-scavenging-garbage-collection}@anchor{171b}
@geindex scavenging garbage collection

@item scavenging garbage collection

@ref{e3,,copying garbage collection}.
@anchor{glossary/s term-SDRAM}@anchor{166c}
@geindex SDRAM

@item SDRAM

Synchronous Dynamic Random Access Memory. A high performance
variant of @ref{166a,,DRAM}.

SDRAM uses an external clock signal to synchronize its data
input and output. It is capable of achieving very high data
rates for linear access to memory.
@anchor{glossary/s term-segmentation-violation}@anchor{1618}
@geindex segmentation violation

@item segmentation violation

A segmentation violation occurs when an attempt is made to
access @ref{194,,memory (2)} whose @ref{126,,address} is
well-formed, but to which access cannot be granted. This might
be due to either a @ref{1d7,,protection fault} or an
@ref{16b4,,invalid page fault}.

The term is sometimes used more loosely as a synonym for any
memory access error, including a @ref{15c9,,bus error}.

@ref{1692,,general protection fault}, @ref{16f0,,read fault}, @ref{16f1,,write fault}.
@anchor{glossary/s term-segmented-addressing}@anchor{15b9}
@geindex segmented addressing

@item segmented addressing

In segmented addressing, @ref{126,,addresses} are in
two parts: a segment identifier and an offset into that
segment.

Each segment has a base address and a limit. If the offset is
greater than the limit, the address is invalid (see
@ref{1618,,segmentation violation}). Otherwise, the offset is
added to the segment’s base address, giving the unsegmented
address. Segment identifiers may be implicit; for instance,
they may be obtained from a `current segment' register.

Segmentation may be layered on top of @ref{51,,virtual memory},
in which case the unsegmented address is a @ref{16b9,,virtual address}, or not, in which case it is a @ref{15aa,,physical address}.

Note that, in segmented architectures, you can have a
two-dimensional @ref{54,,address space}.

Segments are a feature of some processor architectures and
operating systems. This description does not cover all
possible variations on segmentation.

Segment terminology may be used on unsegmented systems for
historical reasons. For instance, Unix processes have
`text segments', even when running on an unsegmented
system.

@ref{16c7,,linear addressing}.
@anchor{glossary/s term-segregated-allocation-cache}@anchor{1b2}
@geindex segregated allocation cache

@item segregated allocation cache

A mechanism for adding a @ref{25c,,segregated free list} to a
@ref{8,,manual} @ref{10,,pool class}. See @ref{25b,,Segregated allocation caches}.
@anchor{glossary/s term-segregated-fit}@anchor{15f3}
@geindex segregated fit

@item segregated fit

One of the @ref{25c,,segregated free list} class of
@ref{15d4,,allocation mechanisms}. There is
an array of @ref{268,,free lists}, each holding
@ref{15bf,,free blocks} of a particular range of
sizes. The @ref{15ce,,allocator} identifies the appropriate free
list and allocates from it (often using a @ref{15f1,,sequential fit} mechanism such as @ref{37f,,first fit}). If this fails, a
larger block is taken from another list and split.

The details of the mechanism depend on the division of sizes
between free lists. See @ref{1675,,exact segregated fit} and
@ref{1613,,strict segregated fit}.

This implements a @ref{15f5,,good fit} @ref{380,,allocation policy}.


@subsubheading See also


@ref{15d4,,allocation mechanism}, @ref{1675,,exact segregated fit}, @ref{268,,free list}, @ref{25c,,segregated free list}, @ref{1613,,strict segregated fit}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/s term-segregated-free-list}@anchor{25c}
@geindex segregated free list

@item segregated free list@anchor{glossary/s term-0}@anchor{171c}
@geindex segregated free-list

@itemx segregated free-list

A class of @ref{15d4,,allocation mechanism} which divides the
@ref{268,,free list} into several subsets, according to the size
of the @ref{15bf,,free blocks}. A @ref{15d2,,freed} or @ref{38c,,coalesced} block is placed on the
appropriate list. An allocation request is serviced from the
appropriate list.

This class of mechanism implements a @ref{15f5,,good fit} or
@ref{382,,best fit} policy.

Variations within this class include @ref{171d,,simple segregated storage}, @ref{15f3,,segregated fit}, and @ref{15f9,,buddy systems}.

@ref{157a,,Wilson et al. (1995)}.

@ref{1b2,,Segregated allocation caches} are a general
mechanism for adding a segregated free list to any
manually managed pool. See @ref{25b,,Segregated allocation caches}.
@anchor{glossary/s term-semi-conservative-garbage-collection}@anchor{348}
@geindex semi-conservative garbage collection

@item semi-conservative garbage collection

`mostly-exact garbage collection', `mostly-precise garbage collection'.

A variant of @ref{349,,conservative garbage collection} which
deals with @ref{61,,exact references} as well
as @ref{9f,,ambiguous references}.

For example, references from the @ref{1716,,root set} might be
ambiguous, but @ref{1ab,,objects} on the @ref{47,,heap}
might be fully described and precisely @ref{65,,scanned}.


@subsubheading See also


@ref{1655,,mostly-copying garbage collection}.


@ref{14f1,,Bartlett (1988)}.
@anchor{glossary/s term-semi-space}@anchor{1612}
@geindex semi-space

@item semi-space

When an area of @ref{194,,memory (2)} is divided into two parts
for the purposes of @ref{e3,,copying garbage collection}, the
parts are known as `semi-spaces', or sometimes just `spaces'.

Each semi-space is a contiguous area of memory. Semi-spaces
are usually used for @ref{1634,,two space collection}, but can be used for @ref{e,,generational collection}.

The semi-space where @ref{1ab,,objects} reside at the start of
the collection is known as the @ref{1682,,fromspace}; the
@ref{1633,,tospace} is where objects will reside, and where new
objects will be @ref{15ca,,allocated}, when the collection is
complete.


@subsubheading See also


@ref{1634,,two-space collector}.

@anchor{glossary/s term-semi-space-collector}@anchor{171e}
@geindex semi-space collector

@item semi-space collector

@ref{1634,,two-space collector}.
@anchor{glossary/s term-sequential-fit}@anchor{15f1}
@geindex sequential fit

@item sequential fit

A class of @ref{15d4,,allocation mechanisms} that maintain the
@ref{268,,free list} as a single linear list of @ref{15bf,,free blocks} (a @ref{15c0,,free block chain}). Sequential fit
mechanisms include @ref{37f,,first fit} and @ref{1681,,next fit}.

To quote @ref{157a,,Wilson et al. (1995)}:

@quotation

The list is often doubly-linked and/or circularly linked.
Typically, sequential fit algorithms use Knuth’s boundary
tag technique, and a doubly-linked list to make
@ref{38c,,coalescing} simple and fast. […] In
considering sequential fits, it is probably most important
to keep strategy and policy issues in mind. The classic
linear-list implementations may not scale well to large
@ref{47,,heaps}, in terms of time costs; as the
number of free blocks grows the time to search the list
may become unacceptable. More efficient and scalable
techniques are available, using totally or partially
ordered trees, or @ref{15f3,,segregated fits}.
@end quotation


@subsubheading See also


@ref{15ff,,bitmapped fit}, @ref{15f4,,indexed fit}.

@anchor{glossary/s term-sequential-store-buffer}@anchor{171f}
@geindex sequential store buffer

@item sequential store buffer

`SSB'.

A sequential store buffer is a technique for dividing the cost
of a @ref{214,,write barrier} by remembering which
@ref{1ab,,objects} are modified and updating @ref{213,,remembered sets} (and so on) at a later stage.

This turns out to be extremely efficient on pipelined
architectures with branch prediction.
@anchor{glossary/s term-shared-memory}@anchor{1720}
@geindex shared memory

@item shared memory

@ref{15b4,,Memory locations} are `shared' if
they are in the range of multiple @ref{54,,address spaces}.
@anchor{glossary/s term-simple-object}@anchor{1646}
@geindex simple object

@item simple object

In the @ref{1645,,PostScript} language, `simple objects' are the
@ref{48,,unboxed} objects.

Unlike a @ref{1644,,composite object}, a simple object contains
all its data in the object itself.

@ref{48,,unboxed}.

@ref{1644,,composite object}.
@anchor{glossary/s term-simple-segregated-storage}@anchor{171d}
@geindex simple segregated storage

@item simple segregated storage

A @ref{25c,,segregated free list} @ref{15d4,,allocation mechanism}
which divides @ref{15b0,,memory (1)} into @ref{92,,pages} or
other areas and only allocates @ref{1ab,,objects} of a
single size, or small range of sizes, within each area. This
makes allocation fast and avoids @ref{1d1,,headers}, but may lead to high @ref{383,,external fragmentation},
as unused parts of areas cannot be reused for other object
sizes.

@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/s term-size}@anchor{183}
@geindex size

@item size

The term `size' in the documentation always refers to a
size that is measured in @ref{17c,,bytes (1)}. The term
`count' is used for the number of elements in an array.
@anchor{glossary/s term-size-class}@anchor{263}
@geindex size class

@item size class

A @ref{1b2,,segregated allocation cache} maintains a reserve
of free @ref{185,,blocks} in a set of @ref{183,,sizes}: each
such size is known as a `size class'. When creating a
segregated allocation cache by calling
@ref{25e,,mps_sac_create()}, the @ref{d0,,client program}
describes the desired set of size classes by passing an
array of structures of type @ref{25d,,mps_sac_class_s}. See
@ref{25b,,Segregated allocation caches}.
@anchor{glossary/s term-skip-method}@anchor{81}
@geindex skip method

@item skip method

A @ref{69,,format method} that returns the address of the
“next object” in a block of @ref{23,,formatted objects}. See @ref{82,,mps_fmt_skip_t}.
@anchor{glossary/s term-smart-pointer}@anchor{1711}
@geindex smart pointer

@item smart pointer

A smart pointer is an instance of a @ref{1d,,C++} class that
encapsulates a @ref{15b8,,pointer} and performs @ref{15e0,,reference counting}.

By overloading certain operators it is possible for the class
to present the illusion of being a pointer, so that
@code{operator*}, @code{operator->}, etc. can be used as normal.
Reference counting allows the objects that are referred to
using the smart pointer class to have their @ref{15b0,,memory (1)}
automatically @ref{4a,,reclaimed} when they are no longer
@ref{24,,referenced}. It is a common technique used when trying
to solve @ref{15dd,,memory management} problems in C++
applications.

However, reference counting is not always an appropriate
memory management technique and smart pointers can be hard to
implement properly in C++. A @ref{15df,,tracing garbage collector} might be worth considering.

@ref{151c,,Edelson (1992a)}.
@anchor{glossary/s term-snap-out}@anchor{1721}
@geindex snap-out

@item snap-out

`transport snap-out'.

In a @ref{e3,,copying collector},
when there is a @ref{24,,reference} to an @ref{1ab,,object} that
was @ref{221,,condemned}, but has been
@ref{1722,,transported}, snap-out is the adjustment of that
reference to point to the preserved copy.

Typically the first transport leaves a @ref{87,,forwarding pointer} that enables the snap-out.


@float Figure

@image{MemoryPoolSystem-figures/snap-out,,,Diagram: Snap-out.,svg}

@caption{Snap-out.}

@end float



@subsubheading See also


@ref{1611,,broken heart}.

@anchor{glossary/s term-snapshot-at-the-beginning}@anchor{16ae}
@geindex snapshot at the beginning

@item snapshot at the beginning

Snapshot-at-the-beginning algorithms for @ref{4b,,tracing}, @ref{d,,incremental GC} note changes made by the @ref{30c,,mutator} to the
@ref{1635,,graph} of @ref{1ab,,objects} and update the
@ref{15ae,,collector (2)} state to make it trace relevant
@ref{1671,,edges} that the mutator deletes.

In order for the collector to miss a @ref{96,,reachable}
@ref{1ab,,object}, the following two conditions need to hold at
some point during tracing:


@enumerate 

@item 
The mutator stores a @ref{24,,reference} to a @ref{1607,,white}
object into a @ref{1604,,black} object.

@item 
All paths from any @ref{1606,,gray} objects to that white
object are destroyed.
@end enumerate

Snapshot-at-the-beginning algorithms ensure the second
condition cannot occur, by causing the collector to process
any reference that the mutator overwrites and that might be
part of such a path.

They are so called because they keep track of references that
existed at the beginning of the @ref{1a2,,collection cycle}. Note
that this does not mean all modifications need to be seen by
the collector, only those needed to complete tracing without
missing a reachable object (see @ref{1555,,Pirinen (1998)} for details), nor does it mean that it won’t
trace some references created during the collection.

This distinction between incremental update and
snapshot at the beginning was first introduced for
write-barrier algorithms, but it applies to any type of
tracing algorithm.

@ref{16ad,,incremental update}.


@subsubheading See also


@ref{60,,barrier (1)}, @ref{1605,,tri-color marking}, @ref{1723,,weak tri-color invariant}.


@ref{1579,,Wilson (1994)}, @ref{1555,,Pirinen (1998)}.
@anchor{glossary/s term-soft-reference}@anchor{1712}
@geindex soft reference

@item soft reference

In @ref{167f,,Java} terminology, `soft reference' is used to mean
a @ref{24,,reference} encapsulated in a @ref{16fb,,reference object}
of class @code{SoftReference}.

Soft references form one of three kinds of @ref{c,,weak reference (1)} in Java. They are handy for building
@ref{162a,,caches (3)} that are automatically
flushed when memory is low.


@subsubheading See also


@ref{16f8,,softly reachable}.


Class java.lang.ref.SoftReference@footnote{http://docs.oracle.com/javase/8/docs/api/java/lang/ref/SoftReference.html}, Reference Objects and Garbage Collection@footnote{http://pawlan.com/monica/articles/refobjs/}.
@anchor{glossary/s term-softly-reachable}@anchor{16f8}
@geindex softly reachable

@item softly reachable

In @ref{167f,,Java}, an object is `softly reachable' if it is not
@ref{16f7,,strongly reachable} and there is a path from the
@ref{97,,roots} to it that contains at least one
@ref{1712,,soft reference} but no @ref{1713,,weak (2)} or @ref{16fa,,phantom references}.

When the Java @ref{15d7,,collector (1)} determines that an object
is softly reachable, it has the option of clearing the soft
references involved, which will usually allow the object to be
@ref{15de,,recycled}. The idea is that they will only be cleared
if the process is running short of @ref{194,,memory (2)}. If it
is done, all soft references involved are cleared, so that the
object is no longer softly reachable, and any affected
@ref{16fb,,reference objects} which are registered with a queue
are enqueued.


@subsubheading See also


@ref{16f5,,phantom reachable}, @ref{96,,reachability}, @ref{16f9,,weakly reachable}.


Class java.lang.ref.SoftReference@footnote{http://docs.oracle.com/javase/8/docs/api/java/lang/ref/SoftReference.html}, Reference Objects and Garbage Collection@footnote{http://pawlan.com/monica/articles/refobjs/}.
@anchor{glossary/s term-space-leak}@anchor{1724}
@geindex space leak

@item space leak

@ref{234,,memory leak}.
@anchor{glossary/s term-spare-commit-limit}@anchor{197}
@geindex spare commit limit

@item spare commit limit

The spare commit limit is a limit on the @ref{18f,,spare committed memory} that the MPS will obtain from the
operating system. It can be retrieved by calling
@ref{189,,mps_arena_spare()} and changed by
calling @ref{198,,mps_arena_spare_set()}.
@anchor{glossary/s term-spare-committed-memory}@anchor{18f}
@geindex spare committed memory

@item spare committed memory

Memory which is not in use by any @ref{18,,pool} and not
otherwise in use for internal MPS data structures, but
which remains @ref{190,,committed} (mapped to
@ref{55,,RAM} by the operating system). It is used by the
@ref{16,,arena} to (attempt to) avoid calling the operating
system to repeatedly map and unmap areas of @ref{51,,virtual memory} as the amount of memory in use goes up and down.
It is subject to the @ref{197,,spare commit limit}. The total
spare committed memory can be retrieved by calling
@ref{191,,mps_arena_spare_committed()}.
@anchor{glossary/s term-spaghetti-stack}@anchor{1725}
@geindex spaghetti stack

@item spaghetti stack

@ref{162c,,cactus stack}.
@anchor{glossary/s term-splat}@anchor{245}
@geindex splat

@item splat

To overwrite a @ref{c,,weak reference (1)} with a null
pointer, when the MPS has determined that there are no
remaining @ref{244,,strong references} to the block referred
to. See @ref{102,,Weak references}.
@anchor{glossary/s term-split}@anchor{1614}
@geindex split

@item split

To divide a @ref{15bf,,free block} into two smaller free blocks in
the process of satisfying an allocation request.

Deciding when to split a block is an important aspect of an
@ref{380,,allocation policy}.

@ref{38c,,coalesce}.


@subsubheading See also


@ref{380,,allocation policy}, @ref{38c,,coalesce}, @ref{15bf,,free block}.

@anchor{glossary/s term-SRAM}@anchor{1726}
@geindex SRAM

@item SRAM

@ref{1623,,static memory (1)}.
@anchor{glossary/s term-SSB}@anchor{1727}
@geindex SSB

@item SSB

@ref{171f,,sequential store buffer}.
@anchor{glossary/s term-stack}@anchor{15bc}
@geindex stack

@item stack

A stack is a LIFO (last in, first out) collection:
@ref{1ab,,objects} may be `pushed' onto the stack, and
`popped' off it in reverse order of pushing.

When people say “the stack”, they usually mean the
@ref{27,,control stack} supported by the OS and/or the
processor.

@ref{15e2,,Stack allocation} is an important technique.
Control stacks are central to the performance of the
system and often require special handling.

The terms “stack”, “push”, and “pop” are taken from the
spring-loaded dish stack found in cafeterias and salad
bars where removing the top plate causes the others to
rise up, exposing the next one, and adding a plate causes
the spring to compress, leaving only that plate
accessible.

So originally, the latest item was the “top”, “down the stack”
meant towards earlier items, and “up” towards later ones, but
today many use “up” and “down” in the opposite sense.

@ref{27,,control stack}.


@subsubheading See also


@ref{162c,,cactus stack}, @ref{1654,,data stack}.

@anchor{glossary/s term-stack-allocation}@anchor{15e2}
@geindex stack allocation

@item stack allocation

`Stack allocation' means run-time @ref{15ca,,allocation} and @ref{15d2,,deallocation} of
@ref{15b0,,memory (1)} in last-in/first-out order.

Typically, stack allocation is performed on top of the main
@ref{15bc,,stack}, but one can have a separate @ref{1654,,data stack}
for this purpose as well, as in Forth, or even multiple ones,
as in the @ref{1645,,PostScript} language.

Allocation and deallocation are typically fast, since they can
be done simply by adding or subtracting the size of the
@ref{185,,block} from the stack pointer.

Using only stack allocation, without heap allocation, is
somewhat restrictive, as only objects whose size is known at
compile-time can be returned from a procedure.

Some programming languages (such as some versions of
@ref{28a,,Lisp} and @ref{1c,,C}) provide program-controlled stack
@ref{15ca,,allocation} and @ref{15d2,,deallocation} of dynamic extent objects for efficiency, despite its
being unsafe.

@ref{15d0,,automatic storage duration}.

@ref{1653,,heap allocation}, @ref{1610,,static allocation}.


@subsubheading See also


@ref{24a,,dynamic extent}, @ref{15e1,,region inference}.

@anchor{glossary/s term-stack-frame}@anchor{15b1}
@geindex stack frame

@item stack frame

`stack record'.

A stack frame or record is an @ref{15ac,,activation record} that
is stored on the @ref{15bc,,stack}.

In a register-based architecture, where the current activation
record may be partially stored in registers, there may be
hardware instructions that facilitate storing registers on the
stack when another activation record is made current. Such
instructions may prescribe a particular layout for activation
records.

Hardware support for saving and restoring registers, for
stacks and for stack addressing may limit or otherwise
prescribe the size and type of data that can be stored in
a stack frame. Knowledge of the layout of each stack frame
may assist a @ref{20,,garbage collector} in finding
@ref{97,,roots}.

@ref{15ac,,activation record}.


@subsubheading See also


@ref{15bc,,stack}.

@anchor{glossary/s term-stack-record}@anchor{1728}
@geindex stack record

@item stack record

@ref{15b1,,stack frame}.
@anchor{glossary/s term-static-allocation}@anchor{1610}
@geindex static allocation

@item static allocation

`Static allocation' means @ref{15ca,,allocation} of
@ref{15b0,,memory (1)} before the program starts and retention
until the end.

The locations of @ref{1ab,,objects} are basically
decided at compile-time, although they might be
@ref{160e,,relocated} at load-time. This implies the
sizes of the objects must be known then.

Using only static allocation is restrictive, as sizes of data
structures can’t be dynamically varied, and procedures cannot
be recursive. However, it is also fast and eliminates the
possibility of running out of memory. For this reason, this
scheme is sometimes used in real-time systems.

@ref{15e3,,static storage duration}.

@ref{1653,,heap allocation}, @ref{15e2,,stack allocation}.


@subsubheading See also


@ref{15e1,,region inference}, @ref{1729,,static memory (2)}.

@anchor{glossary/s term-static-memory-1}@anchor{1623}
@geindex static memory (1)

@item static memory@w{^(1)}

`SRAM', `static RAM'.

Static @ref{194,,memory (2)} or static RAM (SRAM) is a type of
@ref{15b6,,physical memory (2)} that does not need to be refreshed
periodically to avoid losing state.

Static memory is typically faster than @ref{166a,,dynamic memory},
or requires essentially no power to preserve its state, but
rarely both. These benefits result in static RAM being used
for @ref{1622,,cache (1)} memory, and also in portable, low-power
applications (such as PDAs). It is, however, more expensive
than dynamic RAM and requires more transistors, making dynamic
RAM the choice for large amounts of memory (the @ref{311,,main memory} of desktop machines, for example).

@ref{166a,,dynamic memory}.
@anchor{glossary/s term-static-memory-2}@anchor{1729}
@geindex static memory (2)

@item static memory@w{^(2)}

The @ref{194,,memory (2)} where @ref{1610,,statically allocated} objects are stored is sometimes known as
`static memory'. In the context of @ref{f,,garbage collection},
the term is used mean memory used to store @ref{172a,,static objects}.


@subsubheading See also


@ref{15e3,,static storage duration}.

@anchor{glossary/s term-static-object}@anchor{172a}
@geindex static object

@item static object

A static @ref{1ab,,object} is non-@ref{5d,,moving}. That is, it is not @ref{160e,,relocated}
by a @ref{15cd,,memory manager}; its @ref{126,,address} does not
change.
@anchor{glossary/s term-static-RAM}@anchor{170b}
@geindex static RAM

@item static RAM

@ref{1623,,static memory (1)}.
@anchor{glossary/s term-static-storage-duration}@anchor{15e3}
@geindex static storage duration

@item static storage duration

In @ref{1c,,C} and @ref{1d,,C++}, the @code{static} keyword applied
to a file scope variable or function means it is local to the
file; the @code{static} keyword applied to a function or a block
scope variable means it is @ref{15ca,,allocated} and initialized
once only.

Objects declared locally in blocks with the @code{static} keyword
are @ref{15ca,,allocated} in @ref{1729,,static memory (2)}, and
initialized once (usually by the compiler/linker) instead of
each time the block is entered.

Static variables within functions retain their value between
function invocations, and therefore must form part of the
@ref{1716,,root set} of any @ref{15d7,,collector (1)}.

@ref{15d0,,automatic storage duration}.


@subsubheading See also


@ref{b5,,lifetime}.

@anchor{glossary/s term-stepper-function}@anchor{21d}
@geindex stepper function

@item stepper function

`visitor function'.

A function that will be called on each element in a
collection. For example, a stepper function of type
@ref{21c,,mps_roots_stepper_t} can be passed to
@ref{19e,,mps_arena_roots_walk()} and it will be called on
all @ref{97,,roots} in an @ref{16,,arena}.
@anchor{glossary/s term-sticky-reference-count}@anchor{172b}
@geindex sticky reference count

@item sticky reference count

@ref{16c5,,limited-field reference count}.
@anchor{glossary/s term-stop-and-copy-collection}@anchor{16ac}
@geindex stop-and-copy collection

@item stop-and-copy collection

@ref{e3,,Copying garbage collection} that stops the
@ref{30c,,mutator} while the collector runs.


@float Figure

@image{MemoryPoolSystem-figures/two-space,,,Diagram: Two-space collector.,svg}

@caption{Stop-and-copy in a @ref{1634,,two-space collector}.}

@end float


@ref{d,,incremental garbage collection}, @ref{15ed,,parallel garbage collection}.
@anchor{glossary/s term-storage}@anchor{172c}
@geindex storage

@item storage

@ref{15b0,,memory (1)}.
@anchor{glossary/s term-storage-hierarchy}@anchor{1628}
@geindex storage hierarchy

@item storage hierarchy

`memory hierarchy'.

A typical computer has several different `levels' of
@ref{15b0,,storage}. Each level of storage has a
different speed, cost, and size. The levels form a `storage
hierarchy', in which the topmost levels (those nearest the
processor) are fastest, most expensive and smallest.

Levels typically include processor @ref{26,,registers}, possibly some levels of @ref{1622,,cache (1)},
@ref{311,,main memory}, and possibly some levels of
@ref{15d1,,backing store}.

Each level is commonly used as a @ref{1627,,cache (2)} for the
next level. For instance, @ref{51,,virtual memory} systems
use main memory as a cache for backing store.


@float Figure

@image{MemoryPoolSystem-figures/storage,,,Diagram: Storage hierarchy with (typical) relative cost@comma{} speed@comma{} and size.,svg}

@caption{Storage hierarchy with (typical) relative cost, speed, and
size.}

@end float

@anchor{glossary/s term-storage-level}@anchor{1626}
@geindex storage level

@item storage level

One level in a @ref{1628,,storage hierarchy}, for instance a
@ref{1622,,cache (1)}, @ref{311,,main memory}, @ref{15d1,,backing store},
and so on.


@subsubheading See also


@ref{1628,,storage hierarchy}.

@anchor{glossary/s term-storage-management}@anchor{172d}
@geindex storage management

@item storage management

@ref{15dd,,memory management}.
@anchor{glossary/s term-store-1}@anchor{15eb}
@geindex store (1)

@item store@w{^(1)}

To transfer data from a processor’s @ref{26,,registers} to @ref{194,,memory (2)}.

Store can also be used in the more general sense of
transferring data from a part of the @ref{16c8,,memory hierarchy}
that is fast to access to one that is slow to access.

@code{STORE} (or an abbreviation) is also commonly used in many
processor architectures as the mnemonic for the machine code
instructions that store data into memory.

@ref{15ea,,load}.
@anchor{glossary/s term-store-2}@anchor{15e6}
@geindex store (2)

@item store@w{^(2)}

@ref{15b0,,memory (1)}.
@anchor{glossary/s term-stretchy-vector}@anchor{172e}
@geindex stretchy vector

@item stretchy vector

A @ref{15c7,,vector} that may grow or shrink to
accommodate adding or removing elements. Named after the
@code{<stretchy-vector>} abstract class in Dylan.

In the presence of an @ref{a1,,asynchronous garbage collector}, the vector and its size may need to be updated
atomically.

Dylan Reference Manual: Collections@footnote{http://opendylan.org/books/drm/Collection_Classes}.

See @ref{be,,The stretchy vector problem}.
@anchor{glossary/s term-strict-segregated-fit}@anchor{1613}
@geindex strict segregated fit

@item strict segregated fit

A @ref{15f3,,segregated fit} @ref{15d4,,allocation mechanism} which
has only one block size on each @ref{268,,free list}. A requested
block size is rounded up to the next provided size, and the
first block on that list is returned. The sizes must be chosen
so that any block of a larger size can be @ref{1614,,split} into a
number of smaller sized blocks. @ref{15f9,,Buddy systems} are a special case of strict segregated fit
allocators.


@subsubheading See also


@ref{15d4,,allocation mechanism}, @ref{15f9,,buddy system}, @ref{15f3,,segregated fit}, @ref{25c,,segregated free list}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/s term-strong-reference}@anchor{244}
@geindex strong reference

@item strong reference

In a @ref{15df,,tracing garbage collector}, a strong reference is a @ref{24,,reference} that
keeps the @ref{1ab,,object} it refers to @ref{78,,alive}.

A strong reference is the usual sort of reference: the term is
usually used to draw a contrast with @ref{c,,weak reference (1)}.

@ref{c,,weak reference (1)}.


@subsubheading See also


@ref{1717,,strong root}.

@anchor{glossary/s term-strong-root}@anchor{1717}
@geindex strong root

@item strong root

A strong root is a @ref{97,,root} such that all
@ref{24,,references} in it are @ref{244,,strong references}.

A strong root is the usual sort of root: the term is usually
used to draw a contrast with @ref{20d,,weak root}.

@ref{20d,,weak root}.

Strong roots have @ref{9e,,rank} @ref{20a,,mps_rank_ambig()} or
@ref{9d,,mps_rank_exact()}.
@anchor{glossary/s term-strong-tri-color-invariant}@anchor{16af}
@geindex strong tri-color invariant

@item strong tri-color invariant@anchor{glossary/s term-strong-tri-colour-invariant}@anchor{172f}
@geindex strong tri-colour invariant

@itemx strong tri-colour invariant@anchor{glossary/s term-strong-tricolor-invariant}@anchor{1730}
@geindex strong tricolor invariant

@itemx strong tricolor invariant@anchor{glossary/s term-strong-tricolour-invariant}@anchor{1731}
@geindex strong tricolour invariant

@itemx strong tricolour invariant

The strong @ref{1732,,tri-color invariant} is the property of a
@ref{24,,reference} @ref{1635,,graph} that there is no @ref{1671,,edge}
from a @ref{1604,,black} @ref{163e,,node} to a @ref{1607,,white} node.

By preserving this property throughout @ref{1605,,tri-color marking}, a @ref{4b,,tracing} algorithm can ensure that
the @ref{15ae,,collector (2)} will not miss reachable objects,
even if the @ref{30c,,mutator} manipulates the graph during the
collection. This invariant can also be used to ensure that a
@ref{e3,,copying garbage collector}
doesn’t confuse the mutator. Mutator actions might need to
change the @ref{163c,,color} of the nodes affected in order to
preserve the invariant.

Algorithms using this invariant are @ref{16ad,,incremental update}
algorithms.

@ref{1732,,tri-color invariant}.


@subsubheading See also


@ref{60,,barrier (1)}, @ref{1723,,weak tri-color invariant}.


@ref{381,,Johnstone (1997)}, @ref{1555,,Pirinen (1998)}.
@anchor{glossary/s term-strongly-reachable}@anchor{16f7}
@geindex strongly reachable

@item strongly reachable

In @ref{167f,,Java}, an object is `strongly reachable', if there
is a path from the @ref{97,,roots} to it that contains
only @ref{244,,strong references}, that is,
contains no @ref{16fb,,reference objects}.


@subsubheading See also


@ref{16f5,,phantom reachable}, @ref{96,,reachability}, @ref{16f8,,softly reachable}, @ref{16f9,,weakly reachable}.


Reference Objects and Garbage Collection@footnote{http://pawlan.com/monica/articles/refobjs/}.
@anchor{glossary/s term-suballocator}@anchor{16b2}
@geindex suballocator

@item suballocator

A `suballocator' is an @ref{15ce,,allocator} functioning on top of
another allocator.

Suballocators work by @ref{15ca,,allocating} large
@ref{185,,blocks} and @ref{1614,,splitting} them for
use, or by @ref{15de,,recycling} blocks locally.

Application programmers sometimes write their own
suballocators when faced with an inefficient or inadequate
@ref{15cd,,memory manager}. Suballocators can take advantage of
special knowledge of program behavior, but are less efficient
in general than fixing the underlying allocator, mainly
because @ref{15dd,,memory management} is a `global' issue for an
application, and a global strategy can make a big difference.
For example, different suballocators can interact
catastrophically with each other and with the @ref{51,,virtual memory} system, causing the application’s memory
requirements to grow unnecessarily due to
@ref{17e,,fragmentation}.
@anchor{glossary/s term-subgraph}@anchor{1733}
@geindex subgraph

@item subgraph

A subgraph S of a @ref{1635,,graph} G is a graph such that all the
@ref{163e,,nodes} in S are also in G and all the
@ref{1671,,edges} in S are also in G; that is, it is a part
of a graph.
@anchor{glossary/s term-superpage}@anchor{1734}
@geindex superpage

@item superpage

@ref{16a1,,huge page}.
@anchor{glossary/s term-sure-reference}@anchor{1735}
@geindex sure reference

@item sure reference

@ref{61,,exact reference}.
@anchor{glossary/s term-swap-space}@anchor{15e9}
@geindex swap space

@item swap space

@ref{15d1,,Backing store} used by a @ref{15e8,,swapping} system.


@subsubheading See also


@ref{15d1,,backing store}, @ref{15e8,,swapping}.

@anchor{glossary/s term-swapped-in}@anchor{16f3}
@geindex swapped in

@item swapped in

A process or @ref{92,,page} is `swapped in' if it is available
in @ref{16b8,,physical memory (1)}. This usually applies to the
entire program image.

@ref{195,,paged in}.

@ref{169b,,swapped out}.


@subsubheading See also


@ref{15e8,,swapping}.

@anchor{glossary/s term-swapped-out}@anchor{169b}
@geindex swapped out

@item swapped out

A process or @ref{92,,page} is `swapped out' if it is not
available in @ref{16b8,,physical memory (1)}. This usually applies
to the entire program image.

@ref{16d1,,paged out}.

@ref{16f3,,swapped in}.


@subsubheading See also


@ref{15e8,,swapping}.

@anchor{glossary/s term-swapping}@anchor{15e8}
@geindex swapping

@item swapping

Historically, swapping was the technique of moving entire
program images to disk (or drum) and back into @ref{16b8,,physical memory (1)}, an early form of @ref{51,,virtual memory}.
Nowadays, it is used as a synonym for @ref{15e7,,paging}.

@ref{15e7,,paging}.


@subsubheading See also


@ref{16f3,,swapped in}, @ref{169b,,swapped out}.

@anchor{glossary/s term-sweeping}@anchor{16d4}
@geindex sweeping

@item sweeping

Sweeping is the second phase (“the sweep phase”) of the
@ref{15fd,,mark-sweep} algorithm. It performs a sequential
(address-order) pass over memory to @ref{15de,,recycle} unmarked
blocks.

Sweeping typically gathers all unmarked blocks into one or
more @ref{268,,free lists}.


@subsubheading See also


@ref{1600,,marking}.

@anchor{glossary/s term-synchronous-garbage-collector}@anchor{c1}
@geindex synchronous garbage collector

@item synchronous garbage collector

A @ref{15ae,,collector (2)} is asynchronous with respect to the
@ref{30c,,mutator} if it runs at predictable times, for example
only when a collection function is called.

This means that mutator need not ensure that @ref{23,,formatted objects} are always @ref{65,,scannable}, as long as it
makes them scannable before the collector runs.

@ref{a1,,asynchronous garbage collector}.
@end table

@node Memory Management Glossary T,Memory Management Glossary U,Memory Management Glossary S,Memory Management Glossary
@anchor{glossary/t doc}@anchor{1736}@anchor{glossary/t glossary-t}@anchor{15a2}@anchor{glossary/t memory-management-glossary-t}@anchor{1737}
@section Memory Management Glossary: T


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/t term-tabling}@anchor{1738}
@geindex tabling

@item tabling

@ref{162a,,caching (3)}.
@anchor{glossary/t term-tag}@anchor{88}
@geindex tag

@item tag

A tag is a piece of information associated with an
@ref{1ab,,object} or @ref{24,,reference} that allows the
representation of the object to be determined.

Tags are often used to represent types in the implementation
of a dynamically-typed language. In statically-typed
languages, types are usually implicit and not permitted to
change at run-time, so tagging is rarely required.

One of the simplest forms of tag is a @ref{37c,,word} at the
beginning of the object that points to a block of information
about the object’s @ref{164e,,format}.


@float Figure

@image{MemoryPoolSystem-figures/tag-word,,,Diagram: Example of a tag-word at the start of an object.,svg}

@caption{Example of a tag-word at the start of an object.}

@end float


Another common form of tagging is to @ref{68,,align}
objects and keep information in the least significant bits of
the reference.


@float Figure

@image{MemoryPoolSystem-figures/tag-ref,,,Diagram: Example of reference tagging@comma{} using the least significant bits.,svg}

@caption{Example of reference tagging, with objects aligned to
addresses that are multiples of four, and the tag stored
in the least significant two bits of the reference.}

@end float


In @ref{1c,,C}, when a structure contains a union, it is common
to add a field to the structure to indicate which union member
is currently being used. This field is known as a
`discriminator', and is a form of tag. Analogues occur in
other languages, sometimes with compiler or run-time support.


@subsubheading See also


@ref{1d1,,in-band header}, @ref{1658,,tagged architecture}.


@ref{1527,,Gudeman (1993)}.

See @ref{7e,,Tagged references}.
@anchor{glossary/t term-tagged-architecture}@anchor{1658}
@geindex tagged architecture

@item tagged architecture

A tagged architecture is a hardware architecture where each
memory @ref{37c,,word} is divided into a “data” and a @ref{88,,tag}
section. The data section is sufficiently large to contain a
memory @ref{126,,address} and the tag section is used to describe
how the data section is to be interpreted (that is, it encodes
the type of the data).

Tagged architectures greatly simplify the implementation
of a memory manager because each word of memory is
self-describing.

The @ref{16bb,,Lisp Machine} was an example of a tagged
architecture.
@anchor{glossary/t term-tagged-reference}@anchor{7d}
@geindex tagged reference

@item tagged reference

A @ref{24,,reference} containing a @ref{88,,tag} in part of its
address, for example by @ref{68,,aligning} objects
and keeping the tag in the least significant bits of the
address.

See @ref{7e,,Tagged references}.
@anchor{glossary/t term-TB-1}@anchor{1739}
@geindex TB (1)

@item TB@w{^(1)}

@ref{161a,,terabyte}.
@anchor{glossary/t term-TB-2}@anchor{173a}
@geindex TB (2)

@item TB@w{^(2)}

@ref{15be,,translation lookaside buffer}.
@anchor{glossary/t term-telemetry-filter}@anchor{295}
@geindex telemetry filter

@item telemetry filter

A @ref{298,,bitmap} indicating which events the MPS should
include in the @ref{ba,,telemetry stream}. It can be read by
calling @ref{2b3,,mps_telemetry_get()} or changed by calling
@ref{176,,mps_telemetry_set()} or @ref{2b4,,mps_telemetry_reset()}.
@anchor{glossary/t term-telemetry-label}@anchor{12e}
@geindex telemetry label

@item telemetry label

An identifier representing a string, returned from
@ref{296,,mps_telemetry_intern()}, that can be associated
with certain @ref{126,,addresses}, and so appear in
the @ref{ba,,telemetry stream} attached to events concerning
those addresses. See @ref{db,,Telemetry}.
@anchor{glossary/t term-telemetry-stream}@anchor{ba}
@geindex telemetry stream

@item telemetry stream

A sequence of events reported by the MPS to assist with
debugging and profiling. The events that appear in the
stream can be configured by setting the @ref{295,,telemetry filter}. See @ref{db,,Telemetry}.
@anchor{glossary/t term-telemetry-system}@anchor{15b}
@geindex telemetry system

@item telemetry system

The subsystem of the MPS that outputs the @ref{ba,,telemetry stream}. See @ref{db,,Telemetry}.
@anchor{glossary/t term-tenuring}@anchor{173b}
@geindex tenuring

@item tenuring

@ref{223,,promotion}.
@anchor{glossary/t term-terabyte}@anchor{161a}
@geindex terabyte

@item terabyte

`TB'.

A terabyte is 1024 @ref{1619,,gigabytes}, or
1099511627776 @ref{17c,,bytes (1)}.

See @ref{17c,,byte (1)} for general information on this and
related quantities.
@anchor{glossary/t term-termination}@anchor{173c}
@geindex termination

@item termination

@ref{b,,finalization}.
@anchor{glossary/t term-thrash}@anchor{16de}
@geindex thrash

@item thrash

A @ref{1627,,cache (2)} is said to @ref{16de,,thrash} when its
@ref{16a0,,miss rate} is too high, and it spends most of its time
servicing @ref{169e,,misses}. Thrashing is bad for
performance, particularly @ref{51,,virtual memory}
thrashing, because the relative cost of a miss is so high: it
may slow a machine down by a factor of a hundred or more.

Thrashing is typically caused by a process or system having a
@ref{16ba,,working set} which is larger than its @ref{1622,,cache (1)}
or @ref{311,,main memory}. It may also be caused by a failure of
@ref{1625,,cache policy}. A system with an inflexible cache policy
may thrash even when the working set is quite small.

For instance, a virtual memory system which has four megabytes
of @ref{16b8,,physical memory (1)} but which has a working set of
ten megabytes will @ref{16de,,thrash} badly.

@ref{150f,,Denning (1968)}, @ref{1510,,Denning (1970)}, @ref{1511,,Denning & Schwartz (1972)}.
@anchor{glossary/t term-thread}@anchor{99}
@geindex thread

@item thread

A thread of execution is a sequence of instructions that take
place sequentially. In a multi-threaded program, multiple
threads of execution operate in parallel, and are generally
asynchronous with respect to each other.

Access to shared resources such as memory management
interface must be thread-safe. Each thread has its own
@ref{27,,control stack} which may contain @ref{24,,references}
to blocks on the heap.

Threads are represented by values of type
@ref{201,,mps_thr_t}, created by calling
@ref{a8,,mps_thread_reg()}. In order for the MPS to find
references on the control stack of the thread, the thread
must be also be registered as a @ref{97,,root} by calling
@ref{a9,,mps_root_create_thread()}. See @ref{29,,Threads}.
@anchor{glossary/t term-threatened-set}@anchor{173d}
@geindex threatened set

@item threatened set

@ref{221,,condemned set}.
@anchor{glossary/t term-TLB}@anchor{173e}
@geindex TLB

@item TLB

@ref{15be,,translation lookaside buffer}.
@anchor{glossary/t term-to-space}@anchor{173f}
@geindex to space

@item to space@anchor{glossary/t term-tospace}@anchor{1633}
@geindex tospace

@itemx tospace

`new space', `newspace'.

In @ref{e3,,copying garbage collection}, the space to which
@ref{78,,live} object are copied.

@ref{1682,,fromspace}.
@anchor{glossary/t term-trace}@anchor{4b}
@geindex trace

@item trace

In @ref{15df,,tracing garbage collection}, tracing is the process
of following the @ref{1635,,graph} from all @ref{97,,roots}
to all @ref{96,,reachable} data.

@ref{65,,scan}.
@anchor{glossary/t term-tracing-garbage-collection}@anchor{15df}
@geindex tracing garbage collection

@item tracing garbage collection

Tracing garbage collection is @ref{f,,garbage collection} based
on @ref{96,,reachability}.

Tracing garbage collection relies on the fact that if an
@ref{1ab,,object} is not @ref{96,,reachable}, there is no way the
@ref{30c,,mutator} could ever access it, and therefore it cannot
be @ref{78,,live}. In each @ref{1a2,,collection cycle}, some or all
of the objects are @ref{221,,condemned} and the
@ref{1635,,graph} is @ref{4b,,traced} to find which of the condemned
objects are reachable. Those that were not reachable may be
@ref{4a,,reclaimed}.
@anchor{glossary/t term-transform}@anchor{2c3}
@geindex transform

@item transform

A mapping from old @ref{24,,references} to new references,
represented by @ref{2c2,,mps_transform_t}, that can be applied
to all references managed by the MPS. See
@ref{2be,,Transforms}.
@anchor{glossary/t term-translation-buffer}@anchor{1740}
@geindex translation buffer

@item translation buffer@anchor{glossary/t term-translation-lookaside-buffer}@anchor{15be}
@geindex translation lookaside buffer

@itemx translation lookaside buffer

`address translation cache', `ATC', `TB'.

The `translation lookaside buffer' or `address translation
cache' is small piece of associative @ref{15b0,,memory (1)} within
a processor which caches part of the translation from
@ref{16b9,,virtual addresses} to @ref{15aa,,physical addresses}.

In a @ref{51,,virtual memory} system there is a translation from
@ref{16b9,,virtual addresses} to @ref{15aa,,physical addresses}. This
translation can often be very large and complex and the data
structures that implement the translation (often a @ref{16a2,,page table}) can be too large to store efficiently on the
processor. Instead, a few elements of the translation are
stored in the TLB; the processor can access the TLB extremely
quickly. If a required translation for a particular virtual
address is not present in the TLB then `a TLB miss' is taken
and the address is resolved using the more general mechanism.
@anchor{glossary/t term-transparent-alias}@anchor{1741}
@geindex transparent alias

@item transparent alias@anchor{glossary/t term-transparent-type}@anchor{127}
@geindex transparent type

@itemx transparent type

In the MPS interface, a `transparent type' is an alias
defined using @code{typedef}, and this is documented so that
the @ref{d0,,client program} can rely on that fact. For
example, @ref{11d,,mps_addr_t} is a transparent alias for
@code{void *}. See @ref{112,,Interface conventions}.

@ref{16ec,,opaque type}.
@anchor{glossary/t term-transport}@anchor{1722}
@geindex transport

@item transport

In a @ref{e3,,copying collector},
transporting is preventing an @ref{1ab,,object} in the
@ref{221,,condemned set} from being collected by copying it and
adjusting the @ref{24,,reference} by which it was discovered to
point to the new copy.


@subsubheading See also


@ref{e3,,scavenging}, @ref{1721,,snap-out}.

@anchor{glossary/t term-transport-snap-out}@anchor{1742}
@geindex transport snap-out

@item transport snap-out

@ref{1721,,snap-out}.
@anchor{glossary/t term-treadmill}@anchor{163f}
@geindex treadmill

@item treadmill

Henry Baker devised an @ref{d,,incremental} non-@ref{5d,,moving}
@ref{20,,garbage collector} that uses a circular doubly-linked
list, called the `treadmill', to implement @ref{1605,,tri-color marking}.

Every @ref{1ab,,object} is on the list. The list has four
sections corresponding to @ref{163c,,colors}. The
@ref{1604,,black}, @ref{1606,,gray} and @ref{1607,,white} sections are
used for tri-color marking, and an additional
@ref{1640,,off-white} section is used for @ref{15d6,,free (3)}
objects. The color of an object is changed by unlinking it
from the list and relinking it to a different part of the
list.


@float Figure

@image{MemoryPoolSystem-figures/treadmill,,,Diagram: A treadmill.,svg}

@caption{A treadmill. (Based on @ref{1538,,Jones (2012)}.)}

@end float


@ref{14e5,,Baker (1992c)}.
@anchor{glossary/t term-tri-color-invariant}@anchor{1732}
@geindex tri-color invariant

@item tri-color invariant@anchor{glossary/t term-tri-colour-invariant}@anchor{1743}
@geindex tri-colour invariant

@itemx tri-colour invariant@anchor{glossary/t term-tricolor-invariant}@anchor{1744}
@geindex tricolor invariant

@itemx tricolor invariant@anchor{glossary/t term-tricolour-invariant}@anchor{1745}
@geindex tricolour invariant

@itemx tricolour invariant

The term “tri-color invariant” is used to refer to any of a
number of properties of a @ref{24,,reference} @ref{1635,,graph} that
are preserved throughout a @ref{1605,,tri-color marking} algorithm
to ensure the correctness.

There are two important ones: the @ref{16af,,strong tri-color invariant} and the @ref{1723,,weak tri-color invariant}. When
people say “the tri-color invariant” they probably mean the
strong one.

@ref{381,,Johnstone (1997)}, @ref{1555,,Pirinen (1998)}.
@anchor{glossary/t term-tri-color-marking}@anchor{1605}
@geindex tri-color marking

@item tri-color marking@anchor{glossary/t term-tri-colour-marking}@anchor{1746}
@geindex tri-colour marking

@itemx tri-colour marking@anchor{glossary/t term-tricolor-marking}@anchor{1747}
@geindex tricolor marking

@itemx tricolor marking@anchor{glossary/t term-tricolour-marking}@anchor{1748}
@geindex tricolour marking

@itemx tricolour marking

Tri-color marking is a @ref{15df,,tracing garbage collection}
algorithm that assigns a @ref{163c,,color} (@ref{1604,,black},
@ref{1607,,white}, or @ref{1606,,gray}) to each @ref{163e,,node} in the
@ref{1635,,graph}. It is basic to @ref{d,,incremental garbage collection}.

Initially all nodes are colored white. The distinguished
@ref{1716,,root set} is colored gray. The @ref{15ae,,collector (2)}
proceeds to discover the @ref{96,,reachable} nodes by finding an
@ref{1671,,edge} from a gray node to a white node and coloring the
white node gray. Hence each tracing step involves choosing a
gray node and graying its white children.

When all the edges from a gray node lead only to other gray
(or black) nodes, the node is colored black. When no gray
nodes remain, the reachable part of the graph has been
discovered and any nodes that are still white may be
@ref{15de,,recycled}.

The @ref{30c,,mutator} is free to access any part of the graph
and allocate new nodes while the @ref{15ae,,collector (2)} is
determining the reachable nodes, provided the @ref{1732,,tri-color invariant} is maintained, by changing the colors of the nodes
affected, if necessary.

“Tri-color marking” is the term used to describe an
algorithm developed in 1975 by E. W. Dijkstra and others,
as an exercise in proving cooperating programs correct.
They chose as their problem a @ref{15ed,,parallel garbage collector}, with the intent
of illustrating cooperating sequential processes with a
large shared data space but minimal exclusion and
synchronization constraints.

Although the algorithm developed in the paper is not
necessarily the most efficient algorithm for a
@ref{15d7,,collector (1)}, it has been generally accepted to be
correct: an important feature that not all garbage collectors
can claim. A number of other garbage collection algorithms
have been shown to be isomorphic to the tri-color marking
algorithm and thus are also believed to be correct.


@subsubheading See also


@ref{60,,barrier (1)}.


@ref{1515,,Dijkstra et al. (1976)}.
@anchor{glossary/t term-two-space-collector}@anchor{1634}
@geindex two-space collector

@item two-space collector@anchor{glossary/t term-0}@anchor{1749}
@geindex two space collector

@itemx two space collector

`semi-space collector'.

A two-space @ref{15d7,,collector (1)} is a simple form of a
@ref{e3,,copying garbage collector}. The available @ref{194,,memory (2)} is divided into
two halves, called @ref{1612,,semi-spaces}. @ref{1ab,,Objects} are
allocated in one semi-space until it is full. The
@ref{96,,reachable} objects are then copied into the other
semi-space (usually using a @ref{1636,,Cheney scan}) and the old
semi-space is @ref{4a,,reclaimed}. @ref{15ca,,Allocation}
continues in the new semi-space until it is full, at which
point the process is repeated in reverse.

The main disadvantage of a two-space collector is that it only
makes use of half of the available memory. This can be
tolerable in a @ref{51,,virtual memory} system if the
@ref{20,,garbage collector} is written carefully to preserve
@ref{1601,,locality of reference}. Other forms of copying garbage
collector, such as @ref{e,,generational garbage collectors}, have much lower overheads.


@float Figure

@image{MemoryPoolSystem-figures/two-space,,,Diagram: Two-space collector.,svg}

@caption{Two-space collector.}

@end float



@subsubheading See also


@ref{18c,,flip}.

@anchor{glossary/t term-type-accurate-garbage-collection}@anchor{174a}
@geindex type-accurate garbage collection

@item type-accurate garbage collection

@ref{164f,,exact garbage collection}.
@anchor{glossary/t term-type-punning}@anchor{a5}
@geindex type punning

@item type punning

Interpreting a value of one type as if it were a value of
another (for example, via a type cast in @ref{1c,,C}),
especially if such interpretation is not defined by the
language standard. For example, interpreting a value of type
@code{T**} (pointer to pointer to @code{T}) as @code{U**} is undefined.

See @ref{112,,Interface conventions}.
@end table

@node Memory Management Glossary U,Memory Management Glossary V,Memory Management Glossary T,Memory Management Glossary
@anchor{glossary/u doc}@anchor{174b}@anchor{glossary/u glossary-u}@anchor{15a3}@anchor{glossary/u memory-management-glossary-u}@anchor{174c}
@section Memory Management Glossary: U


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/u term-unaligned}@anchor{15cb}
@geindex unaligned

@item unaligned

`misaligned'.

An @ref{126,,address} is unaligned or misaligned if it does not
comply with some @ref{68,,alignment} constraint on it.

For example, typically double precision floating point numbers
occupy 8 @ref{17c,,byte (1)} and have an alignment of 4 bytes;
that is, their address must be a multiple of four. If a
program tries to access such a number using an address that is
not a multiple of four, a @ref{15c9,,bus error} may result,
depending on the processor architecture and instruction used.

@ref{68,,aligned}.


@subsubheading See also


@ref{68,,alignment}, @ref{15c9,,bus error}.

@anchor{glossary/u term-unboxed}@anchor{48}
@geindex unboxed

@item unboxed

Unboxed @ref{1ab,,objects} are represented by an
encoding of the data itself, and not by a @ref{15b8,,pointer} to
that data.

Representations are typically chosen so that unboxed values
are the same size as the pointer part of a @ref{160b,,boxed}
object. Sometimes the value is @ref{88,,tagged} to
distinguish it from a boxed object. The entire object is
duplicated when the object is passed around, so updates to it,
if allowed, only affect one copy.

@ref{16a5,,immediate data}.

@ref{160b,,boxed}.

@ref{1527,,Gudeman (1993)}.
@anchor{glossary/u term-unclamped-state}@anchor{192}
@geindex unclamped state

@item unclamped state

One of the four states an @ref{16,,arena} can be in (the
others being the @ref{19f,,clamped state}, the @ref{b8,,parked state} and the @ref{d5,,postmortem state}). In the unclamped
state, object motion and other background activity may
occur. Call @ref{cf,,mps_arena_release()} to put an arena
into the unclamped state.
@anchor{glossary/u term-undead}@anchor{165d}
@geindex undead

@item undead

An undead object is an @ref{1ab,,object} that cannot be proven to
be @ref{49,,dead} by the @ref{20,,garbage collector}, but whose
@ref{78,,liveness} is dubious.

For example, an @ref{9f,,ambiguous reference} to an object on a
@ref{92,,page} may mark the entire page as @ref{96,,reachable}. No
further data is collected about that page. The other objects
on the page will survive, even though their reachability has
not been determined. They are `undead'.
@anchor{glossary/u term-unmapped}@anchor{1685}
@geindex unmapped

@item unmapped

`free'.

A range of @ref{16b9,,virtual addresses} is said
to be `unmapped' (`free' on Windows) if there is no
@ref{15b6,,physical memory (2)} associated with the range.

An unmapped range may or may not be @ref{16d2,,reserved}.

@ref{190,,mapped}.
@anchor{glossary/u term-unprotected}@anchor{1a8}
@geindex unprotected

@item unprotected

A region of @ref{194,,memory (2)} is said to be unprotected if
there are no @ref{60,,barriers (1)} on that region.

@ref{d4,,protected}
@anchor{glossary/u term-unreachable}@anchor{21}
@geindex unreachable

@item unreachable

An @ref{1ab,,object} is unreachable if there is no
@ref{24,,reference} chain to it from any @ref{97,,root}.

An object will become unreachable when the @ref{30c,,mutator}
overwrites its last (direct or indirect) reference to the
object.

@ref{49,,dead}.

@ref{78,,live}, @ref{96,,reachable}.


@subsubheading See also


@ref{f,,garbage collection}.

@anchor{glossary/u term-unsure-reference}@anchor{174d}
@geindex unsure reference

@item unsure reference

@ref{9f,,ambiguous reference}.
@anchor{glossary/u term-unwrapped}@anchor{170e}
@geindex unwrapped

@item unwrapped

`raw'.

A value is `unwrapped' or `raw' if it is not encoded with type
information.

In a dynamically-typed language, the compiler may sometimes be
able to pick a more compact or efficient representation for a
value if it can prove that the type can be determined at
compile-time. This is a particularly useful optimization for
numeric values such as integers or floats.

@ref{174e,,wrapped}.


@subsubheading See also


@ref{160b,,boxed}, @ref{88,,tag}, @ref{16a6,,value object}.


@ref{1527,,Gudeman (1993)}.
@anchor{glossary/u term-use-after-free}@anchor{174f}
@geindex use after free

@item use after free

@ref{165c,,premature free}.
@end table

@node Memory Management Glossary V,Memory Management Glossary W,Memory Management Glossary U,Memory Management Glossary
@anchor{glossary/v doc}@anchor{1750}@anchor{glossary/v glossary-v}@anchor{15a4}@anchor{glossary/v memory-management-glossary-v}@anchor{1751}
@section Memory Management Glossary: V


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/v term-value-object}@anchor{16a6}
@geindex value object

@item value object

`immutable object'.

A `value object' or `immutable object' is an @ref{1ab,,object}
whose identity depends solely upon its value or magnitude.

In a typed language, the compiler can often determine at
compile time that certain types can be represented as value
objects. Usually these types are a @ref{15c6,,scalar data type}
with bounded magnitude.

If value objects can be identified, the compiler and the
memory manager can make certain optimizations: Value
objects can be represented as @ref{16a5,,immediate data} to
minimize storage overhead, they can be replicated to
improve @ref{1601,,locality}, and a
@ref{15c7,,vector data type} of value objects can be
represented as a @ref{107,,leaf object}.

Some programming languages expose representational details
such as the use of value objects. In @ref{28a,,Lisp}, for
example, numbers are often represented as value objects
but not always as immediate data. The @code{EQ} predicate of
Lisp tests if two objects have the same representation,
whereas the @code{EQL} predicate tests if two objects
represent the same type and value (are computationally
identical). Because the choice of representation is an
optimization, exposing it at the language level can
cause programs to behave differently under different
compilers or optimization settings. Modern languages, such
as @ref{1752,,Dylan} hide this representational distinction,
permitting the compiler greater freedom in optimization.

@ref{16a5,,immediate data}.


@subsubheading See also


@ref{16a7,,immutable}.


@ref{14e9,,Baker (1993a)}.
@anchor{glossary/v term-variety}@anchor{c9}
@geindex variety

@item variety

A behaviour of the MPS that must be selected at
compilation time. There are three varieties: @ref{c8,,cool},
@ref{162,,hot} and @ref{163,,rash}. See
@ref{170,,Varieties}.
@anchor{glossary/v term-vector-data-type}@anchor{15c7}
@geindex vector data type

@item vector data type

A vector data type is an aggregate type whose elements belong
to the same type and are indexed by integers or tuples of
integers.

Examples of vector data types include strings and arrays.

Vector data types are seldom represented using
@ref{16a6,,value objects}, but may be
represented using @ref{107,,leaf objects} if
they are an aggregate of a type that can be represented by
@ref{16a6,,value objects}. @ref{65,,Scanning} information for vectors can be compactly encoded
in terms of the aggregated type and the vector size.


@subsubheading See also


@ref{15c5,,algebraic data type}, @ref{15c6,,scalar data type}, @ref{107,,leaf object}, @ref{16a6,,value object}.

@anchor{glossary/v term-virtual-address}@anchor{16b9}
@geindex virtual address

@item virtual address

`logical address'.

In a @ref{51,,virtual memory} system, the @ref{126,,addresses} that
application programs deal with are known as `virtual
addresses'.

The virtual addresses used by the application program are
translated by the virtual memory system (often using
@ref{15be,,translation lookaside buffers} and @ref{16a2,,page tables})
to @ref{15aa,,physical addresses}. It is the physical address that
is used to retrieve the contents from the @ref{17,,memory (3)}.

@ref{15aa,,physical address}.
@anchor{glossary/v term-virtual-address-space}@anchor{15bb}
@geindex virtual address space

@item virtual address space

The virtual @ref{54,,address space} is the space of
@ref{16b9,,virtual addresses}.

On @ref{51,,virtual memory} systems, user processes see the
virtual address space, and commonly have a separate virtual
address space each, so that they map the same addresses to
different data. These systems often have @ref{1720,,shared memory}
as well.

@ref{15ba,,physical address space}.
@anchor{glossary/v term-virtual-memory}@anchor{51}
@geindex virtual memory

@item virtual memory

`VM'.

In a `virtual memory' (`VM') system, the program code deals
with @ref{16b9,,virtual addresses}. Upon use,
the virtual address is translated by the @ref{16db,,MMU} to obtain
a @ref{15aa,,physical address} that is used to access
@ref{16b8,,physical memory (1)}.

Some operating systems can simulate having more @ref{194,,memory (2)} than is available as @ref{311,,main memory}, by storing part
of the data in @ref{15d1,,backing store}, typically on disk. If
the @ref{92,,page} referenced by the virtual address is not
currently in main memory, a @ref{16b5,,page fault} occurs,
triggering an operating system handler that @ref{16f3,,swaps in} the page. Some other page might be
@ref{169b,,swapped out} to make room.

Each process typically has its own separate @ref{15bb,,virtual address space} with its own @ref{310,,mappings} and
@ref{1fd,,protections}.


@float Figure

@image{MemoryPoolSystem-figures/virtual-memory,,,Diagram: Example of the relationship between the virtual address spaces of two processes@comma{} physical memory@comma{} and backing store.,svg}

@caption{Example of the relationship between the virtual address
spaces of two processes, physical memory, and backing
store.}

@end float


Virtual memory technology can be used in many useful memory
management techniques, such as @ref{60,,barriers (1)},
copy-on-write, and @ref{15b7,,memory mapping}.

@quotation

“Virtual” means never knowing where your next byte is
coming from. — @code{fortune(6)}
@end quotation

@ref{16d7,,real memory (1)}.


@subsubheading See also


@ref{190,,mapped}, @ref{15e7,,paging}, @ref{195,,paged in}, @ref{16d1,,paged out}, @ref{16d2,,reserved}, @ref{1720,,shared memory}, @ref{15e8,,swapping}, @ref{15e9,,swap space}, @ref{1685,,unmapped}.

@anchor{glossary/v term-virtual-memory-arena}@anchor{4f}
@geindex virtual memory arena

@item virtual memory arena

An @ref{11a,,arena class} which gets its @ref{194,,memory (2)}
from the operating system’s @ref{51,,virtual memory}
interface. See @ref{179,,Virtual memory arenas}.
@anchor{glossary/v term-visitor-function}@anchor{1753}
@geindex visitor function

@item visitor function

@ref{21d,,stepper function}.
@anchor{glossary/v term-VM-1}@anchor{1754}
@geindex VM (1)

@item VM@w{^(1)}

@ref{51,,virtual memory}.
@anchor{glossary/v term-VM-2}@anchor{1647}
@geindex VM (2)

@item VM@w{^(2)}

In the @ref{1645,,PostScript} language, `VM' is the @ref{15b0,,memory (1)} where the values of the @ref{1644,,composite objects} reside.

VM is short for “virtual memory”, but this has nothing to do
with the usual sense of the phrase (see @ref{51,,virtual memory}).
@end table

@node Memory Management Glossary W,Memory Management Glossary Z,Memory Management Glossary V,Memory Management Glossary
@anchor{glossary/w doc}@anchor{1755}@anchor{glossary/w glossary-w}@anchor{15a5}@anchor{glossary/w memory-management-glossary-w}@anchor{1756}
@section Memory Management Glossary: W


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/w term-weak-key-hash-table}@anchor{fb}
@geindex weak-key hash table

@item weak-key hash table

A hash table which has @ref{c,,weak references (1)} to its
keys. If the key dies, the value for that key is automatically
deleted from the table too. It can be used to store extra
information about objects without keeping them alive.

@ref{fd,,doubly weak hash table}, @ref{fc,,weak-value hash table}.

See @ref{fe,,AWL (Automatic Weak Linked)}.
@anchor{glossary/w term-weak-value-hash-table}@anchor{fc}
@geindex weak-value hash table

@item weak-value hash table

A hash table which has @ref{c,,weak references (1)} to its
value. If the value dies, any keys that refer to that value
are automatically deleted from the table too. It can be used
to index a set of objects without keeping them alive.

@ref{fd,,doubly weak hash table}, @ref{fb,,weak-key hash table}.

See @ref{fe,,AWL (Automatic Weak Linked)}.
@anchor{glossary/w term-weak-hash-table}@anchor{357}
@geindex weak hash table

@item weak hash table

A @ref{fb,,weak-key} or @ref{fc,,weak-value hash table} (usually the former).
@anchor{glossary/w term-weak-reference-1}@anchor{c}
@geindex weak reference (1)

@item weak reference@w{^(1)}

In @ref{15df,,tracing garbage collection}, a weak reference is a
@ref{24,,reference} that does not keep the @ref{1ab,,object} it
refers to @ref{78,,alive}.

A weak reference does not keep the referent alive, but it will
continue to refer to the object as long as it remains
otherwise alive. When only weak references to the object
remain, the weak references can be deleted (“splatted” or
“cleared”) and the object @ref{4a,,reclaimed}.

@ref{167f,,Java} offers three kinds of weak references, called
@ref{1712,,soft references}, @ref{1713,,weak references (2)}, and
@ref{16fa,,phantom references}, in order of increasing weakness.

@ref{244,,strong reference}.


@subsubheading See also


@ref{20d,,weak root}.

@anchor{glossary/w term-weak-reference-2}@anchor{1713}
@geindex weak reference (2)

@item weak reference@w{^(2)}

In @ref{167f,,Java} terminology, `weak reference' is used to mean
a @ref{24,,reference} encapsulated in a @ref{16fb,,reference object}
of class @code{WeakReference}.

Weak references form one of three kinds of @ref{c,,weak reference (1)} in Java. They are handy for associating extra
data with objects when you cannot store it in the objects
themselves.


@subsubheading See also


@ref{16f9,,weakly reachable}.


Class java.lang.ref.WeakReference@footnote{http://docs.oracle.com/javase/8/docs/api/java/lang/ref/WeakReference.html}, Reference Objects and Garbage Collection@footnote{http://pawlan.com/monica/articles/refobjs/}.
@anchor{glossary/w term-weak-root}@anchor{20d}
@geindex weak root

@item weak root

A weak root is a @ref{97,,root}, such that all
@ref{24,,references} in it are @ref{c,,weak references (1)}; that
is, they do not affect the @ref{78,,liveness} of the
@ref{1ab,,objects} referred to.

@ref{1717,,strong root}.

A weak root has @ref{9e,,rank} @ref{20c,,mps_rank_weak()}.
@anchor{glossary/w term-weak-tri-color-invariant}@anchor{1723}
@geindex weak tri-color invariant

@item weak tri-color invariant@anchor{glossary/w term-weak-tri-colour-invariant}@anchor{1757}
@geindex weak tri-colour invariant

@itemx weak tri-colour invariant@anchor{glossary/w term-weak-tricolor-invariant}@anchor{1758}
@geindex weak tricolor invariant

@itemx weak tricolor invariant@anchor{glossary/w term-weak-tricolour-invariant}@anchor{1759}
@geindex weak tricolour invariant

@itemx weak tricolour invariant

The weak @ref{1732,,tri-color invariant} is the property of a
@ref{24,,reference} @ref{1635,,graph} that all @ref{1607,,white}
@ref{163e,,nodes} pointed to by a @ref{1604,,black} node are
also @ref{96,,reachable} from some @ref{1606,,gray} node through a
chain of white nodes.

By preserving this property throughout @ref{1605,,tri-color marking}, a @ref{4b,,tracing} algorithm can ensure that
the @ref{15ae,,collector (2)} will not miss reachable objects,
even if the @ref{30c,,mutator} manipulates the graph during the
collection. Mutator actions might need to change the
@ref{163c,,color} of the nodes affected in order to preserve the
invariant.

Algorithms using this invariant are
@ref{16ae,,snapshot-at-the-beginning}
algorithms.


@subsubheading See also


@ref{60,,barrier (1)}, @ref{16af,,strong tri-color invariant}.


@ref{381,,Johnstone (1997)}, @ref{1555,,Pirinen (1998)}.
@anchor{glossary/w term-weakly-reachable}@anchor{16f9}
@geindex weakly reachable

@item weakly reachable

In @ref{167f,,Java}, an object is `weakly reachable' if it is
neither @ref{16f7,,strongly} nor
@ref{16f8,,softly reachable} and there is a path from the
@ref{97,,roots} to it that contains at least one
@ref{1713,,weak reference (2)} but no @ref{16fa,,phantom references}.

When the Java @ref{15d7,,collector (1)} determines that an object
is weakly reachable, it clears all the weak references
involved, and declares the object @ref{b,,finalizable}. (Operationally, finalization works as if it
was implemented by a class of “final references” that stand
between weak and phantom references.) Also, the
@ref{16fb,,reference objects} containing the
weak references are enqueued, if they were registered with a
queue.


@subsubheading See also


@ref{16f5,,phantom reachable}, @ref{96,,reachability}.


Class java.lang.ref.WeakReference@footnote{http://docs.oracle.com/javase/8/docs/api/java/lang/ref/WeakReference.html}, Reference Objects and Garbage Collection@footnote{http://pawlan.com/monica/articles/refobjs/}.
@anchor{glossary/w term-weighted-buddies}@anchor{1616}
@geindex weighted buddies

@item weighted buddies

A @ref{15f9,,buddy system} @ref{15d4,,allocation mechanism} using two
series of size classes: @ref{15f8,,binary buddies} (2, 4, 8, …)
and three-times-power-of-two (3, 6, 12, …). A block that is
in the latter series may be @ref{1614,,split} in two different
ways. Thus a block of size 12 may be split into two blocks of
size 6 or one block of size 4 and one block of size 8. The
same applies for @ref{38c,,coalescing}. This gives
this system more flexibility than a regular buddy system.


@subsubheading See also


@ref{15d4,,allocation mechanism}, @ref{15f8,,binary buddies}, @ref{15f9,,buddy system}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/w term-weighted-reference-counting}@anchor{1666}
@geindex weighted reference counting

@item weighted reference counting

A technique for @ref{15e0,,reference counting} which is in common
use for @ref{1663,,distributed garbage collection} because of the
low level of inter-process communication it requires.

Inter-process @ref{24,,references} to @ref{1ab,,objects} are
counted, but instead of simply counting the number of
references, each reference is given a weight. When an object
is created, the initial pointer to it is assigned a weight,
which is usually a power of 2 for easy division. The object
records the sum of all the weights of all of its references.
Whenever a reference is copied, its weight is divided equally
between the new and original copies. Since this operation
preserves the weighted reference sum, there is no need for
communication with the object at this time. When a reference
is deleted, the weighted reference sum is decremented by the
weight of the reference. This is communicated to the object by
sending it a message. When the object detects that the
weighted reference sum has dropped to zero, it may be
@ref{4a,,reclaimed}. The algorithm is tolerant of communication
protocols which don’t guarantee order of arrival of deletion
messages.
@anchor{glossary/w term-white}@anchor{1607}
@geindex white

@item white

In a @ref{1605,,tri-color marking} scheme, white @ref{1ab,,objects}
are objects that were @ref{221,,condemned} at the
beginning of the @ref{1a2,,collection cycle} and have not been
shown to be @ref{96,,reachable}. When @ref{4b,,tracing} is
complete, white objects will be subject to @ref{4a,,reclamation}.

@ref{1604,,black}, @ref{1606,,gray}.
@anchor{glossary/w term-word}@anchor{37c}
@geindex word

@item word

`machine word'.

Almost all processor architectures have a characteristic data
size that is handled most efficiently. This is known as the
`word size', and data of that size are known as `words'. The
word size is usually a power of two multiple of @ref{15c8,,bytes (2)}.

Often the platform’s word size is used to characterize the
architecture by quoting the number of bits in it. For example,
a 32-bit platform has a word size of four bytes and a 64-bit
platform has eight-byte words (assuming 8-bit bytes).
Typically, @ref{15b8,,pointers} are the size of a word,
and traditionally this determined the word size. Nowadays,
word size is usually driven by the need for more accuracy and
range in mathematical calculations.

In the past, the convenience of dealing with powers of two was not as significant, and word sizes such as 36- or 72-bits were not unknown.


@subsubheading See also


@ref{68,,alignment}, @ref{1695,,grain}.

@anchor{glossary/w term-working-set}@anchor{16ba}
@geindex working set

@item working set

The working set of a program or system is that @ref{194,,memory (2)} or set of @ref{126,,addresses} which it will use
in the near future.

This term is generally used when discussing @ref{16a0,,miss rates}
at some @ref{1626,,storage level}; the time scale of “near future”
depends upon the cost of a @ref{169e,,miss}. The working set
should fit in the storage level; otherwise the system may
@ref{16de,,thrash}.


@subsubheading See also


@ref{1627,,cache (2)}, @ref{1715,,resident set}, @ref{1628,,storage hierarchy}.


@ref{1511,,Denning & Schwartz (1972)}.
@anchor{glossary/w term-worst-fit}@anchor{386}
@geindex worst fit

@item worst fit

The @ref{380,,allocation policy} that always allocates from the
largest @ref{15bf,,free block}. Commonly implemented using a
size-ordered @ref{15c0,,free block chain} (largest first).

In practice, this tends to work quite badly because it
eliminates all large blocks, so large requests cannot be met.


@subsubheading See also


@ref{380,,allocation policy}, @ref{382,,best fit}, @ref{37f,,first fit}.


@ref{157a,,Wilson et al. (1995)}.
@anchor{glossary/w term-wrapped}@anchor{174e}
@geindex wrapped

@item wrapped

A value is wrapped if it is encoded with type information.

@ref{170e,,unwrapped}.


@subsubheading See also


@ref{160b,,boxed}, @ref{88,,tag}, @ref{175a,,wrapper}.


@ref{1527,,Gudeman (1993)}.
@anchor{glossary/w term-wrapper}@anchor{175a}
@geindex wrapper

@item wrapper

A wrapper is that part of a @ref{174e,,wrapped} representation
that is copied when the value is passed by value.

The wrapper does not include parts of the representation that
are accessed indirectly, and are not copied when the value is
passed.

For instance, a @ref{28a,,Lisp} implementation might use the top
two bits of a value representation as a @ref{88,,tag} to
distinguish between integers and @ref{15cf,,cons (1)} cells,
setting these bits to 01 for a @ref{15b8,,pointer} to a cons cell
and 11 for an integer. Then the wrapped value of the number 4
would have binary representation 11000…00100, and the
wrapper for this number is the whole of this wrapped value.
The pointer to a cons cell stored at location 4 would have
binary representation 01000…00100. The wrapped value of the
cons cell is the combination of this pointer and the cons cell
in memory itself. The wrapper of the cons cell is just the
pointer; when the cons cell is passed as a function argument,
just the pointer is passed.


@subsubheading See also


@ref{160b,,boxed}, @ref{174e,,wrapped}.


@ref{1527,,Gudeman (1993)}.
@anchor{glossary/w term-write-barrier}@anchor{214}
@geindex write barrier

@item write barrier

A write @ref{60,,barrier (1)} is a block on writing to certain
@ref{194,,memory (2)} @ref{15b4,,locations} by
certain threads or processes.

Write barriers are used for @ref{d,,incremental} or @ref{15ed,,concurrent} @ref{f,,garbage collection}.
They are also used to maintain @ref{213,,remembered sets} for
@ref{e,,generational}
@ref{20,,collectors (1)}.


@subsubheading See also


@ref{1d6,,read barrier}.

@anchor{glossary/w term-write-fault}@anchor{16f1}
@geindex write fault

@item write fault

An exception which occurs when writing to an address in
@ref{51,,virtual memory}.

This is probably either a @ref{16b5,,page fault}, an
@ref{16b4,,invalid page fault} or a @ref{1d7,,protection fault}.

@ref{1618,,segmentation violation}.


@subsubheading See also


@ref{16f0,,read fault}.

@end table

@node Memory Management Glossary Z,All,Memory Management Glossary W,Memory Management Glossary
@anchor{glossary/z doc}@anchor{175b}@anchor{glossary/z glossary-z}@anchor{15a6}@anchor{glossary/z memory-management-glossary-z}@anchor{175c}
@section Memory Management Glossary: Z


@ref{1590,,A}
| @ref{1591,,B}
| @ref{1592,,C}
| @ref{1593,,D}
| @ref{1594,,E}
| @ref{1595,,F}
| @ref{1596,,G}
| @ref{1597,,H}
| @ref{1598,,I}
| J
| @ref{1599,,K}
| @ref{159a,,L}
| @ref{159b,,M}
| @ref{159c,,N}
| @ref{159d,,O}
| @ref{159e,,P}
| @ref{159f,,Q}
| @ref{15a0,,R}
| @ref{15a1,,S}
| @ref{15a2,,T}
| @ref{15a3,,U}
| @ref{15a4,,V}
| @ref{15a5,,W}
| X
| Y
| @ref{15a6,,Z}


@table @asis
@anchor{glossary/z term-ZCT}@anchor{175d}
@geindex ZCT

@item ZCT

@ref{1660,,zero count table}.
@anchor{glossary/z term-zero-count-table}@anchor{1660}
@geindex zero count table

@item zero count table

`ZCT'.

A `zero count table' is used in @ref{165f,,deferred reference counting} to record @ref{1ab,,objects} whose
@ref{15e0,,reference counts} have dropped to
zero but which have not been processed to see if they can be
@ref{4a,,reclaimed}.
@end table

@node All,,Memory Management Glossary Z,Memory Management Glossary
@anchor{glossary/index all}@anchor{175e}
@section All


@c Sphinx presents the terms in this list run together in paragraphs,
@c so we use a visual cue (comma) to separate them, and a wide space
@c to break up the wall-of-text effect.  See `this comment on GitHub
@c pull request #166
@c <https://github.com/Ravenbrook/mps/pull/166#pullrequestreview-1687977425>`__.
@c TODO: Perhaps something more elegant and robust by overriding
@c styles?

@ref{15aa,,absolute address}, 
@ref{15ac,,activation frame}, 
@ref{15ac,,activation record}, 
@ref{27,,activation stack}, 
@ref{78,,active}, 
@ref{126,,address}, 
@ref{54,,address space}, 
@ref{cc,,address space layout randomization}, 
@ref{15be,,address translation cache}, 
@ref{384,,address-ordered first fit}, 
@ref{15c2,,aging space}, 
@ref{15c5,,algebraic data type}, 
@ref{68,,alignment}, 
@ref{78,,alive}, 
@ref{15ca,,allocate}, 
@ref{27d,,allocation frame}, 
@ref{15d4,,allocation mechanism}, 
@ref{272,,allocation pattern}, 
@ref{63,,allocation point}, 
@ref{2a,,allocation point protocol}, 
@ref{380,,allocation policy}, 
@ref{15d5,,allocation strategy}, 
@ref{15ce,,allocator}, 
@ref{9f,,ambiguous reference}, 
@ref{1c4,,ambiguous root}, 
@ref{16,,arena}, 
@ref{11a,,arena class}, 
@ref{cc,,ASLR}, 
@ref{284,,assertion}, 
@ref{a1,,asynchronous garbage collector}, 
@ref{15be,,ATC}, 
@ref{107,,atomic object}, 
@ref{9,,automatic memory management}, 
@ref{15d0,,automatic storage duration}, 

@ref{15d1,,backing store}, 
@ref{60,,barrier (1)}, 
@ref{15ee,,barrier (2)}, 
@ref{1d7,,barrier hit}, 
@ref{1aa,,base pointer}, 
@ref{382,,best fit}, 
@ref{15f6,,BIBOP}, 
@ref{15f6,,big bag of pages}, 
@ref{15f8,,binary buddies}, 
@ref{298,,bit array}, 
@ref{298,,bit table}, 
@ref{298,,bit vector}, 
@ref{298,,bitmap}, 
@ref{15fe,,bitmap marking}, 
@ref{15ff,,bitmapped fit}, 
@ref{218,,bitmask}, 
@ref{298,,bitset}, 
@ref{1604,,black}, 
@ref{1608,,blacklisting}, 
@ref{1609,,black-listing}, 
@ref{185,,block}, 
@ref{c5,,bounds error}, 
@ref{160b,,boxed}, 
@ref{160c,,break-table}, 
@ref{15d9,,brk}, 
@ref{1611,,broken heart}, 
@ref{15c3,,bucket}, 
@ref{15f9,,buddy system}, 
@ref{1cb,,buffer}, 
@ref{15c9,,bus error}, 
@ref{17c,,byte (1)}, 
@ref{15c8,,byte (2)}, 
@ref{161b,,byte (3)}, 
@ref{161c,,byte (4)}, 

@ref{1620,,C89}, 
@ref{1620,,C90}, 
@ref{1621,,C99}, 
@ref{1622,,cache (1)}, 
@ref{1627,,cache (2)}, 
@ref{1622,,cache memory}, 
@ref{1625,,cache policy}, 
@ref{162a,,caching (3)}, 
@ref{162c,,cactus stack}, 
@ref{162d,,card}, 
@ref{162e,,card marking}, 
@ref{1ab,,cell}, 
@ref{1632,,Cheney collector}, 
@ref{1632,,Cheney scan}, 
@ref{19f,,clamped state}, 
@ref{4d,,client arena}, 
@ref{325,,client object}, 
@ref{1d4,,client pointer}, 
@ref{30c,,client program}, 
@ref{1ee,,closure}, 
@ref{38c,,coalesce}, 
@ref{aa,,cold end}, 
@ref{163a,,collect}, 
@ref{1a2,,collection}, 
@ref{1a2,,collection cycle}, 
@ref{20,,collector (1)}, 
@ref{15ae,,collector (2)}, 
@ref{163c,,color}, 
@ref{163d,,colour}, 
@ref{156,,commit limit}, 
@ref{190,,committed (1)}, 
@ref{b1,,committed (2)}, 
@ref{1643,,compactifying}, 
@ref{1643,,compaction}, 
@ref{1644,,composite object}, 
@ref{1648,,comprehensive}, 
@ref{15ed,,concurrent garbage collection}, 
@ref{221,,condemned set}, 
@ref{164c,,connected}, 
@ref{15cf,,cons (1)}, 
@ref{15ca,,cons (2)}, 
@ref{349,,conservative garbage collection}, 
@ref{215,,constant root}, 
@ref{15d3,,constructor (1)}, 
@ref{1651,,constructor (2)}, 
@ref{15ad,,continuation}, 
@ref{27,,control stack}, 
@ref{c8,,cool}, 
@ref{e3,,copying garbage collection}, 
@ref{1656,,core}, 
@ref{15c4,,creation space}, 
@ref{7c,,critical path}, 
@ref{162f,,crossing map}, 
@ref{1659,,cyclic data structure}, 

@ref{281,,dangling pointer}, 
@ref{1654,,data stack}, 
@ref{49,,dead}, 
@ref{15d2,,deallocate}, 
@ref{285,,debugging pool}, 
@ref{1638,,deferred coalescing}, 
@ref{165f,,deferred reference counting}, 
@ref{ff,,dependent object}, 
@ref{1ac,,derived pointer}, 
@ref{1650,,destructor (1)}, 
@ref{1652,,destructor (2)}, 
@ref{1663,,DGC}, 
@ref{1664,,direct method}, 
@ref{1602,,dirty bit}, 
@ref{1663,,distributed garbage collection}, 
@ref{1617,,double buddies}, 
@ref{26b,,double free}, 
@ref{1667,,doubleword}, 
@ref{fd,,doubly weak hash table}, 
@ref{166a,,DRAM}, 
@ref{1653,,dynamic allocation}, 
@ref{24a,,dynamic extent}, 
@ref{166a,,dynamic memory}, 
@ref{166a,,dynamic RAM}, 

@ref{1640,,ecru}, 
@ref{1671,,edge}, 
@ref{1672,,entry table (1)}, 
@ref{1674,,entry table (2)}, 
@ref{164f,,exact garbage collection}, 
@ref{61,,exact reference}, 
@ref{20b,,exact root}, 
@ref{1675,,exact segregated fit}, 
@ref{27,,execution stack}, 
@ref{1673,,exit table}, 
@ref{b5,,extent}, 
@ref{383,,external fragmentation}, 

@ref{283,,fencepost}, 
@ref{167b,,fence post}, 
@ref{167c,,fencepost error}, 
@ref{167d,,fence post error}, 
@ref{1615,,Fibonacci buddies}, 
@ref{385,,FIFO-ordered first fit}, 
@ref{15b7,,file mapping}, 
@ref{b,,finalization}, 
@ref{23d,,finalized block}, 
@ref{37f,,first fit}, 
@ref{b4,,fix}, 
@ref{18c,,flip}, 
@ref{15d8,,floating garbage}, 
@ref{10b,,foreign code}, 
@ref{164e,,format}, 
@ref{69,,format method}, 
@ref{23,,formatted object}, 
@ref{85,,forward method}, 
@ref{1db,,forwarding marker}, 
@ref{66,,forwarding object}, 
@ref{87,,forwarding pointer}, 
@ref{17e,,fragmentation}, 
@ref{1d1,,frame}, 
@ref{15d2,,free (1)}, 
@ref{1b,,free (2)}, 
@ref{15d6,,free (3)}, 
@ref{1685,,free (4)}, 
@ref{15bf,,free block}, 
@ref{15c0,,free block chain}, 
@ref{268,,free list}, 
@ref{47,,free store}, 
@ref{47,,freestore}, 
@ref{1689,,from space}, 
@ref{1682,,fromspace}, 
@ref{168a,,function pointer}, 
@ref{15ac,,function record}, 

@ref{1649,,garbage}, 
@ref{f,,garbage collection}, 
@ref{20,,garbage collector}, 
@ref{1619,,GB}, 
@ref{f,,GC}, 
@ref{1692,,General Protection Fault}, 
@ref{e1,,generation}, 
@ref{e2,,generation chain}, 
@ref{e,,generation scavenging}, 
@ref{e,,generational garbage collection}, 
@ref{35b,,generational hypothesis}, 
@ref{1619,,gigabyte}, 
@ref{15f5,,good fit}, 
@ref{1692,,GPF}, 
@ref{1695,,grain}, 
@ref{1635,,graph}, 
@ref{1606,,gray}, 
@ref{1696,,grey}, 
@ref{1697,,gray list}, 
@ref{1698,,grey list}, 

@ref{1678,,handle}, 
@ref{1d1,,header}, 
@ref{47,,heap}, 
@ref{1653,,heap allocation}, 
@ref{169d,,hit}, 
@ref{169f,,hit rate}, 
@ref{162,,hot}, 
@ref{1639,,hot end}, 
@ref{16a1,,huge page}, 

@ref{16a5,,immediate data}, 
@ref{164b,,immune set}, 
@ref{16a7,,immutable}, 
@ref{16a6,,immutable object}, 
@ref{1d1,,in-band header}, 
@ref{16ab,,in parameter}, 
@ref{120,,in/out parameter}, 
@ref{d,,incremental garbage collection}, 
@ref{16ad,,incremental update}, 
@ref{15af,,indefinite extent}, 
@ref{15f4,,indexed fit}, 
@ref{1665,,indirect method}, 
@ref{35b,,infant mortality}, 
@ref{a,,inline allocation (1)}, 
@ref{16b1,,inline allocation (2)}, 
@ref{1630,,inter-generational pointer}, 
@ref{1ac,,interior pointer}, 
@ref{379,,internal fragmentation}, 
@ref{16b4,,invalid page fault}, 
@ref{16b6,,inverted page table}, 
@ref{16b7,,inverted page-table}, 
@ref{8c,,is-forwarded method}, 

@ref{188,,kB}, 
@ref{53,,keyword argument}, 
@ref{188,,kilobyte}, 

@ref{16c1,,large object area}, 
@ref{16a1,,large page}, 
@ref{107,,leaf object}, 
@ref{234,,leak}, 
@ref{b5,,life}, 
@ref{b5,,lifetime}, 
@ref{15c1,,LIFO-ordered first fit}, 
@ref{16c5,,limited-field reference count}, 
@ref{16c7,,linear addressing}, 
@ref{78,,live}, 
@ref{15ea,,load}, 
@ref{1601,,locality of reference}, 
@ref{15b4,,location}, 
@ref{19a,,location dependency}, 
@ref{1bf,,lock free}, 
@ref{16b9,,logical address}, 
@ref{1667,,longword}, 

@ref{37c,,machine word}, 
@ref{311,,main memory}, 
@ref{1a,,malloc}, 
@ref{8,,manual memory management}, 
@ref{190,,mapped}, 
@ref{310,,mapping}, 
@ref{160d,,mark-compact}, 
@ref{15fd,,mark-sweep}, 
@ref{16d3,,mark-and-sweep}, 
@ref{1600,,marking}, 
@ref{186,,MB}, 
@ref{186,,megabyte}, 
@ref{162a,,memoization}, 
@ref{15b0,,memory (1)}, 
@ref{194,,memory (2)}, 
@ref{311,,memory (3)}, 
@ref{16d8,,memory (4)}, 
@ref{16d9,,memory bandwidth}, 
@ref{1622,,memory cache}, 
@ref{1628,,memory hierarchy}, 
@ref{234,,memory leak}, 
@ref{15b4,,memory location}, 
@ref{15dd,,memory management}, 
@ref{16db,,Memory Management Unit}, 
@ref{15cd,,memory manager}, 
@ref{15b7,,memory mapping}, 
@ref{1fd,,memory protection}, 
@ref{e9,,message}, 
@ref{ea,,message queue}, 
@ref{22c,,message type}, 
@ref{15cb,,misaligned}, 
@ref{169e,,miss}, 
@ref{16a0,,miss rate}, 
@ref{16d0,,mmap}, 
@ref{16db,,MMU}, 
@ref{1655,,mostly-copying garbage collection}, 
@ref{348,,mostly-exact garbage collection}, 
@ref{348,,mostly-precise garbage collection}, 
@ref{5d,,moving garbage collector}, 
@ref{1ad,,moving memory manager}, 
@ref{16a8,,mutable}, 
@ref{30c,,mutator}, 

@ref{1e5,,nailing}, 
@ref{70,,natural alignment}, 
@ref{16e5,,nepotism}, 
@ref{1681,,next fit}, 
@ref{16e6,,new space}, 
@ref{1633,,newspace}, 
@ref{163e,,node}, 
@ref{5e,,non-moving garbage collector}, 
@ref{1e7,,non-moving memory manager}, 
@ref{35f,,nursery generation}, 
@ref{35f,,nursery space}, 

@ref{1ab,,object}, 
@ref{39,,object format}, 
@ref{6e,,object pointer}, 
@ref{1640,,off-white}, 
@ref{1682,,old space}, 
@ref{1682,,oldspace}, 
@ref{16c6,,one-bit reference count}, 
@ref{16ec,,opaque type}, 
@ref{58,,out parameter}, 
@ref{16aa,,out-of-band header}, 
@ref{16cf,,overcommit}, 
@ref{c5,,overwriting error}, 

@ref{16b3,,padding}, 
@ref{90,,padding method}, 
@ref{67,,padding object}, 
@ref{92,,page}, 
@ref{16b5,,page fault}, 
@ref{1657,,page marking}, 
@ref{1fd,,page protection}, 
@ref{16a2,,page table}, 
@ref{195,,paged in}, 
@ref{16d1,,paged out}, 
@ref{15e7,,paging}, 
@ref{16f4,,palimpsest}, 
@ref{15ed,,parallel garbage collection}, 
@ref{b8,,parked state}, 
@ref{15f2,,perfect fit}, 
@ref{16f5,,phantom reachable}, 
@ref{16f6,,phantomly reachable}, 
@ref{16fa,,phantom reference}, 
@ref{15aa,,physical address}, 
@ref{15ba,,physical address space}, 
@ref{16b8,,physical memory (1)}, 
@ref{15b6,,physical memory (2)}, 
@ref{15b6,,physical storage}, 
@ref{16fc,,pig in the python}, 
@ref{16fc,,pig in the snake}, 
@ref{1e5,,pinning}, 
@ref{380,,placement policy}, 
@ref{12f,,platform}, 
@ref{160,,plinth}, 
@ref{15b8,,pointer}, 
@ref{18,,pool}, 
@ref{10,,pool class}, 
@ref{d5,,postmortem state}, 
@ref{164f,,precise garbage collection}, 
@ref{61,,precise reference}, 
@ref{20b,,precise root}, 
@ref{165c,,premature free}, 
@ref{1703,,premature promotion}, 
@ref{1703,,premature tenuring}, 
@ref{311,,primary storage}, 
@ref{223,,promotion}, 
@ref{216,,protectable root}, 
@ref{d4,,protected}, 
@ref{1fd,,protection}, 
@ref{1d7,,protection exception}, 
@ref{1d7,,protection fault}, 
@ref{1d7,,protection violation}, 

@ref{1668,,quadword}, 

@ref{55,,RAM}, 
@ref{55,,random access memory}, 
@ref{277,,ramp allocation}, 
@ref{9e,,rank}, 
@ref{163,,rash}, 
@ref{170e,,raw}, 
@ref{96,,reachable}, 
@ref{1d6,,read barrier}, 
@ref{16f0,,read fault}, 
@ref{16ce,,read-only memory}, 
@ref{16d7,,real memory (1)}, 
@ref{16b8,,real memory (2)}, 
@ref{4a,,reclaim}, 
@ref{15de,,recycle}, 
@ref{24,,reference}, 
@ref{15e0,,reference counting}, 
@ref{16fb,,reference object}, 
@ref{15e1,,region inference}, 
@ref{26,,register}, 
@ref{1714,,register set partitioning}, 
@ref{160e,,relocation}, 
@ref{213,,remembered set}, 
@ref{35d,,remote reference}, 
@ref{16e1,,replicating garbage collector}, 
@ref{16d2,,reserved}, 
@ref{1624,,resident}, 
@ref{1715,,resident set}, 
@ref{59,,result code}, 
@ref{247,,resurrection}, 
@ref{16ce,,ROM}, 
@ref{97,,root}, 
@ref{1718,,root description}, 
@ref{a0,,root mode}, 
@ref{1716,,root set}, 

@ref{160f,,sbrk}, 
@ref{15c6,,scalar data type}, 
@ref{65,,scan}, 
@ref{73,,scan method}, 
@ref{79,,scan state}, 
@ref{e3,,scavenging garbage collection}, 
@ref{166c,,SDRAM}, 
@ref{1618,,segmentation violation}, 
@ref{15b9,,segmented addressing}, 
@ref{1b2,,segregated allocation cache}, 
@ref{15f3,,segregated fit}, 
@ref{25c,,segregated free list}, 
@ref{171c,,segregated free-list}, 
@ref{348,,semi-conservative garbage collection}, 
@ref{1612,,semi-space}, 
@ref{1634,,semi-space collector}, 
@ref{15f1,,sequential fit}, 
@ref{171f,,sequential store buffer}, 
@ref{1720,,shared memory}, 
@ref{1646,,simple object}, 
@ref{171d,,simple segregated storage}, 
@ref{183,,size}, 
@ref{263,,size class}, 
@ref{81,,skip method}, 
@ref{1711,,smart pointer}, 
@ref{1721,,snap-out}, 
@ref{16ae,,snapshot at the beginning}, 
@ref{1712,,soft reference}, 
@ref{16f8,,softly reachable}, 
@ref{234,,space leak}, 
@ref{197,,spare commit limit}, 
@ref{18f,,spare committed memory}, 
@ref{162c,,spaghetti stack}, 
@ref{245,,splat}, 
@ref{1614,,split}, 
@ref{1623,,SRAM}, 
@ref{171f,,SSB}, 
@ref{15bc,,stack}, 
@ref{15e2,,stack allocation}, 
@ref{15b1,,stack frame}, 
@ref{15b1,,stack record}, 
@ref{1610,,static allocation}, 
@ref{1623,,static memory (1)}, 
@ref{1729,,static memory (2)}, 
@ref{172a,,static object}, 
@ref{1623,,static RAM}, 
@ref{15e3,,static storage duration}, 
@ref{21d,,stepper function}, 
@ref{16c5,,sticky reference count}, 
@ref{16ac,,stop-and-copy collection}, 
@ref{15b0,,storage}, 
@ref{1628,,storage hierarchy}, 
@ref{1626,,storage level}, 
@ref{15dd,,storage management}, 
@ref{15eb,,store (1)}, 
@ref{15b0,,store (2)}, 
@ref{172e,,stretchy vector}, 
@ref{1613,,strict segregated fit}, 
@ref{244,,strong reference}, 
@ref{1717,,strong root}, 
@ref{16af,,strong tri-color invariant}, 
@ref{172f,,strong tri-colour invariant}, 
@ref{1730,,strong tricolor invariant}, 
@ref{1731,,strong tricolour invariant}, 
@ref{16f7,,strongly reachable}, 
@ref{16b2,,suballocator}, 
@ref{1733,,subgraph}, 
@ref{16a1,,superpage}, 
@ref{61,,sure reference}, 
@ref{15e9,,swap space}, 
@ref{16f3,,swapped in}, 
@ref{169b,,swapped out}, 
@ref{15e8,,swapping}, 
@ref{16d4,,sweeping}, 
@ref{c1,,synchronous garbage collector}, 

@ref{162a,,tabling}, 
@ref{88,,tag}, 
@ref{1658,,tagged architecture}, 
@ref{7d,,tagged reference}, 
@ref{161a,,TB (1)}, 
@ref{15be,,TB (2)}, 
@ref{295,,telemetry filter}, 
@ref{12e,,telemetry label}, 
@ref{ba,,telemetry stream}, 
@ref{223,,tenuring}, 
@ref{161a,,terabyte}, 
@ref{b,,termination}, 
@ref{16de,,thrash}, 
@ref{99,,thread}, 
@ref{221,,threatened set}, 
@ref{15be,,TLB}, 
@ref{173f,,to space}, 
@ref{1633,,tospace}, 
@ref{4b,,trace}, 
@ref{15df,,tracing garbage collection}, 
@ref{1740,,translation buffer}, 
@ref{15be,,translation lookaside buffer}, 
@ref{1741,,transparent alias}, 
@ref{127,,transparent type}, 
@ref{1722,,transport}, 
@ref{1721,,transport snap-out}, 
@ref{163f,,treadmill}, 
@ref{1732,,tri-color invariant}, 
@ref{1743,,tri-colour invariant}, 
@ref{1744,,tricolor invariant}, 
@ref{1745,,tricolour invariant}, 
@ref{1605,,tri-color marking}, 
@ref{1746,,tri-colour marking}, 
@ref{1747,,tricolor marking}, 
@ref{1748,,tricolour marking}, 
@ref{1634,,two-space collector}, 
@ref{1749,,two space collector}, 
@ref{164f,,type-accurate garbage collection}, 
@ref{a5,,type punning}, 

@ref{15cb,,unaligned}, 
@ref{48,,unboxed}, 
@ref{192,,unclamped state}, 
@ref{165d,,undead}, 
@ref{1685,,unmapped}, 
@ref{1a8,,unprotected}, 
@ref{21,,unreachable}, 
@ref{9f,,unsure reference}, 
@ref{170e,,unwrapped}, 
@ref{165c,,use after free}, 

@ref{16a6,,value object}, 
@ref{c9,,variety}, 
@ref{15c7,,vector data type}, 
@ref{16b9,,virtual address}, 
@ref{15bb,,virtual address space}, 
@ref{51,,virtual memory}, 
@ref{4f,,virtual memory arena}, 
@ref{21d,,visitor function}, 
@ref{51,,VM (1)}, 
@ref{1647,,VM (2)}, 

@ref{fb,,weak-key hash table}, 
@ref{fc,,weak-value hash table}, 
@ref{357,,weak hash table}, 
@ref{c,,weak reference (1)}, 
@ref{1713,,weak reference (2)}, 
@ref{20d,,weak root}, 
@ref{1723,,weak tri-color invariant}, 
@ref{1757,,weak tri-colour invariant}, 
@ref{1758,,weak tricolor invariant}, 
@ref{1759,,weak tricolour invariant}, 
@ref{16f9,,weakly reachable}, 
@ref{1616,,weighted buddies}, 
@ref{1666,,weighted reference counting}, 
@ref{1607,,white}, 
@ref{37c,,word}, 
@ref{16ba,,working set}, 
@ref{386,,worst fit}, 
@ref{174e,,wrapped}, 
@ref{175a,,wrapper}, 
@ref{214,,write barrier}, 
@ref{16f1,,write fault}, 

@ref{1660,,ZCT}, 
@ref{1660,,zero count table}

@node Index to source code,Memory Pool System Kit Open Source License,Memory Management Glossary,Top
@anchor{code-index doc}@anchor{175f}@anchor{code-index code-index}@anchor{1760}
@chapter Index to source code


@menu
* External MPS interface:: 
* Plinth: Plinth<2>. 
* Configuration:: 
* Core MPS:: 
* Platform interfaces:: 
* Pool classes: Pool classes<3>. 
* Auxiliary programs:: 
* Benchmarks:: 
* Test support:: 
* Interactive test cases:: 
* Automated test cases:: 
* Build infrastructure:: 

@end menu

@node External MPS interface,Plinth<2>,,Index to source code
@anchor{code-index external-mps-interface}@anchor{1761}
@section External MPS interface


The external MPS interface consists of header files that the
@ref{d0,,client program} is expected to include, plus the single-file
source code (mps.c). See design.mps.interface-c@footnote{design/interface-c.html}.


@multitable {xxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

File

@tab

Description

@item

mps.h

@tab

Public MPS interface.

@item

mps.c

@tab

Single-file source code. See @ref{14,,Building the Memory Pool System}.

@item

mpsacl.h

@tab

@ref{178,,Client arenas} external interface.

@item

mpsavm.h

@tab

@ref{179,,Virtual memory arenas} external interface.

@item

mpscamc.h

@tab

@ref{62,,AMC (Automatic Mostly-Copying)} pool class external interface.

@item

mpscams.h

@tab

@ref{16c,,AMS (Automatic Mark and Sweep)} pool class external interface.

@item

mpscawl.h

@tab

@ref{fe,,AWL (Automatic Weak Linked)} pool class external interface.

@item

mpsclo.h

@tab

@ref{353,,LO (Leaf Object)} pool class external interface.

@item

mpscmfs.h

@tab

@ref{355,,MFS (Manual Fixed Small)} pool class external interface.

@item

mpscmv2.h

@tab

Former (deprecated) @ref{1bc,,MVT (Manual Variable Temporal)} pool class interface.

@item

mpscmvff.h

@tab

@ref{10c,,MVFF (Manual Variable First Fit)} pool class external interface.

@item

mpscmvt.h

@tab

@ref{1bc,,MVT (Manual Variable Temporal)} pool class external interface.

@item

mpscsnc.h

@tab

@ref{27b,,SNC (Stack No Checking)} pool class external interface.

@item

mpsio.h

@tab

@ref{2b8,,I/O module} interface.

@item

mpslib.h

@tab

@ref{2cb,,Library module} interface.

@end multitable


@node Plinth<2>,Configuration,External MPS interface,Index to source code
@anchor{code-index plinth}@anchor{1762}
@section Plinth


The @ref{160,,plinth} provides an interface between the MPS and the
execution environment, to help support @ref{14e,,freestanding}
implementations. See @ref{3b,,Plinth}.


@multitable {xxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

File

@tab

Description

@item

mpsioan.c

@tab

@ref{2b8,,I/O module} for “ANSI” (hosted) environments.

@item

mpsliban.c

@tab

@ref{2cb,,Library module} for “ANSI” (hosted) environments.

@end multitable


@node Configuration,Core MPS,Plinth<2>,Index to source code
@anchor{code-index configuration}@anchor{1763}
@section Configuration


These header files provide platform-specific constants, type
declarations, and macros. See @ref{306,,Porting the MPS} and
design.mps.config@footnote{design/config.html}.


@multitable {xxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

File

@tab

Description

@item

clock.h

@tab

Fast high-resolution clocks.

@item

config.h

@tab

MPS configuration header.

@item

mpstd.h

@tab

Target detection header.

@end multitable


@node Core MPS,Platform interfaces,Configuration,Index to source code
@anchor{code-index core-mps}@anchor{1764}
@section Core MPS



@multitable {xxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

File

@tab

Description

@item

abq.c

@tab

Fixed-length queue implementation. See design.mps.abq@footnote{design/abq.html}.

@item

abq.h

@tab

Fixed-length queue interface. See design.mps.abq@footnote{design/abq.html}.

@item

arena.c

@tab

Arena implementation. See design.mps.arena@footnote{design/arena.html}.

@item

arenacl.c

@tab

@ref{178,,Client arenas} implementation.

@item

arenavm.c

@tab

@ref{179,,Virtual memory arenas} implementation.

@item

arg.c

@tab

@ref{57,,Keyword arguments} implementation.

@item

arg.h

@tab

@ref{57,,Keyword arguments} interface.

@item

boot.c

@tab

Bootstrap allocator implementation. See design.mps.bootstrap@footnote{design/bootstrap.html}.

@item

boot.h

@tab

Bootstrap allocator interface. See design.mps.bootstrap@footnote{design/bootstrap.html}.

@item

bt.c

@tab

Bit table implementation. See design.mps.bt@footnote{design/bt.html}.

@item

bt.h

@tab

Bit table interface. See design.mps.bt@footnote{design/bt.html}.

@item

buffer.c

@tab

Buffer implementation. See design.mps.buffer@footnote{design/buffer.html}.

@item

cbs.c

@tab

Coalescing block implementation. See design.mps.cbs@footnote{design/cbs.html}.

@item

cbs.h

@tab

Coalescing block interface. See design.mps.cbs@footnote{design/cbs.html}.

@item

check.h

@tab

Assertion interface. See design.mps.check@footnote{design/check.html}.

@item

dbgpool.c

@tab

@ref{10d,,Debugging pools} implementation.

@item

dbgpool.h

@tab

@ref{10d,,Debugging pools} interface.

@item

dbgpooli.c

@tab

@ref{10d,,Debugging pools} external interface.

@item

event.c

@tab

@ref{db,,Telemetry} implementation.

@item

event.h

@tab

@ref{db,,Telemetry} interface (internal).

@item

eventcom.h

@tab

@ref{db,,Telemetry} interface (auxiliary programs).

@item

eventdef.h

@tab

@ref{db,,Telemetry} event definitions.

@item

failover.c

@tab

Fail-over allocator implementation. See design.mps.failover@footnote{design/failover.html}.

@item

failover.h

@tab

Fail-over allocator interface. See design.mps.failover@footnote{design/failover.html}.

@item

format.c

@tab

@ref{6a,,Object formats} implementation.

@item

freelist.c

@tab

Freelist allocator implementation. See design.mps.freelist@footnote{design/freelist.html}.

@item

freelist.h

@tab

Freelist allocator interface. See design.mps.freelist@footnote{design/freelist.html}.

@item

global.c

@tab

Global arena implementation.

@item

land.c

@tab

Land implementation. See design.mps.land@footnote{design/land.html}.

@item

ld.c

@tab

@ref{f8,,Location dependency} implementation.

@item

locus.c

@tab

Locus manager implementation. See design.mps.locus@footnote{design/locus.html}.

@item

locus.h

@tab

Locus manager interface. See design.mps.locus@footnote{design/locus.html}.

@item

message.c

@tab

@ref{f1,,Messages} implementation.

@item

meter.c

@tab

Debugging accumulator implementation.

@item

meter.h

@tab

Debugging accumulator interface.

@item

misc.h

@tab

Miscellaneous constant and macro definitions.

@item

mpm.c

@tab

Miscellaneous support functions. See design.mps.writef@footnote{design/writef.html}.

@item

mpm.h

@tab

Core MPS interface. (“MPM” = “Memory Pool Manager”)

@item

mpmst.h

@tab

Core data structure declarations.

@item

mpmtypes.h

@tab

Core type declarations.

@item

mpsi.c

@tab

External interface implementation. See design.mps.interface-c@footnote{design/interface-c.html}.

@item

mpsiw3.c

@tab

Additional external interface implementation for Windows.

@item

mpswin.h

@tab

Wrapper for windows.h.

@item

nailboard.c

@tab

Nailboard implementation. See design.mps.nailboard@footnote{design/nailboard.html}.

@item

nailboard.h

@tab

Nailboard interface. See design.mps.nailboard@footnote{design/nailboard.html}.

@item

policy.c

@tab

Collection policy decisions. See design.mps.strategy@footnote{design/strategy.html}.

@item

pool.c

@tab

Pool implementation. See design.mps.pool@footnote{design/pool.html}.

@item

poolabs.c

@tab

Abstract pool classes.

@item

poolmrg.c

@tab

Manual Rank Guardian pool implementation. See design.mps.poolmrg@footnote{design/poolmrg.html}.

@item

poolmrg.h

@tab

Manual Rank Guardian pool interface. See design.mps.poolmrg@footnote{design/poolmrg.html}.

@item

protocol.c

@tab

Inheritance protocol implementation. See design.mps.protocol@footnote{design/protocol.html}.

@item

protocol.h

@tab

Inheritance protocol interface. See design.mps.protocol@footnote{design/protocol.html}.

@item

range.c

@tab

Address ranges implementation. See design.mps.range@footnote{design/range.html}.

@item

range.h

@tab

Address ranges interface. See design.mps.range@footnote{design/range.html}.

@item

rangetree.c

@tab

Binary address-ordered range tree implementation.

@item

rangetree.h

@tab

Binary address-ordered range tree interface.

@item

ref.c

@tab

Ranks and zones implementation.

@item

ring.c

@tab

Ring implementation. See design.mps.ring@footnote{design/ring.html}.

@item

ring.h

@tab

Ring interface. See design.mps.ring@footnote{design/ring.html}.

@item

root.c

@tab

@ref{28,,Roots} implementation.

@item

sa.c

@tab

Sparse array implementation.

@item

sa.h

@tab

Sparse array interface.

@item

sac.c

@tab

@ref{25b,,Segregated allocation caches} implementation.

@item

sac.h

@tab

@ref{25b,,Segregated allocation caches} interface.

@item

sc.h

@tab

Stack context interface.

@item

scan.c

@tab

@ref{25,,Scanning} functions.

@item

seg.c

@tab

Segment implementation. See design.mps.seg@footnote{design/seg.html}.

@item

shield.c

@tab

Shield implementation. See design.mps.shield@footnote{design/shield.html}.

@item

splay.c

@tab

Splay tree implementation. See design.mps.splay@footnote{design/splay.html}.

@item

splay.h

@tab

Splay tree interface. See design.mps.splay@footnote{design/splay.html}.

@item

trace.c

@tab

Trace implementation. See design.mps.trace@footnote{design/trace.html}.

@item

traceanc.c

@tab

More trace implementation. See design.mps.trace@footnote{design/trace.html}.

@item

tract.c

@tab

Chunk and tract implementation. See design.mps.arena@footnote{design/arena.html}.

@item

tract.h

@tab

Chunk and tract interface. See design.mps.arena@footnote{design/arena.html}.

@item

tree.c

@tab

Binary tree implementation.

@item

tree.h

@tab

Binary tree interface.

@item

version.c

@tab

MPS version implementation. See design.mps.version@footnote{design/version.html}.

@item

walk.c

@tab

Formatted object walker.

@end multitable


@node Platform interfaces,Pool classes<3>,Core MPS,Index to source code
@anchor{code-index platform-interfaces}@anchor{1765}
@section Platform interfaces


These modules provide interfaces to features that are not available in
standard C, and so may need to be ported to new platforms. See
@ref{306,,Porting the MPS}.


@multitable {xxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

File

@tab

Description

@item

lock.h

@tab

Lock interface. See design.mps.lock@footnote{design/lock.html}.

@item

lockan.c

@tab

Lock implementation for standard C.

@item

lockix.c

@tab

Lock implementation for POSIX.

@item

lockw3.c

@tab

Lock implementation for Windows.

@item

prmc.h

@tab

Mutator context interface. See design.mps.prmc@footnote{design/prmc.html}.

@item

prmcan.c

@tab

Mutator context implementation for generic operating system.

@item

prmcanan.c

@tab

Mutator context implementation for generic architecture.

@item

prmcfri3.c

@tab

Mutator context implementation for FreeBSD, IA-32.

@item

prmcfri6.c

@tab

Mutator context implementation for FreeBSD, x86-64.

@item

prmci3.c

@tab

Mutator context implementation for IA-32.

@item

prmci3.h

@tab

Mutator context interface for IA-32.

@item

prmci6.c

@tab

Mutator context implementation for x86-64.

@item

prmci6.h

@tab

Mutator context interface for x86-64.

@item

prmcix.c

@tab

Mutator context implementation for POSIX.

@item

prmcix.h

@tab

Mutator context interface for POSIX.

@item

prmclia6.c

@tab

Mutator context implementation for Linux, ARM64.

@item

prmclii3.c

@tab

Mutator context implementation for Linux, IA-32.

@item

prmclii6.c

@tab

Mutator context implementation for Linux, x86-64.

@item

prmcw3.c

@tab

Mutator context implementation for Windows.

@item

prmcw3.h

@tab

Mutator context interface for Windows.

@item

prmcw3i3.c

@tab

Mutator context implementation for Windows, IA-32.

@item

prmcw3i6.c

@tab

Mutator context implementation for Windows, x86-64.

@item

prmcxc.c

@tab

Mutator context implementation for macOS.

@item

prmcxc.h

@tab

Mutator context interface for macOS.

@item

prmcxca6.c

@tab

Mutator context implementation for macOS, ARM64.

@item

prmcxci3.c

@tab

Mutator context implementation for macOS, IA-32.

@item

prmcxci6.c

@tab

Mutator context implementation for macOS, x86-64.

@item

prot.h

@tab

Protection interface. See design.mps.prot@footnote{design/prot.html}.

@item

protan.c

@tab

Protection implementation for standard C.

@item

protix.c

@tab

Protection implementation for POSIX.

@item

protsgix.c

@tab

Protection implementation for POSIX (signals part).

@item

protw3.c

@tab

Protection implementation for Windows.

@item

protxc.c

@tab

Protection implementation for macOS.

@item

protxc.h

@tab

Protection interface for macOS.

@item

pthrdext.c

@tab

Protection implementation for POSIX (threads part).

@item

pthrdext.h

@tab

Protection interface for POSIX (threads part).

@item

sp.h

@tab

Stack probe interface. See design.mps.sp@footnote{design/sp.html}.

@item

span.c

@tab

Stack probe implementation for standard C.

@item

spw3i3.c

@tab

Stack probe implementation for Windows, IA-32.

@item

spw3i6.c

@tab

Stack probe implementation for Windows, x86-64.

@item

ss.c

@tab

Stack scanning implementation.

@item

ss.h

@tab

Stack scanning interface. See design.mps.stack-scan@footnote{design/stack-scan.html}.

@item

th.h

@tab

Threads interface. See design.mps.thread-manager@footnote{design/thread-manager.html}.

@item

than.c

@tab

Threads implementation for standard C.

@item

thix.c

@tab

Threads implementation for POSIX.

@item

thw3.c

@tab

Threads implementation for Windows.

@item

thxc.c

@tab

Threads implementation for macOS.

@item

vm.c

@tab

Virtual memory implementation (common part).

@item

vm.h

@tab

Virtual memory interface. See design.mps.vm@footnote{design/vm.html}.

@item

vman.c

@tab

Virtual memory implementation for standard C.

@item

vmix.c

@tab

Virtual memory implementation for POSIX.

@item

vmw3.c

@tab

Virtual memory implementation for Windows.

@end multitable


@node Pool classes<3>,Auxiliary programs,Platform interfaces,Index to source code
@anchor{code-index pool-classes}@anchor{1766}
@section Pool classes


These files implement the supported @ref{10,,pool classes}. Some of
these (MFS, MVFF) are used internally by the MPS; the others are
available for @ref{d0,,client programs} only. See @ref{22,,Pool reference}.


@multitable {xxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

File

@tab

Description

@item

poolamc.c

@tab

@ref{62,,AMC (Automatic Mostly-Copying)} implementation.

@item

poolams.c

@tab

@ref{16c,,AMS (Automatic Mark and Sweep)} implementation.

@item

poolams.h

@tab

@ref{16c,,AMS (Automatic Mark and Sweep)} internal interface.

@item

poolawl.c

@tab

@ref{fe,,AWL (Automatic Weak Linked)} implementation.

@item

poollo.c

@tab

@ref{353,,LO (Leaf Object)} implementation.

@item

poolmfs.c

@tab

@ref{355,,MFS (Manual Fixed Small)} implementation.

@item

poolmfs.h

@tab

@ref{355,,MFS (Manual Fixed Small)} internal interface.

@item

poolmv2.c

@tab

@ref{62,,AMC (Automatic Mostly-Copying)} implementation.

@item

poolmv2.h

@tab

@ref{1bc,,MVT (Manual Variable Temporal)} internal interface.

@item

poolmvff.c

@tab

@ref{10c,,MVFF (Manual Variable First Fit)} implementation.

@item

poolmvff.h

@tab

@ref{10c,,MVFF (Manual Variable First Fit)} internal interface.

@item

poolsnc.c

@tab

@ref{27b,,SNC (Stack No Checking)} implementation.

@end multitable


@node Auxiliary programs,Benchmarks,Pool classes<3>,Index to source code
@anchor{code-index auxiliary-programs}@anchor{1767}
@section Auxiliary programs


These files implement auxiliary programs. See
@ref{28d,,Telemetry utilities}.


@multitable {xxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

File

@tab

Description

@item

eventcnv.c

@tab

@ref{28e,,Decoding the telemetry stream}.

@item

eventsql.c

@tab

@ref{290,,Loading the telemetry stream into SQLite}.

@item

eventpy.c

@tab

@ref{291,,Decoding the telemetry stream in Python}.

@item

eventtxt.c

@tab

@ref{28f,,Making the telemetry stream readable}.

@item

getopt.h

@tab

Command-line option interface. Adapted from FreeBSD.

@item

getoptl.c

@tab

Command-line option implementation. Adapted from FreeBSD.

@item

table.c

@tab

Address-based hash table implementation.

@item

table.h

@tab

Address-based hash table interface.

@end multitable


@node Benchmarks,Test support,Auxiliary programs,Index to source code
@anchor{code-index benchmarks}@anchor{1768}
@section Benchmarks



@multitable {xxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

File

@tab

Description

@item

djbench.c

@tab

Benchmark for manually managed pool classes.

@item

gcbench.c

@tab

Benchmark for automatically managed pool classes.

@end multitable


@node Test support,Interactive test cases,Benchmarks,Index to source code
@anchor{code-index test-support}@anchor{1769}
@section Test support


This is code that’s shared between test cases.


@multitable {xxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

File

@tab

Description

@item

fmtdy.c

@tab

Dylan object format implementation.

@item

fmtdy.h

@tab

Dylan object format interface.

@item

fmtdytst.c

@tab

Dylan object constructor implementation.

@item

fmtdytst.h

@tab

Dylan object constructor interface.

@item

fmthe.c

@tab

Dylan-like object format with headers (implementation).

@item

fmthe.h

@tab

Dylan-like object format with headers (interface).

@item

fmtno.c

@tab

Null object format implementation.

@item

fmtno.h

@tab

Null object format interface.

@item

fmtscheme.c

@tab

Scheme object format implementation.

@item

fmtscheme.h

@tab

Scheme object format interface.

@item

pooln.c

@tab

Null pool implementation.

@item

pooln.h

@tab

Null pool interface.

@item

testlib.c

@tab

Test utilities implementation.

@item

testlib.h

@tab

Test utilities interface.

@item

testthr.h

@tab

Test threads interface. See design.mps.testthr@footnote{design/testthr.html}.

@item

testthrix.c

@tab

Test threads implementation for POSIX.

@item

testthrw3.c

@tab

Test threads implementation for Windows.

@end multitable


@node Interactive test cases,Automated test cases,Test support,Index to source code
@anchor{code-index interactive-test-cases}@anchor{176a}
@section Interactive test cases


These test cases provide harness for interacting with parts of the
MPS, for exploring the interface and testing by hand. These predate
the use of continuous integration: we wouldn’t write this kind of test
case now.


@multitable {xxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

File

@tab

Description

@item

bttest.c

@tab

Interactive bit tables test harness.

@item

teletest.c

@tab

Interactive telemetry test harness.

@end multitable


@node Automated test cases,Build infrastructure,Interactive test cases,Index to source code
@anchor{code-index automated-test-cases}@anchor{176b}
@section Automated test cases


These are test cases that run automatically and form the main test
suite. See design.mps.tests@footnote{design/tests.html}.


@multitable {xxxxxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

File

@tab

Description

@item

abqtest.c

@tab

Fixed-length queue test.

@item

airtest.c

@tab

Ambiguous interior reference test.

@item

amcss.c

@tab

@ref{62,,AMC (Automatic Mostly-Copying)} stress test.

@item

amcsshe.c

@tab

@ref{62,,AMC (Automatic Mostly-Copying)} stress test (using in-band headers).

@item

amcssth.c

@tab

@ref{62,,AMC (Automatic Mostly-Copying)} stress test (using multiple threads).

@item

amsss.c

@tab

@ref{16c,,AMS (Automatic Mark and Sweep)} stress test.

@item

amssshe.c

@tab

@ref{16c,,AMS (Automatic Mark and Sweep)} stress test (using in-band headers).

@item

apss.c

@tab

@ref{1be,,Allocation points} stress test.

@item

arenacv.c

@tab

Arena coverage test.

@item

awlut.c

@tab

@ref{fe,,AWL (Automatic Weak Linked)} unit test.

@item

awluthe.c

@tab

@ref{fe,,AWL (Automatic Weak Linked)} unit test (using in-band headers).

@item

awlutth.c

@tab

@ref{fe,,AWL (Automatic Weak Linked)} unit test (using multiple threads).

@item

btcv.c

@tab

Bit table coverage test.

@item

finalcv.c

@tab

@ref{f0,,Finalization} coverage test.

@item

finaltest.c

@tab

@ref{f0,,Finalization} test.

@item

forktest.c

@tab

@ref{1ff,,Fork safety} test.

@item

fotest.c

@tab

Failover allocator test.

@item

landtest.c

@tab

Land test.

@item

locbwcss.c

@tab

Locus backwards compatibility stress test.

@item

lockcov.c

@tab

Lock coverage test.

@item

lockut.c

@tab

Lock unit test.

@item

locusss.c

@tab

Locus stress test.

@item

locv.c

@tab

@ref{353,,LO (Leaf Object)} coverage test.

@item

messtest.c

@tab

@ref{f1,,Messages} test.

@item

mpmss.c

@tab

Manual allocation stress test.

@item

mpsicv.c

@tab

External interface coverage test.

@item

mv2test.c

@tab

@ref{1bc,,MVT (Manual Variable Temporal)} test.

@item

nailboardtest.c

@tab

Nailboard test.

@item

poolncv.c

@tab

Null pool class test.

@item

qs.c

@tab

Quicksort test.

@item

sacss.c

@tab

@ref{25b,,Segregated allocation caches} stress test.

@item

segsmss.c

@tab

Segment splitting and merging stress test.

@item

steptest.c

@tab

@ref{19c,,mps_arena_step()} test.

@item

tagtest.c

@tab

Tagged pointer scanning test.

@item

walkt0.c

@tab

Roots and formatted objects walking test.

@item

zcoll.c

@tab

Garbage collection progress test.

@item

zmess.c

@tab

Garbage collection and finalization message test.

@end multitable


@node Build infrastructure,,Automated test cases,Index to source code
@anchor{code-index build-infrastructure}@anchor{176c}
@section Build infrastructure


These are makefiles (and makefile fragments) used to build the MPS.
See @ref{306,,Porting the MPS}.


@multitable {xxxxxxxxxxxxxxx} {xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx} 
@headitem

File

@tab

Description

@item

anangc.gmk

@tab

GNU makefile for platform ANANGC.

@item

ananll.gmk

@tab

GNU makefile for platform ANANLL.

@item

ananmv.nmk

@tab

NMAKE file for platform ANANMV.

@item

comm.gmk

@tab

Common GNU make fragment.

@item

commpost.nmk

@tab

Common NMAKE fragment (included before the compiler fragment).

@item

commpre.nmk

@tab

Common NMAKE fragment (included after the compiler fragment).

@item

fri3gc.gmk

@tab

GNU makefile for platform FRI3GC.

@item

fri3ll.gmk

@tab

GNU makefile for platform FRI3LL.

@item

fri6gc.gmk

@tab

GNU makefile for platform FRI6GC.

@item

fri6ll.gmk

@tab

GNU makefile for platform FRI6LL.

@item

gc.gmk

@tab

GNU make fragment for GCC.

@item

gp.gmk

@tab

GNU make fragment for GCC/GProf (broken).

@item

lia6gc.gmk

@tab

GNU makefile for platform LIA6GC.

@item

lia6ll.gmk

@tab

GNU makefile for platform LIA6LL.

@item

lii3gc.gmk

@tab

GNU makefile for platform LII3GC.

@item

lii6gc.gmk

@tab

GNU makefile for platform LII6GC.

@item

lii6ll.gmk

@tab

GNU makefile for platform LII6LL.

@item

ll.gmk

@tab

GNU make fragment for Clang/LLVM.

@item

mv.nmk

@tab

NMAKE fragment for Microsoft Visual C.

@item

pc.nmk

@tab

NMAKE fragment for Pelles C.

@item

w3i3mv.nmk

@tab

NMAKE file for platform W3I3MV.

@item

w3i3pc.nmk

@tab

NMAKE file for platform W3I3PC.

@item

w3i6mv.nmk

@tab

NMAKE file for platform W3I6MV.

@item

w3i6pc.nmk

@tab

NMAKE file for platform W3I6PC.

@item

xca6ll.gmk

@tab

GNU makefile for platform XCA6LL.

@item

xci3gc.gmk

@tab

GNU makefile for platform XCI3GC.

@item

xci3ll.gmk

@tab

GNU makefile for platform XCI3LL.

@item

xci6gc.gmk

@tab

GNU makefile for platform XCI6GC.

@item

xci6ll.gmk

@tab

GNU makefile for platform XCI6LL.

@end multitable


@geindex copyright
@geindex license
@anchor{copyright license}@anchor{11}
@c mode: -*- rst -*-

@node Memory Pool System Kit Open Source License,Contact us,Index to source code,Top
@anchor{copyright doc}@anchor{176d}@anchor{copyright job000825}@anchor{176e}@anchor{copyright memory-pool-system-kit-open-source-license}@anchor{176f}
@chapter Memory Pool System Kit Open Source License


This is the license under which the Memory Pool System Kit is made
available by Ravenbrook Limited. This license is generally known as
the BSD 2-clause license@footnote{https://opensource.org/licenses/BSD-2-Clause}.  It is GPL compatible@footnote{https://www.gnu.org/licenses/license-list.html} and
OSI approved@footnote{https://opensource.org/licenses/sleepycat}.

For avoidance of doubt, this license supersedes any older licenses
that may appear in other files that are part of this distribution
and in any of its branches.

Prior to 2020, the MPS was “multi-licensed” under the Sleepycat License@footnote{https://en.wikipedia.org/wiki/Sleepycat_License} and also by other specifically arranged license agreements.

@menu
* License:: 

@end menu

@node License,,,Memory Pool System Kit Open Source License
@anchor{copyright bsd-2-clause-license}@anchor{1770}@anchor{copyright id1}@anchor{1771}
@section License


Copyright © 2001-2020 Ravenbrook Limited@footnote{https://www.ravenbrook.com/}.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:


@enumerate 

@item 
Redistributions of source code must retain the above copyright
notice, this list of conditions and the following disclaimer.

@item 
Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
@end enumerate

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
“AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

@c end

@node Contact us,Contributing to the MPS,Memory Pool System Kit Open Source License,Top
@anchor{contact doc}@anchor{1772}@anchor{contact contact}@anchor{d8}@anchor{contact contact-us}@anchor{1773}
@chapter Contact us



@itemize *

@item 
If you have questions about the project, or suggestions for
improvement, please write to @email{mps-questions@@ravenbrook.com}.

@item 
You can also join the mps-discussion mailing list@footnote{http://mailman.ravenbrook.com/mailman/listinfo/mps-discussion} if
you are interested in project progress, or if you’re adapting or
extending the Memory Pool System. The goals of the list are:


@enumerate 

@item 
to provide feedback to the project on requirements, design,
implementation, etc.;

@item 
to allow people to exchange information and experience with using
and adapting the project;

@item 
to keep people informed about project progress.
@end enumerate

To join, follow these instructions@footnote{http://mailman.ravenbrook.com/mailman/listinfo/mps-discussion},
or send a message with the word “subscribe” in the body to
@email{mps-discussion-request@@ravenbrook.com}.

The mailing list is archived and the archives are published on Ravenbrook's web site@footnote{http://mailman.ravenbrook.com/pipermail/mps-discussion/}.
@end itemize

@geindex building
@geindex compiling
@geindex installing

@node Contributing to the MPS,Release notes,Contact us,Top
@anchor{contributing doc}@anchor{1774}@anchor{contributing contributing}@anchor{31c}@anchor{contributing contributing-to-the-mps}@anchor{1775}
@chapter Contributing to the MPS


We are very happy to receive contributions to the Memory Pool System so
that we can improve it for everyone.

@menu
* Review:: 
* Licensing:: 
* Thank you:: 

@end menu

@node Review,Licensing,,Contributing to the MPS
@anchor{contributing review}@anchor{1776}
@section Review


The MPS is highly engineered and rigorously controlled in order to
prevent defects.  This approach has lead to an extremely small number of
bugs in production since its first commercial use in 1997.  There are a
fairly large number of rules, both low- and high-level that your code
must follow in order to be accepted.  These rules are the result of
continuous process improvement to prevent defects.  Unfortunately, we do
not have many of them published at present.  We apologise if you find it
frustrating that we do not accept your changes as they are.

The style guide in guide.impl.c.format@footnote{design/guide.impl.c.format.txt} contains basic rules for style.

@node Licensing,Thank you,Review,Contributing to the MPS
@anchor{contributing guide-impl-c-format}@anchor{1777}@anchor{contributing licensing}@anchor{1778}
@section Licensing


All contributions are deemed to have been made under the same license
as the material to which the contribution is made, unless you
expressly state otherwise in your contribution request.  In nearly all
cases this is the BSD 2-clause license@footnote{https://opensource.org/licenses/BSD-2-Clause}.  You retain the
copyright to such contributions.

@node Thank you,,Licensing,Contributing to the MPS
@anchor{contributing thank-you}@anchor{1779}
@section Thank you


Finally, thank you for making the MPS more useful to everyone.

@c validated with rst2html -v contributing.rst > /dev/null

@c end

@node Release notes,Introduction to memory management,Contributing to the MPS,Top
@anchor{release doc}@anchor{177a}@anchor{release id1}@anchor{177b}@anchor{release release-notes}@anchor{177c}
@chapter Release notes


@menu
* Release 1.118.0: Release 1 118 0. 
* Release 1.117.0: Release 1 117 0. 
* Release 1.116.0: Release 1 116 0. 
* Release 1.115.0: Release 1 115 0. 
* Release 1.114.0: Release 1 114 0. 
* Release 1.113.0: Release 1 113 0. 
* Release 1.112.0: Release 1 112 0. 
* Release 1.111.0: Release 1 111 0. 
* Release 1.110.0: Release 1 110 0. 

@end menu

@node Release 1 118 0,Release 1 117 0,,Release notes
@anchor{release release-1-118-0}@anchor{177d}@anchor{release release-notes-1-118}@anchor{177e}
@section Release 1.118.0


@menu
* New features:: 
* Interface changes:: 
* Other changes:: 

@end menu

@node New features,Interface changes,,Release 1 118 0
@anchor{release new-features}@anchor{177f}
@subsection New features



@enumerate 

@item 
New supported platforms:


@itemize *

@item 
@code{lia6gc} (Linux, ARM64, GCC).

@item 
@code{lia6ll} (Linux, ARM64, Clang/LLVM).

@item 
@code{xca6ll} (macOS, ARM64, Clang/LLVM).
@end itemize

See @ref{303,,Platform limitations} for limitations in the
support for Apple Hardened Runtime on @code{xca6ll}.

@item 
Support removed for platform:


@itemize *

@item 
@code{xci3ll} (macOS, IA-32, Clang/LLVM).
@end itemize

Support for this platform was removed in macOS 10.15 (Catalina),
making it inconvenient to develop and test.

@item 
The arena’s @ref{197,,spare commit limit} is now expressed as a
fraction of the @ref{190,,committed} memory (rather than a
fixed size, as previously). This allows the @ref{18f,,spare committed memory} to scale with the @ref{16ba,,working set} size. Set the spare
commit limit using the keyword argument @code{MPS_KEY_SPARE} to
@ref{52,,mps_arena_create_k()}, or the function
@ref{198,,mps_arena_spare_set()}, and query it using the function
@ref{189,,mps_arena_spare()}.

@item 
A new support tool, the `monitor', implements a graphical user
interface for analysis of @ref{db,,Telemetry}. This is
experimental: the implementation is likely to change in future
versions of the MPS. See @ref{737,,Monitor}.

@item 
The newly-public `transforms' feature updates references to a set
of objects throughout the automatically managed portion of the
heap, allowing them to be replaced by new versions. See
@ref{2be,,Transforms}.

@item 
The new function @ref{1a6,,mps_pool_walk()} visits all areas of
@ref{23,,formatted objects} in a pool using the
@ref{16f,,Scanning protocol}, support hot reloading and
serialization.  See @ref{bd1,,Walking formatted objects}.

@item 
An @ref{63,,allocation point} for a pool belonging to the class
@ref{62,,AMC (Automatic Mostly-Copying)} can now be configured so that allocations do not
provoke garbage collections, reducing the amount of re-hashing for
address-based hash tables using @ref{19a,,location dependency}. See
@ref{360,,Hash arrays}.

@item 
The new function @ref{1a9,,mps_addr_object()} allows clients to
discover the base pointer of an object from a pointer to anywhere
inside the object. This is intended to support stack tracing and
debugging for client programs that allocate their code on the
heap.

@item 
A @ref{4f,,virtual memory arena} can now be configured to call
functions when it acquires a new chunk of @ref{54,,address space},
and when it returns a chunk of address space to the operation
system. This is intended to support dynamic function tables in
Windows. See @ref{181,,Arena extension callbacks}.
@end enumerate

@node Interface changes,Other changes,New features,Release 1 118 0
@anchor{release interface-changes}@anchor{1780}
@subsection Interface changes



@enumerate 

@item 
The deprecated pool class MV (Manual Variable), and the deprecated
functions @code{mps_mv_free_size} and @code{mps_mv_size} have been
removed. Use @ref{10c,,MVFF (Manual Variable First Fit)} and the generic functions
@ref{1b7,,mps_pool_free_size()} and @ref{1b6,,mps_pool_total_size()}
instead.

@item 
The deprecated function @code{mps_tramp()} has been removed. The
MPS has had no need for a trampoline, and client programs have not
needed to take any special precautions before calling functions in
the MPS, since version 1.111.

@item 
The deprecated functions @code{mps_arena_expose()},
@code{mps_arena_unsafe_expose_remember_protection()} and
@code{mps_arena_unsafe_expose_restore_protection()} have been
removed. If you need access to protected memory for debugging a
fatal error, use @ref{d6,,mps_arena_postmortem()} instead.

@item 
The deprecated reservoir functions
@code{mps_ap_fill_with_reservoir_permit()},
@code{mps_reservoir_available()}, @code{mps_reservoir_limit()},
@code{mps_reservoir_limit_set()} and
@code{mps_reserve_with_reservoir_permit()}, have been removed.

@item 
The deprecated function @code{mps_fix()} has been removed. Use
the macro @ref{77,,MPS_FIX12()} instead.

@item 
The deprecated function @code{mps_telemetry_control()} has been
removed. Use @ref{2b3,,mps_telemetry_get()},
@ref{176,,mps_telemetry_set()} and @ref{2b4,,mps_telemetry_reset()}
instead.

@item 
The keyword argument @code{MPS_KEY_SPARE_COMMIT_LIMIT} to
@ref{52,,mps_arena_create_k()}, and the functions
@ref{320,,mps_arena_spare_commit_limit()} and
@ref{321,,mps_arena_spare_commit_limit_set()} are now deprecated. Use
@code{MPS_KEY_SPARE}, @ref{189,,mps_arena_spare()} and
@ref{198,,mps_arena_spare_set()} instead.

@item 
The format of the @ref{ba,,telemetry stream} has changed: Booleans
are no longer packed into bitfields, but are emitted as unsigned
bytes. This makes it possible to decode the telemetry stream using
the Python function struct.unpack()@footnote{https://docs.python.org/3/library/struct.html#struct.unpack}.

@item 
The functions @code{mps_formatted_objects_walk()} and
@ref{324,,mps_amc_apply()} are deprecated in favour of the new
function @ref{1a6,,mps_pool_walk()}.
@end enumerate

@node Other changes,,Interface changes,Release 1 118 0
@anchor{release other-changes}@anchor{1781}
@subsection Other changes



@enumerate 

@item 
On FreeBSD and Linux, if the MPS handles a signal while the client
program is blocked in a system call, the system call is
automatically restarted and does not fail with @code{EINTR}. See
@ref{d1,,Signal and exception handling issues}.

@item 
On FreeBSD and Linux, the MPS signal handlers no longer modify
@code{errno}. See GitHub issue #10@footnote{https://github.com/Ravenbrook/mps/issues/10}.

@item 
The MPS now builds with Clang 10 and
@code{-Wimplicit-int-float-conversion}. See GitHub issue #51@footnote{https://github.com/Ravenbrook/mps/issues/51}.

@item 
The MPS now builds with @code{clang -Wcomma}. See GitHub issue #47@footnote{https://github.com/Ravenbrook/mps/issues/47}.
@end enumerate

@node Release 1 117 0,Release 1 116 0,Release 1 118 0,Release notes
@anchor{release release-1-117-0}@anchor{1782}@anchor{release release-notes-1-117}@anchor{1783}
@section Release 1.117.0


@menu
* New features: New features<2>. 
* Interface changes: Interface changes<2>. 
* Other changes: Other changes<2>. 

@end menu

@node New features<2>,Interface changes<2>,,Release 1 117 0
@anchor{release id2}@anchor{1784}
@subsection New features



@enumerate 

@item 
On FreeBSD, Linux and macOS, the MPS is now able to run in the
child process after @code{fork()}. See @ref{1ff,,Fork safety}.

@item 
The MPS now supports Windows Vista or later; it no longer supports
Windows XP. (Microsoft’s own support for Windows XP expired in April 2014@footnote{https://www.microsoft.com/en-gb/windowsforbusiness/end-of-xp-support}.) This is so that we can use InitOnceExecuteOnce()@footnote{https://docs.microsoft.com/en-us/windows/desktop/api/synchapi/nf-synchapi-initonceexecuteonce} to
ensure thread-safe initialization.
@end enumerate

@node Interface changes<2>,Other changes<2>,New features<2>,Release 1 117 0
@anchor{release id3}@anchor{1785}
@subsection Interface changes



@enumerate 

@item 
The pool class MV (Manual Variable) is now deprecated.
@end enumerate

@node Other changes<2>,,Interface changes<2>,Release 1 117 0
@anchor{release id4}@anchor{1786}
@subsection Other changes



@enumerate 

@item 
References from the MPS’s own stack frames no longer @ref{1e5,,pin} objects allocated by the @ref{d0,,client program} in
moving pools, which prevented them from moving. See job003525@footnote{https://www.ravenbrook.com/project/mps/issue/job003525/}.

@item 
Creation of @ref{16,,arenas} is now thread-safe on Windows. See
job004056@footnote{https://www.ravenbrook.com/project/mps/issue/job004056/}.

@item 
@ref{fe,,AWL (Automatic Weak Linked)} and @ref{353,,LO (Leaf Object)} pools now detect (and assert on)
invalid @ref{61,,exact references}. See job004070@footnote{https://www.ravenbrook.com/project/mps/issue/job004070/}.

@item 
The MPS now compiles without warnings on GCC version 7 with
@code{-Wextra}. See job004076@footnote{https://www.ravenbrook.com/project/mps/issue/job004076/}.

@item 
Deprecated function @ref{19e,,mps_arena_roots_walk()} no longer causes
@ref{322,,mps_arena_formatted_objects_walk()} to miss some objects. See
job004090@footnote{https://www.ravenbrook.com/project/mps/issue/job004090/}.
@end enumerate

@node Release 1 116 0,Release 1 115 0,Release 1 117 0,Release notes
@anchor{release release-1-116-0}@anchor{1787}@anchor{release release-notes-1-116}@anchor{1788}
@section Release 1.116.0


@menu
* New features: New features<3>. 
* Interface changes: Interface changes<3>. 
* Other changes: Other changes<3>. 

@end menu

@node New features<3>,Interface changes<3>,,Release 1 116 0
@anchor{release id5}@anchor{1789}
@subsection New features



@enumerate 

@item 
The MPS now measures the mortality of a @ref{e1,,generation} each
time it is @ref{163a,,collected}, and maintains a moving average. This
means that it is no longer important to provide an accurate
estimate of the mortality when creating a @ref{e2,,generation chain}
by calling @ref{225,,mps_chain_create()}.

@item 
The MPS no longer supports Linux 2.4 and 2.5. (These versions used
LinuxThreads@footnote{https://en.wikipedia.org/wiki/LinuxThreads} instead of POSIX threads; all major distributions
have long since ceased to support these versions and so it is no
longer convenient to test against them.) See
@ref{12,,Supported target platforms}.

@item 
New function @ref{d6,,mps_arena_postmortem()} assists with postmortem
debugging.

@item 
New function @ref{1a7,,mps_arena_busy()} assists debugging of re-entry
errors in dynamic function table callbacks on Windows on x86-64.
@end enumerate

@node Interface changes<3>,Other changes<3>,New features<3>,Release 1 116 0
@anchor{release id6}@anchor{178a}
@subsection Interface changes



@enumerate 

@item 
The pool class @ref{27b,,SNC (Stack No Checking)} is no longer deprecated.

@item 
Allocation frames are no longer deprecated. See @ref{27a,,Allocation frames}.

@item 
On Linux and FreeBSD, it is now possible to configure the signals
used to suspend and resume threads. See @ref{d1,,Signal and exception handling issues}.
@end enumerate

@node Other changes<3>,,Interface changes<3>,Release 1 116 0
@anchor{release id7}@anchor{178b}
@subsection Other changes



@enumerate 

@item 
It is now possible to register a @ref{99,,thread} with the MPS
multiple times on OS X, thus supporting the use case where a
program that does not use the MPS is calling into MPS-using code
from multiple threads. (This was already supported on other
platforms.) See job003559@footnote{https://www.ravenbrook.com/project/mps/issue/job003559/}.

@item 
The function @ref{322,,mps_arena_formatted_objects_walk()} walks the
@ref{23,,formatted objects} in all @ref{18,,pools}. Previously this was
not implemented for @ref{16c,,AMS (Automatic Mark and Sweep)} pools. See job003738@footnote{https://www.ravenbrook.com/project/mps/issue/job003738/}.

@item 
Objects in @ref{27b,,SNC (Stack No Checking)} pools are no longer scanned after their
@ref{27d,,allocation frame} is popped, and so do not keep objects in
automatically managed pools alive. See job003883@footnote{https://www.ravenbrook.com/project/mps/issue/job003883/}.

@item 
When the MPS @ref{163a,,collects} a set of @ref{e1,,generations}, it
@ref{221,,condemns} only the @ref{185,,blocks} in those
generations. Previously, it also condemned blocks that happened to
share a region of memory with blocks currently or formerly
allocated in those generations. See job004000@footnote{https://www.ravenbrook.com/project/mps/issue/job004000/}.

@item 
Memory in @ref{63,,allocation points} no longer contributes to the
decision to start a @ref{f,,garbage collection}, avoiding wasted
work repeatedly collecting generations with very small capacities.
See job004007@footnote{https://www.ravenbrook.com/project/mps/issue/job004007/}.

@item 
The MPS no longer considers @ref{163a,,collecting} the world
again, without allowing the @ref{d0,,client program} to run first.
See job004011@footnote{https://www.ravenbrook.com/project/mps/issue/job004011/}.

@item 
@ref{97,,Roots} created by @ref{219,,mps_root_create_thread_scanned()}
no longer cause an assertion failure. See job004036@footnote{https://www.ravenbrook.com/project/mps/issue/job004036/}.

@item 
The MPS test suite now compiles and passes with GCC 6.1. See job004037@footnote{https://www.ravenbrook.com/project/mps/issue/job004037/}.

@item 
The MPS no longer passes an uninitialized variable to
@code{thread_swap_exception_ports()} on OS X. See job004040@footnote{https://www.ravenbrook.com/project/mps/issue/job004040/}.
@end enumerate

@node Release 1 115 0,Release 1 114 0,Release 1 116 0,Release notes
@anchor{release release-1-115-0}@anchor{178c}@anchor{release release-notes-1-115}@anchor{178d}
@section Release 1.115.0


@menu
* New features: New features<4>. 
* Interface changes: Interface changes<4>. 
* Other changes: Other changes<4>. 

@end menu

@node New features<4>,Interface changes<4>,,Release 1 115 0
@anchor{release id8}@anchor{178e}
@subsection New features



@enumerate 

@item 
The MPS now provides control over the maximum time that operations
within an arena may pause the @ref{d0,,client program} for. This can
be specified by the new function @ref{180,,mps_arena_pause_time_set()}
or by passing the new keyword argument
@code{MPS_KEY_PAUSE_TIME} to @ref{52,,mps_arena_create_k()}. The
current value can be retrieved by the new function
@ref{193,,mps_arena_pause_time()}.

The maximum pause time defaults to 0.1 seconds. For the old
behaviour (whereby the MPS always returned to the @ref{d0,,client program} as soon as possible), set it to zero.

@item 
New supported platforms @code{fri3ll} (FreeBSD, IA-32, Clang/LLVM)
and @code{fri6ll} (FreeBSD, x86-64, Clang/LLVM).

@item 
When creating an @ref{62,,AMC (Automatic Mostly-Copying)} pool, @ref{166,,mps_pool_create_k()}
accepts the new keyword argument @code{MPS_KEY_EXTEND_BY},
specifying the minimum size of the memory segments that the pool
requests from the @ref{16,,arena}.

@item 
The function @ref{52,,mps_arena_create_k()} accepts two new
@ref{53,,keyword arguments}. @code{MPS_KEY_COMMIT_LIMIT}
sets the @ref{156,,commit limit} for the arena, and
@code{MPS_KEY_SPARE_COMMIT_LIMIT} sets the @ref{197,,spare commit limit} for the arena.

@item 
New area scanning functions @ref{1ef,,mps_scan_area()},
@ref{1f2,,mps_scan_area_masked()}, @ref{1f3,,mps_scan_area_tagged()},
@ref{1f4,,mps_scan_area_tagged_or_zero()} for use when scanning,
especially when scanning threads and @ref{7d,,tagged references}.

@item 
New thread root functions @ref{a9,,mps_root_create_thread()},
@ref{1ec,,mps_root_create_thread_tagged()}, and
@ref{219,,mps_root_create_thread_scanned()} allow flexible scanning of
thread stacks and registers in any format, with convenient
implementations provided for @ref{7d,,tagged references}.

@item 
New function @ref{330,,mps_root_create_table_tagged()} for tables of roots
containing @ref{7d,,tagged references}.

@item 
New area root functions @ref{206,,mps_root_create_area()} and
@ref{21a,,mps_root_create_area_tagged()} for areas of memory
that can be scanned by area scanning functions.
@end enumerate

@node Interface changes<4>,Other changes<4>,New features<4>,Release 1 115 0
@anchor{release id9}@anchor{178f}
@subsection Interface changes



@enumerate 

@item 
The pool class MV (Manual Variable) is no longer deprecated.

@item 
The type of pool classes is now @ref{1b4,,mps_pool_class_t}. The old
name @ref{328,,mps_class_t} is still available via a @code{typedef},
but is deprecated.

@item 
The functions @code{mps_mv_free_size}, @code{mps_mv_size},
@ref{329,,mps_mvff_free_size()}, @ref{32a,,mps_mvff_size()},
@ref{32b,,mps_mvt_free_size()} and @ref{32c,,mps_mvt_size()} are now
deprecated in favour of the generic functions
@ref{1b7,,mps_pool_free_size()} and @ref{1b6,,mps_pool_total_size()}.

@item 
The function @ref{32d,,mps_root_create_reg()} is deprecated in favour
of @ref{1ec,,mps_root_create_thread_tagged()}.

@item 
The function @ref{331,,mps_root_create_table_masked()} is deprecated in
favour of @ref{330,,mps_root_create_table_tagged()}.

@item 
The @ref{27b,,SNC (Stack No Checking)} pool class now implements
@ref{1b6,,mps_pool_total_size()} and @ref{1b7,,mps_pool_free_size()}.

@item 
The (undocumented) reservoir functions
@code{mps_ap_fill_with_reservoir_permit()},
@code{mps_reservoir_available()}, @code{mps_reservoir_limit()},
@code{mps_reservoir_limit_set()}, and
@code{mps_reserve_with_reservoir_permit()}, together with the
@code{has_reservoir_permit} arguments to @ref{25f,,mps_sac_alloc()} and
@ref{260,,MPS_SAC_ALLOC_FAST()} are now deprecated.
@end enumerate

@node Other changes<4>,,Interface changes<4>,Release 1 115 0
@anchor{release id10}@anchor{1790}
@subsection Other changes



@enumerate 

@item 
@ref{18e,,mps_arena_committed()} now returns a meaningful value (the
amount of memory marked as in use in the page tables) for
@ref{4d,,client arenas}. See job001887@footnote{https://www.ravenbrook.com/project/mps/issue/job001887/}.

@item 
@ref{62,,AMC (Automatic Mostly-Copying)} pools now assert that exact references into the
pool are aligned to the pool’s alignment. See job002175@footnote{https://www.ravenbrook.com/project/mps/issue/job002175/}.

@item 
Internal calculation of the address space available to the MPS no
longer takes time proportional to the number of times the arena has
been extended, speeding up allocation when memory is tight. See
job003814@footnote{https://www.ravenbrook.com/project/mps/issue/job003814/}.

@item 
Setting @code{MPS_KEY_SPARE} for a @ref{10c,,MVFF (Manual Variable First Fit)} pool now
works. See job003870@footnote{https://www.ravenbrook.com/project/mps/issue/job003870/}.

@item 
In the @ref{162,,hot} (production) variety,
@ref{1b7,,mps_pool_free_size()} now returns the correct result for
@ref{fe,,AWL (Automatic Weak Linked)} and @ref{353,,LO (Leaf Object)} pools. See job003884@footnote{https://www.ravenbrook.com/project/mps/issue/job003884/}.

@item 
When the arena is out of memory and cannot be extended without
hitting the @ref{156,,commit limit}, the MPS now returns
@ref{155,,MPS_RES_COMMIT_LIMIT} rather than substituting
@ref{153,,MPS_RES_RESOURCE}. See job003899@footnote{https://www.ravenbrook.com/project/mps/issue/job003899/}.

@item 
Unfinalizable objects can no longer be registered for finalization.
Previously the objects would be registered but never finalized. See
job003865@footnote{https://www.ravenbrook.com/project/mps/issue/job003865/}.

@item 
@ref{d2,,mps_arena_has_addr()} now returns the correct result for
objects allocated from the @ref{355,,MFS (Manual Fixed Small)}, MV (Manual Variable),
and @ref{10c,,MVFF (Manual Variable First Fit)} pools. See job003866@footnote{https://www.ravenbrook.com/project/mps/issue/job003866/}.

@item 
The MPS can now make use of @ref{18f,,spare committed memory} even if
it is @ref{190,,mapped} at an unhelpful address, by unmapping it and
remapping at a better address. See job003898@footnote{https://www.ravenbrook.com/project/mps/issue/job003898/}.

@item 
@ref{19c,,mps_arena_step()} now always considers starting a new
@ref{f,,garbage collection} if the remaining idle time is long
enough to complete it. (Previously, if there was already a
collection in progress when @ref{19c,,mps_arena_step()} was called, it
would finish the collection but not consider starting a new one.)
See job003934@footnote{https://www.ravenbrook.com/project/mps/issue/job003934/}.

@item 
The MPS no longer carries out @ref{f,,garbage collections} when there
is no collection work to be done. See job003938@footnote{https://www.ravenbrook.com/project/mps/issue/job003938/}.

@item 
The MPS is less aggressive in its use of hardware memory protection
to maintain @ref{214,,write barrier} to speed up future collections.
This is particularly important for OS X, where memory protection
operations are very expensive.  See job003371@footnote{https://www.ravenbrook.com/project/mps/issue/job003371/} and job003975@footnote{https://www.ravenbrook.com/project/mps/issue/job003975/}.

@item 
The MPS coalesces memory protection, reducing the number of system
calls. This markedly improves real run time on operating systems
where memory protection operations are very expensive, such as OS
X, but also has a significant effect on Linux. See job003371@footnote{https://www.ravenbrook.com/project/mps/issue/job003371/} and
job003975@footnote{https://www.ravenbrook.com/project/mps/issue/job003975/}.
@end enumerate

@node Release 1 114 0,Release 1 113 0,Release 1 115 0,Release notes
@anchor{release release-1-114-0}@anchor{1791}@anchor{release release-notes-1-114}@anchor{1792}
@section Release 1.114.0


@menu
* New features: New features<5>. 
* Interface changes: Interface changes<5>. 
* Other changes: Other changes<5>. 

@end menu

@node New features<5>,Interface changes<5>,,Release 1 114 0
@anchor{release id11}@anchor{1793}
@subsection New features



@enumerate 

@item 
@ref{9f,,Ambiguous} @ref{1ac,,interior pointers}
now keep objects in @ref{62,,AMC (Automatic Mostly-Copying)} and @ref{89,,AMCZ (Automatic Mostly-Copying Zero-rank)} pools
alive.

This means that if the compiler optimizes away a pointer to the
base of an object, leaving an interior pointer as the only
reference keeping the object alive, this does not cause the object
to be incorrectly collected. Or, if you are writing your own
compiler, you can now perform such an optimization safely.

If you require the old behaviour (in which ambiguous interior
pointers were ignored) then you can set the
@code{MPS_KEY_INTERIOR} keyword argument to @code{FALSE} when
calling @ref{166,,mps_pool_create_k()}.

@item 
The logic for deciding which generations should be collected has
changed. Now, a chain may be scheduled for collection if the new
size of `any' of its generations exceeds its capacity, and when a
chain is collected, all generations are collected up to, and
including, the highest generation whose new size exceeds its
capacity. This ensures that all generations are collected reliably
on chains where there is no allocation into the nursery generation.
See @ref{226,,Scheduling of collections}.

(Previously, only the nursery generation in each chain
was considered, and a chain was collected up to, but not including,
the lowest generation whose new size was within its capacity.)

As a result of this change, we recommend that you retune your
generation sizes. (This is not necessary, but may improve
performance.)

@item 
New pool introspection functions @ref{1b7,,mps_pool_free_size()} and
@ref{1b6,,mps_pool_total_size()}.
@end enumerate

@node Interface changes<5>,Other changes<5>,New features<5>,Release 1 114 0
@anchor{release id12}@anchor{1794}
@subsection Interface changes



@enumerate 

@item 
The granularity with which the arena manages memory can now be
specified using the @code{MPS_KEY_ARENA_GRAIN_SIZE} keyword
argument to @ref{52,,mps_arena_create_k()}. See
@ref{4e,,mps_arena_class_cl()} and @ref{50,,mps_arena_class_vm()}.

@item 
There is now a default value (currently 256 @ref{186,,megabytes})
for the @code{MPS_KEY_ARENA_SIZE} keyword argument to
@ref{52,,mps_arena_create_k()} when creating a virtual memory arena.
See @ref{50,,mps_arena_class_vm()}.

@item 
The keyword argument @code{MPS_KEY_AMS_SUPPORT_AMBIGUOUS} now
defaults to @code{TRUE} in order to better support the general case:
the value @code{FALSE} is appropriate only when you know that all
references are exact. See @ref{16c,,AMS (Automatic Mark and Sweep)}.

@item 
There is now a default value for the
@code{MPS_KEY_AWL_FIND_DEPENDENT} keyword argument to
@ref{166,,mps_pool_create_k()} when creating an @ref{fe,,AWL (Automatic Weak Linked)} pool.
The default value is a function that always returns @code{NULL}
(meaning that there is no dependent object).

@item 
It is now possible to configure the alignment of objects allocated
in an MV (Manual Variable) pool, by passing the
@code{MPS_KEY_ALIGN} keyword argument to
@ref{166,,mps_pool_create_k()}.

@item 
The @ref{10c,,MVFF (Manual Variable First Fit)} pool class takes a new keyword argument
@code{MPS_KEY_SPARE}. This specifies the maximum proportion of
memory that the pool will keep spare for future allocations.

@item 
The alignment requirements for @ref{10c,,MVFF (Manual Variable First Fit)} and @ref{1bc,,MVT (Manual Variable Temporal)}
pools have been relaxed on the platforms @code{w3i3mv} and @code{w3i6mv}.
On all platforms it is now possible to specify alignments down to
@code{sizeof(void *)} as the alignment for pools of these classes.

@item 
The sizes of the templates in a @ref{143,,mps_pool_debug_option_s}
structure no longer have to be related to the alignment of the
pools that they are used with. This makes it easier to reuse these
structures.
@end enumerate

@node Other changes<5>,,Interface changes<5>,Release 1 114 0
@anchor{release id13}@anchor{1795}
@subsection Other changes



@enumerate 

@item 
The @ref{16c,,AMS (Automatic Mark and Sweep)} pool class no longer triggers the assertion
@code{!AMS_IS_INVALID_COLOUR(seg, i)} under rare circumstances
(namely, detaching an @ref{63,,allocation point} from a @ref{1696,,grey}
segment when @code{MPS_KEY_AMS_SUPPORT_AMBIGUOUS} is
@code{FALSE}). See job001549@footnote{https://www.ravenbrook.com/project/mps/issue/job001549/}.

@item 
@ref{19e,,mps_arena_roots_walk()} no longer triggers an assertion
failure when run twice in succession. See job003496@footnote{https://www.ravenbrook.com/project/mps/issue/job003496/}.

@item 
The alignment of @ref{fe,,AWL (Automatic Weak Linked)} pools is now configurable via the
object format, as documented, and is no longer always
@ref{6f,,MPS_PF_ALIGN}. See job003745@footnote{https://www.ravenbrook.com/project/mps/issue/job003745/}.

@item 
The debugging version of the @ref{10c,,MVFF (Manual Variable First Fit)} pool class,
@ref{145,,mps_class_mvff_debug()}, no longer triggers an assertion
failure if you allocate a large object. See job003751@footnote{https://www.ravenbrook.com/project/mps/issue/job003751/}.

@item 
@code{mpseventtxt} now successfully processes a telemetry log
containing multiple labels associated with the same address. See
job003756@footnote{https://www.ravenbrook.com/project/mps/issue/job003756/}.

@item 
@ref{16c,,AMS (Automatic Mark and Sweep)}, @ref{fe,,AWL (Automatic Weak Linked)} and @ref{353,,LO (Leaf Object)} pools get
reliably collected, even in the case where the pool is the only
pool on its generation chain and is allocating into some generation
other than the nursery. See job003771@footnote{https://www.ravenbrook.com/project/mps/issue/job003771/}.

@item 
Allocation into @ref{fe,,AWL (Automatic Weak Linked)} pools again reliably provokes
garbage collections of the generation that the pool belongs to. (In
version 1.113, the generation would only be collected if a pool of
some other class allocated into it.) See job003772@footnote{https://www.ravenbrook.com/project/mps/issue/job003772/}.

@item 
All unreachable objects in @ref{353,,LO (Leaf Object)} pools are finalized.
(Previously, objects on a segment attached to an allocation point
were not finalized until the allocation point was full.) See
job003773@footnote{https://www.ravenbrook.com/project/mps/issue/job003773/}.

@item 
The @ref{1bc,,MVT (Manual Variable Temporal)} and @ref{10c,,MVFF (Manual Variable First Fit)} pool classes are now
around 25% faster (in our benchmarks) than they were in version
1.113.

@item 
The default assertion handler in the default @ref{160,,plinth} now
flushes the telemetry stream before aborting. See
@ref{161,,mps_lib_assert_fail()}.

@item 
Garbage collection performance is substantially improved in the
situation where the arena has been extended many times. Critical
operations now take time logarithmic in the number of times the
arena has been extended (rather than linear, as in version 1.113
and earlier). See job003554@footnote{https://www.ravenbrook.com/project/mps/issue/job003554/}.
@end enumerate

@node Release 1 113 0,Release 1 112 0,Release 1 114 0,Release notes
@anchor{release release-1-113-0}@anchor{1796}@anchor{release release-notes-1-113}@anchor{1797}
@section Release 1.113.0


@menu
* New features: New features<6>. 
* Interface changes: Interface changes<6>. 
* Other changes: Other changes<6>. 

@end menu

@node New features<6>,Interface changes<6>,,Release 1 113 0
@anchor{release id14}@anchor{1798}
@subsection New features



@enumerate 

@item 
In previous releases there was an implicit connection between
blocks allocated by @ref{fe,,AWL (Automatic Weak Linked)} and @ref{353,,LO (Leaf Object)} pools, and
blocks allocated by other automatically managed pool classes.

In particular, blocks allocated by AWL and LO pools were garbage
collected together with blocks allocated by @ref{16c,,AMS (Automatic Mark and Sweep)} pools,
and blocks allocated by @ref{62,,AMC (Automatic Mostly-Copying)} pools in generation 1 of
their chains.

This is no longer the case: to arrange for blocks to be collected
together you need to ensure that they are allocated in the `same'
generation chain, using the @code{MPS_KEY_CHAIN} and
@code{MPS_KEY_GEN} keyword arguments to
@ref{166,,mps_pool_create_k()}.

So if you have code like this:

@example
res = mps_pool_create(&my_amc, arena, mps_class_amc(), my_chain);
res = mps_pool_create(&my_awl, arena, mps_class_awl());
@end example

and you want to retain the connection between these pools, then you
must ensure that they use the same generation chain:

@example
MPS_ARGS_BEGIN(args) @{
  MPS_ARGS_ADD(args, MPS_KEY_CHAIN, my_chain);
  res = mps_pool_create_k(&my_amc, arena, mps_class_amc(), args);
@} MPS_ARGS_END(args);

MPS_ARGS_BEGIN(args) @{
  MPS_ARGS_ADD(args, MPS_KEY_CHAIN, my_chain);
  MPS_ARGS_ADD(args, MPS_KEY_GEN, 1);
  res = mps_pool_create_k(&my_awl, arena, mps_class_awl(), args);
@} MPS_ARGS_END(args);
@end example
@end enumerate

@node Interface changes<6>,Other changes<6>,New features<6>,Release 1 113 0
@anchor{release id15}@anchor{1799}
@subsection Interface changes



@enumerate 

@item 
When creating a list of keyword arguments, there is no longer any
need to call @ref{333,,MPS_ARGS_DONE()}. See @ref{57,,Keyword arguments}.

@item 
When creating an automatically managed pool using
@ref{166,,mps_pool_create_k()}, it is no longer necessary to pass in a
generation chain. The arena has a default generation chain and this
is used by all automatically managed pools where no generation
chain was specified.

@item 
It is now possible to specify a generation chain for
@ref{fe,,AWL (Automatic Weak Linked)} and @ref{353,,LO (Leaf Object)} pool classes, by using the
optional @code{MPS_KEY_CHAIN} keyword argument to
@ref{166,,mps_pool_create_k()}.

@item 
It is now possible to specify which generation the @ref{16c,,AMS (Automatic Mark and Sweep)},
@ref{fe,,AWL (Automatic Weak Linked)}, and @ref{353,,LO (Leaf Object)} pool classes allocate new
objects into, using the optional @code{MPS_KEY_GEN} keyword
argument to @ref{166,,mps_pool_create_k()}.
@end enumerate

@node Other changes<6>,,Interface changes<6>,Release 1 113 0
@anchor{release id16}@anchor{179a}
@subsection Other changes



@enumerate 

@item 
The MPS now retains some unused memory instead of returning it to
the operating system. This reduces unnecessary overhead due to
system calls, thrashing the operating system’s page table, and
zeroing memory when re-allocated. See job003700@footnote{https://www.ravenbrook.com/project/mps/issue/job003700/}.
@end enumerate

@node Release 1 112 0,Release 1 111 0,Release 1 113 0,Release notes
@anchor{release release-1-112-0}@anchor{179b}@anchor{release release-notes-1-112}@anchor{179c}
@section Release 1.112.0


@menu
* New features: New features<7>. 
* Interface changes: Interface changes<7>. 
* Other changes: Other changes<7>. 

@end menu

@node New features<7>,Interface changes<7>,,Release 1 112 0
@anchor{release id17}@anchor{179d}
@subsection New features



@enumerate 

@item 
New supported platform @code{lii6ll} (Linux, x86-64, Clang/LLVM).

@item 
On Windows, you can now request that the MPS allocate address space
from the top down, allowing a 32-bit executable linked with
@code{/LARGEADDRESSAWARE} to use the top half of the address space.
Use the keyword argument @code{MPS_KEY_VMW3_TOP_DOWN} when
creating an arena of class @ref{50,,mps_arena_class_vm()}.

@item 
On OS X, multi-threaded programs are now supported. See
@ref{29,,Threads}.

@item 
On OS X, you can now debug the MPS using @code{lldb}.
@end enumerate

@node Interface changes<7>,Other changes<7>,New features<7>,Release 1 112 0
@anchor{release id18}@anchor{179e}
@subsection Interface changes



@enumerate 

@item 
In the @ref{162,,hot} (production) variety, the default assertion handler
now prints messages to standard error but does `not' terminate the
program. Even though assertions indicate serious problems in the
program, an end-user does not always want an application to terminate when
there is a chance to shut down safely and save work, or even to limp
along indefinitely.  See @ref{15f,,Assertion handling}.

@item 
The behaviour when an assertion is triggered is now configurable in
the default @ref{160,,plinth} by installing an assertion handler. See
@ref{164,,mps_lib_assert_fail_install()}.

@item 
Functions that take a variable number of arguments
(@ref{335,,mps_arena_create()}, @ref{337,,mps_pool_create()},
@ref{339,,mps_ap_create()}) and their @code{va_list} alternatives
(@ref{336,,mps_arena_create_v()} etc.) are now deprecated in favour of
functions that use a @ref{53,,keyword argument} interface
(@ref{52,,mps_arena_create_k()}, @ref{166,,mps_pool_create_k()},
@ref{af,,mps_ap_create_k()}).

Similarly, the object format variant structures
(@ref{33b,,mps_fmt_A_s} etc.) and the functions that take them as
arguments (@ref{33c,,mps_fmt_create_A()} etc.) are now deprecated in
favour of @ref{13f,,mps_fmt_create_k()}.

The new interfaces provide better reporting of errors, default
values for arguments, and forward compatibility. See
@ref{57,,Keyword arguments}.

The old interfaces continue to be supported for now, but new
features will become available through the keyword interface only.

@item 
@ref{355,,MFS (Manual Fixed Small)} pools no longer refuse to manage blocks that are
smaller than the platform alignment. They now round up smaller
sizes internally if necessary.

@item 
@ref{1bc,,MVT (Manual Variable Temporal)} pools now allow the client to specify the alignment
of blocks. Use the keyword argument @code{MPS_KEY_ALIGN} when
creating a pool of class @ref{137,,mps_class_mvt()}.

@item 
On OS X, signals are no longer used for handling memory protection
exceptions. This means that programs are free to handle @code{SIGBUS},
but must not install a thread-local Mach exception handler for
@code{EXC_BAD_ACCESS} exceptions. See @ref{d1,,Signal and exception handling issues}.

@item 
On OS X, when debugging with @code{gdb}, you no longer need to turn on
@code{dont-handle-bad-access} or to request special handling of
@code{SIGBUS}.
@end enumerate

@node Other changes<7>,,Interface changes<7>,Release 1 112 0
@anchor{release id19}@anchor{179f}
@subsection Other changes



@enumerate 

@item 
On Windows, an execute exception no longer triggers an assertion.
See job003301@footnote{https://www.ravenbrook.com/project/mps/issue/job003301/}.

@item 
Rehashing of large address-based hash tables no longer provokes a
nursery collection that immediately renders the hash table stale
again. See job003435@footnote{https://www.ravenbrook.com/project/mps/issue/job003435/}.

@item 
An @ref{1bc,,MVT (Manual Variable Temporal)} pool no longer triggers an assertion failure
when it runs out of space on its reserved block queue. See
job003486@footnote{https://www.ravenbrook.com/project/mps/issue/job003486/}.

@item 
The @code{-i} and @code{-o} options no longer cause
@code{mpseventsql} to crash. See job003507@footnote{https://www.ravenbrook.com/project/mps/issue/job003507/}.

@item 
On Windows, telemetry files now have correct clock values.
Previously the top 32 bits were incorrectly output as zero. See
job003519@footnote{https://www.ravenbrook.com/project/mps/issue/job003519/}.

@item 
On 64-bit Windows, it’s no longer possible to get a stack overflow
exception while the MPS is holding the arena lock. See job003640@footnote{https://www.ravenbrook.com/project/mps/issue/job003640/}.
@end enumerate

@node Release 1 111 0,Release 1 110 0,Release 1 112 0,Release notes
@anchor{release release-1-111-0}@anchor{17a0}@anchor{release release-notes-1-111}@anchor{17a1}
@section Release 1.111.0


@menu
* New features: New features<8>. 
* Interface changes: Interface changes<8>. 
* Other changes: Other changes<8>. 

@end menu

@node New features<8>,Interface changes<8>,,Release 1 111 0
@anchor{release id20}@anchor{17a2}
@subsection New features



@enumerate 

@item 
Reporting features have been removed from the @ref{28e,,mpseventcnv} utility. Instead, the telemetry system
comes with two new utility programs to assist with reporting and
analysis: @ref{28f,,mpseventtxt} converts an
event stream into human-readable form, and @ref{290,,mpseventsql} loads an event stream into a SQLite
database for further analysis. See @ref{db,,Telemetry}.

@item 
The new pool class @ref{355,,MFS (Manual Fixed Small)} provides manually managed
allocation of fixed-size objects.

@item 
The new pool class @ref{1bc,,MVT (Manual Variable Temporal)} provides manually managed
allocation of variable-size objects using a `temporal fit'
allocation policy (that is, objects that are allocated together are
expected to be freed together).
@end enumerate

@node Interface changes<8>,Other changes<8>,New features<8>,Release 1 111 0
@anchor{release id21}@anchor{17a3}
@subsection Interface changes



@enumerate 

@item 
It is no longer necessary for client programs to use
@code{mps_tramp()} to ensure that exceptions due to barrier hits
are caught. This function is now deprecated.

@item 
You can set the environment variable
@geindex MPS_TELEMETRY_CONTROL
@geindex environment variable; MPS_TELEMETRY_CONTROL
@ref{288,,MPS_TELEMETRY_CONTROL} to @code{all} to make the telemetry
system output all events. See @ref{db,,Telemetry}.

@item 
New functions @ref{2b3,,mps_telemetry_get()},
@ref{176,,mps_telemetry_set()} and @ref{2b4,,mps_telemetry_reset()}
provide a more convenient interface to telemetry control than
@code{mps_telemetry_control()}, which is now deprecated. See
@ref{db,,Telemetry}.

@item 
The pool classes MV (Manual Variable) and @ref{27b,,SNC (Stack No Checking)} are now
deprecated.

@item 
Allocation frames are now deprecated. See @ref{27a,,Allocation frames}.

@item 
Additionally, the functions @code{mps_arena_expose()},
@code{mps_arena_unsafe_expose_remember_protection()},
@code{mps_arena_unsafe_restore_protection()},
@ref{19e,,mps_arena_roots_walk()}, and @code{mps_fix()} are now
deprecated.
@end enumerate

@node Other changes<8>,,Interface changes<8>,Release 1 111 0
@anchor{release id22}@anchor{17a4}
@subsection Other changes



@enumerate 

@item 
@ref{19c,,mps_arena_step()} no longer unclamps the arena as a side
effect. If the arena is clamped or parked before calling
@ref{19c,,mps_arena_step()}, it is clamped afterwards. See job003320@footnote{https://www.ravenbrook.com/project/mps/issue/job003320/}.

@item 
The ambiguous stack scanner, @ref{32f,,mps_stack_scan_ambig()}, no
longer asserts on Linux when there are multiple threads. See
job003412@footnote{https://www.ravenbrook.com/project/mps/issue/job003412/}.

@item 
It is no longer possible for the “ramp” allocation pattern,
@ref{26f,,mps_alloc_pattern_ramp()}, to get stuck. Now
@ref{274,,mps_ap_alloc_pattern_end()} reliably clears this pattern.
See job003454@footnote{https://www.ravenbrook.com/project/mps/issue/job003454/}.

@item 
The build system now correctly detects the FreeBSD operating system
running on the x86-64 architecture, for FreeBSD version 9.1 or
later. See job003473@footnote{https://www.ravenbrook.com/project/mps/issue/job003473/}.
@end enumerate

@node Release 1 110 0,,Release 1 111 0,Release notes
@anchor{release release-1-110-0}@anchor{17a5}@anchor{release release-notes-1-110}@anchor{17a6}
@section Release 1.110.0


@menu
* New features: New features<9>. 
* Interface changes: Interface changes<9>. 

@end menu

@node New features<9>,Interface changes<9>,,Release 1 110 0
@anchor{release id23}@anchor{17a7}
@subsection New features



@enumerate 

@item 
New supported platforms:


@itemize *

@item 
@code{fri6gc} (FreeBSD, x86-64, GCC)

@item 
@code{lii6gc} (Linux, x86-64, GCC)

@item 
@code{w3i6mv} (Windows, x86-64, Microsoft Visual C)

@item 
@code{xci3ll} (OS X, IA-32, Clang/LLVM)

@item 
@code{xci6gc} (OS X, x86-64, GCC)

@item 
@code{xci6ll} (OS X, x86-64, Clang/LLVM)
@end itemize

@item 
Support removed for platforms:


@itemize *

@item 
@code{iam4cc} (Irix 6, MIPS R4000, MIPSpro C)

@item 
@code{lii3eg} (Linux, IA-32, EGCS)

@item 
@code{lippgc} (Linux, PowerPC, GCC)

@item 
@code{o1alcc} (OSF/1, Alpha, Digital C)

@item 
@code{o1algc} (OSF/1, Alpha, GCC)

@item 
@code{s7ppmw} (System 7, PowerPC, MetroWerks C)

@item 
@code{sos8gc} (Solaris, SPARC 8, GCC)

@item 
@code{sos9sc} (Solaris, SPARC 9, SunPro C)

@item 
@code{sus8gc} (SunOS, SPARC 8, GCC)

@item 
@code{xcppgc} (OS X, PowerPC, GCC)
@end itemize

@item 
On Unix platforms, the MPS can now be built and installed by
running @code{./configure && make install}. See @ref{14,,Building the Memory Pool System}.

@item 
The MPS can be compiled in a single step via the new source file
@code{mps.c}. This also allows you to compile the MPS in the same
compilation unit as your object format, allowing the compiler to
perform global optimizations between the two. See
@ref{14,,Building the Memory Pool System}.

@item 
The set of build varieties has been reduced to three: the
@ref{c8,,cool} variety for development and debugging, the @ref{162,,hot}
variety for production, and the @ref{163,,rash} variety for people who
like to live dangerously. See @ref{170,,Varieties}.

@item 
The environment variable 
@geindex MPS_TELEMETRY_CONTROL
@geindex environment variable; MPS_TELEMETRY_CONTROL
@ref{288,,MPS_TELEMETRY_CONTROL} can now be
set to a space-separated list of event kinds. See
@ref{db,,Telemetry}.

@item 
Telemetry output is now emitted to the file named by the
environment variable 
@geindex MPS_TELEMETRY_FILENAME
@geindex environment variable; MPS_TELEMETRY_FILENAME
@ref{289,,MPS_TELEMETRY_FILENAME}, if it is
set. See @ref{db,,Telemetry}.
@end enumerate

@node Interface changes<9>,,New features<9>,Release 1 110 0
@anchor{release id24}@anchor{17a8}
@subsection Interface changes



@enumerate 

@item 
Deprecated constants @code{MPS_MESSAGE_TYPE_FINALIZATION},
@code{MPS_MESSAGE_TYPE_GC} and @code{MPS_MESSAGE_TYPE_GC_START} have been
removed. Use @ref{236,,mps_message_type_finalization()},
@ref{18d,,mps_message_type_gc()} and
@ref{22a,,mps_message_type_gc_start()} instead.

@item 
Deprecated constants @code{MPS_RANK_AMBIG}, @code{MPS_RANK_EXACT} and
@code{MPS_RANK_WEAK} have been removed. Use @ref{20a,,mps_rank_ambig()},
@ref{9d,,mps_rank_exact()} and @ref{20c,,mps_rank_weak()} instead.

@item 
Deprecated functions with names starting @code{mps_space_} have been
removed. Use the functions with names starting @code{mps_arena_}
instead.
@end enumerate

@node Introduction to memory management,Home,Release notes,Top
@anchor{mmref/index doc}@anchor{17a9}@anchor{mmref/index introduction-to-memory-management}@anchor{17aa}@anchor{mmref/index mmref-intro}@anchor{17ab}
@chapter Introduction to memory management


@menu
* Overview: Overview<34>. 
* Allocation techniques:: 
* Recycling techniques:: 
* Memory management in various languages:: 

@end menu

@node Overview<34>,Allocation techniques,,Introduction to memory management
@anchor{mmref/begin doc}@anchor{17ac}@anchor{mmref/begin mmref-overview}@anchor{17ad}@anchor{mmref/begin overview}@anchor{17ae}
@section Overview


Memory management is a complex field of computer science and there are
many techniques being developed to make it more efficient. This guide
is designed to introduce you to some of the basic memory management
issues that programmers face.

This guide attempts to explain any terms it uses as it introduces
them. In addition, there is a @ref{158e,,Memory Management Glossary} of memory management
terms that gives fuller information; some terms are linked to the
relevant entries.

@ref{15dd,,Memory management} is usually divided into three areas,
although the distinctions are a little fuzzy:


@itemize *

@item 
@ref{17af,,Hardware memory management}

@item 
@ref{17b0,,Operating system memory management}

@item 
@ref{17b1,,Application memory management}
@end itemize

These are described in more detail below. In most computer systems,
all three are present to some extent, forming layers between the
user’s program and the actual memory hardware. The Memory Management
Reference is mostly concerned with application memory management.

@menu
* Hardware memory management:: 
* Operating system memory management:: 
* Application memory management:: 
* Memory management problems:: 
* Manual memory management:: 
* Automatic memory management:: 
* More information:: 

@end menu

@node Hardware memory management,Operating system memory management,,Overview<34>
@anchor{mmref/begin hardware-memory-management}@anchor{17b2}@anchor{mmref/begin mmref-overview-hardware}@anchor{17af}
@subsection Hardware memory management


Memory management at the hardware level is concerned with the
electronic devices that actually store data. This includes things like
@ref{55,,RAM} and @ref{1622,,memory caches}.

@node Operating system memory management,Application memory management,Hardware memory management,Overview<34>
@anchor{mmref/begin mmref-overview-os}@anchor{17b0}@anchor{mmref/begin operating-system-memory-management}@anchor{17b3}
@subsection Operating system memory management


In the operating system, memory must be allocated to user programs,
and reused by other programs when it is no longer required. The
operating system can pretend that the computer has more memory than it
actually does, and also that each program has the machine’s memory to
itself; both of these are features of @ref{51,,virtual memory} systems.

@node Application memory management,Memory management problems,Operating system memory management,Overview<34>
@anchor{mmref/begin application-memory-management}@anchor{17b4}@anchor{mmref/begin mmref-overview-app}@anchor{17b1}
@subsection Application memory management


Application memory management involves supplying the memory needed for
a program’s objects and data structures from the limited resources
available, and recycling that memory for reuse when it is no longer
required. Because application programs cannot in general predict in
advance how much memory they are going to require, they need
additional code to handle their changing memory requirements.

Application memory management combines two related tasks:

`Allocation'

@quotation

When the program requests a block of memory, the memory manager
must allocate that block out of the larger blocks it has received
from the operating system. The part of the memory manager that
does this is known as the @ref{15ce,,allocator}. There are many ways
to perform allocation, a few of which are discussed in
@ref{17b5,,Allocation techniques}.
@end quotation

`Recycling'

@quotation

When memory blocks have been allocated, but the data they contain
is no longer required by the program, then the blocks can be
recycled for reuse. There are two approaches to recycling memory:
either the programmer must decide when memory can be reused (known
as @ref{8,,manual memory management}); or the memory manager must
be able to work it out (known as @ref{9,,automatic memory management}). These are both described in more detail below.
@end quotation

An application memory manager must usually work to several
constraints, such as:

`CPU overhead'

@quotation

The additional time taken by the memory manager while the program
is running.
@end quotation

`Pause times'

@quotation

The time it takes for the memory manager to complete an operation
and return control to the program.

This affects the program’s ability to respond promptly to
interactive events, and also to any asynchronous event such as a
network connection.
@end quotation

`Memory overhead'

@quotation

How much space is wasted for administration, rounding (known as
@ref{379,,internal fragmentation}), and poor layout (known as
@ref{383,,external fragmentation}).
@end quotation

Some of the common problems encountered in application memory
management are considered in the next section.

@node Memory management problems,Manual memory management,Application memory management,Overview<34>
@anchor{mmref/begin memory-management-problems}@anchor{17b6}@anchor{mmref/begin mmref-overview-problem}@anchor{17b7}
@subsection Memory management problems


The basic problem in managing memory is knowing when to keep the data
it contains, and when to throw it away so that the memory can be
reused. This sounds easy, but is, in fact, such a hard problem that it
is an entire field of study in its own right. In an ideal world, most
programmers wouldn’t have to worry about memory management issues.
Unfortunately, there are many ways in which poor memory management
practice can affect the robustness and speed of programs, both in
manual and in automatic memory management.

Typical problems include:

`Premature frees and dangling pointers'

@quotation

Many programs give up memory, but attempt to access it later and
crash or behave randomly. This condition is known as a
@ref{165c,,premature free}, and the surviving reference to the memory
is known as a @ref{281,,dangling pointer}. This is usually confined
to @ref{8,,manual memory management}.
@end quotation

`Memory leak'

@quotation

Some programs continually allocate memory without ever giving it
up and eventually run out of memory. This condition is known as a
@ref{234,,memory leak}.
@end quotation

`External fragmentation'

@quotation

A poor allocator can do its job of giving out and receiving blocks
of memory so badly that it can no longer give out big enough
blocks despite having enough spare memory. This is because the
free memory can become split into many small blocks, separated by
blocks still in use. This condition is known as @ref{383,,external fragmentation}.
@end quotation

`Poor locality of reference'

@quotation

Another problem with the layout of allocated blocks comes from the
way that modern hardware and operating system memory managers
handle memory: successive memory accesses are faster if they are
to nearby memory locations. If the memory manager places far apart
the blocks a program will use together, then this will cause
performance problems. This condition is known as poor
@ref{1601,,locality of reference}.
@end quotation

`Inflexible design'

@quotation

Memory managers can also cause severe performance problems if they
have been designed with one use in mind, but are used in a
different way. These problems occur because any memory management
solution tends to make assumptions about the way in which the
program is going to use memory, such as typical block sizes,
reference patterns, or lifetimes of objects. If these assumptions
are wrong, then the memory manager may spend a lot more time doing
bookkeeping work to keep up with what’s happening.
@end quotation

`Interface complexity'

@quotation

If objects are passed between modules, then the interface design
must consider the management of their memory.
@end quotation

A well-designed memory manager can make it easier to write debugging
tools, because much of the code can be shared. Such tools could
display objects, navigate links, validate objects, or detect abnormal
accumulations of certain object types or block sizes.

@node Manual memory management,Automatic memory management,Memory management problems,Overview<34>
@anchor{mmref/begin manual-memory-management}@anchor{17b8}@anchor{mmref/begin mmref-overview-manual}@anchor{17b9}
@subsection Manual memory management


Manual memory management is where the programmer has direct control
over when memory may be recycled. Usually this is either by explicit
calls to @ref{47,,heap} management functions (for example,
@ref{1a,,malloc} and @ref{1b,,free (2)} in @ref{1c,,C}), or by language
constructs that affect the @ref{27,,control stack} (such as local
variables). The key feature of a manual memory manager is that it
provides a way for the program to say, “Have this memory back; I’ve
finished with it”; the memory manager does not recycle any memory
without such an instruction.

The advantages of manual memory management are:


@itemize *

@item 
it can be easier for the programmer to understand exactly what is
going on;

@item 
some manual memory managers perform better when there is a shortage
of memory.
@end itemize

The disadvantages of manual memory management are:


@itemize *

@item 
the programmer must write a lot of code to do repetitive bookkeeping
of memory;

@item 
memory management must form a significant part of any module interface;

@item 
manual memory management typically requires more memory overhead per
object;

@item 
memory management bugs are common.
@end itemize

It is very common for programmers, faced with an inefficient or
inadequate manual memory manager, to write code to duplicate the
behavior of a memory manager, either by allocating large blocks and
splitting them for use, or by recycling blocks internally. Such code
is known as a @ref{16b2,,suballocator}. Suballocators can take advantage
of special knowledge of program behavior, but are less efficient in
general than fixing the underlying allocator. Unless written by a
memory management expert, suballocators may be inefficient or
unreliable.

The following languages use mainly manual memory management in most
implementations, although many have @ref{349,,conservative garbage collection} extensions: @ref{1637,,Algol}; @ref{1c,,C}; @ref{1d,,C++};
@ref{17ba,,COBOL}; @ref{17bb,,Fortran}; @ref{17bc,,Pascal}.

@node Automatic memory management,More information,Manual memory management,Overview<34>
@anchor{mmref/begin automatic-memory-management}@anchor{17bd}@anchor{mmref/begin mmref-overview-automatic}@anchor{17be}
@subsection Automatic memory management


Automatic memory management is a service, either as a part of the
language or as an extension, that automatically recycles memory that a
program would not otherwise use again. Automatic memory managers
(often known as garbage collectors, or simply collectors) usually do
their job by recycling blocks that are @ref{21,,unreachable} from the
program variables (that is, blocks that cannot be reached by following
pointers).

The advantages of automatic memory management are:


@itemize *

@item 
the programmer is freed to work on the actual problem;

@item 
module interfaces are cleaner;

@item 
there are fewer memory management bugs;

@item 
memory management is often more efficient.
@end itemize

The disadvantages of automatic memory management are:


@itemize *

@item 
memory may be retained because it is reachable, but won’t be used again;

@item 
automatic memory managers (currently) have limited availability.
@end itemize

There are many ways of performing automatic recycling of memory, a few
of which are discussed in @ref{17bf,,Recycling techniques}.

Most modern languages use mainly automatic memory management:
@ref{17c0,,BASIC}, @ref{1752,,Dylan}, Erlang, Haskell, @ref{167f,,Java},
@ref{17c1,,JavaScript}, @ref{28a,,Lisp}, @ref{168e,,ML}, @ref{168f,,Modula-3},
@ref{1680,,Perl}, @ref{1645,,PostScript}, @ref{162b,,Prolog}, Python,
@ref{46,,Scheme}, @ref{1661,,Smalltalk}, etc.

@node More information,,Automatic memory management,Overview<34>
@anchor{mmref/begin more-information}@anchor{17c2}
@subsection More information


For more detailed information on the topics covered briefly above,
please have a look at the @ref{158e,,Memory Management Glossary}. Books and research papers
are available on many specific techniques, and can be found via our
@ref{14d7,,Bibliography}; particularly recommended are: @ref{1579,,Wilson (1994)}, which is survey of garbage collection techniques;
@ref{157a,,Wilson et al. (1995)}, which is a survey of allocation
techniques; and @ref{1538,,Jones et al. (2012)}, which is a
handbook covering all aspects of garbage collection.

@node Allocation techniques,Recycling techniques,Overview<34>,Introduction to memory management
@anchor{mmref/alloc doc}@anchor{17c3}@anchor{mmref/alloc allocation-techniques}@anchor{17c4}@anchor{mmref/alloc mmref-alloc}@anchor{17b5}
@section Allocation techniques


Memory allocation is the process of assigning blocks of memory on
request. Typically the @ref{15ce,,allocator} receives memory from the
operating system in a small number of large blocks that it must divide
up to satisfy the requests for smaller blocks. It must also make any
returned blocks available for reuse. There are many common ways to
perform this, with different strengths and weaknesses. A few are
described briefly below.


@itemize *

@item 
@ref{17c5,,First fit}

@item 
@ref{17c6,,Buddy system}

@item 
@ref{17c7,,Suballocators}
@end itemize

These techniques can often be used in combination.

@menu
* First fit:: 
* Buddy system:: 
* Suballocators:: 

@end menu

@node First fit,Buddy system,,Allocation techniques
@anchor{mmref/alloc first-fit}@anchor{17c8}@anchor{mmref/alloc mmref-alloc-first-fit}@anchor{17c5}
@subsection First fit


In the @ref{37f,,first fit} algorithm, the allocator keeps a list of free
blocks (known as the @ref{268,,free list}) and, on receiving a request
for memory, scans along the list for the first block that is large
enough to satisfy the request. If the chosen block is significantly
larger than that requested, then it is usually split, and the
remainder added to the list as another free block.

The first fit algorithm performs reasonably well, as it ensures that
allocations are quick. When recycling free blocks, there is a choice
as to where to add the blocks to the free list—effectively in what
order the free list is kept:

`Memory location (address)'

@quotation

This is not fast for allocation or recycling, but supports
efficient merging of adjacent free blocks (known as
@ref{38c,,coalescence}). According to @ref{157a,,Wilson et al. (1995)}, this ordering reduces @ref{17e,,fragmentation}. It
can also improve @ref{1601,,locality of reference}.
@end quotation

`Increasing size'

@quotation

This is equivalent to the @ref{382,,best fit} algorithm, in that the
free block with the “tightest fit” is always chosen. The fit is
usually sufficiently tight that the remainder of the block is
unusably small.
@end quotation

`Decreasing size'

@quotation

This is equivalent to the @ref{386,,worst fit} algorithm. The first
block on the free list will always be large enough, if a large
enough block is available. This approach encourages
@ref{383,,external fragmentation}, but allocation is very fast.
@end quotation

`Increasing time since last use'

@quotation

This is very fast at adding new free blocks, because they are
added to the beginning of the list. It encourages good
@ref{1601,,locality of reference} (where blocks used together are not
spread throughout memory), but can lead to bad external
fragmentation.
@end quotation

A variation of first fit, known as @ref{1681,,next fit}, continues each
search for a suitable block where the previous one left off, by using
a roving pointer into the free block chain. This is not usually
combined with increasing or decreasing size ordering because it would
eliminate their advantages.

@node Buddy system,Suballocators,First fit,Allocation techniques
@anchor{mmref/alloc buddy-system}@anchor{17c9}@anchor{mmref/alloc mmref-alloc-buddy}@anchor{17c6}
@subsection Buddy system


In a @ref{15f9,,buddy system}, the allocator will only allocate blocks of
certain sizes, and has many free lists, one for each permitted size.
The permitted sizes are usually either powers of two, or form a
Fibonacci sequence (see below for example), such that any block except
the smallest can be divided into two smaller blocks of permitted
sizes.

When the allocator receives a request for memory, it rounds the
requested size up to a permitted size, and returns the first block
from that size’s free list. If the free list for that size is empty,
the allocator splits a block from a larger size and returns one of the
pieces, adding the other to the appropriate free list.

When blocks are recycled, there may be some attempt to merge adjacent
blocks into ones of a larger permitted size (@ref{38c,,coalescence}). To make this easier, the free lists may be stored in
order of address. The main advantage of the buddy system is that
coalescence is cheap because the “buddy” of any free block can be
calculated from its address.


@float Figure

@image{MemoryPoolSystem-figures/buddy1,,,Diagram: A binary buddy heap before allocation.,svg}

@caption{A binary buddy heap before allocation}

@end float



@float Figure

@image{MemoryPoolSystem-figures/buddy2,,,Diagram: A binary buddy heap after allocating a 8 kB block.,svg}

@caption{A binary buddy heap after allocating a 8 kB block.}

@end float



@float Figure

@image{MemoryPoolSystem-figures/buddy3,,,Diagram: A binary buddy heap after allocating a 10 kB block; note the 6 kB wasted because of rounding up.,svg}

@caption{A binary buddy heap after allocating a 10 kB block; note the 6 kB wasted because of rounding up.}

@end float


For example, an allocator in a binary buddy system might have sizes of
16, 32, 64, …, 64 kB. It might start off with a single block of 64 kB.
If the application requests a block of 8 kB, the allocator would check
its 8 kB free list and find no free blocks of that size. It would then
split the 64 kB block into two block of 32 kB, split one of them into
two blocks of 16 kB, and split one of them into two blocks of 8 kB.
The allocator would then return one of the 8 kB blocks to the
application and keep the remaining three blocks of 8 kB, 16 kB, and 32
kB on the appropriate free lists. If the application then requested a
block of 10 kB, the allocator would round this request up to 16 kB,
and return the 16 kB block from its free list, wasting 6 kB in the
process.

A Fibonacci buddy system might use block sizes 16, 32, 48, 80, 128,
208, … bytes, such that each size is the sum of the two preceding
sizes. When splitting a block from one free list, the two parts get
added to the two preceding free lists.

A buddy system can work very well or very badly, depending on how the
chosen sizes interact with typical requests for memory and what the
pattern of returned blocks is. The rounding typically leads to a
significant amount of wasted memory, which is called @ref{379,,internal fragmentation}. This can be reduced by making the permitted block
sizes closer together.

@node Suballocators,,Buddy system,Allocation techniques
@anchor{mmref/alloc mmref-alloc-suballocator}@anchor{17c7}@anchor{mmref/alloc suballocators}@anchor{17ca}
@subsection Suballocators


There are many examples of application programs that include
additional memory management code called a @ref{16b2,,suballocator}. A
suballocator obtains large blocks of memory from the system memory
manager and allocates the memory to the application in smaller pieces.
Suballocators are usually written for one of the following reasons:


@itemize *

@item 
To avoid general inefficiency in the system memory manager;

@item 
To take advantage of special knowledge of the application’s memory
requirements that cannot be expressed to the system memory manager;

@item 
To provide memory management services that the system memory manager
does not supply.
@end itemize

In general, suballocators are less efficient than having a single
memory manager that is well-written and has a flexible interface. It
is also harder to avoid memory management bugs if the memory manager
is composed of several layers, and if each application has its own
variation of suballocator.

Many applications have one or two sizes of block that form the vast
majority of their allocations. One of the most common uses of a
suballocator is to supply the application with objects of one size.
This greatly reduces the problem of @ref{383,,external fragmentation}.
Such a suballocator can have a very simple allocation policy.

There are dangers involved in making use of special knowledge of the
application’s memory requirements. If those requirements change, then
the performance of the suballocator is likely to be much worse than
that of a general allocator. It is often better to have a memory
manager that can respond dynamically to changing requirements.

@node Recycling techniques,Memory management in various languages,Allocation techniques,Introduction to memory management
@anchor{mmref/recycle doc}@anchor{17cb}@anchor{mmref/recycle mmref-recycle}@anchor{17bf}@anchor{mmref/recycle recycling-techniques}@anchor{17cc}
@section Recycling techniques


There are many ways for automatic memory managers to determine what
memory is no longer required. In the main, garbage collection relies
on determining which blocks are not pointed to by any program
variables. Some of the techniques for doing this are described briefly
below, but there are many potential pitfalls, and many possible
refinements. These techniques can often be used in combination.

@menu
* Tracing collectors:: 
* Reference counts:: 

@end menu

@node Tracing collectors,Reference counts,,Recycling techniques
@anchor{mmref/recycle tracing-collectors}@anchor{17cd}
@subsection Tracing collectors


Automatic memory managers that follow pointers to determine which
blocks of memory are @ref{96,,reachable} from program variables (known
as the @ref{1716,,root set}) are known as `tracing' collectors. The
classic example is the mark-sweep collector.

@menu
* Mark-sweep collection:: 
* Copying collection:: 
* Incremental collection:: 
* Conservative garbage collection:: 

@end menu

@node Mark-sweep collection,Copying collection,,Tracing collectors
@anchor{mmref/recycle mark-sweep-collection}@anchor{17ce}
@subsubsection Mark-sweep collection


In a @ref{15fd,,mark-sweep} collection, the collector first examines the
program variables; any blocks of memory pointed to are added to a list
of blocks to be examined. For each block on that list, it sets a flag
(the mark) on the block to show that it is still required, and also
that it has been processed. It also adds to the list any blocks
pointed to by that block that have not yet been marked. In this way,
all blocks that can be reached by the program are marked.

In the second phase, the collector `sweeps' all allocated memory,
searching for blocks that have not been marked. If it finds any, it
returns them to the allocator for reuse.


@float Figure

@image{MemoryPoolSystem-figures/mark-sweep,,,Diagram: Five memory blocks@comma{} three of which are reachable from program variables.,svg}

@caption{Five memory blocks, three of which are reachable from program variables.}

@end float


In the diagram above, block 1 is directly accessible from a program
variable, and blocks 2 and 3 are indirectly accessible. Blocks 4 and 5
cannot be reached by the program. The first step would mark block 1,
and remember blocks 2 and 3 for later processing. The second step
would mark block 2. The third step would mark block 3, but wouldn’t
remember block 2 as it is already marked. The sweep phase would ignore
blocks 1, 2, and 3 because they are marked, but would recycle blocks 4
and 5.

The two drawbacks of simple mark-sweep collection are:


@itemize *

@item 
it must scan the entire memory in use before any memory can be freed;

@item 
it must run to completion or, if interrupted, start again from scratch.
@end itemize

If a system requires real-time or interactive response, then simple
mark-sweep collection may be unsuitable as it stands, but many more
sophisticated garbage collection algorithms are derived from this
technique.

@node Copying collection,Incremental collection,Mark-sweep collection,Tracing collectors
@anchor{mmref/recycle copying-collection}@anchor{17cf}
@subsubsection Copying collection


After many memory blocks have been allocated and recycled, there are
two problems that typically occur:


@itemize *

@item 
the memory in use is widely scattered in memory, causing poor
performance in the @ref{1622,,memory caches} or
@ref{51,,virtual memory} systems of most modern computers (known as
poor @ref{1601,,locality of reference});

@item 
it becomes difficult to allocate large blocks because free memory is
divided into small pieces, separated by blocks in use (known as
@ref{383,,external fragmentation}).
@end itemize

One technique that can solve both these problems is @ref{e3,,copying garbage collection}. A copying garbage collector may move allocated
blocks around in memory and adjust any references to them to point to
the new location. This is a very powerful technique and can be
combined with many other types of garbage collection, such as
mark-sweep collection.

The disadvantages of copying collection are:


@itemize *

@item 
it is difficult to combine with @ref{d,,incremental garbage collection} (see below) because all references must be adjusted to
remain consistent;

@item 
it is difficult to combine with @ref{349,,conservative garbage collection} (see below) because references cannot be confidently
adjusted;

@item 
extra storage is required while both new and old copies of an object
exist;

@item 
copying data takes extra time (proportional to the amount of
@ref{78,,live} data).
@end itemize

@node Incremental collection,Conservative garbage collection,Copying collection,Tracing collectors
@anchor{mmref/recycle incremental-collection}@anchor{17d0}
@subsubsection Incremental collection


Older garbage collection algorithms relied on being able to start
collection and continue working until the collection was complete,
without interruption. This makes many interactive systems pause during
collection, and makes the presence of garbage collection obtrusive.

Fortunately, there are modern techniques (known as @ref{d,,incremental garbage collection}) to allow garbage collection to be performed in a
series of small steps while the program is never stopped for long. In
this context, the program that uses and modifies the blocks is
sometimes known as the @ref{30c,,mutator}. While the collector is trying
to determine which blocks of memory are reachable by the mutator, the
mutator is busily allocating new blocks, modifying old blocks, and
changing the set of blocks it is actually looking at.

Incremental collection is usually achieved with either the cooperation
of the memory hardware or the mutator; this ensures that, whenever
memory in crucial locations is accessed, a small amount of necessary
bookkeeping is performed to keep the collector’s data structures
correct.

@node Conservative garbage collection,,Incremental collection,Tracing collectors
@anchor{mmref/recycle conservative-garbage-collection}@anchor{17d1}
@subsubsection Conservative garbage collection


Although garbage collection was first invented in 1958, many languages
have been designed and implemented without the possibility of garbage
collection in mind. It is usually difficult to add normal garbage
collection to such a system, but there is a technique, known as
@ref{349,,conservative garbage collection}, that can be used.

The usual problem with such a language is that it doesn’t provide the
collector with information about the data types, and the collector
cannot therefore determine what is a pointer and what isn’t. A
conservative collector assumes that anything `might' be a pointer. It
regards any data value that looks like a pointer to or into a block of
allocated memory as preventing the recycling of that block.

Note that, because the collector does not know for certain which
memory locations contain pointers, it cannot readily be combined with
copying garbage collection. Copying collection needs to know where
pointers are in order to update them when blocks are moved.

You might think that conservative garbage collection could easily
perform quite poorly, leaving a lot of garbage uncollected. In
practice, it does quite well, and there are refinements that improve
matters further.

@node Reference counts,,Tracing collectors,Recycling techniques
@anchor{mmref/recycle reference-counts}@anchor{17d2}
@subsection Reference counts


A reference count is a count of how many @ref{24,,references} (that is,
pointers) there are to a particular memory block from other blocks. It
is used as the basis for some automatic recycling techniques that do
not rely on tracing.

@menu
* Simple reference counting:: 
* Deferred reference counting:: 
* One-bit reference counting:: 
* Weighted reference counting:: 

@end menu

@node Simple reference counting,Deferred reference counting,,Reference counts
@anchor{mmref/recycle simple-reference-counting}@anchor{17d3}
@subsubsection Simple reference counting


In a simple @ref{15e0,,reference counting} system, a reference count is
kept for each @ref{1ab,,object}. This count is incremented for each new
reference, and is decremented if a reference is overwritten, or if the
referring object is recycled. If a reference count falls to zero, then
the object is no longer required and can be recycled.

Reference counting is frequently chosen as an automatic memory
management strategy because it seems simple to implement using
@ref{8,,manual memory management} primitives. However, it is hard to
implement efficiently because of the cost of updating the counts. It
is also hard to implement reliably, because the standard technique
cannot reclaim objects connected in a loop. In many cases, it is an
inappropriate solution, and it would be preferable to use
@ref{15df,,tracing garbage collection} instead.

Reference counting is most useful in situations where it can be
guaranteed that there will be no loops and where modifications to the
reference structure are comparatively infrequent. These circumstances
can occur in some types of database structure and some file systems.
Reference counting may also be useful if it is important that objects
are recycled promptly, such as in systems with tight memory
constraints.

@node Deferred reference counting,One-bit reference counting,Simple reference counting,Reference counts
@anchor{mmref/recycle deferred-reference-counting}@anchor{17d4}
@subsubsection Deferred reference counting


The performance of reference counting can be improved if not all
references are taken into account. In one important technique, known
as @ref{165f,,deferred reference counting}, only references from other
objects are counted, and references from program variables are
ignored. Since most of the references to the object are likely to be
from local variables, this can substantially reduce the overhead of
keeping the counts up to date. An object cannot be reclaimed as soon
as its count has dropped to zero, because there might still be a
reference to it from a program variable. Instead, the program
variables (including the @ref{27,,control stack}) are periodically
@ref{65,,scanned}, and any objects which are not referenced from
there and which have zero count are reclaimed.

Deferred reference counting cannot normally be used unless it is
directly supported by the compiler. It’s more common for modern
compilers to support tracing garbage collectors instead, because they
can reclaim loops. Deferred reference counting may still be useful for
its promptness—but that is limited by the frequency of scanning the
program variables.

@node One-bit reference counting,Weighted reference counting,Deferred reference counting,Reference counts
@anchor{mmref/recycle one-bit-reference-counting}@anchor{17d5}
@subsubsection One-bit reference counting


Another variation on reference counting, known as the @ref{16c6,,one-bit reference count}, uses a single bit flag to indicate whether each
object has either “one” or “many” references. If a reference to an
object with “one” reference is removed, then the object can be
recycled. If an object has “many” references, then removing references
does not change this, and that object will never be recycled. It is
possible to store the flag as part of the `pointer' to the object, so
no additional space is required in each object to store the count.
One-bit reference counting is effective in practice because most
actual objects have a reference count of one.

@node Weighted reference counting,,One-bit reference counting,Reference counts
@anchor{mmref/recycle weighted-reference-counting}@anchor{17d6}
@subsubsection Weighted reference counting


Reference counting is often used for tracking inter-process references for @ref{1663,,distributed garbage collection}.  This fails to collect objects in separate processes if they have looped references, but tracing collectors are usually too inefficient as inter-process tracing entails much communication between processes.  Within a process, tracing collectors are often used for local recycling of memory.

Many distributed collectors use a technique called @ref{1666,,weighted reference counting}, which reduces the level of communication even
further. Each time a reference is copied, the weight of the reference
is shared between the new and the old copies. Since this operation
doesn’t change the total weight of all references, it doesn’t require
any communication with the object. Communication is only required when
references are deleted.

@node Memory management in various languages,,Recycling techniques,Introduction to memory management
@anchor{mmref/lang doc}@anchor{17d7}@anchor{mmref/lang lang}@anchor{17d8}@anchor{mmref/lang memory-management-in-various-languages}@anchor{17d9}
@section Memory management in various languages



@table @asis
@anchor{mmref/lang term-ALGOL}@anchor{1637}
@geindex ALGOL

@item ALGOL

ALGOL, designed in 1958 for scientific computing, was the
first block-structured language. It spawned a whole family of
languages, and inspired many more, including @ref{46,,Scheme},
@ref{17da,,Simula} and @ref{17bc,,Pascal}.

The block structure of ALGOL 60 induced a @ref{15e2,,stack allocation} discipline. It had limited dynamic arrays, but no
general @ref{1653,,heap allocation}. The substantially redesigned
ALGOL 68 had both heap and stack allocation. It also had
something like the modern @ref{15b8,,pointer} type, and required
@ref{f,,garbage collection} for the heap. The new language was
complex and difficult to implement, and it was never as
successful as its predecessor.

@ref{14fd,,Branquart & Lewi (1972)}.
@anchor{mmref/lang term-BASIC}@anchor{17c0}
@geindex BASIC

@item BASIC

BASIC is a simple and easily-learned programming language
created by T. E. Kurtz and J. G. Kemeny in 1963–4. The
motivation was to make computers easily accessible to
undergraduate students in all disciplines.

Most BASICs had quite powerful string handling operations that
required a simple @ref{20,,garbage collector}. In many
implementations, the garbage collector could be forced to run
by running the mysterious expression @code{FRE("")}.

BASIC is now old-fashioned, but survives as a scripting
language, in particular in Visual BASIC, which is an
application development environment with a BASIC-like
scripting language. These descendants invariably have
automatic memory management as well.
@anchor{mmref/lang term-C}@anchor{1c}
@geindex C

@item C

C is a systems programming language sometimes described as “a
portable assembler” because it was intended to be sufficiently
low-level to allow performance comparable to assembler or
machine code, but sufficiently high-level to allow programs to
be reused on other platforms with little or no modification.

@ref{15dd,,Memory management} is typically manual (the standard
library functions for @ref{194,,memory (2)} management in C,
@ref{1a,,malloc} and @ref{1b,,free (2)}, have become almost
synonymous with @ref{8,,manual memory management}), although
with the Memory Pool System, or the Boehm–Demers–Weiser
collector, it is now possible to use @ref{f,,garbage collection}.

The language is notorious for fostering memory management
bugs, including:


@enumerate 

@item 
Accessing arrays with indexes that are out of bounds;

@item 
Using @ref{15e2,,stack-allocated} structures
beyond their @ref{b5,,lifetimes} (see @ref{174f,,use after free});

@item 
Using @ref{1653,,heap-allocated} structures
after @ref{15d2,,freeing} them (see @ref{174f,,use after free});

@item 
Neglecting to free heap-allocated objects when they are no
longer required (see @ref{234,,memory leak});

@item 
Failing to allocate memory for a @ref{15b8,,pointer} before using it;

@item 
Allocating insufficient memory for the intended contents;

@item 
Loading from allocated memory before storing into it;

@item 
Dereferencing non-pointers as if they were pointers.
@end enumerate


@subsubheading See also


@ref{15d0,,automatic storage duration}, @ref{15e3,,static storage duration}.


@ref{118,,ISO/IEC 9899;1990}, @ref{9d6,,ISO/IEC 9899;1999}, @ref{14f6,,Boehm & Weiser (1988)}, @ref{150c,,Daconta (1993)}, @ref{1513,,Zorn (1993)}.

Memory Pool System@footnote{https://www.ravenbrook.com/project/mps/},
Boehm–Demers–Weiser collector@footnote{http://hboehm.info/gc/},
C standardization@footnote{http://www.open-std.org/jtc1/sc22/wg14/},
comp.lang.c Frequently Asked Questions@footnote{http://c-faq.com/}.
@anchor{mmref/lang term-COBOL}@anchor{17ba}
@geindex COBOL

@item COBOL

COBOL was designed by the CODASYL committee in 1959–60 to be a
business programming language, and has been extended many
times since. A 1997 Gartner Group report estimated that 80% of
computer software (by count of source lines) was written in
COBOL.

Prior to 2002, COBOL had no @ref{1653,,heap allocation}, and did
well in its application domain without it. COBOL 2002 has
@ref{15b8,,pointers} and heap allocation through @code{ALLOCATE} and
@code{FREE}, mainly in order to be able to use C-style
interfaces. It also supports a high level of abstraction
through object-oriented programming and @ref{f,,garbage collection} (including @ref{b,,finalization}).

COBOL standardization@footnote{http://www.cobolstandard.info/wg4/wg4.html}.
@anchor{mmref/lang term-Common-Lisp}@anchor{17db}
@geindex Common Lisp

@item Common Lisp

Common Lisp is the major dialect of the @ref{28a,,Lisp} family.
In addition to the usual Lisp features, it has an advanced
object system, data types from hash tables to complex numbers,
and a rich standard library.

Common Lisp is a @ref{f,,garbage-collected} language, and modern implementations, such as
LispWorks@footnote{http://www.lispworks.com/} and Allegro CL@footnote{http://www.franz.com/products/allegro-common-lisp/},
include advanced features, such as @ref{b,,finalization} and
@ref{c,,weakness}.

Common Lisp HyperSpec@footnote{http://www.lispworks.com/documentation/HyperSpec/Front/}.
@anchor{mmref/lang term-0}@anchor{17dc}
@geindex C#

@item C#

C# is a strongly typed object-oriented language created at
Microsoft in 1999–2000. It is designed to run on the Common
Language Runtime, the virtual machine from the .NET Framework.
It also runs on the open source Mono runtime.

Memory is @ref{9,,automatically managed}: memory is allocated when an object is created,
and reclaimed at some point after the object becomes
@ref{21,,unreachable}.

The language supports @ref{b,,finalization} (classes may have
`destructor functions', which are run just before the object
is reclaimed by the memory manager), and @ref{c,,weak references (1)} (via the @code{WeakReference} class).

The @ref{20,,garbage collector} in the .NET Framework is
configurable to run in soft real time, or in batch mode.

The Mono runtime comes with two collectors: the
Boehm–Demers–Weiser @ref{349,,conservative collector}, and a @ref{e,,generational} @ref{e3,,copying collector}.

Automatic memory management in C#@footnote{http://msdn.microsoft.com/en-us/library/aa691138.aspx},
WeakReference Class@footnote{http://msdn.microsoft.com/en-us/library/system.weakreference.aspx},
Memory Management and Garbage Collection in the .NET Framework@footnote{http://msdn.microsoft.com/en-us/library/hh156531.aspx},
Mono project@footnote{http://www.mono-project.com/Main_Page}.
@anchor{mmref/lang term-1}@anchor{1d}
@geindex C++

@item C++

C++ is a (weakly) object-oriented language, extending the
systems programming language @ref{1c,,C} with a
multiple-inheritance class mechanism and simple method
dispatch.

The standard library functions for @ref{194,,memory (2)}
management in C++ are @code{new} and @code{delete}. The higher
abstraction level of C++ makes the bookkeeping required for
@ref{8,,manual memory management} even harder. Although the
standard library provides only manual memory management, with
the Memory Pool System, or the Boehm–Demers–Weiser collector,
it is now possible to use @ref{f,,garbage collection}.
@ref{1711,,Smart pointers} are another popular solution.

The language is notorious for fostering memory management
bugs, including:


@enumerate 

@item 
Using @ref{15e2,,stack-allocated} structures
beyond their @ref{b5,,lifetimes} (see @ref{174f,,use after free});

@item 
Using @ref{1653,,heap-allocated} structures
after @ref{15d2,,freeing} them (see @ref{174f,,use after free});

@item 
Neglecting to free heap-allocated objects when they are no
longer required (see @ref{234,,memory leak});

@item 
Excessive copying by copy @ref{15d3,,constructors (1)};

@item 
Unexpected sharing due to insufficient copying by copy
constructors;

@item 
Allocating insufficient memory for the intended contents;

@item 
Accessing arrays with indexes that are out of bounds.
@end enumerate

C++ was designed by Bjarne Stroustrup, as a minimal
object-oriented extension to C. It has since grown to
include some other modern programming language ideas. The
first implementations were preprocessors that produced C
code, but modern implementations are dedicated C++
compilers.

Ellis and Stroustrup write in `The Annotated C++ Reference
Manual':

@quotation

C programmers think memory management is too important to
be left to the computer. Lisp programmers think memory
management is too important to be left to the user.
@end quotation


@subsubheading See also


@ref{1651,,constructor (2)}, @ref{1652,,destructor (2)}.


@ref{14dd,,Attardi & Flagella (1994)}, @ref{14f2,,Bartlett (1989)}, @ref{14f6,,Boehm & Weiser (1988)}, @ref{151d,,Edelson (1992)}, @ref{151f,,Ellis (1993)}, @ref{1513,,Zorn (1993)}.

Memory Pool System@footnote{https://www.ravenbrook.com/project/mps/},
Boehm–Demers–Weiser collector@footnote{http://hboehm.info/gc/},
comp.lang.c++ FAQ@footnote{http://www.parashift.com/c++-faq/},
C++ standardization@footnote{http://www.open-std.org/jtc1/sc22/wg21/}.
@anchor{mmref/lang term-Dylan}@anchor{1752}
@geindex Dylan

@item Dylan

Dylan is a modern programming language invented by Apple
around 1993 and developed by Harlequin@footnote{https://en.wikipedia.org/wiki/Harlequin_(software_company)}
and other partners. The language is a distillation of the best
ideas in dynamic and object-oriented programming. Its
ancestors include @ref{28a,,Lisp}, @ref{1661,,Smalltalk}, and
@ref{1d,,C++}. Dylan is aimed at building modular component
software and delivering safe, compact applications. It also
facilitates the rapid development and incremental refinement
of prototype programs.

Dylan provides @ref{9,,automatic memory management}. The
generic allocation function is called @code{make}. Most
implementations provide @ref{b,,finalization} and @ref{c,,weak} hash tables, although interfaces for
these features have not yet been standardized. An object may
be registered for finalization via the function
@code{finalize-when-unreachable}, in which case there will be a
call to the @code{finalize} function once the @ref{20,,garbage collector} has determined that the object is
@ref{21,,unreachable}. Weak hash tables may have either weak
keys or values, depending on a parameter supplied at
allocation time. A hash table entry will be deleted once the
garbage collector has determined that there are no
@ref{244,,strong references} to the key or value of the entry,
for weak key or value tables, respectively.

Open Dylan@footnote{http://opendylan.org/}.
@anchor{mmref/lang term-Emacs-Lisp}@anchor{17dd}
@geindex Emacs Lisp

@item Emacs Lisp

Emacs Lisp or elisp is a dialect of @ref{28a,,Lisp} used in the
Emacs family of text editors, of which the most widely-used is
GNU Emacs@footnote{http://www.gnu.org/software/emacs/emacs.html}.

Like most Lisps, Emacs Lisp requires @ref{f,,garbage collection}. GNU Emacs has a simple @ref{15fd,,mark-sweep}
collector. It has been speculated that the
non-@ref{d,,incremental}
nature of the Emacs collector, combined with the fact that,
prior to version 19.31 (May 1996), it printed a message
whenever it collected, gave garbage collection a bad name in
programming circles.

Erik Naggum reported at the time:

@quotation

I have run some tests at the U of Oslo with about 100
users who generally agreed that Emacs had become faster in
the latest Emacs pretest. All I had done was to remove the
“Garbage collecting” message which people perceive as
slowing Emacs down and tell them that it had been sped up.
It is, somehow, permissible for a program to take a lot of
time doing any other task than administrative duties like
garbage collection.
@end quotation

Emacs was originally written in Teco, not in Lisp, but it
still had a garbage collector, though this was heuristic and
conservative in nature. Teco-based Emacs was capable of
running for weeks at a time in a 256 kB @ref{54,,address space}.

GNU Emacs Lisp Reference Manual@footnote{http://www.gnu.org/software/emacs/manual/elisp.html},
Entry on Garbage Collection@footnote{http://www.gnu.org/software/emacs/manual/html_node/elisp/Garbage-Collection.html}.
@anchor{mmref/lang term-Fortran}@anchor{17bb}
@geindex Fortran

@item Fortran

Fortran, created in 1957, was one of the first languages
qualifying as a high-level language. It is popular among
scientists and has substantial support in the form of
numerical libraries.

Early versions of Fortran required the size of arrays to be
known at compilation time, and the earliest Fortran compilers
accordingly used only @ref{1610,,static allocation} (however, the
1966 standard gave compiler writers freedom to use other
allocation mechanisms).

The Fortran 90 standard added recursion and automatic arrays
with @ref{15e2,,stack allocation} semantics (though many compilers
in fact allocate them on the @ref{47,,heap}). It also added
@ref{166b,,dynamic allocation} using @code{ALLOCATE} with manual
deallocation using @code{DEALLOCATE}. Fortran 95 made it explicit
that allocated arrays have @ref{24a,,dynamic extent} and are
automatically deallocated when they go out of scope.

Fortran standardization@footnote{http://www.j3-fortran.org/}.
@anchor{mmref/lang term-Java}@anchor{167f}
@geindex Java

@item Java

A modern object-oriented language with a rich collection of
useful features. The Java language started as an attempt by
the Java group at Sun Microsystems to overcome software
engineering problems introduced by @ref{1d,,C++}. Key reasons
for the language’s success were the security model and the
portable execution environment, the Java Virtual Machine
(JVM), which created a lot of interest for it as a platform
for distributed computing on open networks.

Java is @ref{f,,garbage-collected}, as
this facilitates object-oriented programming and is essential
for security (which @ref{174f,,use after free} would break). It
had @ref{b,,finalization} from version 1.0 and three kinds of
@ref{c,,weakness} from version 1.2
(confusingly, part of the Java 2 Platform).

Early JVMs had simple collectors that didn’t scale well for
large programs, but the current crop is catching up to the
state of the art.


@subsubheading See also


@ref{16fb,,reference object}, @ref{244,,strong reference}, @ref{1712,,soft reference}, @ref{1713,,weak reference (2)}, @ref{16fa,,phantom reference}, @ref{16f7,,strongly reachable}, @ref{16f8,,softly reachable}, @ref{16f9,,weakly reachable}, @ref{16f5,,phantom reachable}.

@anchor{mmref/lang term-JavaScript}@anchor{17c1}
@geindex JavaScript

@item JavaScript

JavaScript is a scripting language used by web browsers. The
loose type system resembles other scripting languages,
although the syntax follows @ref{1c,,C}. There’s a
prototype-based object system. Note that JavaScript is not
related to @ref{167f,,Java} in any way except name. There’s a
standard by ECMA@footnote{http://www.ecma-international.org}, known
as ECMAScript.

Despite the @ref{1d,,C++}-like syntax (with @code{new} and
@code{delete} operators), JavaScript is @ref{f,,garbage-collected}.

Standard ECMA-262: ECMAScript Language Specification@footnote{http://www.ecma-international.org/publications/standards/Ecma-262.htm}.
@anchor{mmref/lang term-Lisp}@anchor{28a}
@geindex Lisp

@item Lisp

Lisp is a family of computer languages combining functional
and procedural features with automatic memory management.

Lisp was invented by John McCarthy around 1958 for the
manipulation of symbolic expressions. As part of the original
implementation of Lisp, he invented @ref{f,,garbage collection}. He noted:

@quotation

This process, because it is entirely automatic, is more
convenient for the programmer than a system in which he
has to keep track of lists and erase unwanted lists.
@end quotation

Modern Lisp implementations, such as LispWorks@footnote{http://www.lispworks.com/} and Allegro CL@footnote{http://www.franz.com/products/allegro-common-lisp/}, have
advanced @ref{20,,garbage collectors}.

Lisp is now used for all kinds of symbolic programming and
other advanced software development. Major dialects today are
@ref{17dd,,Emacs Lisp}, @ref{17db,,Common Lisp} and @ref{46,,Scheme}.
Most modern dialects and related languages, such as
@ref{1752,,Dylan}, are object-oriented.


@subsubheading See also


@ref{15cf,,cons (1)}.


@ref{14e1,,Baker (1978)}, @ref{151e,,Edwards}, @ref{1540,,McCarthy & Minsky (1959)}, @ref{1541,,McCarthy (1960)}, @ref{28b,,McCarthy (1979)}, @ref{1544,,Moon (1984)}, @ref{1546,,Moon (1990)}, @ref{1547,,Moon (1991)}, @ref{1569,,Sobalvarro (1988)}, @ref{1585,,Zorn (1988)}.

Common Lisp HyperSpec@footnote{http://www.lispworks.com/documentation/HyperSpec/Front/}.
@anchor{mmref/lang term-Lisp-Machine}@anchor{16bb}
@geindex Lisp Machine

@item Lisp Machine

Of particular interest in the history of memory management are
the `Lisp Machines', early workstation computers built around
a custom processor designed to improve the execution speed of
Lisp by implementing primitive Lisp operations in microcode.
The Lisp Machine @ref{20,,garbage collector} is a generalization
of the algorithm described in @ref{14e1,,Baker (1978)}
and used a technique similar to that described in @ref{1573,,Ungar (1984)}, but utilizing hardware to improve
performance.

A description of the garbage collector of one particular model
is in @ref{1544,,Moon (1984)}. The features important for
its performance were:


@enumerate 

@item 
Hardware support for data typing using @ref{88,,tags};

@item 
Reference-based @ref{1d6,,read barriers} for
@ref{d,,incremental}
collecting;

@item 
@ref{214,,Write barriers} for @ref{213,,remembered sets} and
@ref{e,,generational}
collecting;

@item 
A tight integration with the @ref{51,,virtual memory}
system.
@end enumerate

The remembered sets were based on a @ref{15f6,,BIBOP} division of
the virtual @ref{54,,address space}. The Lisp Machine
@ref{16a2,,page table}, unlike virtually all modern virtual memory
systems, was a flat, hash-based table (sometimes called an
@ref{16b6,,inverted page table}), and thus insensitive to
sparsely-populated virtual address spaces associated with
BIBOP schemes.

These custom processors eventually lost out to rapidly
advancing stock hardware. Many of the techniques pioneered on
Lisp Machines are used in today’s implementations, at a cost
of a few more cycles.

Lisp Machine Manual@comma{} 6th edition@footnote{http://common-lisp.net/project/bknr/static/lmman/frontpage.html},
The Garbage Collector@footnote{http://common-lisp.net/project/bknr/static/lmman/fd-hac.xml#The%20Garbage%20Collector-section}.
@anchor{mmref/lang term-Lua}@anchor{17de}
@geindex Lua

@item Lua

Lua is a dynamically typed language created by Roberto
Ierusalimschy, Luiz Henrique de Figueiredo, and Waldemar Celes
in 1993. The language supports object-oriented and functional
styles of programming, and is designed to be easily embedded
in a larger programming system as an extension or scripting
language.

Lua uses @ref{9,,automatic memory management} and comes with a
@ref{5e,,non-moving}
@ref{d,,incremental}
@ref{20,,garbage collector} supporting soft real time
applications. This uses a software @ref{60,,barrier (1)} in
order to be highly portable.

The language supports @ref{c,,weak references (1)} in the form
of weak (hash) tables, which have the unusual feature that
their keys and values can be dynamically switched from being
@ref{244,,strong references} to weak references, and vice versa
(by assigning to the @code{__mode} field of the table’s
metatable). It also supports @ref{b,,finalization} (by
assigning the @code{__gc} field of the object’s metatable).

Lua@footnote{http://lua.org},
Garbage Collection@footnote{http://www.lua.org/manual/5.1/manual.html#2.10}.
@anchor{mmref/lang term-ML}@anchor{168e}
@geindex ML

@item ML

ML is a family of strongly-typed functional languages, of
which the principal members are Standard ML and Caml.

Like other functional languages, ML provides @ref{9,,automatic memory management}. Modern ML implementations usually have
advanced @ref{20,,garbage collectors}. The combination of clean
functional semantics and strong typing allows advanced
techniques, such as @ref{15e1,,region inference}.

The Standard ML of New Jersey (SML/NJ) system, which
implements a slight variant of Standard ML, has been important
to memory management research for three reasons. Firstly, the
source code is publicly available and widely ported, allowing
experimentation with both the @ref{15ae,,collector (2)} and
@ref{30c,,mutator}. Secondly, the compiler generates code that
does not use a @ref{27,,control stack}, but @ref{15ca,,allocates}
function @ref{15ac,,activation records} on the @ref{47,,heap}
instead. This means that the allocation rate is very high (up
to one byte per instruction), and also that the collector has
a very small @ref{1716,,root set}. Thirdly, it uses a simple
@ref{e3,,copying collector} that is
easy to modify.


@subsubheading See also


@ref{16a7,,immutable}.


@ref{150b,,Cooper et al. (1992)}, @ref{1519,,Doligez (1993)}, @ref{1572,,Tofte & Talpin (1997)}.

comp.lang.ml FAQ@footnote{http://www.faqs.org/faqs/meta-lang-faq/}.
@anchor{mmref/lang term-Modula-3}@anchor{168f}
@geindex Modula-3

@item Modula-3

An object-oriented descendant of @ref{17bc,,Pascal}.

Modula-3 is mostly @ref{f,,garbage-collected}, although it is possible to use @ref{8,,manual memory management} in certain modules.

modula3.org@footnote{http://www.modula3.org/},
Modula-3 language definition@footnote{http://www.hpl.hp.com/techreports/Compaq-DEC/SRC-RR-52.pdf}.
@anchor{mmref/lang term-Pascal}@anchor{17bc}
@geindex Pascal

@item Pascal

An imperative language characterized by block structure and a
relatively strong (for its time) static type system. Pascal
was designed by Niklaus Wirth around 1970.

Pascal was popular as a teaching language due to its small
size, but it lacked many features needed for applications
programming. Now it’s been largely supplanted by its more
feature-rich descendants Modula-2, @ref{168f,,Modula-3}, and
Oberon, mainly surviving in the popular Delphi development
tool.

Pascal uses @ref{8,,manual memory management} (with the
operators @code{NEW} and @code{DISPOSE}). The descendants mentioned
all offer @ref{9,,automatic memory management}.

Embarcadero (formely Borland) Delphi@footnote{https://www.embarcadero.com/products/delphi},
Pascal standardization@footnote{http://www.open-std.org/JTC1/sc22/docs/oldwgs/wg2.html}.
@anchor{mmref/lang term-Perl}@anchor{1680}
@geindex Perl

@item Perl

Perl is a complex but powerful language that is an eclectic
mixture of scripting languages and programming languages.

Perl programmers can work with strings, arrays, and
associative arrays without having to worry about @ref{8,,manual memory management}. Perl is well-suited to complex text file
manipulation, such as report generation, file format
conversion, and web server CGI scripts. It is also useful for
rapid prototyping, but large Perl scripts are often
unmaintainable.

Perl’s @ref{15dd,,memory management} is well-hidden, but is based
on @ref{15e0,,reference counts} and
@ref{f,,garbage collection}. It also has `mortal' variables,
whose @ref{b5,,lifetimes} are limited to the current context. It
is possible to @ref{15d2,,free (1)} the @ref{194,,memory (2)}
assigned to variables (including arrays) explicitly, by
@code{undef}-ing the only reference to them.

The Perl Programming Language@footnote{http://www.perl.org/}.
@anchor{mmref/lang term-PostScript}@anchor{1645}
@geindex PostScript

@item PostScript

The PostScript language is an interpretive language with
powerful graphics features, widely used as a page description
language for printers and typesetters.

The Level 1 PostScript language has a simple
@ref{15bc,,stack}-like memory management model, using @code{save}
and @code{restore} operators to @ref{15de,,recycle} memory. The Level
2 PostScript language adds @ref{f,,garbage collection} to this
model.


@subsubheading See also


@ref{1647,,VM (2)}, @ref{1644,,composite object}, @ref{1646,,simple object}.


Harlequin RIP@footnote{https://en.wikipedia.org/wiki/Harlequin_RIP}.
@anchor{mmref/lang term-Prolog}@anchor{162b}
@geindex Prolog

@item Prolog

A logic programming language invented by Alain Colmerauer
around 1970, Prolog is popular in the AI and symbolic
computation community. It is special because it deals directly
with relationships and inference rather than functions or
commands.

Storage is usually managed using a @ref{20,,garbage collector},
but the complex control flow places special requirements on
the collector.

Prolog Standardization@footnote{http://people.sju.edu/~jhodgson/wg17/},
Prolog Memory Management - Garbage Collection@footnote{http://www.informatik.uni-trier.de/%7Eley/db/prolog/gc.html}.
@anchor{mmref/lang term-Python}@anchor{17df}
@geindex Python

@item Python

Python is a “duck-typed” object-oriented language created in
the early 1990s by Guido van Rossum.

There are several implementations running on a variety of
virtual machines: the original “CPython” implementation runs
on its own virtual machine; IronPython runs on the Common
Language Runtime; Jython on the Java Virtual Machine.

CPython manages memory using a mixture of @ref{15e0,,reference counting} and @ref{1e7,,non-moving}
@ref{16d3,,mark-and-sweep} @ref{f,,garbage collection}. Reference
counting ensures prompt deletion of objects when their
reference count falls to zero, while the garbage collector
reclaims @ref{1659,,cyclic data structures}.

The language supports @ref{b,,finalization} (classes may have a
@code{__del__} method, which is run just before the object is
destroyed), and @ref{c,,weak references (1)} (via the
@code{weakref} module).

Python@footnote{http://python.org/},
Garbage Collector interface@footnote{http://docs.python.org/3/library/gc.html},
__del__ method@footnote{http://docs.python.org/3/reference/datamodel.html#object.__del__},
weakref module@footnote{http://docs.python.org/3/library/weakref.html}.
@anchor{mmref/lang term-Scheme}@anchor{46}
@geindex Scheme

@item Scheme

A small functional language blending influences from
@ref{28a,,Lisp} and @ref{1637,,Algol}.

Key features of Scheme include symbol and list operations,
@ref{1653,,heap allocation} and @ref{f,,garbage collection},
lexical scoping with first-class function objects (implying
@ref{1ee,,closures}), reliable tail-call elimination (allowing
iterative procedures to be described tail-recursively), the
ability to dynamically obtain the current @ref{15ad,,continuation}
as a first-class object, and a language description that
includes a formal semantics.

Scheme has been gaining popularity as an extension language;
Project GNU’s extension package of choice, Guile@footnote{http://www.gnu.org/software/guile/}, is a Scheme
interpreter. @ref{f,,Garbage collection} is an important part
of the ease of use that is expected from an extension
language.

Scheme Standards documents@footnote{http://www.cs.indiana.edu/scheme-repository/doc.standards.html},
Scheme Requests for Implementation@footnote{http://srfi.schemers.org/}.
@anchor{mmref/lang term-Simula}@anchor{17da}
@geindex Simula

@item Simula

Simula was designed as a language for simulation, but it
expanded into a full general-purpose programming language and
the first object-oriented language.

Simula I, designed in 1962–64 by Kristen Nygaard and Ole-Johan
Dahl, was based on @ref{1637,,ALGOL} 60, but the @ref{15e2,,stack allocation} discipline was replaced by a two-dimensional
@ref{268,,free list}.

It was Simula 67 that pioneered classes and inheritance to
express behavior. This domain-oriented design was supported by
@ref{f,,garbage collection}.

@ref{150e,,Dahl (1963)}.
@anchor{mmref/lang term-Smalltalk}@anchor{1661}
@geindex Smalltalk

@item Smalltalk

Smalltalk is an object-oriented language with single
inheritance and message-passing.

@ref{9,,Automatic memory management} is an essential part of
the Smalltalk philosophy. Many important techniques were first
developed or implemented for Smalltalk.

@ref{1514,,Deutsch & Bobrow (1976)}, @ref{1573,,Ungar (1984)}, @ref{1574,,Ungar (1988)}.

Smalltalk standardization@footnote{http://www.smalltalk.org/versions/ANSIStandardSmalltalk.html}.
@end table

@node Home,Frequently Asked Questions,Introduction to memory management,Top
@anchor{mmref-index doc}@anchor{17e0}@anchor{mmref-index home}@anchor{17e1}
@chapter Home


Welcome to the `Memory Management Reference'!  This is a resource for programmers and computer scientists interested in @ref{15dd,,memory management} and @ref{f,,garbage collection}.

@cartouche
@quotation Memory Management Glossary 
A glossary of more than 500 @ref{15dd,,memory management} terms, from
@ref{15a9,,absolute address} to @ref{1660,,zero count table}.

@image{MemoryPoolSystem-figures/treadmill,,,,svg}
@end quotation
@end cartouche

@cartouche
@quotation Introduction to memory management 
Articles giving a beginner’s overview of @ref{15dd,,memory management}.

@image{MemoryPoolSystem-figures/address,,,,svg}
@end quotation
@end cartouche

@cartouche
@quotation Bibliography 
Books and research papers related to @ref{15dd,,memory management}.

@image{MemoryPoolSystem-figures/copying,,,,svg}
@end quotation
@end cartouche

@cartouche
@quotation Frequently Asked Questions 
Frequently asked questions about @ref{15dd,,memory management}.

@image{MemoryPoolSystem-figures/snap-out,,,,svg}
@end quotation
@end cartouche

The Memory Management Reference is maintained by Ravenbrook Limited@footnote{https://www.ravenbrook.com/}. We also maintain the Memory Pool System@footnote{https://www.ravenbrook.com/project/mps/} (an open-source,
thread-safe, @ref{d,,incremental garbage collector}), and we are happy to provide advanced @ref{15dd,,memory management} solutions to language and application developers through
our consulting service@footnote{https://www.ravenbrook.com/services/mm/}.

@node Frequently Asked Questions,Copyright,Home,Top
@anchor{mmref/faq doc}@anchor{17e2}@anchor{mmref/faq frequently-asked-questions}@anchor{17e3}@anchor{mmref/faq memory-pool-system}@anchor{17e4}@anchor{mmref/faq mmref-faq}@anchor{17e5}
@chapter Frequently Asked Questions


This is a list of questions that represent the problems people often
have with memory management. Some answers appear below, with links to
helpful supporting material, such as the @ref{158e,,Memory Management Glossary}, the
@ref{14d7,,Bibliography}, and external sites. For a full explanation of any
terms used, see the glossary.

@menu
* C-specific questions:: 
* C++-specific questions:: 
* Common objections to garbage collection:: 
* Miscellaneous:: 

@end menu

@node C-specific questions,C++-specific questions,,Frequently Asked Questions
@anchor{mmref/faq c-specific-questions}@anchor{17e6}
@section C-specific questions


@menu
* Can I use garbage collection in C?:: 
* Why do I need to test the return value from malloc? Surely it always succeeds?:: 
* What’s the point of having a garbage collector? Why not use malloc and free?:: 
* What’s wrong with ANSI malloc in the C library?:: 

@end menu

@node Can I use garbage collection in C?,Why do I need to test the return value from malloc? Surely it always succeeds?,,C-specific questions
@anchor{mmref/faq can-i-use-garbage-collection-in-c}@anchor{17e7}
@subsection Can I use garbage collection in C?


Yes. Various @ref{349,,conservative garbage collectors} for @ref{1c,,C} exist as add-on libraries.

Memory Pool System@footnote{https://www.ravenbrook.com/project/mps/},
Boehm–Demers–Weiser collector@footnote{http://hboehm.info/gc/}.

@node Why do I need to test the return value from malloc? Surely it always succeeds?,What’s the point of having a garbage collector? Why not use malloc and free?,Can I use garbage collection in C?,C-specific questions
@anchor{mmref/faq why-do-i-need-to-test-the-return-value-from-malloc-surely-it-always-succeeds}@anchor{17e8}
@subsection Why do I need to test the return value from malloc?  Surely it always succeeds?


For small programs, and during light testing, it is true that
@ref{1a,,malloc} usually succeeds. Unfortunately, there are all sorts of
unpredictable reasons why @ref{1a,,malloc} might fail one day; for
example:


@itemize *

@item 
someone uses your program for a far larger data set than you
anticipated;

@item 
your program is running on a machine with less memory than you
expected;

@item 
the machine your program is running on is heavily loaded.
@end itemize

In this case, @ref{1a,,malloc} will return @code{NULL}, and your program
will attempt to store data by resolving the null pointer. This might
cause your program to exit immediately with a helpful message, but it
is more likely to provoke mysterious problems later on.

If you want your code to be robust, and to stand the test of time, you
must check all error or status codes that may be returned by functions
you call, especially those in other libraries, such as the C run-time
library.

If you really don’t want to check the return value from
@ref{1a,,malloc}, and you don’t want your program to behave mysteriously
when out of memory, wrap @ref{1a,,malloc} in something like this:

@example
#include <stdio.h>
#include <stdlib.h>

void *my_malloc(size_t size)
@{
    void *p = malloc(size);

    if (p == NULL) @{
        fputs("Out of memory.\n", stderr);
        exit(EXIT_FAILURE);
    @}

    return p;
@}
@end example

Undefined behavior is worth eliminating even in small programs.

@node What’s the point of having a garbage collector? Why not use malloc and free?,What’s wrong with ANSI malloc in the C library?,Why do I need to test the return value from malloc? Surely it always succeeds?,C-specific questions
@anchor{mmref/faq what-s-the-point-of-having-a-garbage-collector-why-not-use-malloc-and-free}@anchor{17e9}
@subsection What’s the point of having a garbage collector? Why not use malloc and free?


@ref{8,,Manual memory management}, such as @ref{1a,,malloc} and
@ref{1b,,free (2)}, forces the programmer to keep track of which memory
is still required, and who is responsible for freeing it. This works
for small programs without internal interfaces, but becomes a rich
source of bugs in larger programs, and is a serious problem for
interface abstraction.

@ref{9,,Automatic memory management} frees the programmer from these
concerns, making it easier for him to code in the language of his
problem, rather than the tedious details of the implementation.


@subsubheading See also


@ref{f,,garbage collection}


@node What’s wrong with ANSI malloc in the C library?,,What’s the point of having a garbage collector? Why not use malloc and free?,C-specific questions
@anchor{mmref/faq what-s-wrong-with-ansi-malloc-in-the-c-library}@anchor{17ea}
@subsection What’s wrong with ANSI malloc in the C library?


The @ref{1a,,malloc} function provides a very basic @ref{8,,manual memory management} service. However, it does not provide the following
things, which may be desirable in your memory manager:


@itemize *

@item 
high performance for specified block sizes;

@item 
@ref{7d,,tagged references};

@item 
simultaneous frees;

@item 
@ref{1601,,locality of reference} hints;

@item 
@ref{23,,formatted objects};

@item 
garbage collection;

@item 
deallocation of partial blocks;

@item 
multi-threading without synchronization;

@item 
inlined allocation code;

@item 
@ref{b,,finalization}.
@end itemize

Many of these can be added on top of @ref{1a,,malloc}, but not with full
performance.

@node C++-specific questions,Common objections to garbage collection,C-specific questions,Frequently Asked Questions
@anchor{mmref/faq id1}@anchor{17eb}
@section C++-specific questions


@menu
* Can I use garbage collection in C++?:: 
* Why is delete so slow?:: 
* What happens if you use class libraries that leak memory?:: 
* Can’t I get all the benefits of garbage collection using C++ constructors and destructors?:: 

@end menu

@node Can I use garbage collection in C++?,Why is delete so slow?,,C++-specific questions
@anchor{mmref/faq id2}@anchor{17ec}@anchor{mmref/faq mmref-faq-c-gc}@anchor{17ed}
@subsection Can I use garbage collection in C++?


Yes. The C++ specification has always permitted garbage collection.
Bjarne Stroustrup (C++’s designer) has proposed that this be made
explicit in the standard. There exist various conservative and
semi-conservative garbage collectors for C++.


@subsubheading See also


@ref{1d,,C++}, @ref{349,,conservative garbage collection}, @ref{348,,semi-conservative garbage collection}.


Memory Pool System@footnote{https://www.ravenbrook.com/project/mps/},
Boehm–Demers–Weiser collector@footnote{http://hboehm.info/gc/}.

@node Why is delete so slow?,What happens if you use class libraries that leak memory?,Can I use garbage collection in C++?,C++-specific questions
@anchor{mmref/faq why-is-delete-so-slow}@anchor{17ee}
@subsection Why is delete so slow?


Often @code{delete} must perform a more complex task than simply freeing
the memory associated with an object; this is known as
@ref{b,,finalization}. Finalization typically involves releasing any
resources indirectly associated with the object, such as files that
must be closed or ancillary objects that must be finalized themselves.
This may involve traversing memory that has been unused for some time
and hence is @ref{16d1,,paged out}.

With @ref{8,,manual memory management} (such as @code{new} and
@code{delete}), it is perfectly possible for the @ref{15d2,,deallocation} operation to vary in complexity. Some systems do quite a
lot of processing on freed blocks to @ref{38c,,coalesce} adjacent blocks,
sort free blocks by size (in a @ref{15f9,,buddy system}, say), or sort the
@ref{268,,free list} by address. In the last case, deallocating blocks in
address order (or sometimes reverse address order) can result in poor
performance.

@node What happens if you use class libraries that leak memory?,Can’t I get all the benefits of garbage collection using C++ constructors and destructors?,Why is delete so slow?,C++-specific questions
@anchor{mmref/faq what-happens-if-you-use-class-libraries-that-leak-memory}@anchor{17ef}
@subsection What happens if you use class libraries that leak memory?


In @ref{1d,,C++}, it may be that class libraries expect you to call
@code{delete} on objects they create, to invoke the @ref{1652,,destructor (2)}. Check the interface documentation.

Failing this, if there is a genuine @ref{234,,memory leak} in a class
library for which you don’t have the source, then the only thing you
can try is to add a @ref{20,,garbage collector}.

Memory Pool System@footnote{https://www.ravenbrook.com/project/mps/},
Boehm–Demers–Weiser collector@footnote{http://hboehm.info/gc/}.

@node Can’t I get all the benefits of garbage collection using C++ constructors and destructors?,,What happens if you use class libraries that leak memory?,C++-specific questions
@anchor{mmref/faq can-t-i-get-all-the-benefits-of-garbage-collection-using-c-constructors-and-destructors}@anchor{17f0}
@subsection Can’t I get all the benefits of garbage collection using C++ constructors and destructors?


Carefully designed @ref{1d,,C++} @ref{1651,,constructors (2)} and
@ref{1652,,destructors (2)} can go a long way towards easing the pain of
@ref{8,,manual memory management}. Objects can know how to deallocate
all their associated resources, including dependent objects (by
recursive destruction). This means that clients of a class library do
not need to worry about how to free resources allocated on their
behalf.

Unfortunately, they still need to worry about `when' to free such
resources. Unless all objects are allocated for precisely one purpose,
and referred to from just one place (or from within one compound data
structure that will be destroyed atomically), then a piece of code
that has finished with an object cannot determine that it is safe to
call the destructor; it cannot be certain (especially when working
with other people’s code) that there is not another piece of code that
will try to use the object subsequently.

This is where garbage collection has the advantage, because it can
determine when a given object is no longer of interest to anyone (or
at least when there are no more references to it). This neatly avoids
the problems of having multiple copies of the same data or complex
conditional destruction. The program can construct objects and store
references to them anywhere it finds convenient; the garbage collector
will deal with all the problems of data sharing.

@node Common objections to garbage collection,Miscellaneous,C++-specific questions,Frequently Asked Questions
@anchor{mmref/faq common-objections-to-garbage-collection}@anchor{17f1}
@section Common objections to garbage collection


@menu
* What languages use garbage collection?:: 
* What’s the advantage of garbage collection?:: 
* Programs with GC are huge and bloated; GC isn’t suitable for small programs or systems:: 
* I can’t use GC because I can’t afford to have my program pause:: 
* Isn’t it much cheaper to use reference counts rather than garbage collection?:: 
* Isn’t GC unreliable? I’ve heard that GCs often kill the program:: 
* I’ve heard that GC uses twice as much memory:: 
* Doesn’t garbage collection make programs slow?:: 
* Manual memory management gives me control—it doesn’t pause:: 

@end menu

@node What languages use garbage collection?,What’s the advantage of garbage collection?,,Common objections to garbage collection
@anchor{mmref/faq what-languages-use-garbage-collection}@anchor{17f2}
@subsection What languages use garbage collection?


@ref{167f,,Java}, @ref{17dc,,C#}, @ref{17df,,Python}, @ref{28a,,Lisp}, @ref{168e,,ML}, …
the list goes on. It surprises many to learn that many implementations
of @ref{17c0,,BASIC} use @ref{f,,garbage collection} to manage character
strings efficiently.

@ref{1d,,C++} is sometimes characterized as the last holdout against
garbage collection, but this is not accurate. See
@ref{17ed,,Can I use garbage collection in C++?}

The notion of @ref{9,,automatic memory management} has stood the test
of time and is becoming a standard part of modern programming
environments. Some will say “the right tool for the right job”,
rejecting automatic memory management in some cases; few today are
bold enough to suggest that there is never a place for garbage
collection among tools of the modern programmer—either as part of a
language or as an add-on component.

@node What’s the advantage of garbage collection?,Programs with GC are huge and bloated; GC isn’t suitable for small programs or systems,What languages use garbage collection?,Common objections to garbage collection
@anchor{mmref/faq what-s-the-advantage-of-garbage-collection}@anchor{17f3}
@subsection What’s the advantage of garbage collection?


@ref{f,,Garbage collection} frees you from having to keep track of
which part of your program is responsible for the deallocation of
which memory. This freedom from tedious and error-prone bookkeeping
allows you to concentrate on the problem you are trying to solve,
without introducing additional problems of implementation.

This is particularly important in large-scale or highly modular programs,
especially libraries, because the problems of manual memory management
often dominate interface complexity.  Additionally, garbage collection can reduce the amount of memory used because the interface problems of manual memory management are often solved by creating extra copies of data.

In terms of performance, garbage collection is often faster than manual memory management.  It can also improve performance indirectly, by increasing @ref{1601,,locality of reference} and hence reducing the size of the @ref{16ba,,working set}, and decreasing @ref{15e7,,paging}.

@ref{158b,,Zorn (1992)}.

@node Programs with GC are huge and bloated; GC isn’t suitable for small programs or systems,I can’t use GC because I can’t afford to have my program pause,What’s the advantage of garbage collection?,Common objections to garbage collection
@anchor{mmref/faq programs-with-gc-are-huge-and-bloated-gc-isn-t-suitable-for-small-programs-or-systems}@anchor{17f4}
@subsection Programs with GC are huge and bloated; GC isn’t suitable for small programs or systems


While it is true that the major advantages of @ref{f,,garbage collection} are only seen in complex systems, there is no reason for
garbage collection to introduce any significant overhead at any scale.
The data structures associated with garbage collection compare
favorably in size with those required for @ref{8,,manual memory management}.

Some older systems gave garbage collection a bad name in terms of
space or time overhead, but many modern techniques exist that make
such overheads a thing of the past. Additionally, some garbage
collectors are designed to work best in certain problem domains, such
as large programs; these may perform poorly outside their target
environment.

@ref{158b,,Zorn (1992)}.

@node I can’t use GC because I can’t afford to have my program pause,Isn’t it much cheaper to use reference counts rather than garbage collection?,Programs with GC are huge and bloated; GC isn’t suitable for small programs or systems,Common objections to garbage collection
@anchor{mmref/faq i-can-t-use-gc-because-i-can-t-afford-to-have-my-program-pause}@anchor{17f5}
@subsection I can’t use GC because I can’t afford to have my program pause


While early garbage collectors had to complete without interruption
and hence would pause observably, many techniques are now available to
ensure that modern collectors can be unobtrusive.


@subsubheading See also


@ref{d,,incremental garbage collection}, @ref{15ed,,parallel garbage collection}.


@node Isn’t it much cheaper to use reference counts rather than garbage collection?,Isn’t GC unreliable? I’ve heard that GCs often kill the program,I can’t use GC because I can’t afford to have my program pause,Common objections to garbage collection
@anchor{mmref/faq isn-t-it-much-cheaper-to-use-reference-counts-rather-than-garbage-collection}@anchor{17f6}
@subsection Isn’t it much cheaper to use reference counts rather than garbage collection?


No, updating @ref{15e0,,reference counts} is quite
expensive, and they have a couple of problems:


@itemize *

@item 
They can’t cope with @ref{1659,,cyclic data structures}; that is, sets
of objects that are referred to only by objects in that set, but
that don’t have a zero reference count.

@item 
Reference counting gets more expensive if you have to allow for the
count overflowing.
@end itemize

There are many systems that use reference counts, and avoid the
problems described above by using a conventional @ref{20,,garbage collector} to complement it. This is usually done for real-time
benefits. Unfortunately, experience shows that this is generally less
efficient than implementing a proper real-time garbage collector,
except in the case where most reference counts are one.

@ref{157f,,Wise (1993)}.

@node Isn’t GC unreliable? I’ve heard that GCs often kill the program,I’ve heard that GC uses twice as much memory,Isn’t it much cheaper to use reference counts rather than garbage collection?,Common objections to garbage collection
@anchor{mmref/faq isn-t-gc-unreliable-i-ve-heard-that-gcs-often-kill-the-program}@anchor{17f7}
@subsection Isn’t GC unreliable? I’ve heard that GCs often kill the program


@ref{20,,Garbage collectors} usually have to manipulate vulnerable data
structures and must often use poorly-documented, low-level interfaces.
Additionally, any garbage collection problems may not be detected
until some time later. These factors combine to make most garbage
collection bugs severe in effect, hard to reproduce, and difficult to
work around.

On the other hand, commercial garbage collection code will generally
be heavily tested and widely used, which implies it must be reliable.
It will be hard to match that reliability in a manual memory manager
written for one program, especially given that @ref{8,,manual memory management} doesn’t scale as well as the automatic variety.

In addition, bugs in the compiler or run-time (or application if the
language is as low-level as @ref{1c,,C}) can corrupt the heap in ways
that only the garbage collector will detect later. The collector is
blamed because it found the corruption. This is a classic case of
shooting the messenger.

@node I’ve heard that GC uses twice as much memory,Doesn’t garbage collection make programs slow?,Isn’t GC unreliable? I’ve heard that GCs often kill the program,Common objections to garbage collection
@anchor{mmref/faq i-ve-heard-that-gc-uses-twice-as-much-memory}@anchor{17f8}
@subsection I’ve heard that GC uses twice as much memory


This may be true of primitive collectors (like the @ref{1634,,two-space collector}), but this is not generally true of garbage collection. The
data structures used for garbage collection need be no larger than
those for @ref{8,,manual memory management}.

@node Doesn’t garbage collection make programs slow?,Manual memory management gives me control—it doesn’t pause,I’ve heard that GC uses twice as much memory,Common objections to garbage collection
@anchor{mmref/faq doesn-t-garbage-collection-make-programs-slow}@anchor{17f9}
@subsection Doesn’t garbage collection make programs slow?


No. @ref{158b,,Benjamin Zorn (1992)} found that:

@quotation

the CPU overhead of @ref{349,,conservative garbage collection} is
comparable to that of explicit storage management techniques. […]
Conservative garbage collection performs faster than some explicit
algorithms and slower than others, the relative performance being
largely dependent on the program.
@end quotation

Note also that the version of the conservative collector used in this
paper is now rather old and the collector has been much improved since
then.

@node Manual memory management gives me control—it doesn’t pause,,Doesn’t garbage collection make programs slow?,Common objections to garbage collection
@anchor{mmref/faq manual-memory-management-gives-me-control-it-doesn-t-pause}@anchor{17fa}
@subsection Manual memory management gives me control—it doesn’t pause


It is possible for @ref{8,,manual memory management} to pause for
considerable periods, either on @ref{15ca,,allocation} or
@ref{15d2,,deallocation}. It certainly gives no guarantees
about performance, in general.

With @ref{9,,automatic memory management}, such as @ref{f,,garbage collection}, modern techniques can give guarantees about interactive
pause times, and so on.


@subsubheading See also


@ref{d,,incremental garbage collection}, @ref{15ed,,parallel garbage collection}.


@node Miscellaneous,,Common objections to garbage collection,Frequently Asked Questions
@anchor{mmref/faq miscellaneous}@anchor{17fb}
@section Miscellaneous


@menu
* Why does my disk rattle so much?:: 
* Where can I find out more about garbage collection?:: 
* Where can I get a garbage collector?:: 
* Why does my program use so much memory?:: 
* I use a library@comma{} and my program grows every time I call it. Why?: I use a library and my program grows every time I call it Why?. 
* Should I write my own memory allocator to make my program fast?:: 
* Why can’t I just use local data on the stack or in global variables?:: 
* Why should I worry about virtual memory? Can’t I just use as much memory as I want?:: 

@end menu

@node Why does my disk rattle so much?,Where can I find out more about garbage collection?,,Miscellaneous
@anchor{mmref/faq why-does-my-disk-rattle-so-much}@anchor{17fc}
@subsection Why does my disk rattle so much?


When you are using a @ref{51,,virtual memory} system, the computer may
have to fetch @ref{92,,pages} of memory from disk before they can be
accessed. If the total @ref{16ba,,working set} of your active programs
exceeds the @ref{16b8,,physical memory (1)} available, @ref{15e7,,paging} will
happen continually, your disk will rattle, and performance will
degrade significantly. The only solutions are to install more physical
memory, run fewer programs at the same time, or tune the memory
requirements of your programs.

The problem is aggravated because virtual memory systems approximate
the theoretical working set with the set of pages on which the working
set lies. If the actual working set is spread out onto a large number
of pages, then the working page-set is large.

When objects that refer to each other are distant in memory, this is
known as poor @ref{1601,,locality of reference}. This happens either
because the program’s designer did not worry about this, or the memory
manager used in the program doesn’t permit the designer to do anything
about it.

Note that @ref{e3,,copying garbage collection} can dynamically organize
your data according to the program’s reference patterns and thus
mitigate this problem.


@subsubheading See also


@ref{16de,,thrash}


@ref{150f,,Denning (1968)}.

@node Where can I find out more about garbage collection?,Where can I get a garbage collector?,Why does my disk rattle so much?,Miscellaneous
@anchor{mmref/faq where-can-i-find-out-more-about-garbage-collection}@anchor{17fd}
@subsection Where can I find out more about garbage collection?


Many modern languages have @ref{f,,garbage collection} built in, and
the language documentation should give details. For some other
languages, garbage collection can be added, for example via the
Memory Pool System, or the Boehm–Demers–Weiser collector.


@subsubheading See also


@ref{f,,garbage collection}


@ref{1538,,Jones et al. (2012)}, @ref{1579,,Wilson (1994)}.

Memory Pool System@footnote{https://www.ravenbrook.com/project/mps/},
Boehm–Demers–Weiser collector@footnote{http://hboehm.info/gc/},
GC-LIST FAQ@footnote{http://iecc.com/gclist/GC-faq.html}.

@node Where can I get a garbage collector?,Why does my program use so much memory?,Where can I find out more about garbage collection?,Miscellaneous
@anchor{mmref/faq where-can-i-get-a-garbage-collector}@anchor{17fe}
@subsection Where can I get a garbage collector?


The Memory Pool System and the Boehm–Demers–Weiser collector are
suitable for C or C++. The best way to get a garbage collector,
however, is to program in a language that provides garbage collection
natively.


@subsubheading See also


@ref{f,,garbage collection}


Memory Pool System@footnote{https://www.ravenbrook.com/project/mps/},
Boehm–Demers–Weiser collector@footnote{http://hboehm.info/gc/}.

@node Why does my program use so much memory?,I use a library and my program grows every time I call it Why?,Where can I get a garbage collector?,Miscellaneous
@anchor{mmref/faq why-does-my-program-use-so-much-memory}@anchor{17ff}
@subsection Why does my program use so much memory?


If you are using @ref{8,,manual memory management} (for example,
@ref{1a,,malloc} and @ref{1b,,free (2)} in @ref{1c,,C}), it is likely that
your program is failing to free memory blocks after it stops using
them. When your code allocates memory on the heap, there is an implied
responsibility to free that memory. If a function uses heap memory for
returning data, you must decide who takes on that responsibility. Pay
special attention to the interfaces between functions and modules.
Remember to check what happens to allocated memory in the event of an
error or an exception.

If you are using @ref{9,,automatic memory management} (almost certainly
@ref{f,,garbage collection}), it is probable that your code is
remembering some blocks that it will never use in future. This is
known as the difference between @ref{78,,liveness} and
@ref{96,,reachability}. Consider clearing variables that
refer to large blocks or networks of blocks, when the data structure
is no longer required.

@node I use a library and my program grows every time I call it Why?,Should I write my own memory allocator to make my program fast?,Why does my program use so much memory?,Miscellaneous
@anchor{mmref/faq i-use-a-library-and-my-program-grows-every-time-i-call-it-why}@anchor{1800}
@subsection I use a library, and my program grows every time I call it. Why?


If you are using @ref{8,,manual memory management}, it is likely that
the library is allocating data structures on the heap every time it is
used, but that they are not being freed. Check the interface
documentation for the library; it may expect you to take some action
when you have finished with returned data. It may be necessary to
close down the library and re-initialize it to recover allocated
memory.

Unfortunately, it is all too possible that the library has a memory
management bug. In this case, unless you have the source code, there
is little you can do except report the problem to the supplier. It may
be possible to add a garbage collector to your language, and this
might solve your problems.

With a @ref{20,,garbage collector}, sometimes objects are retained
because there is a reference to them from some global data structure.
Although the library might not make any further use of the objects,
the collector must retain the objects because they are still
@ref{96,,reachable}.

If you know that a particular reference will never be used in future,
it can be worthwhile to overwrite it. This means that the collector
will not retain the referred object because of that reference. Other
references to the same object will keep it @ref{78,,alive}, so
your program doesn’t need to determine whether the object itself will
ever be accessed in future. This should be done judiciously, using the
garbage collector’s tools to find what objects are being retained and
why.

If your garbage collector is @ref{e,,generational}, it is possible that you are suffering from @ref{1703,,premature tenuring}, which can often be solved by tuning the collector or using a separate memory area for the library.

@node Should I write my own memory allocator to make my program fast?,Why can’t I just use local data on the stack or in global variables?,I use a library and my program grows every time I call it Why?,Miscellaneous
@anchor{mmref/faq should-i-write-my-own-memory-allocator-to-make-my-program-fast}@anchor{1801}
@subsection Should I write my own memory allocator to make my program fast?


If you are sure that your program is spending a large proportion of
its time in @ref{15dd,,memory management}, and you know what you’re doing,
then it is certainly possible to improve performance by writing a
@ref{16b2,,suballocator}. On the other hand, advances in memory management
technology make it hard to keep up with software written by experts.
In general, improvements to memory management don’t make as much
difference to performance as improvements to the program algorithms.

@ref{158b,,Benjamin Zorn (1992)} found that:

@quotation

In four of the programs investigated, the programmer felt
compelled to avoid using the general-purpose storage allocator by
writing type-specific allocation routines for the most common
object types in the program. […] The general conclusion […] is
that programmer optimizations in these programs were mostly
unnecessary. […] simply using a different algorithm
appears to improve the performance even more.
@end quotation

and concluded:

@quotation

programmers, instead of spending time writing domain-specific
storage allocators, should consider using other publicly-available
implementations of storage management algorithms if the one they
are using performs poorly.
@end quotation

@node Why can’t I just use local data on the stack or in global variables?,Why should I worry about virtual memory? Can’t I just use as much memory as I want?,Should I write my own memory allocator to make my program fast?,Miscellaneous
@anchor{mmref/faq why-can-t-i-just-use-local-data-on-the-stack-or-in-global-variables}@anchor{1802}
@subsection Why can’t I just use local data on the stack or in global variables?


Global, or static, data is fixed size; it cannot grow in response to
the size or complexity of the data set received by a program.
Stack-allocated data doesn’t exist once you leave the function (or
program block) in which it was declared.

If your program’s memory requirements are entirely predictable and
fixed at compile-time, or you can structure your program to rely on
stack data only while it exists, then you can entirely avoid using
heap allocation. Note that, with some compilers, use of large global
memory blocks can bloat the object file size.

It may often seem simpler to allocate a global block that seems
“probably large enough” for any plausible data set, but this
simplification will almost certainly cause trouble sooner or later.


@subsubheading See also


@ref{15e2,,stack allocation}, @ref{1653,,heap allocation}, @ref{1610,,static allocation}.


@node Why should I worry about virtual memory? Can’t I just use as much memory as I want?,,Why can’t I just use local data on the stack or in global variables?,Miscellaneous
@anchor{mmref/faq why-should-i-worry-about-virtual-memory-can-t-i-just-use-as-much-memory-as-i-want}@anchor{1803}
@subsection Why should I worry about virtual memory? Can’t I just use as much memory as I want?


While @ref{51,,virtual memory} can greatly increase your capacity to
store data, there are three problems typically experienced with it:


@itemize *

@item 
It does not provide an unlimited amount of memory. In particular,
all memory that you actually allocate (as opposed to reserve) has to
be stored somewhere. Usually you must have disk space available for
all pages containing allocated memory. In a few systems, you can
subtract the available physical memory from the disk space required.
If the memory contains images of program or data files, then
@ref{167e,,file mapping}, or assigning existing files to regions of the
virtual address space, can help considerably.

@item 
In most computers, there is a large difference in speed between main
memory and disk; running a program with a @ref{16ba,,working set} that
does not fit in physical memory almost always results in
unacceptable performance.

@item 
An additional problem with using unnecessary quantities of memory is
that poor @ref{1601,,locality of reference} can result in heavy paging.
@end itemize


@subsubheading See also


@ref{16de,,thrash}.


@node Copyright,Acknowledgements,Frequently Asked Questions,Top
@anchor{mmref-copyright doc}@anchor{1804}@anchor{mmref-copyright copyright}@anchor{1805}
@chapter Copyright


Copyright © 2001-2020 Ravenbrook Limited@footnote{https://www.ravenbrook.com/}.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:


@enumerate 

@item 
Redistributions of source code must retain the above copyright
notice, this list of conditions and the following disclaimer.

@item 
Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
@end enumerate

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
“AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

@node Acknowledgements,Index,Copyright,Top
@anchor{mmref/credit doc}@anchor{1806}@anchor{mmref/credit acknowledgements}@anchor{1807}@anchor{mmref/credit mmref-acknowledgements}@anchor{1808}
@chapter Acknowledgements


The Memory Management Reference is maintained by Ravenbrook Limited@footnote{http://ravenbrook.com/}.

Most of it was originally written by memory management experts in the
Adaptive Memory Management Group at Harlequin Limited@footnote{https://en.wikipedia.org/wiki/Harlequin_(software_company)}:


@itemize *

@item 
Nick Barnes

@item 
Richard Brooksby

@item 
David Jones

@item 
David Lovemore

@item 
Tony Mann

@item 
Gavin Matthews

@item 
Pekka P. Pirinen

@item 
Richard Tucker

@item 
P. T. Withington
@end itemize

Gavin Matthews was the original editor of the Memory Management
Reference.

The Adaptive Memory Management Group no longer exists, and Harlequin
has become a part of Global Graphics@footnote{http://www.globalgraphics.com/}. However, most of the group’s work
has been aquired by Ravenbrook Limited@footnote{http://ravenbrook.com/}, whose directors are Richard
Brooksby, the group’s chief architect and manager, and Nick Barnes, a
senior group member.

Particular thanks go to Richard Jones for his enormously useful book
@ref{1538,,The Garbage Collection Handbook}, and for his comments
on the Reference.

Many people have @ref{d8,,made valuable suggestions} for the
Reference and contributed glossary entries. We are grateful for the
help of:


@itemize *

@item 
Judy Anderson

@item 
Giuseppe Attardi

@item 
Daniel Barrett

@item 
Leah Bateman

@item 
Stephen Bevan

@item 
Hans Boehm

@item 
Hans Feldt

@item 
Lars Hansen

@item 
Anthony Hosking

@item 
Paul Jackson

@item 
Mark S. Johnstone

@item 
Richard Kistruck

@item 
Stavros Macrakis

@item 
Gareth McCaughan

@item 
David A. Moon

@item 
Eliot Moss

@item 
John S. Pieper

@item 
Kent Pitman

@item 
Andrew Shires

@item 
Walter Spector

@item 
Martin Simmons

@item 
David Stoutamire

@item 
Tom Thomson

@item 
Mark Tillotson

@item 
JonL White

@item 
David S. Wise

@item 
Benjamin Zorn
@end itemize


@itemize *

@item 
genindex
@end itemize

@node Index,,Acknowledgements,Top
@unnumbered Index


@printindex ge


@c %**end of body
@bye
